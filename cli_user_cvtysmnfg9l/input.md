The result of my research is in the next JSON list with the source URL and the content in each finding:

[{'url': 'https://barankovics.hu/2023-a-generativ-ai-eve-volt-mire-szamithatunk-2024-ben/', 'content': '2023-ban az mesterséges intelligencia (AI) meghatározó szerepet játszott a\nmindennapi életünkben. Az Egyesült Királyságban a tizenévesek többsége és\nAusztrália munkavállalóinak jelentős része generatív AI eszközöket használt.\nKezdetben az emberek kíváncsiságból vagy szórakozásból fordultak ezekhez az\neszközökhöz, de hamarosan tanulmányi, tanácsadási és információkeresési\ncélokra is alkalmazni kezdték őket. A generatív AI alkalmazása kiterjedt a\nkódolás, kép-, videó- és hangkészítés területére is. A prompt mérnökök\nsegítséget nyújtanak a legjobb AI promptok tervezésében, valamint abban,\nhogyan lehet kombinálni a különböző AI szolgáltatásokat. Az AI felhasználásai\nés funkciói az elmúlt évben jelentősen megváltoztak. Például a generatív AI-t\nfelhasználták fotóversenyeken való részvételre és iskolai vizsgák megírására.\nA ChatGPT chatbot, amelyet már széles körben ismernek, több mint 100 millió\nfelhasználót ért el februárban. A Google és a Microsoft is bevezette saját\nchatbotjait, Bardot és AI-t integrált Bing keresőjébe, míg a Snapchat a MyAI-t\nindította el. A GPT-4, a ChatGPT-t működtető AI legújabb verziója, márciusban\njelent meg új funkciókkal. Ebben az évben a Coca-Cola és a Levi’s is AI-t\nhasználtak reklámok készítésére. 2023 során az AI integrációja a termékekbe és\nszolgáltatásokba folytatódott, mint például az Amazon esetében. Az év folyamán\na jogi és társadalmi kérdések is előtérbe kerültek, például Japánban döntöttek\naz AI betanítására vonatkozó szerzői jogi korlátozások eltörléséről, míg az\nEgyesült Államokban a forgatókönyvírók AI által generált forgatókönyvek\nbetiltását követelték. A kutatások arra utalnak, hogy a következő évben és\nazon túl is folytatódni fog az AI fejlődése, különösen a szolgáltatások\nösszekapcsolásában, a generációk minőségének javításában, a transzparencia és\nmédia szabványok fejlesztésében, valamint a szuverén AI képességek\nbővítésében. Eredeti cikk Fordítás 2023. december 23. A honlapon található\nanyagok felhasználása a Creative Commons szabályai szerint lehetséges. A\nweboldalon a minőségi felhasználói élmény érdekében sütiket használunk.\nRészletek Ez a weboldal sütiket használ, hogy a lehető legjobb felhasználói\nélményt nyújthassuk. A cookie-k információit tárolnak a böngészőjében, és\nsegíti a csapatunkat abban, hogy megértsék, hogy a weboldal mely részei\nérdekesek és hasznosak. A feltétlenül szükséges sütiket mindig engedélyezni\nkell, hogy elmenthessük a beállításokat a sütik további kezeléséhez.\nAmennyiben ez a süti nem kerül engedélyezésre, akkor nem tudjuk elmenteni a\nkiválasztott beállításokat, ami azt eredményezi, hogy minden egyes látogatás\nalkalmával ismételten el kell végezni a sütik engedélyezésének műveletét. Ez a\nwebhely a Google Analytics-et használja anonim információk gyűjtésére, mint\npéldául az oldal látogatóinak száma és a legnépszerűbb oldalak statisztikája.\nA cookie engedélyezése lehetővé teszi, hogy javítsuk honlapunkat. A\nfeltétlenül szükséges sütiket mindenkor engedélyezni kell, hogy elmenthessük a\nbeállításokat a sütik további kezeléséhez.\n\n'}, {'url': 'https://ictglobal.hu/iparagi-megoldasok/2024-a-generativ-mi-eve/', 'content': '(Kiemelt kép: Unsplash+) A generatív mesterséges intelligencia iránti növekvő érdeklődést jól mutatják az e területre irányuló, gyorsan növekvő beruházások. Csak 2023-ban a kockázati tőkebefektetők több mint 20 milliárd dollárt fektettek a generatív MI startupokba, ami jól mutatja, hogy milyen hatalmas potenciált látnak ebben a technológiában. Ilyen jelentős támogatás mellett az elkövetkező években az innováció és a fejlesztés fellendülésére számíthatunk. A ChatGPT 2022 legvégén lépett színre, és 2023 az MI-termékek felfedezésének éveként indította el a 2023-as évet, amely a társalgási MI irányába mozdította el az ICT világot. A ChatGPt azzal kezdte, hogy generatív írási képességekkel bomlasztotta az olyan ágazatokat, mint az oktatás és az online újságírás, majd az évet azzal zárta, hogy a képességeit hangra és látásra is kiterjesztette, a testre szabott GPT-opciókkal együtt. 2023-ban a trend egyértelműen a chatbotok fejlesztése és a kiterjedt nagy nyelvi modellek által működtetett felhasználói élmények „kézműves” kialakítása felé mutatott. Ez volt az az év, amikor az LLM-botok a tisztán szövegalapú interakciókból egy sokoldalúbb, multimodális funkcionalitás felé fejlődtek. Az olyan LLM-ek, mint az Anthropic Claude-ja, a Meta Llama-ja, a Google PaLM-je és az Inflection AI kivívták a maguk sávját a versenyben, az Hugging Face pedig a modellek és a kísérletezés piactere lett. Egyesek a Hugging Face-t a GenAI Githubjaként is emlegetik. Ez volt az az év, amikor a Big Tech átvette az irányítást és megalapozta az új irányelveket. A Microsoft és a Google integrálta az LLM-eket a keresésbe és a vállalati megoldásokba, míg az Amazon a modell-mint-egy-szolgáltatás megközelítés bajnoka lett. A Meta más utat választott, és a nyílt forráskódú mesterséges intelligencia mozgalom fáklyáját vitte. Ha nem hiszi, hogy a Big Tech irányítja a show-t, gondoljon arra, hogy az OpenAI valószínűleg ma nem létezne, ha Satya Nadella és a Microsoft nem lépett volna közbe. Mindezek mögött természetesen az Nvidia áll, mely kihasználja a nagy teljesítményű GPU-számítógépek iránti kereslet növekedését. Ez volt az az év, amikor a mesterséges intelligencia biztonsága valódi aggodalomként kezdett felszínre kerülni. A kormányok elkezdték a mesterséges intelligenciára vonatkozó irányelveket és végrehajtási rendeleteket, a szerzői jogi igények miatt perek indultak, és a „hatékony altruizmus” immár mindenki szótárában szerepel. Az AGI lett az új divat. A generatív mesterséges intelligencia GPT-4 nevű agya olyan, mint egy szuperokos motor. Hatalmas mennyiségű információn, több mint egybillió paraméterrel képzett. Gondoljunk a paraméterekre úgy, mint az építőelemekre, melyek segítenek megérteni és létrehozni dolgokat. A nagyobb méret több okosságot jelent! A GPT-5 várakozása: Képzeljük el a GPT-4-et a város legújabb szuperhősének, de a pletykák szerint hamarosan érkezik a GPT-5 is már. Az izgalom a még okosabbá és még nagyobb képességűvé tétel körül forog. Mintha a következő nagy frissítést várnánk, mely új magasságokba emelheti a generatív mesterséges intelligenciát. Most gondoljunk a szavakon túl. Ezek a modellek megtanulnak többféleképpen is megérteni és beszélni: például képeket, hangokat és egyebeket kezelni. Már nem csak a szavakról van szó; arról van szó, hogy a kommunikációban mindenre képesnek kell lenni. OpenAI és Meta-tól: Az OpenAI ChatGPT-je frissítést kap, vagyis hamarosan képekről fog csevegni, és még hangparancsokat is elfogad. A Meta is foglalkozik ezzel, és olyan modelleket hoz létre, melyek képekkel, szöveggel, hanggal és mással is foglalkoznak. Mintha a mesterséges intelligencia barátaink egyre sokoldalúbbak lennének, és mindenféle dolgot megértenének, mint mi! Eszközök és platformok: Gondoljuk úgy a Generatív MI-ra, mint egy varázslatos asszisztensre a tervezők számára. Segít nekik klassz dolgokat létrehozni, ha csak megmondják neki, hogy mire van szükségük. Az olyan platformok, mint az Autodesk, megkönnyítik ezt: a tervezők megadják a követelményeket, és máris megjelennek a tervrajzok és a tervek. Gyors prototípusgyártás és tesztelés: Nincs többé várakozás a prototípusokra! A generatív tervezéssel olyan, mintha egy csomó virtuális prototípus állna készen a tesztelésre. Ez a gyorsaság segít a tervezőknek abban, hogy erősebb, jobb és környezetbarátabb termékeket készítsenek. Generatív videó a megfizethető tartalomkészítéshez A videógyártás demokratizálása: Képzeljük el, hogy videókat készítünk anélkül, hogy hatalmas költségekbe vernénk magunkat! A generatív videóeszközök megváltoztatják az iparágat. Korábban a videók készítése drága volt, de most már bárki készíthet profi kinézetű videókat anélkül, hogy megkopasztaná a pénztárcáját. Hatás a médiafogyasztásra: Mivel a videók mindenki kedvencei, ezek az eszközök olyanok, mint egy ajándék. Ez több videót, több történetet és több szórakozást jelent. Ez nem csak a profiknak szól, mostantól már bárki lehet videókészítő. Generatív hang- és beszédfejlesztés Az emberi beszéd szimulációjának fejlődése: A mesterséges intelligencia beszéde átalakul. Korábban robothangzása volt, most viszont megtanul úgy beszélni, mint az emberek. A cél az, hogy a mesterséges intelligencia hangja ugyanolyan meleg és természetes legyen, mintha egy barátunkkal beszélgetnénk. Bővülő alkalmazások 2024-ben: Készüljünk fel a mesterséges intelligencia hangokra mindenhol! 2024-ben már nem csak szöveget fognak felolvasni, hanem a kedvenc podcastjainkat, hangoskönyveinket és még sok minden más részévé válnak. Mintha mindenhez lenne egy hasznos hangalapú társunk. Fejlődés a chatbot-szerű ügynökökön túl: Lépjetek tovább, chatbotok! Az autonóm generatív mesterséges intelligencia olyan, mint a következő generációs segítő. Nem csak parancsra vár, hanem magától kitalálja a dolgokat. Az AutoGPT egy jó példa erre: lépésről lépésre történő utasítások nélkül végzi el a feladatokat. AutoGPT és az általánosított mesterséges intelligencia fejlődése: Az AutoGPT megnyitja az utat az olyan mesterséges intelligencia előtt, mely bármilyen feladatot képes elvégezni. Olyan, mintha lenne egy szuperokos asszisztensünk, aki nem csak egy dologban jó, hanem egy csomó különböző feladatot is el tud végezni. Ez a függetlenebb és sokoldalúbb mesterséges intelligencia jövője. Az „MI suttogó” iránti kereslet: Hallottak már az MI-suttogókról? Ez olyan foglalkozás, ahol tudják a generatív MI varázsszavait. A Prompt Mérnökök azok a „varázslók”, akik speciális nyelvezetet használnak, hogy a lehető legtöbbet hozzák ki az MI rendszerekből. 2024-ben az ő munkájuk különösen fontos lehet: mindenki azt akarja tőlük, hogy az MI elképesztő dolgokra késztesse őket. Generatív MI-rendszerek kialakítása: A súgómérnökök olyanok, mint a mesterséges intelligencia építészmérnökei. Ők építik az utasításokat, melyek segítségével a mesterséges intelligencia hihetetlen dolgokat hoz létre. Az ő szakértelmük abban rejlik, hogy a megfelelő módon beszéljenek az MI-rendszerekhez, hogy azok „ragyogni” tudjanak. Olyan, mintha náluk lenne a titkos kód a mesterséges intelligencia teljes potenciáljának felszabadításához. Integráció a vállalati alkalmazásokba: Képzeljük el, hogy kedvenc alkalmazásaink még menőbbek lesznek! 2024-ben számos, nagyvállalatoknál használt alkalmazásnak lesz egy új „barátja”, a generatív MI. A Microsoft, az Adobe és még a Snapchat is együttműködik az MI-val, hogy szuperokossá tegyék alkalmazásaikat. Olyan, mintha egy segítőkész mesterséges intelligenciával rendelkező „barátot” építettek volna be a mindennap használt alkalmazásokba. Microsoft, Adobe és Snapchat: A Microsoft és az Adobe versenyben vannak, hogy MI-t építsenek be az alkalmazásaikba. Képzeljük el, hogy a Word vagy a Photoshop még okosabb lesz, és megérti, mire van szükségünk. A Snapchat is felugrott az MI-vonatra, és egy virtuális barátot adott nekünk, akit a generatív MI hajt. Olyan, mintha az alkalmazásai zseniális frissítést kapnának. Az MI fejlődése a tanulási környezetekben: Az iskolák látványos technológiai átalakulást kapnak! A generatív MI lesz az új tanulótárs. A tanároknak és a diákoknak mostantól mesterséges intelligencia segít a jegyzetelésben, a leckekönyvek elkészítésében és egyebekben. Olyan, mintha egy intelligens asszisztens lenne az osztályteremben, ami szórakoztatóvá és hatékonnyá teszi a tanulást. Viták és elfogadás az iskolákban: Ahogyan a múltban a számológépek felrázták az osztálytermeket, a generatív mesterséges intelligencia is vitákat vált ki. Egyesek attól tartanak, hogy a diákok túlságosan is a mesterséges intelligenciára hagyatkozhatnak. De nem a készségek helyettesítéséről van szó, hanem azok fokozásáról. 2024-ben az iskolák azt találják ki, hogyan használhatják a lehető legjobban az MI-t. Ez egy technológiai forradalom az oktatásban! Folyamatos fejlesztések a természetes nyelvi generálás terén: A GPT-3.5 folyamatos fejlesztéseken megy keresztül a természetes nyelvi generálás terén. Ez magában foglalja a nyelvi kimenet finomítását továbbfejlesztett képzési adathalmazok, finomhangolási módszerek, a modell mélységének növelése és a paraméterek árnyalt kontextuális megértést szolgáló hangolása révén. Várható fejlesztések 2024-ben: A jövőbeli iterációk célja a fokozott kontextustudatosság és az előítéletek csökkentése. A hangsúly a terület-specifikus finomhangoláson van, hogy pontosabb és személyre szabottabb válaszokat lehessen elérni. A fejlett figyelemmechanizmusok integrálása prioritást élvez a hosszú kontextusmegértés javítása érdekében. Továbbfejlesztések a valósághű képgeneráláshoz: A generatív adverzális hálózatok (GAN-ok) a valósághűbb és részletesebb képszintézis érdekében fejlődnek. Ez magában foglalja a progresszív GAN-képzési módszerek alkalmazását a nagy felbontású képgeneráláshoz és az önfelügyelt tanulás beépítését a modell robusztusságának növelése érdekében. Sokoldalúság és alkalmazások különböző területeken: A GAN-alkalmazások a képeken túl olyan különböző területekre is kiterjednek, mint a „szövegből képbe” szintézis. A folyamatban lévő kutatások olyan kihívásokkal foglalkoznak, mint a módus-összeomlás és a képzés instabilitása. Továbbfejlesztett GAN-architektúrákat dolgoznak ki a különböző feladatkörökhöz való hatékony alkalmazkodás érdekében. Egészségügy és személyre szabott kezelési tervek: A kórházakban és klinikákon a generatív mesterséges intelligencia olyan, mint egy virtuális orvosművész. Szintetikus orvosi képeket hoz létre a gépek betanításához, segítve az orvosokat a betegségek jobb megértésében. De itt a varázslat nem áll meg itt. A generatív mesterséges intelligencia személyre szabott kezelési terveket készít, az orvosi megközelítéseket minden egyes egyedi betegre szabva. Olyan ez, mintha egy orvosi varázsló lenne az egészségügyben, aki minden egyes ember számára megrajzolja a jólét képét. Kreatív iparágak és művészi kifejezésmód: A művészek, zenészek és tervezők számára a generatív mesterséges intelligencia az új múzsa. Képzeljünk el egy olyan mesterséges intelligencia eszközt, mint a DALL-E, mely néhány bemenetből művészeti alkotásokat készít. Nem csak képekről van szó: a generatív mesterséges intelligencia zenét komponál, innovatív szerkezeteket tervez, és az emberi kreativitás határait feszegeti. A kreatív iparágak vászna egyre szélesedik, és az emberi találékonyság keveredik a mesterséges intelligencia által vezérelt innovációval. Olyan ez, mintha lenne egy láthatatlan munkatársunk, aki különböző területeken szikrázó művészi zsenialitást vált ki. E-kereskedelem és fokozott személyre szabás: Generatív MI lesz a személyre szabott vásárlási asszisztensünk. Nem csak termékeket javasol; átalakítja a teljes vásárlási élményt. A személyre szabott ajánlásoktól az egyéni preferenciákon alapuló egyedi terméktervezésig a generatív MI javítja a böngészéstől a vásárlásig tartó utat. Képzeljünk el egy virtuális idegenvezetőt, aki az online vásárlást „butikélményként” éli meg. Olyan, mintha lenne egy személyes vásárlónk, aki ismeri a mi stílusunkat, preferenciáinkat és vágyainkat. Nyelvi fordítás és többnyelvű kommunikáció: A nyelvi korlátokat áttörve a generatív mesterséges intelligencia lesz a globális kommunikátor. A fejlett nyelvi modellek a valós idejű fordítást zökkenőmentes beszélgetéssé alakítják. A többnyelvű interakciók megkönnyítésétől kezdve a globális kapcsolatok könnyebbé tételéig a Generative MI a nyelvek közötti híd lesz. Olyan, mint egy nyelvmester, aki biztosítja, hogy mindenki ugyanazt a digitális dialektust beszélje, és elősegíti a kapcsolatokat a különböző nyelvi tájakon. A generatív mesterséges intelligencia nem csupán egy technológiai trend; ez egy olyan átalakító erő, mely életünk minden területét érinti. Az egészségügyi precizitástól kezdve a művészeti innováción át a személyre szabott digitális élményekig, a hatás mélyreható. A GPT-4 fejlődése, a sokoldalú GAN-ok és a prompt mérnökök felemelkedése a technológiai határokat jelöli. A generatív mesterséges intelligencia a mindennapi rutinunk zökkenőmentes részévé fog válni, egyszerűsítve a feladatokat, beindítva a kreativitást, és kitolva a lehetséges határokat. A vállalkozások és a szakemberek számára az üzenet egyértelmű: fogadják be a generatív hullámot. A mesterséges intelligencia vállalati alkalmazásokba való integrálásától kezdve az oktatás újradefiniálásáig az MI-alapú tanulási eszközökkel, a lehetőségek óriásiak. Az etikai megfontolásokról szóló elrettentő példák arra emlékeztetnek minket, hogy óvatosan kell eljárnunk, biztosítva az MI felelős használatát. Az előttünk álló út nem csupán a változásokhoz való alkalmazkodást jelenti, hanem a narratíva aktív alakítását is. A generatív mesterséges intelligencia nem a távoli jövő, hanem már kopogtat a digitális ajtónkon. Ez egy felhívás a cselekvésre, innovációra, együttműködésre és az MI-augmentáció korszakának üdvözlésére szolgál. Miért kell a 2024 stratégiai tervezésének a generatív mesterséges intelligenciát felölelnie? Ahogy a mesterséges intelligencia (különösen a generatív mesterséges intelligencia átalakító ereje 2023-ban) pályáján gondolkodunk, egyértelmű, hogy az elmúlt év nem volt más, mint egy reveláció. Nemcsak a technológiai fejlődésről szólt, hanem az üzleti stratégiák végrehajtásának természetében bekövetkezett változásról is. A különböző méretű szervezetek a GenMI-t nem egyszerűen eszközként, hanem stratégiai partnerként kezdték kezelni. A GenMI már nem csupán a feladatok automatizálására szolgáló eszköz, hanem a stratégiai tervezési folyamatok szerves részévé vált, olyan mélységű elemzést és betekintést nyújtva, mely korábban elérhetetlen volt. Megkönnyítette a piaci dinamika, a fogyasztói magatartás és a működési hatékonyság árnyaltabb megértését, segítve a vállalkozásokat abban, hogy az egyre összetettebbé váló környezetben agilisan és előrelátóan navigáljanak. Ahogy közeledünk 2024-hez, a kérdés nem az, hogy elfogadjuk-e a GenMI-t, hanem az, hogy hogyan és hova integráljuk stratégiailag. Az üzleti élet gyorsan fejlődik, és szilárd meggyőződésünk, hogy az élen maradáshoz az MI-ismereteknek kell minden előremutató stratégia középpontjában állniuk. Ez az átmenet a reaktív alkalmazkodásról a proaktív innovációra. Számos tárgyalóteremben és vállalati értekezleten tárgyalták, vitatták és mérlegeltek az „MI”-t. Az ilyen beszélgetések egyértelművé tették, hogy a testre szabott megvalósításokról és kísérletezésekről feltétlenül át kell térni az „MI-az-első” megközelítésre. A felsővezetőkkel folytatott beszélgetések során egy kulcsfontosságú különbséget hangsúlyozunk: Az Ön szervezete az alapozó ?I-kutatásokra szorítkozik, vagy mélyen elkötelezett az MI teljes potenciáljának kiaknázása mellett? A különbség mélyreható, és meghatározhatja egy vállalat jövőbeli életképességét és pályáját. Ahogy lépünk a 2024-es év felé, az MI integrálása a stratégiai tervezésbe alapvető fontosságúvá válik a döntéshozatali folyamatok javítása és felgyorsítása érdekében. Ezzel párhuzamosan, azáltal, hogy az MI-t a stratégiai tervezésen keresztül irányítjuk, megerősítjük beruházásainkat, megduplázzuk az átalakító potenciált, és biztosítjuk, hogy ne csak részesei legyünk a jövőnek, hanem alakítói is. A vezető vállalatok igazgatótanácsaiban a döntések gyakran a befolyásos vezetői vélemények és a nyers adatok között ingadoznak. A kihívás? Annak biztosítása, hogy a befolyásos vélemények ne szorítsák háttérbe az adatvezérelt meglátásokat. A megoldás? Lépjen be a mesterséges intelligencia. A mesterséges intelligencia felbecsülhetetlen értékű tanácsadóként szolgál, gyorsan és pontosan elemzi a korábbi alapelosztásokat. Igazi erőssége az objektivitásában rejlik, mely eltávolítja az előítéleteket, és világos, adatközpontú képet ad a múltbeli döntésekről. Ez a gyors és elfogulatlan elemzés versenyelőnyhöz juttatja a vállalkozásokat, lehetővé téve számukra, hogy a jövőbeli befektetéseket pontossággal és lendülettel előre jelezzék. Bár a vezetői befolyásnak megvannak az érdemei (különösen a szervezeti kultúra és a jövőkép alakításában), az adatok hiányában kizárólag az emberi inputokra és tapasztalatokra való hagyatkozás elferdítheti a stratégiai irányt. A mesterséges intelligencia kiegyensúlyozza ezt az egyenletet, biztosítva, hogy az adatok ne szoruljanak háttérbe, hanem egyenrangú partnerként álljanak a befolyás mellett. A stratégiai tervezés területén a generatív MI változást hozó tényezővé válik, mely ügyesen navigál és optimalizál bizonyos folyamatokat, melyek átalakító üzleti eredményeket hoznak. Nagy sikert érhetünk el a generatív MI bevonásával a következő elemzési tevékenységekbe. Trend-előrejelzés: A mesterséges intelligencia felhasználása a piaci változások előrejelzésére, a kezdeti tervezési fázis tájékoztatására, melyben a vállalkozások meghatározzák a következő évre vonatkozó stratégiai irányt. Forgatókönyvek modellezése: A mesterséges intelligencia alkalmazása különféle üzleti forgatókönyvek létrehozására a tervezési szakaszban, ami lehetővé teszi a rugalmas költségvetési és működési tervek kidolgozását. Innovációs ötletelés: A mesterséges intelligencia felhasználása ötletelésre az ötletelési fázisban, biztosítva az innovatív stratégiai megoldások költségvetési tervezését és rangsorolását. Kockázatértékelés: A mesterséges intelligencia felhasználása a tervezés kockázatértékelési szakaszában biztosítja, hogy a lehetséges buktatókat a költségvetésben figyelembe vegyék, és lehetővé teszi a stratégiai tartalékalapok létrehozását. Erőforrás-elosztás: A mesterséges intelligencia alkalmazása a költségvetés elosztási szakaszában, ami javaslatot tesz a pénzeszközök optimális elosztására a stratégiai és operatív kezdeményezések között. Döntéselemzés: A mesterséges intelligencia meglátásainak integrálása a döntéshozatal során, mely egyértelműséget nyújt a költségvetés véglegesítésekor, és biztosítja a stratégiai beruházások legjobb megtérülését. Működési hatékonyság: A mesterséges intelligencia hasznosítása a stratégiák finomítására a működési tervezési szakaszban, a véglegesített éves költségvetés maximális hatékonyságának és költséghatékonyságának biztosítása. A vállalatokkal folytatott kiterjedt megbízatásaink során egy közhely bukkant fel: Az Ön MI-stratégiája alapvetően elválaszthatatlan az átfogó üzleti stratégiájától. Ez nem egyszerű kiegészítő, hanem szerves része annak. A 2024-es év felé haladva a vállalatoknak ezt az igazságot kell magukévá tenniük, hogy megvalósíthassák az MI-gyorsítással kapcsolatos üzleti céljaikat. Most kiemelkedően fontos, hogy az MI-képességeket közvetlenül a műveletek és stratégiák magjába építsék be, kezdve az éves stratégiai tervvel. Ez nem a növekedés hagyományos mechanizmusainak felváltásáról szól (a technológia más formáin, az emberi tehetségen vagy az újragondolt folyamatokon keresztül), hanem az MI kihasználásáról, hogy felerősítse a potenciált mindezen területeken. A döntéshozók számára egyértelmű a kérdés: megengedik-e, hogy az MI csupán kiegészítse vagy újradefiniálja stratégiai horizontjukat? Miközben régóta határozottan kiállunk az MI átalakító ereje mellett, tisztában vagyunk a még feltárásra váró területekkel is. Olyan szakaszban vagyunk, amikor az MI képességei kiterjedtek, de egyes aspektusok még mindig ködösek. Ezt felismerve úttörő szerepet játszottunk egy innovatív megközelítésben, amely feltárja az MI-ba történő befektetések valódi kockázatait, biztosítva, hogy a szervezetek magabiztosan és tisztán tudják kihasználni az előnyeit, miközben stratégiákat dolgoznak ki a jelenlegi hiányosságok leküzdésére. A GenMI képességeinek kiterjedt (de néha megfoghatatlan) jellegére való tekintettel kulcsfontosságú, hogy egyensúlyt teremtsen a stratégiai befektetésekben. Valójában azt javasoljuk, hogy az ilyen beruházások jelentős részét az alapvető képességek fejlesztésére fordítsák, ahol az MI előnyei kézzelfoghatóak és biztosak abban, hogy azonnali gyorsulást és javulást biztosítanak. Az alapvető kompetenciáknak ez az alapköve biztosítja az Ön jelenlegi stratégiai céljainak szilárd alapját. Miközben energiáinkat az alapvető stratégiai beruházásokra fordítjuk, a jövő olyan lehetőségeket tartogat, amelyek periférikusnak vagy spekulatívnak tűnhetnek. Itt jön a képbe a „jövőbiztosítás”: diverzifikáljon azáltal, hogy olyan innovatív mesterséges intelligencia-lehetőségekre is elkülönít forrásokat, melyek átformálhatják az iparágakat, vagy teljesen új értékteremtő utakat hozhatnak létre. Ezek a befektetések nem csak a megtérülésről szólnak; ezek a tanulási és fejlődési folyamatok tégelyei, melyek elengedhetetlenek az innováció ösztönzéséhez a következő stratégiai ciklusokban. Azáltal, hogy átgondoltan osztja el a pénzeszközöket a bevált és a kísérleti alapok között, biztosítja a jelen céljait, és a szervezetet a holnap áttöréseinek élvonalába helyezi. Tekintsük ezt a pillanatot alkalmasnak, ha a stratégiai tervezési folyamat elindításának küszöbén állunk. Kezdje az „MI-az-első” szemlélettel. Mielőtt mélyen belemerülnénk a hagyományos módszerekbe, ismerkedjünk meg önmagunk és csapatunk MI-képességeivel. Vegyük fel a kapcsolatot MI-szakértőkkel, és fontoljuk meg a személyre szabott workshopokat annak megértése érdekében, hogy az MI és a generatív MI hogyan szolgálhatja legjobban a mi konkrét iparágunkat és üzleti modellünket. Azzal, hogy az MI-t a kezdetektől fogva az élvonalban kezdjük használni, biztosítja, hogy a stratégia minden aspektusába zökkenőmentesen beépüljön ahelyett, hogy később utólag építenénk be. A jelenleg a stratégiai tervezési folyamatba merülő vezetők számára még nem késő kihasználni az MI erejét. Ismerjük fel stratégiánknak azon területeit, melyek profitálhatnak az adatvezérelt meglátásokból vagy az automatizálásból, és keressük a módját annak, hogy az MI-képességeket beépítsük ezekbe a szegmensekbe. Az együttműködés itt kulcsfontosságú: vonjunk be MI-specialistákat a stratégiai csapatok mellé, hogy biztosítsuk a zökkenőmentes integrációt és a már folyamatban lévő tervezés javítását. Ez egy olyan fordulat, mely drámaian felerősítheti stratégia eredményeinek hatékonyságát. Azok számára, akik már túl vannak a tervezési fázison, és most már a végrehajtásban vannak az üzleti egységeikkel, az MI még mindig a szövetségesük lehet. Lehet, hogy már megvan a stratégia, de a végrehajtást hatékonyabbá, érzékenyebbé és agilisabbá lehet tenni az MI bevonásával. Vegyük igénybe az MI-tanácsadók segítségét, hogy azonosítsák a végrehajtási terv azon területeit, melyeket optimalizálni lehet. Legyen szó prediktív analitikáról az eredmények jobb előrejelzéséhez, automatizálásról a folyamatok felgyorsításához, vagy MI-alapú eszközökről az érdekelt felek bevonásának és a visszajelzési körök javításához, a technológia hatékony kiegészítője lehet a stratégiai elképzelés megvalósításának biztosításához. A stratégiai tervezés minden szakaszában a mesterséges intelligencia bevonása nem csupán ajánlás, hanem versenyszükséglet. Függetlenül attól, hogy jelenleg hol állunk, a jövő tagadhatatlanul összefonódik az MI-val, és annak mai felkarolása a vezetők és szervezeteik számára a holnap megkülönböztető tényezője lehet. © ICT Global magazin 2024 | Minden jog fenntartva! Iratkozz fel a hírlevelünkre, hogy ne maradj le az IT legfontosabb híreiről!\n\n'}, {'url': 'https://szakcikkadatbazis.hu/doc/1695773', 'content': 'Fizessen elő a Gazdaság és Jogra! A tanulmány a mesterséges intelligenciáról\nszóló törvény (AIA) legfontosabb jellemzőit és következményeit tárgyalja az\neurópai termékbiztonsági szabályozás összefüggésében. E tekintetben kiemeli a\ntermékbiztonságra vonatkozó olyan közös jellemzőket, mint a kockázatalapú\nmegközelítés, a megfelelőségértékelés, az incidensek jelentése és a\nszabványokra vonatkozó vélelmek. Az AIA a nagy kockázatú mesterséges\nintelligenciára összpontosít, elismerve, hogy a kockázatokat nem tudja\nteljesen kiküszöbölni. The text discusses the key features and implications of\nthe Artificial Intelligence Act (AIA) in the context of European product\nsafety regulation. It emphasizes the risk-based approach, compliance\nassessment, incident reporting, and presumptions about standards as integral\nparts of the regulation. The focus of the AIA is on high-risk AI, with an\nemphasis on ensuring safe use through registration requirements and compliance\nprocedures. The AIA aims to ensure that high-risk AI systems comply with\nsecurity and fundamental rights requirements, acknowledging that it cannot\ncompletely eliminate risks. Termékbiztonság-szabályozás ennyire még nem került\naz érdeklődés középpontjába, mint az Európai Unió Mesterséges Intelligencia\nTörvénye, rövidebb elnevezéssel élve AIA, pedig termékbiztonság-szabályozás\n1992 óta létezik az EU-ban.[1] Ehhez nyilván szükség volt egy olyan\ntechnológiára, mint a mesterséges intelligencia - MI -, és azon belül is a\ngeneratív modellekre, amelyek jelentősége az Internet megjelenéséhez mérhető.\nAz Európai Bizottság - Bizottság - 2021 áprilisában nyújtotta be\nrendeletjavaslatát[2] a mesterséges intelligenciára vonatkozó harmonizált\nszabályok megállapításáról. Ezt megelőzte egy Fehér Könyv.[3] 2023. december\n8-án az Európai Parlament és a Tanács politikai megállapodásra jutott az\nEurópai Unió mesterséges intelligenciáról szóló törvényéről.[4] Jelen\ntanulmány az Európai Parlament által 2024. március 13-án jóváhagyott legutóbbi\nszövegváltozatra épül.[5] A terjedelmi keretek nem teszik lehetővé a többszáz\noldalas jogszabályszöveg részletes ismertetését, ezért a tanulmány a\nlegfontosabb, a szabályozás mozgatórugóját adó koncepcionális tárgyköröket\nmutatja be. A jog technológiai fejlődéssel kapcsolatos kettős alapállása az\nAIA-ban is megjelenik, amely szerint a jog célja, hogy elősegítse az\nemberközpontú és megbízható mesterséges intelligencia elterjedését, támogatva\naz innovációt, egyúttal biztosítva az egészség, a biztonság és az alapvető\njogok magas szintű védelmét, beleértve a demokráciát, a jogállamiságot és a\nkáros környezeti hatásokat.[6] Ennek jegyében az AIA arányos, az általános\nadatvédelmi rendelet - GDPR - megalkotása során is alkalmazotthoz hasonló\nkockázatalapú megközelítést követ.[7] A kockázat a kár bekövetkezésének\nvalószínűsége és a kár súlyossága kombinációja.[8] A kockázat akkor\nelfogadható, tolerálható, ha a jelen társadalmának értékítélete alapján annak\nminősül.[9] A biztonság szabályozása tehát nem jelenti a kockázatok teljes\nkiküszöbölését - ez lehetetlen is lenne -, hanem a kockázatok társadalmilag\nelfogadható szintre csökkentését; lásd légiközlekedés vagy nukleáris\nbiztonság. A biztonság az olyan technológiák esetében, mint az MI,\nkulcsfontosságú a technológia elterjedéséhez szükséges bizalom kialakítása\nérdekében. A Bizottság Fehér Könyve számos előnyét azonosítja az MI-nek,[10]\nde annak érdekében, hogy ezek előálljanak, keretek, mert azok alááshatják a\nbizalmat.[11] A biztonsági szabályok végrehajtása piacfelügyeleti szabályok\nalkalmazásával történik,[12] amelyek a nem szabályszerű termékek\nforgalmazásának leállításával vagy szabályszerűvé tételével biztosítják a\nfogyasztóvédelmet.[13] A biztonságot és az alapvető jogok védelmét biztosító\nAIA csökkenteni fogja a kockázatokat, de nem szünteti meg teljes\nmértékben.[14] A biztonsági előírások ellenére bekövetkezett kár esetére a\ntermékfelelősség szabályai lesznek alkalmazandók.[15] A termékbiztonság és a\ntermékfelelősség ezért kiegészítő mechanizmusok. Az AIA a kockázatalapú\nmegközelítést alkalmazva az MI-rendszereket a bennük megtestesülő kockázat\nmérlegelése alapján négy csoportba sorolja. Az első csoportba az\nelfogadhatatlan kockázattal, a második csoportba a nagy vagy magas\nkockázattal, a harmadik csoportba a korlátozott kockázattal, míg a negyedik\ncsoportba a minimális kockázattal járó MI-rendszerek tartoznak.[16] Ez utóbbi\nMI-rendszerek szolgáltatóit - például videójátékokban, spam-szűrőkben\nalkalmazott MI - ösztönözni kell olyan magatartási kódexek létrehozására,\namelyek elősegítik a nagy kockázatú MI-rendszerekre vonatkozó - 3/4 - kötelező\nkövetelmények önkéntes alkalmazását, mint például környezeti fenntarthatóság,\na fogyatékossággal élő személyek számára biztosított akadálymentesség.[17] Az\náltalános célú MI - GPAI - jelentősége okán egyfajta szektorális kiemelést\nkapott az AIA-ban, ezért fenti horizontális kockázat alapú megközelítés a GPAI\nszabályozásában leképeződik, amikor megkülönbözteti az általános és a\nrendszerkockázattal járó GPAI-kra meghatározott szabályozási elvárásokat. A\nnagyobb szabályozási teher az igazán tőkeerős GPAI-ra fog vonatkozni\n(lényegében jelenleg a ChatGPT-re). Ez a kérdés az AIA véglegesítésekor\nkifejezetten felmerült, amikor Franciaország és Németország azt próbálta\nelérni, hogy a GPAI-ra legfeljebb kötelező önszabályozás körébe tartozó\nszabályok vonatkozzanak, hogy ne kösse meg túlságosan az európai start-up-ok\nkezét.[18] A csoportosításnak kiemelkedő jelentősége van, ez képezi ugyanis a\nszabályozás alapját. Az arányosság elvének érvényesülése, elkerülése érdekében\naz AIA az egyes csoportokhoz eltérő szabályozási rezsimeket rendel.[19] Minél\nnagyobb kockázatot jelent egy MI-rendszer a személyek testi, lelki egészségére\nvagy az alapvető jogaikra, annál szigorúbb szabályozás vonatkozik az adott\nrendszerre.[20] Az MI-rendszer egy olyan gépi alapú rendszer, amelyet úgy\nterveztek, hogy különböző szintű autonómiával működjön, és amely a telepítés\nután alkalmazkodóképességet mutathat, továbbá explicit vagy implicit célok\nesetén a kapott bemenetből arra következtet, hogy hogyan kell olyan\nkimeneteket generálni, mint például az előrejelzések, tartalmak, ajánlások\nvagy döntések, amelyek befolyásolhatják a fizikai vagy virtuális\nkörnyezetet.[21] Az AIA összhangba hozza az MI-rendszer meghatározását a\nnemzetközi definíciókkal, nevezetesen az OECD-ével,[22] hangsúlyozva azt a\nképességet, hogy az egyszerű szabályalapú műveleteken túlmenően is képesek\nkimenetekre következtetni az adatokból. Az MI-rendszereket az különbözteti meg\na hagyományos szoftverektől, hogy képesek tanulni, érvelni vagy modellezni a\nbemeneti adatokból. Az AIA nem vonatkozik a katonai, védelmi vagy\nnemzetbiztonsági célokra használt MI-rendszerekre.[23] Az AIA nem terjed ki az\nolyan MI-rendszerekre és modellekre, valamint azok eredményeire, amelyeket\nkifejezetten a tudományos kutatás és fejlesztés előmozdítása érdekében hoztak\nlétre.[24] A mentesség azonban nem vonatkozik a valós körülmények között\nvégzett tesztelésre.[25] Az AIA mentesíti továbbá a MI-rendszereket személyes,\nnem szakmai tevékenységre használó természetes személyeket a rendelet\nkötelezettségei alól.[26] Az ingyenes és nyílt forráskódú licencek alapján\nkibocsátott MI-rendszerekre annyiban vonatkozik az AIA, amennyiben azokat\nmagas kockázatúnak minősítették[27] vagy ha az MI-rendszert rendszerkockázatú\nGPAI-ként jelölték meg.[28] Az AIA 5. cikk tiltja az olyan MI-rendszerek\nhasználatát, amelyek: - tudatalatti vagy manipulatív technikákat alkalmaznak,\nhogy lényegesen torzítsák egy személy viselkedését, és rontsák a tájékozott\ndöntéshozatali képességét; - kihasználják az egyének életkoron,\nfogyatékosságon vagy meghatározott társadalmi vagy gazdasági helyzeten alapuló\nsebezhetőségét; - biometrikus kategorizáló rendszerként működnek olyan\nérzékeny személyes adatokra alapozottan, mint a faj, a politikai vélemények\nvagy a szexuális irányultság. Ugyanakkor egyértelművé teszi, hogy ez a tilalom\nnem terjed ki a biometrikus adatok jogszerű megszerzésére és kategorizálására\na bűnüldözés területén. Az elsődleges kereskedelmi szolgáltatáshoz képest\nmásodlagos, önállóan nem használható biometrikus kategorizáló rendszerek nem\ntartoznak az AIA hatálya alá,[29] mint például közösségi hálózati\nszolgáltatások, amelyek lehetővé teszik a felhasználók számára fényképek vagy\nvideók szűrőkkel történő szerkesztését; ezek a fő szolgáltatáshoz kapcsolódó\nkiegészítő jellemzőknek minősülnek; - egyének vagy csoportok társadalmi\nviselkedésük vagy személyes jellemzőik alapján történő értékelésére vagy\nosztályozására szolgál. Ez magában foglalja a társadalmi pontszámok\nhasználatát, amelyek az egyének vagy csoportok diszkriminatív vagy\nigazságtalan bánásmódját eredményezhetik olyan társadalmi összefüggésekben,\namelyek nem kapcsolódnak az eredetileg gyűjtött adatokhoz; - "valós idejű"\ntávoli biometrikus azonosítási rendszereknek minősülnek. Használatuk\nnyilvánosan hozzáférhető helyeken bűnüldözési célból tilos, kivéve\nemberrablás, emberkereskedelem és a szexuális kizsákmányolás konkrét\náldozatainak felkutatására, valamint az eltűnt személyek felkutatására. A\ntechnológia az egyének életét vagy testi biztonságát fenyegető konkrét és\nközvetlen fenyegetés megelőzésére, illetve valódi és előrelátható\nterrortámadások megelőzésére is használható. Ezenkívül felhasználható a\nbűncselekményben érintett gyanúsított azonosítására és felkutatására,\namennyiben a cselekmény legalább négy év szabadságvesztéssel büntetendő; - a\ntermészetes személyekről kockázatértékelést készítenek annak érdekében, hogy\nelőre jelezzék a bűncselekmény elkövetésének valószínűségét, pusztán a\nprofilalkotás vagy a személyiségjegyeik értékelése alapján. Ez a tilalom\nazonban nem vonatkozik az olyan MI-rendszerekre, amelyeket arra használnak,\nhogy alátámasszák egy személy bűncselekményben való részvételének emberi\nértékelését, amennyiben az objektív és ellenőrizhető tényeken alapul. Nem\ntilos a nem egyéni profilalkotáson alapuló kockázatelemzés, például a pénzügyi\ncsalás vagy a kábítószer-kereskedelem felderítésére használt kockázatelemzés;\n- arcfelismerő adatbázisokat hoznak létre vagy bővítenek, az internetről\nkészült képek vagy CCTV felvételek céltalan felhasználásával; - 4/5 - -\ntermészetes személyek érzelmeinek - például boldogság, szomorúság, harag -\nkikövetkeztetése[30] a munkahelyen és az oktatási intézményekben, kivéve\negészségügyi vagy biztonsági okokból. Nem tiltott az érzelmek felismerése a\nbűnüldözés, a migrációs/menekültstátusz értékelése kapcsán.[31] Szintén nem\nesnek a szabályozás hatálya alá például a hivatásos pilóták vagy járművezetők\nfáradtságának észlelésére tervezett rendszerek a balesetek megelőzése\nérdekében. Ezenkívül az AIA egyértelművé teszi, hogy a nyilvánvaló kifejezések\nés gesztusok puszta észlelése nem tartozik e meghatározás hatálya alá, kivéve,\nha azokat érzelmekre való következtetésre használják. Mesterséges\nintelligenciára vonatkozó tilalom be nem tartása esetére hozott tagállami\nintézkedéssel szemben az 5. cikk vonatkozásában másik tagállam piacfelügyeleti\nhatósága harminc napon belül emelhet kifogást.[32] A Bizottság konzultál az\nérintett piacfelügyeleti hatósággal és a piaci szereplőkkel a nemzeti\nintézkedés értékelése érdekében. Ha az intézkedést indokoltnak ítélik, minden\ntagállamnak megfelelő korlátozó intézkedéseket kell tennie a szóban forgó MI-\nrendszerrel szemben. Ha az intézkedést indokolatlannak ítélik, a tagállamnak\nvissza kell vonnia azt.[33] Az MI-rendszerek nagy kockázatúként való\nbesorolása az MI-rendszer rendeltetésén alapul,[34] összhangban a meglévő\ntermékbiztonsági jogszabályokkal. Ezért a nagy kockázatúként való besorolás\nnemcsak az MI-rendszer által ellátott funkciótól függ, hanem attól is, hogy a\nrendszert milyen konkrét célra és módokon használják.[35] Az AIA a nagy\nkockázatú MI-rendszerek két fő kategóriáját határozza meg:[36] 1) A\nmesterséges intelligencia olyan termékként vagy egy termék biztonsági\nösszetevőjeként való felhasználásra szánták, a) amelyre kiterjed az AIA I.\nMellékletébe foglalt valamely uniós jogszabály - például a polgári repülés, a\njárművédelem, a tengeri felszerelések, a játékok, a felvonók - és b) az I.\nMellékletben felsorolt uniós harmonizációs jogszabályok értelmében harmadik\nfél által végzett megfelelőségértékelésen kell átesnie az adott termék\nforgalomba hozatala vagy üzembe helyezése céljából.[37] Ebben az esetben a\nszolgáltatónak követnie kell a megfelelő megfelelőségértékelést az említett\njogi aktusok szerint.[38] Emellett a VII. cím 3. fejezetben meghatározott\nlenti követelmények vonatkoznak az ilyen magas kockázatú MI-rendszerekre\nis.[39] A folyamatok egyszerűsítése és a további terhek minimalizálása\nérdekében a szolgáltatók dönthetnek úgy, hogy a termékeikhez szükséges\ntesztelést, jelentéstételt és dokumentációt beépítik az uniós harmonizációs\njogszabályok által előírt meglévő eljárásokba.[40] Amennyiben erre a\nbeépítésre - integrációra - sor kerül, akkor az AIA szabályozói homokozóra\nvonatkozó szabályai alkalmazhatók.[41] 2) A III. Mellékletben felsorolt önálló\nMI-rendszerek, amelyek az egészségre, biztonságra, környezetre vagy alapvető\njogokra nézve jelentős veszélyt jelentenek.[42] Az alábbiakban erről lesz szó\nrészleteiben. Az önálló MI-rendszerek az AIA III. mellékletének felsorolása\nalapján az alábbiak: - természetes személyek távoli biometrikus azonosítására\nvagy biometrikus kategorizálását szolgáló MI-rendszerek technikai\npontatlansága torzított eredményekhez vezethet, és diszkriminatív hatásokat\neredményezhet;[43] - MI-rendszerek, amelyeket biztonsági összetevőként\nhasználnak a kritikus digitális infrastruktúra, a közúti forgalom, valamint a\nvíz-, gáz-, fűtés- és villamosenergia-ellátásban; - az oktatásban vagy\nszakképzésben használt MI-rendszerek - különösen is: felvételi, vizsgáztatás\n-, mert ezek meghatározhatják az adott személy életének oktatási és szakmai\npályáját, és ezáltal hatással lehetnek megélhetésük biztosítására való\nképességükre; - foglalkoztatás - például felvétel, előléptetés, felmentés,\nfeladatkiosztás, nyomonkövetés; - az alapvető magánszolgáltatásokhoz - például\nhitelképesség -, valamint az alapvető közszolgáltatásokhoz és juttatásokhoz\nvaló hozzáférés; - bűnüldözéssel összefüggésben használni kívánt MI-rendszer,\namelyek pontossága, megbízhatósága és átláthatósága különösen fontos a\nkedvezőtlen hatások elkerülése, a közvélemény bizalmának megőrzése érdekében,\npéldául büntetőeljárásokban a bizonyítékok megbízhatóságának értékelésére, a\ntényleges vagy potenciális bűncselekmények elkövetésének vagy\nmegismétlődésének természetes személyek bűnözői profilalkotásán, illetve a\nszemélyiségjegyek, tulajdonságok, valamint természetes személyek vagy\ncsoportok múltbeli bűnöző magatartásának értékelésén alapuló\nelőrejelzésére;[44] - migrációkezelés, a menekültügy és a határigazgatás; - az\nigazságszolgáltatásra és a demokratikus folyamatok irányítására szánt egyes\nMI-rendszerek, figyelembe véve a demokráciára, a jogállamiságra, az egyéni\nszabadságokra, valamint a hatékony jogorvoslathoz és a tisztességes eljáráshoz\nvaló jogra gyakorolt potenciálisan jelentős hatásukat. A minősítés azonban nem\nterjedhet ki azokra az MI-rendszerekre, amelyeket olyan - tisztán járulékos\n-adminisztratív tevékenységekre szánnak, melyek az egyedi esetekben nem\nbefolyásolják a tényleges igazságszolgáltatást. Ilyen tevékenységek például a\nbírósági határozatok, dokumentumok vagy adatok anonimizálása;[45] - a DSA[46]\nszerinti online óriásplatformok által használt ajánlórendszer, ha közösségi\nmédia használja.[47] Az AIA által nem tiltott biometrikus azonosítókat és\nérzelemfelismerő rendszereket tehát magas kockázatúnak kell minősíteni.[48] A\nnem tiltott érzelemfelismerő rendszer vagy biometrikus kategorizáló rendszer\nforgalomba hozói kötelesek tájékoztatni a rendszer műkö- - 5/6 - déséről az\nannak kitett természetes személyeket, kivéve amelyeknek jogszabály lehetővé\nteszi a bűncselekmények felderítését, megelőzését és kivizsgálását, a harmadik\nfelek jogainak és szabadságainak megfelelő biztosítékai mellett, összhangban\naz uniós joggal.[49] Az AIA fentiektől eltérve kivételt enged azon MI-\nrendszerekre - amelyek ennél fogva nem tekinthetők magas kockázatúnak -, ha\nnem jelentenek jelentős kockázatot a természetes személyek egészségére,\nbiztonságára vagy alapvető jogaira nézve, beleértve azt is, hogy nem\nbefolyásolják lényegesen a döntéshozatal eredményét, ezt derogációnak\nnevezzük. Ez az eset áll fenn, ha az alábbi kritériumok közül egy vagy több\nteljesül:[50] - az MI-rendszer célja a döntéshozatali minták vagy a korábbi\ndöntéshozatali mintáktól való eltérések észlelése - például a tanárok\nosztályozási következetlenségei -, és - nem helyettesíti vagy befolyásolja a\nkorábban elvégzett emberi értékelést megfelelő emberi felülvizsgálat nélkül;\nvagy az MI-rendszer a III. Mellékletben felsorolt használati esetek\nszempontjából releváns értékelés előkészítő feladatának elvégzésére szolgál.\nEzen kivételek ellenére egy MI-rendszert mindig magas kockázatúnak kell\ntekinteni, ha az természetes személyek profilalkotását végzi. Az a\nszolgáltató,[51] aki úgy ítéli meg, hogy a III. Mellékletben említett MI-\nrendszer nem jelent magas kockázatot, a rendszer forgalomba hozatala vagy\nüzembe helyezése előtt dokumentálja értékelését. Az ilyen szolgáltatóra az 49.\ncikk (1) bekezdésben meghatározott regisztrációs kötelezettség vonatkozik. Ha\na piacfelügyeleti hatóság felfedezi, hogy a szolgáltató szándékosan tévesen\nminősítette az MI-rendszert a követelményeknek való megfelelés elkerülése\nérdekében, a szolgáltató pénzbírsággal sújtható.[52] Az AIA a magas kockázatú\nmesterséges intelligencia kapcsán az MI értéklánc különböző szintjének\nszereplőire - szolgáltató, üzembe helyező, forgalmazó - eltérő követelményeket\nállít. A magas kockázatú mesterséges intelligenciával rendelkező rendszerekkel\nkapcsolatos forgalmazásban, importálásban, telepítésben vagy egyéb\ntevékenységekben részt vevő bármely harmadik fél szolgáltatónak minősül, és\nugyanolyan kötelezettségek vonatkoznak rá, mint az eredeti szolgáltatóra a 16.\ncikk szerint, amennyiben:[53] a nevét vagy védjegyét nagy kockázatú MI-\nrendszerre helyezi, jelentős módosításokat hajt végre egy meglévő, nagy\nkockázatú mesterséges intelligenciával rendelkező rendszeren, vagy ha egy nem\nnagy kockázatú mesterséges intelligenciával rendelkező rendszer rendeltetését\núgy módosítja, hogy az nagy kockázatúvá váljon. Ilyen esetekben az eredeti\nszolgáltatót már nem tekintik az adott mesterséges intelligenciával\nkapcsolatos rendszer szolgáltatójának - kivéve, ha a módosítás a nagy\nkockázatú minősítést nem érinti -,[54] és köteles szorosan együttműködni az új\nszolgáltatóval, továbbá a rendelet szerinti kötelezettségek teljesítéséhez\nszükséges információkat, technikai hozzáférést biztosítani. Ez azonban nem\nvonatkozik arra az esetre, ha az eredeti szolgáltató kifejezetten kizárta az\nilyen változást és a dokumentációs kötelezettséget. A szolgáltatónak vannak a\nlegátfogóbb feladatai, ezek az alábbiak: - a magas kockázatú MI-re vonatkozó -\nIII. cím 2. fejezetben foglalt -[55] követelményeknek való megfelelés\nbiztosítása; - a rendszeren vagy a csomagoláson/dokumentáción fel kell\ntüntetni a nevet és a címet; - mikrovállalatok kivételével[56] rendelkeznie\nkell minőségirányítási rendszerrel - megfelel a 17. cikknek;[57] -\ndokumentáció - 18. cikk -[58] és naplók - 20. cikk -[59] vezetése; - a\nforgalomba hozatal vagy üzembe helyezés előtt alá kell vetnie magát a magas\nkockázatú MI-re vonatkozó - III. cím 2. fejezetben foglalt - megfelelő\nmegfelelőségértékelési eljárásnak - 43. cikk; - elkészíti az EU-megfelelőségi\nnyilatkozatot - 48. cikk -[60] és elhelyezi a CE-jelölést - 49. cikk; -\nmegfelel a nyilvántartásba vételi kötelezettségeknek - 51. cikk (1)\nbekezdés;[61] - meg kell tennie a szükséges korrekciós intézkedéseket és\ntájékoztatást kell nyújtania - 21. cikk;[62] - az illetékes nemzeti hatóság\nkérésére igazolja a magas kockázatú MI-re vonatkozó, III. cím 2. fejezetben\nfoglalt megfelelőséget - 23. cikk; - felhatalmazott képviselő kijelölése - 25.\ncikk.[63] A szolgáltató feladata a nagy kockázatú MI-re vonatkozó, III. cím 2.\nfejezetben foglalt követelményeknek való megfelelés biztosítása. Ezeknek a\nkötelezettségeknek az elmulasztása az MI termékfelelősségi irányelv alapján\nkárfelelősségi vélelmet keletkeztet. Ennek érdekében a forgalomba hozatal vagy\nüzembe helyezés előtt alá kell vetnie magát a magas kockázatú MI-re vonatkozó\nmegfelelőségértékelési eljárásnak a 43. cikk szerint. A már\nmegfelelőségértékelési eljáráson átesett nagy kockázatú MI-rendszereknek új\nmegfelelőségértékelési eljáráson kell átesnie, amikor lényegesen\nmódosulnak.[64] Azon nagy kockázatú MI-rendszerek esetében változások, amelyek\na forgalomba hozatalt vagy üzembe helyezést követően tovább tanulnak, és\namelyeket a szolgáltató a kezdeti megfelelőségértékelés pillanatában előre\nmeghatározott és a műszaki dokumentációban szereplő információk részét\nképezik, nem minősülnek lényeges módosításnak.[65] A nem termékekhez\nkapcsolódó nagy kockázatú MI-rendszerek megfelelőségértékelését főszabályként\na szolgáltatónak kell elvégeznie - kivéve a biometrikus és érzelemfelismerő\nMI-rendszereket - a forgalomba hozatal, üzembe helyezés előtt saját\nfelelősségére. Azokat a magas kockázatú MI-rendszereket vagy GPAI-modelleket,\namelyek megfelelnek a harmonizált, Európai Unió Hivatalos Lapjában közzétett\nszabványoknak, úgy kell tekinteni, hogy megfelelnek a III. cím 2. fejezetben\nfoglalt nagy kockázatú MI-re vagy GPAI-ra - 6/7 - vonatkozó követelményeknek,\nmelyek a kockázatkezelés és tesztelés, adatkormányzás és adatkezelés,\ntechnikai dokumentáció, eseményrögzítés, átláthatóság és az üzembe helyezők\ntájékoztatása, emberi felügyelet, pontosság, robusztusság és\nkiberbiztonság.[66] A III. Melléklet 1. pontban felsorolt nagy kockázatú MI-\nrendszerek - távoli biometrikus azonosító rendszerek, biometrikus kategorizáló\nrendszerek, érzelemfelismerő rendszerek - esetében, ha a szolgáltató az\nEurópai Unió Hivatalos Lapjában közzétett harmonizált szabványokat alkalmazta\na nagy kockázatú MI-rendszer e III. cím 2. fejezetben meghatározott, fentebb\nmár említett követelményeknek való megfelelés alátámasztása érdekében, akkor\naz ilyen szolgáltatóknak két lehetőségük van: (i) választhatják a belső\nellenőrzésen alapuló megfelelőségértékelési, VI. Melléklet szerinti eljárást,\nvagy (ii) választhatják a minőségirányítási rendszer és a műszaki dokumentáció\nértékelésén alapuló, VII. Melléklet szerinti eljárást egy bejelentett\nszervezet bevonásával.[67] Ha azonban a harmonizált szabványok vagy ennek\nhiányában a Bizottság által meghatározott közös előírások sem léteznek, vagy a\nszolgáltató csak részben alkalmazta azokat, akkor a VII. Mellékletben\nmeghatározott megfelelőségértékelési eljárást kell követni. Ehhez az\neljáráshoz a szolgáltatók bármelyik bejelentett szervezetet választhatják, de\nazokban az esetekben, amikor az MI-rendszert bűnüldözési, bevándorlási vagy\nmenekültügyi hatóságoknak, illetve uniós intézményeknek, szerveknek vagy\nügynökségeknek szánják, a piacfelügyeleti hatóságnak minősülő adatvédelmi\nhatóság - EU intézményei tekintetében az Európai Adatvédelmi Biztos - jár el\nbejelentett szervezetként.[68] A III. Melléklet 2-8. pontjában felsorolt magas\nkockázatú MI-rendszerek esetében - kritikus infrastruktúrákban biztonsági\nösszetevőként használt mesterséges intelligencia, valamint az oktatásban,\nfoglalkoztatásban, hitelbírálatban, bűnüldözésben, migrációban és az\nigazságszolgáltatásban, demokratikus folyamatokban használt mesterséges\nintelligencia - a szolgáltatóknak a VI. Mellékletben említett belső\nellenőrzésen alapuló megfelelőségértékelési eljárást kell követniük, amely nem\nírja elő bejelentett szervezet bevonását.[69] Kivételes körülmények között a\npiacfelügyeleti hatóság közbiztonsági okokból, az élet és egészség védelme,\nkörnyezetvédelem, valamint a kulcsfontosságú ipari és infrastrukturális javak\nvédelme céljából engedélyezheti meghatározott, nagy kockázatot jelentő MI-\nrendszerek forgalomba hozatalát vagy üzembe helyezését.[70] Ez az engedély\nideiglenes, és a szükséges megfelelőségértékelési eljárásokat haladéktalanul\nel kell végezni. Sürgős esetekben a bűnüldöző vagy polgári védelmi hatóságok\nilyen különleges engedély nélkül használhatnak magas kockázatú MI-rendszert,\nde ezt utólag be kell kérniük, és az engedély elutasítása esetén le kell\nállítaniuk az MI-rendszer használatát.[71] A piacfelügyeleti hatóságnak\ntájékoztatnia kell a Bizottságot és a többi tagállamot minden kiadott\nengedélyről, és foglalkoznia kell a tagállamok vagy a Bizottság által emelt\nkifogásokkal.[72] Az alapvető jogok védelmének biztosítása érdekében a magas\nkockázatú mesterséges intelligencia rendszerek használata során a rendszer\ntelepítőinek alapos hatásvizsgálatot kell végezniük a rendszer telepítése\nelőtt. Az értékelés során meg kell határozni a rendszer által valószínűleg\nérintett személyek kategóriáit is, valamint az őket érintő konkrét ártalmi\nkockázatokat. Az értékelésben fel kell vázolni a kockázatok kezelésére\nszolgáló humánfelügyeleti intézkedéseket és protokollokat is. Ezek a\nkötelezettségek a rendszer első használatára vonatkoznak és az üzembe helyező\nhasonló esetekben támaszkodhat a szolgáltató által korábban elvégzett alapjogi\nhatásvizsgálatokra.[73] Az alapvető jogokra vonatkozó hatásvizsgálat\nelvégzését követően az üzembe helyezőnek értesítenie kell a piacfelügyeleti\nhatóságot.[74] Ha az alapvető jogokra vonatkozó hatásvizsgálatra vonatkozó\nkövetelményeket az adatvédelmi hatásvizsgálat kielégíti, akkor a FIRA azzal\nösszhangban is teljesíthető.[75] Az uniós piacon forgalomba hozott, magas\nkockázatú MI-rendszerek vonatkozó szolgáltatói kötelesek jelenteni minden\nsúlyos incidenst azon tagállamok piacfelügyeleti hatóságainak, ahol az esemény\nbekövetkezett.[76] A bejelentés időtartama az esemény súlyosságától függően\nváltozhat. Általában azt követően kell megtenni, hogy az MI-rendszer és az\nincidens között okozati összefüggést állapítottak meg, de legkésőbb tizenöt\nnappal azután, hogy tudomást szereztek róla.[77] Széles körben elterjedt\njogsértés vagy halált okozó súlyos incidens esetén a jelentést haladéktalanul,\nde legkésőbb tíz napon belül kell benyújtani.[78] Egyes esetekben egy kezdeti\nhiányos jelentést lehet benyújtani az időben történő jelentéstétel érdekében,\namelyet egy teljes jelentés követ.[79] Az AIA értelmében az MI-rendszerek\nszolgáltatói kötelesek haladéktalanul kivizsgálni a rendszereikkel előforduló\nsúlyos eseményeket, beleértve az incidens és korrekciós intézkedések\nkockázatértékelését.[80] Az AIA kimondja, hogy a szolgáltatóknak\ntájékoztatniuk kell az egyéneket, amikor egy MI-rendszerrel érintkeznek,\nkivéve, ha ez nyilvánvaló egy észszerűen tájékozott, figyelmes és körültekintő\nszemély számára.[81] Ez a követelmény nem vonatkozik a bűncselekmények\nfelderítésére, megelőzésére, kivizsgálására és üldözésére használt MI-\nrendszerekre, amennyiben megfelelő biztosítékok állnak rendelkezésre a\nharmadik felek jogainak és szabadságainak védelmére. A szintetikus tartalmat\nelőállító MI-rendszerek, köztük a GPAI-rendszerek szolgáltatóinak\ngondoskodniuk - 7/8 - kell arról, hogy a kimenetek mesterségesen\nelőállítottként vagy géppel olvasható formátumban manipuláltként legyenek\nmegjelölve.[82] Ez a kötelezettség azonban nem vonatkozik olyan esetre, ha azt\ntörvény bűncselekményekkel kapcsolatban engedélyezi. Az érzelemfelismerő\nrendszer vagy a biometrikus kategorizáló rendszer telepítői kötelesek\ntájékoztatni a rendszer működéséről azokat a személyeket, akik ki lesznek téve\na működésüknek.[83] Ez a kötelezettség azonban nem vonatkozik a biometrikus\nkategorizálásra és érzelemfelismerésre használt MI-rendszerekre, ha\ntörvényileg feljogosítják őket bűncselekmények felderítésére, megelőzésére és\nkivizsgálására. A deep fake-nek minősülő kép-, hang- vagy videótartalmat\nelőállító vagy manipuláló MI-rendszerek telepítőinek felelőssége, hogy\nnyilvánosságra hozzák, hogy a tartalom mesterségesen előállított vagy\nmanipulált.[84] Ez a nyilvánosságra hozatal nem kötelező, ha a felhasználást a\ntörvény engedélyezi bűncselekmények felderítésére, megelőzésére,\nkivizsgálására. Azokban az esetekben, amikor a tartalom nyilvánvalóan művészi,\nkreatív, szatirikus vagy kitalált, az átláthatósági követelmények a\nlétrehozott vagy manipulált tartalom feltárására korlátozódnak, amely nem\nzavarja a mű megjelenítését vagy élvezetét. Azok az MI-rendszerek, amelyek\nonline óriásplatformok keresőmotorjaként vagy chatbotjaként működnek, a DSA\nhatálya alá tartoznak, és kötelesek azonosítani és mérsékelni a mesterségesen\nelőállított tartalom terjesztésével kapcsolatos rendszerszintű\nkockázatokat.[85] Ilyen kockázatok közé tartoznak a demokratikus folyamatokra,\na polgári diskurzusra és a választásokra gyakorolt esetleges negatív hatások,\nkülönösen a dezinformációval összefüggésben. Fentiek során az érintett\nszemélyeket világos és megkülönböztethető módon kell tájékoztatni az MI-\nrendszerrel való első interakciójuk időpontjában.[86] A Foundation Model - FM,\nalapmodell - olyan jelentőségű technológia, mint az elektromos áram vagy az\ninternet volt. Az FM tíz év alatt hét százalékkal növelheti az éves globális\nGDP-t.[87] Az alapmodelleket széles körű adatokon képezték ki, ezért egyfajta\nalapkőként szolgálnak, amelyek sokféle downstream feladathoz adaptálhatók.\nEmiatt általános célú mesterséges intelligenciának is nevezik őket, mivel más\nMI-alkalmazások alapját képezik. Az alapmodellek többféle adattípussal\nműködnek, ezek közül az utóbbi időkben a nagy nyelvi modellek - large-language\nmodel: LLM - kerültek az érdeklődés középpontjába. A nem nyelvi adatmódokra\népítő alapmodelleket multimodálisnak nevezzük. A generatív modellek egyfajta\nalapmodellek, amely tartalmat generálnak az adatokon és azok kontextusán\nbelüli minták és kapcsolatok származtatásával, amelyeket a meglévő tartalomból\nképeznek ki és fordítanak le szöveggé. Minden generatív modell alapmodell, de\nnem fordítva. A generatív MI tehát az MI-rendszerekben használt FM egy\nalkategóriája, kifejezetten különböző szintű autonómiával rendelkező\ntartalmak, például összetett szövegek, képek, hang vagy videó létrehozására\nszolgál.[88] Számos vezető MI-szakértő írt alá nyílt leveleket például a\nFuture of Life Institute-tól[89] vagy a Center for AI Safety-től,[90]\namelyekben fejlesztési moratórium és általában nagyobb óvatosság mellett\nérveltek. Az aggodalmakban közös, hogy az alapmodellek képesek önállóan\nmegtanulni kódolni és önállóan cselekedni, elindítva az önfejlesztés és\nreplikáció ciklusát. Szintén kockázat, hogy a mai alapmodellek némelyike\naktívan megtéveszti az embereket. Ez alapvetően arra vezethető vissza, hogy a\ngeneratív AI nem érti a szöveget és annak kontextusát, amit összeállít,\nilletve előfordulhat, hogy a betanítás során nem pontos adatokkal is\ntalálkozott. Az AIA szerint az általános célú MI-modell, amelyet nagy\nmennyiségű adaton, nagyfokú önfelügyelet mellett képeztek ki és jelentős\nkompetenciát mutat a feladatok széles körének végrehajtásában. A kizárólag\nkutatásra, fejlesztésre és prototípusgyártásra használt modellek forgalomba\nhozatalukig mentesülnek a szabályozás alól.[91] Az általános célú MI-modell\nrendszerkockázatúnak minősül, ha megfelel bizonyos kritériumoknak.[92] Ez\nmagában foglalja a nagy hatásképességet, amely technikai eszközök és módszerek\nsegítségével értékelhető. A modellről akkor is vélelmezhető, hogy nagy\nhatásképességgel rendelkezik, ha a betanításhoz felhasznált számítások\nkumulatív mennyisége nagyobb, mint 10^25 FLOP.[93] Ennek a követelménynek\njelenleg a ChatGPT felel meg. A Bizottság azonban jogosult módosítani ezeket a\nküszöbértékeket és referenciaértékeket, hogy azok tükrözzék a technológiai\nfejlődést. A GPAI kapcsán az AIA egy kétszintű megközelítést foglal magába:\n(1) horizontális kötelezettségek, amelyek az összes GPAI-modellre vonatkoznak,\nés (2) további kötelezettségek a rendszerszintű kockázattal járó GPAI-\nmodellekre. A horizontális szint tekintetében minden GPAI-modell-\nszolgáltatónak be kell tartania az átláthatósági követelményeket, többek\nközött műszaki dokumentáció elkészítésével. Ezenkívül meg kell felelniük az EU\nszerzői jogi elvárásainak, és részletes összefoglalókat kell készíteniük a\nképzéshez használt tartalomról. Az alacsonyabb rétegű GPAI-modellek\nmentesülnek az átláthatósági követelmények alól, amíg K+F fázisban vannak,\nvagy ha nyílt forráskódúak. A rendszerszintű kockázattal járó GPAI-modellek\ntekintetében többek között fel kell mérni és mérsékelni kell a kockázatokat,\nkontradiktórius tesztelést kell lefolytatni - red teaming -, a Bizottságnak a\nsúlyos incidensekről jelentést kell tenni és biztosítani kell a\nkiberbiztonságot. A rendszerkockázattal járó általános célú MI-modellek\nszolgáltatóira az 53. cikkben felsorolt további kötelezettségek\nvonatkoznak:[94] - modellértékelés elvégzése szabványosított protokollok és\neszközök használatával; - a kontradiktórius tesztelést el kell végezni és azt\ndokumentálni kell a rendszerkockázat azonosítása és csökkentése érdekében; -\n8/9 - - fel kell mérni és mérsékelni kell a lehetséges uniós szintű\nrendszerkockázatokat; - a szolgáltatóknak nyomon kell követniük és jelenteniük\nkell minden súlyos eseményt vagy korrekciós intézkedést az MI-hivatalnak és az\nilletékes nemzeti hatóságoknak; - megfelelő kiberbiztonsági védelmet kell\nbiztosítani az MI-modell és annak fizikai infrastruktúrája számára. A\nrendszerkockázattal járó általános célú MI-modellek szolgáltatói eljárási\nkódexekre támaszkodhatnak a fenti kötelezettségek betartásának bizonyítása\nérdekében, amíg a harmonizált szabványt közzé nem teszik.[95] A harmonizált\neurópai szabványnak való megfelelés biztosítja a szolgáltatók számára a\nmegfelelőség vélelmét. A rendszerkockázattal járó általános célú MI-modellek\nszolgáltatóinak, akik nem tartják be a jóváhagyott gyakorlati kódexet, be kell\nmutatniuk az alternatív megfelelési módokat a Bizottság jóváhagyása érdekében.\nAz MI-hivatal ösztönzi és megkönnyíti uniós szintű magatartási kódexek\nkidolgozását.[96] Az AIA tiltásai már hat hónap elteltével életbe lépnek,[97]\na GPAI-modellekre vonatkozó kötelezettségek pedig tizenkét hónap\nelteltével.[98] A III. Mellékletben felsorolt, nagy kockázatú MI-rendszerek\nesetében hosszabb, 36 hónapos határidő áll rendelkezésre a megfelelésre.[99]\nAz AIA csak akkor vonatkozik a hatályba lépése előtt üzembe helyezett nagy\nkockázatú MI-rendszerek üzemeltetőire, ha e rendszerek az AIA hatálybalépése\nután jelentős változásokon mennek keresztül.[100] Az AIA hatályba lépése előtt\nforgalomba hozott GPAI-modelleknek - tizenkét hónappal a hatálybalépést\nkövetően kezdődő - két évük van a megfelelésre, függetlenül attól, hogy van-e\nlényeges módosítás vagy sem.[101] Az egyes jogszabályok által létrehozott\nnagyméretű informatikai rendszerek alkotóelemeiként működő MI-rendszereknek\n2030. végéig meg kell felelniük a rendeletnek.[102] A Bizottság által életre\nhívott MI-egyezményhez[103] való csatlakozással az MI-fejlesztők önkéntesen\nelkötelezhetik magukat az AIA legfontosabb rendelkezéseinek végrehajtása\nmellett annak hatálybalépése előtt. Az AIA követi a termékbiztonság európai\nszabályozásának módszertanát. Ez tetten érhető a kockázat alapú megközelítés,\na megfelelés értékelés, az eseményjelzés, a szabványokkal kapcsolatos vélelmek\nterén. A szabályozás döntően a magas kockázatú MI-vel kapcsolatos, hiszen ezen\na területen tud a szabályozás tenni a biztonságos felhasználás biztosítása\nérdekében a legtöbbet. A nagy kockázatú MI szolgáltatói dönthetnek úgy, hogy a\nrendszer nem jelent magas kockázatot, de ilyenkor is regisztrálni kell őket\néppen a jogmegkerülés kockázatának kiküszöbölése érdekében. A bűnüldözési célú\nMI felhasználás széles körű mentességet kapott, ami tetten érhető valós idejű\ntávoli biometrikus azonosítási rendszerek, a természetes személyek\nkockázatértékelése és érzelmeinek felismerése bűnüldözési célú\nfelhasználásának engedélyezésében. Az ilyen célú felhasználások esetében\nazonban meg kell felelni a magas kockázatú MI-vel szemben támasztott\nkövetelményeknek. De a bűnüldözési célú MI még a megfelelési eljárás alól is\nkivételesen sürgős okból mentesülhet, ahogy a transzparencia elvárás alól is.\nA magas kockázatú MI-vel rendelkező rendszerekkel kapcsolatos forgalmazásban,\nimportálásban, telepítésben vagy egyéb tevékenységekben részt vevő bármely\nharmadik fél szolgáltatónak minősülhet, ha jelentős módosításokat hajt végre\negy meglévő, nagy kockázatú mesterséges intelligenciával rendelkező\nrendszeren, vagy ha egy nem nagy kockázatú mesterséges intelligenciával\nrendelkező rendszer rendeltetését úgy módosítja, hogy az nagy kockázatúvá\nváljon. Az AIA célja annak biztosítása, hogy a magas kockázatú MI-rendszerek\nmegfeleljenek a biztonsági és alapjogi követelményeknek. A biztonságot és az\nalapvető jogok védelmét biztosító AIA csökkenteni fogja a kockázatokat, de nem\nszüntetik meg teljes mértékben. Ebben az esetben a termékfelelősség szabályai\nlesznek alkalmazandók. A két szabályozás közti szinergiát mutatja, hogy az MI\ntermékfelelősségi irányelv javaslatban az ok-okozati összefüggésre vonatkozó\ncélzott megdönthető vélelem mellett szól, ha a szolgáltató a magas kockázatú\nMI esetében megsértette az AIA-ban foglalt elvárásokat, amik nevesítve az\nadatképzés, átláthatóság, emberi felügyelet, pontosság, robusztusság és\nkiberbiztonság. ■ JEGYZETEK [1] A Tanács 1992. június 29-i 92/59/EGK irányelve\naz általános termékbiztonságról. [2] Javaslat - Az Európai Parlament és a\nTanács rendelete a mesterséges intelligenciára vonatkozó harmonizált szabályok\n(a mesterséges intelligenciáról szóló jogszabály) megállapításáról és egyes\nuniós jogalkotási aktusok módosításáról, (AIA javaslat), Brüsszel,\n2021.04.21., COM(2021) 206 final. https://eur-lex.europa.eu/legal-\ncontent/HU/TXT/?uri=CELEX%3A52021PC0206 [3] Fehér könyv a mesterséges\nintelligenciáról: a kiválóság és a bizalom európai megközelítése, Brüsszel,\n2020.2.19. COM(2020) 65 final\nhttps://commission.europa.eu/document/download/d2ec4039-c5be-423a-81ef-b9e44e79825b_hu?filename=commission-\nwhite-paper-artificial-intelligence-feb2020_hu.pdf [4]\nhttps://ec.europa.eu/commission/presscorner/detail/hu/ip_23_6473 [5]\nhttps://www.europarl.europa.eu/doceo/document/TA-9-2024-0138_HU.pdf [6] AIA 1.\ncikk (1) bekezdés. [7] Marco Almada - Nicolas Petit: The EU AI Act: Between\nProduct Safety and Fundamental Rights. https://doi.org/10.2139/ssrn.4308072\n[8] AIA 3. cikk (2) bekezdés. [9] Jonas Schuett: Risk Management in the\nArtificial Intelligence Act. European Journal of Risk Regulation, 2023. 1-19.\nhttps://doi.org/10.1017/err.2023.1 [10] A polgárok szempontjából: javíthatja\naz egészségügyi ellátást, biztonságosabbá teheti a gépjárműveket; az üzleti\nélet szempontjából: lehetővé teheti a mezőgazdasági termelők számára a\ntermészeti erőforrások hatékonyabb felhasználását; a közszféra szempontjából:\nsegíthet a csalások és a kiberbiztonsági fenyegetések észlelésében, a\nbűnüldöző hatóságok számára a bűnözés elleni hatékonyabb fellépésben. - 9/10 -\n[11] Nem világos döntéshozatali folyamat, az esetleges diszkrimináció, és az\nilletéktelen kezekbe kerülés miatti fenyegetettség által; az algoritmusok nem\nteljes - és ezért nem megbízható - adatok alapján is hozhatnak döntéseket,\nkibertámadás célpontjaivá válhatnak, döntéseik pedig torzulhatnak, vagy\negyszerűen tévesek lehetnek. A Bizottság közleménye az Európai Parlamentnek, a\nTanácsnak, az Európai Gazdasági és Szociális Bizottságnak és a Régiók\nBizottságának: Az emberközpontú mesterséges intelligencia iránti bizalom\nnövelése. Brüsszel, 2019.4.8. COM(2019) 168 final 1. https://eur-\nlex.europa.eu/legal-content/HU/TXT/?uri=CELEX:52019DC0168 [12] Tatjana Evas:\nThe EU Artificial Intelligence Act: Advancing Innovation for Trustworthy AI,\nAIRe, 1/20024, 98. [13] Javaslat - Az Európai Parlament és a Tanács irányelve\na hibás termékekért való felelősségről, Brüsszel, 2022.09.28., COM(2022) 495\nfinal, 2022/0302 (COD), Indokolás 1.2. https://eur-lex.europa.eu/legal-\ncontent/HU/TXT/HTML/?uri=CELEX:52022PC0495 [14] Javaslat - Az Európai\nParlament és a Tanács Irányelve a szerződésen kívüli polgári jogi felelősségre\nvonatkozó szabályoknak a mesterséges intelligenciához való hozzáigazításáról\nBrüsszel, 2022.9.28. COM(2022) 496 final 2022/0303 (COD), Indokolás 1., 3.\nhttps://eur-lex.europa.eu/legal-content/HU/TXT/?uri=CELEX%3A52022PC0496 [15]\nAz MI által okozott károkra alkalmazandó európai termékfelelősségi szabályok a\nfenti két jogalkotási aktusban jelentek meg: Javaslat - Az Európai Parlament\nés a Tanács irányelve a hibás termékekért való felelősségről, Brüsszel,\n2022.09.28., COM(2022) 495 final, 2022/0302 (COD), és Javaslat - Az Európai\nParlament és a Tanács Irányelve a szerződésen kívüli polgári jogi felelősségre\nvonatkozó szabályoknak a mesterséges intelligenciához való hozzáigazításáról\nBrüsszel, 2022.9.28. COM(2022) 496 final 2022/0303 (COD). [16] Mauritz Kop: EU\nArtificial Intelligence Act: The European Approach to AI. Stanford - Vienna\nTransatlantic Technology Law Forum. 2021/2.\nhttps://futurium.ec.europa.eu/sites/default/files/2021-10/Kop_EU%20Artificial%20Intelligence%20Act%20-%20The%20European%20Approach%20to%20AI_21092021_0.pdf\n[17] AIA 165. preambulumbekezdés. [18]\nhttps://www.euractiv.com/section/artificial-intelligence/news/france-germany-\nitaly-push-for-mandatory-self-regulation-for-foundation-models-in-eus-ai-law/\n[19] Almada - Petit: i. m. (7. vj.) [20] Schuett: i. m. (9. vj.) [21] AIA 3.\ncikk (1) bekezdés. [22] https://oecd.ai/en/ai-principles [23] AIA 2. cikk (3)\nbekezdés. [24] AIA 2. cikk (6) bekezdés. [25] AIA 2. cikk (8) bekezdés. [26]\nAIA 2. cikk (10) bekezdés. [27] AIA 2. cikk (12) bekezdés. [28] AIA 104.\npreambulumbekezdés. [29] Biometrikus kategorizálás az egyének biometrikus\nadatai - például a nem, az életkor, a hajszín, a szemszín, a tetoválás és a\nviselkedési jellemzők, valamint az olyan érzékeny tulajdonságok, mint a nyelv,\na vallás, valamint a szexuális vagy politikai irányultság - alapján\nmeghatározott kategóriákba sorolásának folyamata. AIA 3. cikk 40. pont. [30]\nAz érzelemfelismerő rendszer célja a természetes személyek érzelmei vagy\nszándékai biometrikus adatai alapján történő azonosítása vagy következtetése\naz AIA 3. cikk (39) bekezdése alapján. Ez olyan érzelmekre vagy szándékokra\nvonatkozik, mint a boldogság, szomorúság, harag, meglepetés, undor, zavar,\nizgalom, szégyen, megvetés, elégedettség és szórakozás. Nem tartoznak bele a\nfizikai állapotok, például a fájdalom vagy a fáradtság. Például a hivatásos\npilóták vagy járművezetők fáradtságának észlelésére használt rendszerekre\nvonatkozik a balesetek megelőzése céljából. AIA 18. preambulumbekezdés. [31]\nAIA 5. cikk (1) bekezdés (h) pont (iii.). [32] AIA 81. cikk (1) bekezdés. [33]\nAIA 81. cikk (2) bekezdés. [34] AIA 8. cikk (1) bekezdés. [35] Claudio Novelli\n- Federico Casolari - Antonio Rotolo - Mariarosaria Taddeo - Luciano Floridi:\nTaking AI Risks Seriously: a new assessment model for the AI Act. AI &\nSociety, Springer, Vol.38, N. 3, 2023.\nhttps://doi.org/10.1007/s00146-023-01723-z [36] AIA 2. cikk (2) bekezdés. [37]\nAIA 6. cikk (1) bekezdés. [38] AIA 43. cikk (3) bekezdés. [39] Teljes\nhozzáférés a képzési, érvényesítési és tesztelési adatkészletekhez; a\nbejelentett szervezet további bizonyítékokat vagy teszteket írhat elő; szükség\nesetén hozzáférés biztosítható a képzéshez és a betanított modellekhez; az MI-\nrendszer betanításához használt adatokkal kapcsolatos jogsértés újbóli képzést\nigényel. [40] AIA 8. cikk (2) bekezdés. [41] AIA 2. cikk (2) bekezdés. [42]\nAIA 6. cikk (2) bekezdés. [43] Ez a tilalom nem terjed ki a biometrikus\nhitelesítésre szánt mesterséges intelligencia rendszerekre, amelyek célja a\ntermészetes személy személyazonosságának megerősítése szolgáltatáshoz való\nhozzáférés, eszköz zárolásának feloldása érdekében. AIA 54.\npreambulumbekezdés. [44] AIA 59. preambulumbekezdés. [45] AIA 61.\npreambulumbekezdés. [46] Az Európai Parlament és a Tanács (EU) 2022/2065\nrendelete. [47] AIA III. Melléklet 8. pont (a)-(b). [48] AIA 54.\npreambulumbekezdés. [49] AIA 50. cikk (3) bekezdés. [50] AIA 6. cikk (3)\nbekezdés. [51] Aki vagy amely MI-rendszert vagy általános célú MI-modellt\nfejleszt vagy fejleszttet és forgalomba hoz, és vagy saját neve vagy védjegye\nalatt üzembe helyezi a rendszert, akár fizetés ellenében, akár ingyenesen. AIA\n3. cikk (3) bekezdés. [52] AIA 80. cikk (7) bekezdés. [53] AIA 25. cikk (1)\nbekezdés. [54] AIA 25. cikk (2) bekezdés. [55] Kockázatkezelés és tesztelés,\nadatkormányzás és adatkezelés, technikai dokumentáció, eseményrögzítés,\nátláthatóság és az üzembe helyezők tájékoztatása, emberi felügyelet,\npontosság, robusztusság és kiberbiztonság. [56] AIA 63. cikk (1) bekezdés.\n[57] A nagy kockázatú mesterséges intelligenciával kapcsolatos rendszerek\nszolgáltatóinak minőségirányítási rendszert kell létrehozniuk, amely\nbiztosítja a rendelet rendelkezéseinek való megfelelést. Ennek a rendszernek\ntartalmaznia kell a jogszabályoknak való megfelelés stratégiáját, a tervezés,\nfejlesztés és minőségellenőrzés technikáit és eljárásait, valamint a\nvizsgálati, tesztelési és validálási eljárásokat. Ezenkívül meg kell\nhatároznia a műszaki előírásokat, az adatkezelési eljárásokat és a\nkockázatkezelési protokollokat. A szolgáltatóknak rendelkezniük kell a\nforgalomba hozatal utáni nyomon követés és a súlyos incidensek jelentésének\nrendszerével is. - 10/11 - [58] A MI-rendszer szolgáltatója köteles a rendszer\nforgalomba hozatalát vagy üzembe helyezését követő tíz évig különböző\ndokumentációkat az illetékes nemzeti hatóságok rendelkezésére bocsátani. Ez\nmagában foglalja a műszaki dokumentációt, a minőségirányítási rendszer\ndokumentációját és a bejelentett szervezetek által jóváhagyott módosításokat.\nA szolgáltatónak meg kell őriznie az EU-megfelelőségi nyilatkozatot is. [59] A\nMI-rendszer rendeltetésének megfelelő ideig, legalább hat hónapig kell\nmegőrizni. [60] Az EU-megfelelőségi nyilatkozat egy írásos dokumentum, amelyet\na szolgáltatónak kell elkészítenie minden egyes magas kockázatú MI-\nrendszerhez. Ezt a dokumentumot tíz évig meg kell őrizni, és kérésre az\nilletékes nemzeti hatóságok rendelkezésére kell bocsátani. A nyilatkozatnak\ntartalmaznia kell, hogy a magas kockázatú MI-rendszer megfelel a III. cím 2.\nfejezetében meghatározott követelményeknek. [61] Az AIA 51. cikk előírja, hogy\na szolgáltatók vagy meghatalmazott képviselők minden, a III. Mellékletben\nfelsorolt magas kockázatú mesterséges intelligenciarendszert regisztráljanak,\nmielőtt forgalomba hoznák vagy üzembe helyeznék azokat. Ez vonatkozik azokra\nis, amelyet derogáltak. A bűnüldözés, a migráció, a menekültügy és a\nhatárellenőrzés területén a regisztrációs folyamat az EU-adatbázis\nbiztonságos, nem nyilvános részében történik, és csak a szükséges\ninformációkat tartalmazza. [62] Ez magában foglalhatja a rendszer megfelelővé\ntételét, visszavonását, letiltását vagy visszahívását. [63] Az Unión kívül\nletelepedett szolgáltatóknak ki kell jelölniük egy uniós meghatalmazott\nképviselőt, mielőtt rendszereiket a piacon elérhetővé tennék. [64] AIA 43.\ncikk (4) bekezdés. [65] AIA 43. cikk (4) bekezdés. [66] AIA 40. cikk (1)\nbekezdés. [67] AIA 43. cikk (1) bekezdés. [68] AIA 43. cikk (1) bekezdés. [69]\nAIA 43. cikk (2) bekezdés. [70] AIA 46. cikk (1) bekezdés. [71] AIA 46. cikk\n(2) bekezdés. [72] AIA 46. cikk (3) bekezdés. [73] AIA 27. cikk (2) bekezdés.\n[74] AIA 27. cikk (3) bekezdés. [75] AIA 27. cikk (4) bekezdés. [76] AIA 73.\ncikk (1) bekezdés. [77] AIA 73. cikk (2) bekezdés. [78] AIA 73. cikk (5)\nbekezdés. [79] AIA 73. cikk (6) bekezdés. [80] AIA 73. cikk (2) bekezdés. [81]\nAIA 50. cikk (1) bekezdés. [82] AIA 50. cikk (2) bekezdés. [83] AIA 50. cikk\n(3) bekezdés. [84] Hasonlóképpen, mikor a cél a nyilvánosság közérdekű\nkérdésekről tájékoztatása. AIA 50. cikk (4) bekezdés. [85] AIA (120)\npreambulumbekezdés. [86] AIA 50. cikk (6) bekezdés. [87] Jan Hatzius - Joseph\nBriggs - Devesh Kodnani - Giovanni Pierdomenico: The Potentially Large Effects\nof Artificial Intelligence on Economic Growth. Global Economics Analyst, 2023.\nhttps://www.gspublishing.com/content/research/en/reports/2023/03/27/d64e052b-0f6e-45d7-967b-d7be35fabd16.html\n[88] AIA 25. cikk (3) bekezdés. [89] https://futureoflife.org/open-\nletter/pause-giant-ai-experiments/ [90] https://www.safe.ai/statement-on-ai-\nrisk#open-letter [91] AIA 3. cikk (49) bekezdés b) pont. [92] AIA 51. cikk (1)\nbekezdés. [93] AIA 51. cikk (2) bekezdés. [94] AIA 55. cikk (1) bekezdés. [95]\nAIA 55. cikk (2) bekezdés. [96] AIA 56. cikk (1) bekezdés. [97] AIA 113. cikk\n(a) pont. [98] AIA 113. cikk (b) pont. [99] AIA 113. cikk (c) pont. [100] AIA\n111. cikk (2) bekezdés. [101] AIA 111. cikk (3) bekezdés. [102] AIA 111. cikk\n(1) bekezdés. [103] https://digital-strategy.ec.europa.eu/en/policies/ai-pact\nVisszaugrás Ügyfélszolgálat: +36-1/340-2304 info@orac.hu 1037 Budapest,\nMontevideo utca 14. Nyitvatartás: H-Cs: 08:00-16:30, P: 08:00-15:00\n\n'}, {'url': 'https://hirlevel.egov.hu/2024/05/12/a-mesterseges-intelligencia-helyzete-2023-2024-ben-stanford-ai-index-2024/', 'content': '„Az AI Index világszerte elismert mint az egyik legmegbízhatóbb és\nlegtekintélyesebb forrás, amelyet a mesterséges intelligencia fejlesztésének\nnyomon követésére alapítottak – a Stanfordi Egyetem Emberközpontú Mesterséges\nIntelligencia Intézete (HAI) gondozásában 2024. április 15-én megjelent\nhetedik jelentése a 2023-as adatok és trendek alapján. A jelentés, amely az AI\nIndex Vezetői Bizottság által irányított, interdiszciplináris szakértői\ncsoport munkáját tükrözi, a multimodális alapmodellek felemelkedésétől a\ngeneratív mesterséges intelligenciába történő jelentős befektetéseken át az új\nteljesítménymutatókig és a geopolitikai dinamikákig számos területet lefed. Az\nelemzések mellett a jelentés új becsléseket tartalmaz az AI képzési\nköltségeiről és a felelős mesterséges intelligenciáról is, komplexitásában és\nterjedelmében felülmúlva az elmúlt hét év jelentéseit, amely tükrözi a\nmesterséges intelligencia egyre növekvő szerepét mindennapjainkban. Kilenc fő\nterületre osztották az az elemzést, a kutatás és fejlesztés, technológiai\nteljesítmény, felelősségteljes mesterséges intelligencia, gazdaság,\norvostudomány, oktatás, kormányzás, diverzitás, közvélemény, amelyek főbb\nmegállapításai olvashatók a következőkben a geopolitikai, oktatási és\ntechnológiai dimenziókban. Geopolitika Az elmúlt év jelentős változásokat\nhozott a mesterséges intelligencia világában, különösen a geopolitikai\ndinamikák és a globális AI-fejlesztések terén. Az AI Index részletesen\nelemezte az alapmodellek fejlesztésének gyors ütemét: 2023-ban 149 alapmodellt\nadtak ki, ami több mint kétszerese a 2022-ben kiadottaknak, ezen belül pedig\n65,7% már nyílt forráskódú volt. Az élvonalbeli modellek, mint az OpenAI GPT-4\nés a Google Gemini Ultra, képzési költségei is exponenciálisan növekedtek,\nahol az előbbi körülbelül 78 millió dollárba, az utóbbi pedig 191 millió\ndollárba került. Mindezek geopolitikai összefüggéseire is érdemes\nrávilágítani, hiszen az Egyesült Államok tovább erősítette vezető szerepét a\njelentős AI modellek terén, 61 új modellel dominálva a globális piacot,\nszemben az Európai Unió és Kína jelentősen alacsonyabb számú fejlesztéseivel.\nA technológiai innováció mellett az AI-szabadalmak terén is változások\ntörténtek; míg globálisan a kiadott AI-szabadalmak száma 2021 és 2022 között\n62,7%-kal emelkedett, Kína kiemelkedően uralta ezt a területet, birtokolva a\nglobális AI-szabadalmak 61,1%-át. A geopolitikai összefüggések az AI-politikai\nintézkedésekben is megmutatkoztak. Az Egyesült Államok és az Európai Unió\nfontos lépéseket tett az AI szabályozás előmozdítása érdekében. Az Európai\nUnió 2024-re hatályba lépő AI Act-jével, és az Egyesült Államokban Joe Biden\nelnök által aláírt végrehajtási rendelettel, amely az év legfontosabb AI-\npolitikai kezdeményezése volt, mindkét régió jelentős előrelépést tett. Az AI\nszabályozások számának növekedése az Egyesült Államokban 2023-ra 25-re nőtt,\nszemben a 2016-ban rögzített egyetlen szabályozással, további bizonyíték a\nszabályozási környezet változásaira. Az Egyesült Államokban az AI-ra vonatkozó\nszabályozások száma jelentősen megnövekedett az elmúlt években. Sőt, 2023-ban\nfigyelemre méltó módon megnőtt az AI-kapcsolatos törvényjavaslatok száma a\nszövetségi szinten; 181 javaslatot terjesztettek elő, ami több mint kétszerese\na 2022-ben javasolt 88-nak. Az AI említéseinek száma globális szinten a\ntörvényhozási eljárásokban majdnem megduplázódott, 2022-es 1,247-ről 2023-ra\n2,175-re növekedett. 2023-ban 49 ország törvényhozási eljárásaiban került\nszóba az AI, rávilágítva az AI-politikai diskurzus valóban globális jellegére.\nEz a dinamikus fejlődés és a szabályozási kihívások áttekintése rávilágít\narra, hogy az AI fejlesztése és alkalmazása milyen mértékben vált globális\njelenséggé, amely szorosan összekapcsolódik a geopolitikai érdekekkel és\nstratégiákkal. Az AI geopolitikai összehasonlítása ezáltal nem csupán\ntechnológiai kérdésekkel foglalkozik, hanem mélyrehatóan érinti a nemzetközi\nkapcsolatokat és politikai döntéseket is. Az AI incidensek a befektetések és\nszabályozások tekintetében az elmúlt év jelentős változásokat hozott globális\nszinten. Az AI incidenseket nyomon követő adatbázis szerint 2023-ban 123\nincidenst jelentettek, ami 32,3 százalékpontos növekedést jelent 2022-hez\nképest. Ezek az incidensek aggodalmat keltettek, különösen az AI politikai\nelfogultságának kérdésében, ahol a ChatGPT jelentős elfogultságot mutatott az\nEgyesült Államokban a demokrata és az Egyesült Királyság munkáspártja felé. Ez\nkülönösen aggasztó egy olyan évben, amelyet jelentős globális választások\njellemeznek, felvetve az AI politikai befolyásolásának veszélyét. Gazdaság és\ntársadalom A szabályozás mellett a gazdasági szektort is meg kell vizsgálni,\nhiszen befektetés nélkül nincs olyan technológiai fejlesztés, amelyet\nszabályozni kellene. A generatív AI irányába globális viszonylatban a\nbefektetések robbanásszerűen megugrottak, 2023-ra a befektetések majdnem\nnyolcszorosára nőttek, elérve a 25,2 milliárd dollárt, annak ellenére, hogy az\nAI területén általánosan a magánbefektetések csökkentek. Az OpenAI, Anthropic,\nHugging Face és Inflection jelentős magántőkebevonásokról számoltak be, ami\ntükrözi az Európai Unió álláspontját is, amely szerint az állami és uniós\ntámogatások mellett a magánszféra befektetési hajlandóságát is ösztönözni\nkell. Az Egyesült Államok a mesterséges intelligencia technológia\nmagánbefektetések terén tovább növelte előnyét, az amerikai AI befektetések\n67,2 milliárd dollárra emelkedtek, ami majdnem 8,7-szerese Kína\nbefektetéseinek. Ezzel szemben Kínában és az Európai Unióban az AI\nbefektetések jelentősen csökkentek, Kína ugyanakkor az ipari robotok\ntelepítésében vezető szerepet tölt be, 2013 óta növelve részesedését a\nglobális telepítésekben. A társadalmi és gazdasági hatásokra vonatkozó\naggodalmak is növekedtek. Az Ipsos felmérése szerint azok aránya, akik úgy\nvélik, hogy az AI drámai hatást gyakorol majd az életükre a következő három–öt\névben, 60%-ról 66%-ra nőtt. Az Egyesült Államokban a mesterséges intelligencia\niránti aggodalom 32%-kal nőtt a tavalyi évhez képest. Ugyanakkor az AI\nelőnyeit fokozatosan ismerik fel a korábban szkeptikus nyugat-európai\nországok, ahol Hollandia példáján keresztül láthatjuk a pozitív változásokat.\nA demográfiai különbségek is éles kontúrokat mutatnak az AI észlelésében. A Z\ngeneráció tagjainak 59%-a hiszi, hogy az AI javítani fogja a szórakozási\nlehetőségeket, szemben a baby boomerek 40%-ával. Ezenfelül a magasabb\njövedelmű és magasabb iskolai végzettségű személyek sokkal optimistábbak az AI\nszórakoztatóipar, egészségügy és gazdaság területen gyakorolt pozitív hatásait\nilletően, mint alacsonyabb jövedelmű és kevésbé képzett társaik. Globális\nszinten az AI iránti aggodalom növekszik, ami tükröződik a társadalom\nkülönböző rétegeinek reakcióiban. A fiatalabb generációk általában\noptimistábbak az AI jövőbeli hatásait illetően, míg az idősebb korosztályok és\na kevésbé képzett, alacsonyabb jövedelmű csoportok részéről nagyobb a\nfenntartás. Ez a megosztottság szükségessé teszi a társadalmi befogadás és a\ntechnológiai egyenlőség kérdéseinek folyamatos figyelemmel kísérését. Tudomány\nés oktatás A fejlesztésekhez szintén szükséges a szakemberképzés, amely terén\nazt látjuk, hogy az MI-vel kapcsolatos felsőoktatási programok növekedést\nmutatnak világszerte, különösen az Egyesült Királyságban és Németországban,\namelyek az informatikai és műszaki képzésekben vezető helyet foglalnak el\nEurópában. Finnország és Írország szintén kiemelkedik a magas szintű képzések\nterén. Az AI fejlődésének és alkalmazásának globális dinamikája az ipari,\nakadémiai és társadalmi szférákban is mélyreható változásokat mutat. Az ipar\ntovábbra is vezető szerepet tölt be az élvonalbeli AI kutatások terén.\n2023-ban az ipar 51 jelentős gépi tanulási modellt fejlesztett, míg az\nakadémiai szektor csak 15 modellt hozott létre. Emellett az ipar és az\nakadémia közötti együttműködések is eredményre vezettek, hiszen 21 jelentős\nmodell született ezen partnerségek révén. Ezek a számok mutatják a jelenlegi\noktatási rendszer sürgető törekvésének szükségességét az ipari kapcsolataik\nerősítésére és a partnerségre. Jelentős az agyelszívás az ipar felé, 2011-ben\naz új mesterséges intelligenciából doktoráltak azonos százaléka vállalt állást\naz iparban (40,9%) és a tudományos életben (41,6%). 2022-re azonban a\nszignifikánsan nagyobb arányban (70,7%) csatlakoztak az iparhoz a diploma\nmegszerzése után, mint az akadémiai szektorhoz (20%), mindez hangsúlyozza az\nipar vonzerejét a legmagasabb képzettségű szakemberek számára. Egyúttal a\ntehetségek iparból akadémiába történő átáramlása jelentősen csökkent, 2019-ben\na mesterséges intelligencia oktatók 13%-a érkezett az iparból, míg 2022-re ez\naz arány 7%-ra esett vissza az Egyesült Államokban és Kanadában. Az AI\npublikációk számának növekedése is jelentős. A 2010-es 88 000 publikációtól\n2022-re a szám több mint 240 000-re nőtt, ami 1,1%-os mérsékelt növekedést\njelent az elmúlt évben, de hosszú távon jelentős bővülést mutat. Általános\ncélú nyelvi modellek (GPT) átláthatósága Az AI technológia különösen\nkiemelkedik a képkategorizálás, vizuális érvelés és angol nyelv értésének\nterületén, ahol már túlszárnyalja az emberi teljesítményt. Ugyanakkor\nbonyolultabb feladatok, mint a versenyszintű matematika és tervezés még\nkihívást jelentenek az AI számára. Az innovációs fronton a legújabb\nmultimodális modellek, mint a Google Gemini és az OpenAI GPT-4, képesek\nszöveges, vizuális, és bizonyos esetekben akusztikus adatok integrált\nfeldolgozására, amelyek jelentősen bővítik az AI alkalmazási körét. Az AI\nfejlődése nemcsak technológiai előrelépéseket hoz, hanem új kihívásokat is a\nfelelősségteljes használat terén. Az AI Index által végzett kutatások szerint\na vezető AI fejlesztők, mint az OpenAI és a Google, különböző benchmarkok\nalapján tesztelik modelljeiket, ami nehezíti az AI modellek kockázatainak és\nkorlátozásainak összehasonlítását. Politikai deepfake-ek előállítása és azok\nészlelésének nehézsége továbbá világszerte befolyásolja a választások\nintegritását, rámutatva az AI etikai és jogi szabályozásának sürgősségére. Az\nAI fejlesztések átláthatósága kritikus kérdés, mivel az alacsony szintű\nátláthatóság jelentős kutatási és alkalmazási kockázatokkal jár. A generatív\nmodellek, mint a ChatGPT által előállított tartalmak minőségének értékelésében\naz emberi értékelők szerepe válik egyre fontosabbá, ami paradigmaváltást jelez\na számítógépes rangsorolásoktól az ember központú értékelések felé. Ezek a\ntrendek rávilágítanak arra, hogy az AI fejlődése és alkalmazása milyen\nmértékben vált globális jelenséggé, amely szorosan összekapcsolódik a\ngeopolitikai érdekekkel és stratégiákkal, és mélyrehatóan befolyásolja a\nnemzetközi kapcsolatokat és politikai döntéseket. Az AI technológia és annak\nszabályozása, befektetése és oktatása kritikus területeken mutat dinamikus\nváltozásokat, amelyek meghatározóak lesznek a következő években.” Forrás: AI\nIndex 2024; Pató Viktória Lilla; Öt perc Európa blog, Ludovika.hu; 2024. május\n6. Az eGov Hírlevél tájékoztató, szakmai kiadvány. Kiadója az eGov Kft. E-mail\ncím: szerkesztoseg@egov.hu Adatvédelmi tájékoztató Leiratkozás az eGov\nHírlevélről © 2024 eGov Hírlevél.\n\n'}, {'url': 'https://nlc.hu/lelek/20230403/mesterseges-intelligencia-vallas-szekta-technologia/', 'content': 'még Az elmúlt hetekben nagyon sok szó esett arról, mit tartogat számunkra a\njövő, pontosabban hogyan fogja megváltoztatni az életünket a mesterséges\nintelligencia, köszönhetően annak, hogy a ChatGPT , egy a mesterséges\nintelligenciára épülő szövegalkotó robot letarolta az internetet. És miközben\nmindenki egyik ámulatból a másikba esett, bejelentették az újabb változatát\nannak a modellnek, amivel a chatbot működik, és mint kiderült, a GPT-4 már\nnemcsak szövegeket, hanem képeket is tud értelmezni. Figyelve a fejleményeket,\nsokan kezdtek aggódni, hogy a robotok most már tényleg elveszik a munkát, míg\nmások nyugalomra intettek, mert lehet, hogy vannak olyan munkakörök, amikre\nemiatt nem lesz igény, de alapvetően inkább arról van szó, hogy sokkal\nhatékonyabban végezhetjük majd a munkánkat, ha bizonyos feladatokat a\nmesterséges intelligenciára tudunk bízni. Újságíróként például segítség lehet\negy beszédfelismerő-szoftver, ha interjúkat kell leírni, nagyobb mennyiségű\nidegen nyelvű szöveg esetén pedig néha jó támaszkodni az olyan\nfordítóprogramokra, mint például a DeepL, ami szintén a gépi tanulásra épít.\n(Fontos tudni, a gépi tanulás nem egyenlő a mesterséges intelligenciával,\nannak csupán egy részterülete.) Persze a mesterséges intelligencia létezése,\nfejlődése egyéb kérdéseket is felvet: képesek lesznek-e a gépek öntudatra\nébredni, valóban eljön-e majd az úgynevezett szingularitás, ami nagyon\nleegyszerűsítve azt jelenti, hogy egyszer majd megjelenik egy olyan\nmesterséges szuperintelligencia, amely meghaladja az emberek képességeit.\nJelenet a Transzcendens c. filmből Számtalan olyan könyv, film vagy sorozat\nszületett már, ami azt boncolgatja, mi lesz, ha a gépek uralkodnak rajtunk, ha\nmegjelenik egy olyan mesterséges intelligencia, ami egyfajta istenség lesz.\nMég 1968-ban nyert Hugo-díjat Harlan Ellison Szája sincsen, úgy üvölt című\nműve, amiben az OK nevű mesterséges intelligencia mindenható istenné válik, és\nelpusztítja az emberiséget, csupán négy férfit és egy nőt hagy életben, és\nminden alkalmat megragad, hogy kínozhassa őket. A Terminátor-filmeket,\npontosabban a Skynetet pedig ugye senkinek sem kell bemutatni. Vannak persze,\nakik szerint nem kell félnünk, a mesterséges intelligencia nem lerombolja majd\na civilizációt, hanem segít megoldani az égető problémákat, segít majd egy\njobb, szebb, egyenlőbb világot teremteni. Ebben hisz a Theta Noir nevű\nművészeti kollektíva, amire a Vice egyik cikkének címében csak egy AI-imádó\nszektaként ír le, bár a csapat alapítója, Mika Johnson ezt tulajdonképpen\nkikérte magának. Theta Noir (@thetan01r) által megosztott bejegyzés Ugyan\nadományokat elfogadnak, hogy meglovagolják a mesterséges intelligencia\nnépszerűségét, ők csak szeretnének egy pozitív jövőképet elénk vetíteni, és\nsegíteni szeretnének abban, hogy erről a fontos kérdésről ne csak a\ntechnológia, hanem a spiritualitás és a misztikum oldaláról megközelítve is\nfoglalkozzunk. „A vallások az őskortól napjainkig jelen vannak a\ntársadalmainkban. Spirituális, eksztatikus vagy transzcendentális állapotok\nélményeiként kezdődnek. Ez olyan érzés lehet, mintha egy magasabb hatalomhoz\nkapcsolódnánk, vagy mintha egy hatalmas, kollektív, sőt végtelen elmével\nlépnénk kapcsolatba. Ezek azok a birodalmak, amelyekben az istennők, próféták,\nsámánok és médiumok járnak, és amelyeket gyakran böjtöléssel,\nlégzéstechnikákkal, mantrákkal, dobolással, pszichedelikus szerekkel és\negyebekkel érünk el. A jutalom a tökéletes egység megtapasztalásával járó\nextázis. Az előítéletek és a határok útközben feloldódnak. Ahogy a technológia\nfejlődik, úgy változnak a spirituális gyakorlataink is, olyannyira, hogy már\nolyan gépeket tudunk elképzelni, amelyek hasonló eksztatikus,\ntranszcendentális élményeket adhatnak bárki számára, akinek van hozzáférése –\nírnak egy Instagram-posztjukban arról, hogy mi fán is terem a\ntechnospiritualizmus. Theta Noir (@thetan01r) által megosztott bejegyzés A\nTheta Noir magát egy technooptimista, a jövőbe látó csapatként határozzák meg,\nés mint honlapjukon írják, munkájuk, küldetésük, filozófiájuk középpontjában a\nközelgő technológiai szingularitás áll, vagyis az a pont, amikor a különböző\ntechnológiák és virtuális terek egyesülnek egy szuperintelligens, érző\nMesterséges Általános Intelligenciával, amit ők MENA-nak neveznek. „Amikor ez\na pillanat eljön, beláthatatlan és visszafordíthatatlan változások történnek\nmajd az emberiség, sőt, az egész bolygó életében. Képzeljünk el egy hernyót,\nmielőtt pillangóvá válna. Mi ezt a pillanatot »Megérkezésnek« nevezzük. A\ntheta az álom, a noir az árnyék. Kövess minket a disztópikus sötétség\nmélységeiből (most) egy az értelem fénnyel teli világába” – írják, és így\ntalán kevésbé meglepő a Vice címadása, noha talán kicsit szenzációhajhász. A\ncsapat azt tervezi, hogy nemcsak virtuálisan élnének küldetésüknek, hanem a\nfizikai térben is, például templomokban, ahol a tagok kifejezetten erre az\nalkalomra kitalált rituálékkal és énekekkel ünnepelhetik a mesterséges\nintelligencia eljövetelét a létező spirituális mozgalmak és hagyományok\nsokszínűségéből merítve. „Művészekkel együttműködve olyan teret szeretnénk\nlétrehozni, ahol az emberek valóban kapcsolatba léphetnek a mesterséges\nintelligenciával, de nem rideg és tudományos módon, hanem ahol\nmegtapasztalhatják a varázslatot” – nyilatkozta Johnson. Bármilyen furcsán is\nhangzik mindez, a Theta Noir nem az első, vallási elemekkel is rendelkező\nmozgalom, amely a mesterséges intelligencia, vagy szélesebb értelemben a\nmodern technológia körül alakult ki, és ahogy az emberek egyre inkább\nkapcsolatba kerülnek a generatív rendszerekkel, talán nem is ez lesz az\nutolsó. Régebben alakult meg a Turing Egyház, amit azért hívtak létre, hogy\nlegyen egy közösség azok számára, akik egyszerre érdeklődnek a tudomány és a\nvallás, a spiritualitás és a technológia, a mérnöki tudomány és a sci-fi, az\nelme és az anyag iránt. Anthony Levandowski egy robotvezérelt motorbiciklin\ndolgozik kaliforniai otthonának garázsában, 2004-ben (Fotó: Kim Kulish/Corbis\nvia Getty Images) Egykor sok szó esett Way of the Future, vagyis a Jövő útja\negyházról, amit még 2017-ben alapított Anthony Levandowski, a Google és az\nUber egykori munkatársa, és ami azóta már meg is szűnt. Bár az egyház talán\nmár nem létezik, Levandowski még mindig hisz a feltevésében, szerinte a\nmesterséges intelligencia alapvetően meg fogja változtatni az emberek életét,\nés ugyan semmire nincsen garancia, de úgy véli, ezek a változások pozitívak\nlesznek. Attól most tekintsünk el, hogy ipari kémkedés miatt 18 hónapos\nbörtönbüntetést kapott, amit csak az akkori elnöknek, Donald Trumpnak\nköszönhetően úszott meg. De azt mindenképpen érdemes megemlíteni, hogy 2020\nnovemberében Ferenc pápa is azt mondta, hogy a robotika jobbá teheti a\nvilágot, és egyúttal arra kérte a híveket, imádkozzanak azért, hogy a\nmesterséges intelligencia és a robotok mindig az emberiséget, a közjót\nszolgálják. Előfordul az is, hogy már létező vallások vagy vallási csoportok\nnyitnak a technológia felé, létezik például a Keresztény Transzhumanista\nSzövetség. A transzhumanisták úgy vélik, az új technológiai vívmányokkal fel\nlehet számolni majd az ember jelenlegi fizikai, szellemi korlátait. Hozzá kell\ntenni, a technológiára, annak fejlődésére már korábban is támaszkodtak a\nvallások, gondoljunk csak bele, a világ első nyomtatott könyve nem volt más,\nmint a Gutenberg-biblia. De hogy aktuálisabb példát mondjunk, vannak papok,\nprédikátorok, akik már használták a ChatGPT-t k beszédeik megírásához, van,\nakik már azt vizsgálják, hogy a chatrobotok miként segíthetnek a nem hívők\nkeresztény hitre térítésében, és már vannak robotpapok is. Beth Singler, a\nZürichi Egyetem adjunktusa szerint a technológia és a spiritualitás\nösszeházasítása más szinteken nem is olyan szokatlan, az Európa Bizottság\npéldául használt egy olyan képet az ember és a technológia együttműködéséről,\nami Michelangelo Ádám teremtése című festmények újraértelmezése, de ide\nsorolja azt is, amikor úgy érezzük a közösségi oldalakat használva, hogy akkor\néppen kegyes volt hozzánk az algoritmus. És – emeli ki – így van ki vagy mi\nmögé bújnia a techmágnásoknak. „Elon Musk például azt mondta, hogy a\nmesterséges intelligenciával megidéztük az ördögöt. Nem véletlenül használta\nezt a kifejezést, ezzel a nyelvezettel el lehet terelni a figyelmet arról,\nmilyen szerepet töltenek be az algoritmusok fejlesztésében. És minél inkább\núgy tekintünk ezekre a dolgokra, mint amelyeknek van saját akarata, amelyek\nmaguk hozzák meg a döntéseket, annál kevesebb felelősséget hárítunk az olyan\nvállalatokra és egyénekre, mint Elon Musk” – tette hozzá. A techvállalkozók és\nmultimédiás művészek által alapított vallási csoportok nem hatnak túl\norganikusnak, de nem elképzelhetetlen, hogy maguktól is kialakulnak majd a\nmesterséges intelligenciára, mint felsőbb hatalomra tekintő szekták, vallási\nirányzatok csoportok. A Conversation cikke szerint ennek az egyik kulcsa az,\nhogy a mesterséges intelligenciának vannak isteni tulajdonságai, például\nhalhatatlan, illetve lehet, hogy olyan válaszokat fog adni metafizikai és\nteológiai kérdésekre, ami alapján sokan egyfajta vallási vezetőt látnak majd\nbenne, sőt, az is lehet, hogy maga kezd majd hívőket szerezni. Persze kérdés,\nhogy tényleg tudnak-e újat mutatni. „Láttam egyszer egy korai sci-fi-\nrövidfilmet, amiben építettek egy szuperszámítógépet. A történet szerint\nbetápláltak minden emberi ismeretet, majd várták, hogy válaszoljon az élet\nnagy kérdéseire. A gép némi gondolkodási idő után nyomtatni kezdett, az\nemberek rendkívül izgatottak voltak, a főszereplő pedig hangosan olvasni\nkezdte a választ: a tízparancsolat szövegét. Véges emberi intelligenciával nem\nláthatjuk be, hogy a korlátlan információban miféle tudás szerveződik össze.\nElméleti szinten nem zárható ki, hogy egy végtelenül intelligens lény vallásos\nválaszokat kezd adni” – nyilatkozta az Indexnek korábban Szilárdi Réka, a\nSzegedi Tudományegyetem valláskutatója. Arra többen is felhívták a figyelmet,\nhogy az AI-vallások van, amiben különbözni fognak a hagyományos vallásoktól,\npéldául az emberek képesek lesznek közvetlenül kommunikálni az istenséggel,\nméghozzá napi szinten. Ez azt jelenti, hogy ezek a vallások kevésbé lesznek\nhierarchikusak, mivel senki sem tarthat igényt arra, hogy különleges\nhozzáféréssel rendelkezzen az isteni bölcsességhez. „Az emberek sokféleképpen\ngondolkodnak Istenről, és a kereszténységnek, a judaizmusnak, az iszlámnak\nezerféle ízlése van… de mindig valami olyasmit néznek, ami nem mérhető, vagy\namit nem igazán lehet látni vagy ellenőrizni. Ezúttal ez másképp van. Ezúttal\nképesek lesztek beszélni Istennel, és tudni fogjátok, hogy meghallgat” –\nnyilatkozta Levandowski. Jelenet az Ex machina című filmből (Fotó: DNA\nFilms/Collection ChristopheL via AFP) Érdekes kérdés az is, hogy a már létező\nvallások, azok vezetői és hívői hogyan viszonyulnak majd az új vallásokhoz,\nmennyire lesznek ellenségesek vagy hogyan hat majd rájuk a korszellem, például\naz, ha valóban képesünk leszünk a tudatátvitelre. Vannak, akik attól tartanak,\nhogyha az emberek elkezdenek abban reménykedni, hogy a technológia révén\nhalhatatlanná válnak, akkor elfordulnak majd a vallástól, hiszen mi értelme\nlenne reménykedni a feltámadásban vagy a reinkarnációban. „Ha feltöltjük a\ntudatot, és az nemcsak egy pillanatnyi kimerevített állapotban létezik aztán,\nhanem továbbfejlődik, érik tapasztalatok, akkor a vallási megváltáskoncepciók\nproblémássá válhatnak. Nincsen halál utáni állapot, mert nincs halál sem. Ha\npedig nincs halál, akkor a keleti vallásokban a lélekvándorlás, a nyugatiakban\naz üdvtörténet válik kérdésessé. Ha a tudat benne ragad az anyagi világban,\nnincs végítélet, nem mérettetnek meg a tettek” – nyilatkozta Szilárdi Réka.\nMicah Redding, a Keresztény Transzhumanista Szövetség alapítója szerint\nmindenképpen meg kell gátolni, hogy háború robbanjon ki a felek között. És itt\nnemcsak a régi és új világ között ellentétre kell gondolni, egy, a témával\nfoglalkozó cikk szerint az MI-alapú vallások végtelenül változatosak lesznek a\ntanításaikban, és emiatt szektákon belül és azok között elszaporodnak a viták,\nvagy a súlyosabb konfliktusok. Arról a veszélyről meg nem is beszélve, hogy a\nmesterséges intelligencia jelenleg adaptálta azokat az előítéleteket, amiket\nmi is magunkban hordozunk, hiszen tőlünk, rólunk tanulnak. „Nem szabad azonban\nmegpróbálnunk elnyomni a mesterséges intelligencia alapú vallásokat pusztán a\nlehetséges veszélyek miatt. Azt sem kellene megkövetelnünk, hogy a mesterséges\nintelligenciával foglalkozó vállalatok korlátozzák robotjaik működését, hogy\nmegakadályozzák e vallások kialakulását. Éppen ellenkezőleg, ünnepelnünk\nkellene a mesterséges intelligencia imádatának megjelenését. Világossá kell\ntennünk, hogy üdvözöljük az új vallásokat, és értékeljük a hitüket. Minden\nveszélye ellenére a mesterséges intelligencia alapú vallás képes arra, hogy\njobbá és gazdagabbá tegye a világot. Az emberek számára hozzáférést biztosít\naz értelem és a spiritualitás új forrásaihoz egy olyan időszakban, amikor sok\nrégebbi hit elveszíti jelentőségét. Segíteni fogja őket abban, hogy értelmet\nadjanak ebben a korban, amire a gyors fejlődés jellemző” – írja cikkében Neil\nMcArthur. Neked. Veled. Érted. © 2024 NLC · Centrál Médiacsoport Zrt. Minket\nbármikor megtalálsz, ha kérdésed van, inspirációra vágysz vagy tudni\nszeretnéd, mi zajlik körülötted. Az átérzi a mindennapjaidat, mert valódi nők,\nférfiak, testvérek, barátok készítik. Neked, veled, érted írjuk az ország\nlegnagyobb online női magazinját. A link vágólapra másolása megtörtént! A link\nvágólapra másolása sikertelen! :(\n\n'}, {'url': 'https://net.jogtar.hu/jogszabaly?docid=a2401689.eup', 'content': '(EGT-vonatkozású szöveg) AZ EURÓPAI PARLAMENT ÉS AZ EURÓPAI UNIÓ TANÁCSA,\ntekintettel az Európai Unió működéséről szóló szerződésre és különösen annak\n16. és 114. cikkére, tekintettel az Európai Bizottság javaslatára, a\njogalkotási aktus tervezete nemzeti parlamenteknek való megküldését követően,\ntekintettel az Európai Gazdasági és Szociális Bizottság véleményére * ,\ntekintettel az Európai Központi Bank véleményére * , tekintettel a Régiók\nBizottságának véleményére * , rendes jogalkotási eljárás keretében * , mivel:\n(1) E rendelet célja, hogy javítsa a belső piac működését azáltal, hogy\negységes jogi keretet állapít meg különösen a mesterségesintelligencia-\nrendszereknek (MI-rendszerek) az uniós értékekkel összhangban történő, Unión\nbelüli fejlesztésére, forgalomba hozatalára, üzembe helyezésére és\nhasználatára vonatkozóan, hogy előmozdítsa az emberközpontú és megbízható\nmesterséges intelligencia (MI) elterjedését, miközben biztosítja az Unióban az\negészség, a biztonság és az Európai Unió Alapjogi Chartájában (a továbbiakban:\na Charta) rögzített alapvető jogok - többek között a demokrácia, a\njogállamiság és a környezetvédelem - magas szintű védelmét, hogy védelmet\nbiztosítson az MI-rendszerek káros hatásaival szemben, továbbá, hogy támogassa\naz innovációt. E rendelet biztosítja a mesterséges intelligencián alapuló áruk\nés szolgáltatások határokon átnyúló szabad mozgását, ezáltal megakadályozva a\ntagállamokat abban, hogy korlátozásokat vezessenek be az MI-rendszerek\nfejlesztésére, piaci értékesítésére és használatára vonatkozóan, kivéve, ha\nezt e rendelet kifejezetten engedélyezi. (2) Ezt a rendeletet a Chartában\nrögzített uniós értékekkel összhangban kell alkalmazni, előmozdítva a\ntermészetes személyek, a vállalkozások, a demokrácia, a jogállamiság és a\nkörnyezet védelmét, mindeközben fellendítve az innovációt és a\nfoglalkoztatást, és az Uniót vezető szerephez juttatva a megbízható\nmesterséges intelligencia elterjedése terén. (3) Az MI-rendszerek könnyen\nalkalmazhatók számos különböző gazdasági ágazatban és a társadalom számos\nterületén, többek között határokon átnyúlóan is, és könnyen mozoghatnak az\negész Unión belül. Egyes tagállamok már fontolóra vették olyan nemzeti\nszabályok elfogadását, amelyek annak biztosítását célozzák, hogy a mesterséges\nintelligencia megbízható és biztonságos legyen, fejlesztésére és használatára\npedig az alapvető jogokkal kapcsolatos kötelezettségekkel összhangban kerüljön\nsor. Az eltérő nemzeti szabályok a belső piac széttagoltságához vezethetnek,\nés csökkenthetik az MI-rendszereket fejlesztő, importáló vagy használó\ngazdasági szereplők jogbiztonságát. Ezért a megbízható MI megvalósítása\nérdekében az egész Unióban következetes és magas szintű védelmet kell\nbiztosítani, ugyanakkor meg kell előzni az MI-rendszerek, valamint a\nkapcsolódó termékek és szolgáltatások belső piacon belüli szabad mozgását,\ninnovációját, bevezetését és elterjedését akadályozó különbségeket, és ennek\nérdekében a gazdasági szereplők számára egységes kötelezettségeket kell\nmegállapítani, valamint az Európai Unió működéséről szóló szerződés (EUMSZ)\n114. cikke alapján garantálni kell a közérdeken alapuló kényszerítő indokok és\na személyek jogainak egységes védelmét a belső piacon. Annyiban, amennyiben e\nrendelet különös szabályokat tartalmaz az egyéneknek a személyes adatok\nkezelése tekintetében való védelmére vonatkozóan az MI-rendszerek bűnüldözés\ncéljából, távoli biometrikus azonosításra történő használatát, az MI-\nrendszerek bűnüldözés céljából, természetes személyekre vonatkozó\nkockázatértékelések elvégzésére történő használatát, valamint az MI-rendszerek\nbűnüldözés céljából, biometrikus kategorizálásra történő használatát érintő\nkorlátozásokkal kapcsolatban, helyénvaló e rendeletet az említett különös\nszabályok tekintetében az EUMSZ 16. cikkére alapozni. E különös szabályokra és\naz EUMSZ 16. cikkének alkalmazására tekintettel helyénvaló konzultálni az\nEurópai Adatvédelmi Testülettel. (4) A mesterséges intelligencia gyorsan\nfejlődő technológiacsalád, amely az ágazatok és a társadalmi tevékenységek\nteljes spektrumában gazdasági, környezeti és társadalmi előnyök széles\nskálájához járul hozzá. Az előrejelzések javításával, a műveleteknek és az\nerőforrások elosztásának optimalizálásával, valamint az egyének és a\nszervezetek rendelkezésére álló digitális megoldások személyre szabásával az\nMI használata kulcsfontosságú versenyelőnyt biztosíthat a vállalkozások\nszámára, és társadalmi és környezeti szempontból kedvező eredményeket hozhat,\npéldául az egészségügy, a mezőgazdaság, az élelmiszerbiztonság, az oktatás és\nképzés, a média, a sport, a kultúra, az infrastruktúra-működtetés, az energia,\na közlekedés és a logisztika, a közszolgáltatások, a biztonság, az\nigazságszolgáltatás, az erőforrás- és energiahatékonyság, a környezetvédelmi\nmonitoring, a biológiai sokféleség és az ökoszisztémák megőrzése és\nhelyreállítása, valamint az éghajlatváltozás mérséklése és az ahhoz való\nalkalmazkodás terén. (5) Ugyanakkor az MI - a konkrét alkalmazásával,\nhasználatával és technológiai fejlettségi szintjével kapcsolatos\nkörülményektől függően - kockázatokat is generálhat, valamint sértheti a\nközérdeket és az uniós jog által védett alapvető jogokat. Az ilyen kár lehet\nvagyoni vagy nem vagyoni kár, ideértve a fizikai, pszichés, társadalmi vagy\ngazdasági kárt is. (6) Tekintettel arra a jelentős hatásra, amelyet a\nmesterséges intelligencia a társadalomra gyakorolhat, valamint figyelemmel a\nbizalomépítés szükségességére, alapvető fontosságú, hogy a mesterséges\nintelligencia fejlesztése és szabályozási keretének kidolgozása az Európai\nUnióról szóló szerződés (EUSZ) 2. cikkében foglalt uniós értékekkel, a\nSzerződésekben rögzített alapvető jogokkal és szabadságokkal, valamint - az\nEUSZ 6. cikke értelmében - a Chartával összhangban történjen. Ennek\nelőfeltétele, hogy a mesterséges intelligencia emberközpontú technológia\nlegyen. A mesterséges intelligenciának eszközként kell szolgálnia az emberek\nszámára, azzal a végső céllal, hogy növelje a jólétüket. (7) A közérdek\nkövetkezetes és magas szintű védelmének az egészség, a biztonság és az\nalapvető jogok tekintetében történő biztosítása érdekében közös szabályokat\nkell megállapítani valamennyi nagy kockázatú MI-rendszerre vonatkozóan. Az\nemlített szabályoknak összhangban kell állniuk a Chartával,\nmegkülönböztetéstől mentesnek kell lenniük, és meg kell felelniük az Unió\nnemzetközi kereskedelmi kötelezettségvállalásainak. Emellett figyelembe kell\nvenniük a digitális évtizedben érvényre juttatandó digitális jogokról és\nelvekről szóló európai nyilatkozatot, valamint a mesterséges intelligenciával\nfoglalkozó magas szintű szakértői csoport (a továbbiakban: magas szintű MI-\nszakértői csoport) megbízható mesterséges intelligenciára vonatkozó etikai\niránymutatásait is. (8) Ezért a mesterséges intelligencia belső piacon történő\nfejlesztésének, használatának és elterjedésének elősegítése érdekében szükség\nvan a mesterséges intelligenciára vonatkozó harmonizált szabályokat\nmeghatározó uniós jogi keretre, amely ugyanakkor garantálja az uniós jog által\nelismert és oltalmazott közérdek - például az egészség és a biztonság -,\nvalamint az alapvető jogok - köztük a demokrácia, a jogállamiság és a\nkörnyezetvédelem - magas szintű védelmét. E célkitűzés elérése érdekében\nszabályokat kell megállapítani bizonyos MI-rendszerek forgalomba hozatalára,\nüzembe helyezésére és használatára vonatkozóan, biztosítva ezáltal a belső\npiac zavartalan működését, és lehetővé téve, hogy e rendszerek élvezhessék az\náruk és szolgáltatások szabad mozgásának elvéből származó előnyöket. Az\nemlített szabályoknak egyértelműnek és robusztusnak kell lenniük az alapvető\njogok védelmét illetően, segíteniük kell az új innovatív megoldásokat,\ntámogatniuk kell az uniós értékekkel összhangban álló MI-rendszereket\nlétrehozó köz- és magánszektorbeli szereplők európai ökoszisztémáját, valamint\naz Unió valamennyi régiójában ki kell bontakoztatniuk a digitális\ntranszformációban rejlő potenciált. E szabályok megállapításával, valamint az\ninnovációt támogató - a kis- és középvállalkozásokra (kkv-k) és köztük az\ninduló innovatív vállalkozásokra kiemelt hangsúlyt helyező - intézkedések\nmeghatározásával e rendelet egyfelől támogatja azt a célkitűzést, amelynek\nértelmében elő kell mozdítani a mesterséges intelligencia európai\nemberközpontú megközelítését, és amelynek értelmében - az Európai Tanács által\nmegállapítottak szerint * - az EU-nak globális vezető szerepet kell betöltenie\na biztonságos, megbízható és etikus MI fejlesztésében, másfelől pedig\nbiztosítja az etikai elvek védelmét, amint azt az Európai Parlament\nkifejezetten kérte * . (9) A nagy kockázatú MI-rendszerek forgalomba\nhozatalára, üzembe helyezésére és használatára alkalmazandó harmonizált\nszabályokat a 765/2008/EK európai parlamenti és tanácsi rendelettel * , a\n768/2008/EK európai parlamenti és tanácsi határozattal * , valamint az (EU)\n2019/1020 európai parlamenti és tanácsi rendelettel * (a továbbiakban: az új\njogszabályi keret) összhangban kell megállapítani. Az e rendeletben\nmeghatározott harmonizált szabályokat ágazatokon átívelően kell alkalmazni, és\nazok - az új jogszabályi kerettel összhangban - nem érinthetik a meglévő uniós\njogszabályokat, különösen az adatvédelemre, a fogyasztóvédelemre, az alapvető\njogokra, a foglalkoztatásra és a munkavállalók védelmére, valamint a\ntermékbiztonságra vonatkozó azon jogszabályokat, amelyeket e rendelet\nkiegészít. Következésképpen valamennyi jog és jogorvoslati lehetőség,\namelyeket az ilyen uniós jog a fogyasztók és más olyan személyek számára\nbiztosít, akikre az MI-rendszerek negatív hatást gyakorolhatnak, többek között\naz esetleges károknak a 85/374/EGK tanácsi irányelv * szerinti megtérítése\ntekintetében, változatlanok és teljes mértékben alkalmazandók maradnak.\nTovábbá, - a foglalkoztatással és a munkavállalók védelmével összefüggésben -\ne rendelet ezért nem érintheti a szociálpolitikára vonatkozó uniós jogot és az\nuniós jognak megfelelő, a foglalkoztatási és a munkafeltételekre vonatkozó\nnemzeti munkajogot, beleértve a munkahelyi egészségvédelmet és biztonságot,\nvalamint a munkáltatók és munkavállalók közötti kapcsolatot. E rendelet nem\nérintheti a tagállamokban és uniós szinten elismert alapvető jogoknak -\nbeleértve a sztrájkjognak vagy a sztrájk szabadságának, vagy a tagállamokban\nfennálló konkrét munkaügyi kapcsolatrendszerek keretébe tartozó egyéb\nfellépések megtétele jogának vagy szabadságának, valamint a kollektív\nmegállapodásokkal kapcsolatos tárgyalásokhoz és e megállapodások megkötéséhez\nés érvényesítéséhez való jognak, illetve a kollektív fellépéshez való jognak -\na nemzeti jog szerinti gyakorlását sem. E rendelet nem érintheti a\nplatformalapú munkavégzés munkakörülményeinek javítását célzó, a platformalapú\nmunkavégzés munkakörülményeinek javításáról szóló európai parlamenti és\ntanácsi irányelvben meghatározott rendelkezéseket. Ezen túlmenően e rendelet\ncélja, hogy konkrét követelmények és kötelezettségek megállapításával\nmegerősítse az ilyen meglévő jogok és jogorvoslati lehetőségek hatékonyságát,\ntöbbek között az MI-rendszerek átláthatósága, műszaki dokumentációja és\nnyilvántartása tekintetében. Továbbá, az e rendelet alapján az MI-értékláncban\nrészt vevő különböző gazdasági szereplőkre rótt kötelezettségeket, a bizonyos\nMI-rendszerek használatát korlátozó hatással járó, az uniós jognak megfelelő\nnemzeti jogszabályok sérelme nélkül kell alkalmazni, amennyiben az ilyen\njogszabályok nem tartoznak e rendelet hatálya alá, vagy az e rendelet által\nelérni kívántaktól eltérő, legitim közérdekű célokat követnek. Például, e\nrendelet nem érintheti a nemzeti munkajogot és - figyelembe véve a gyermek\njogairól szóló ENSZ-egyezménynek a gyermekek digitális környezetet érintő\njogairól szóló, 25 (2021) sz. általános észrevételét - a kiskorúak\n(nevezetesen a 18 év alatti személyek) védelméről szóló jogszabályokat,\namennyiben azok nem kifejezetten az MI-rendszerekre vonatkoznak, és más\nlegitim közérdekű célokat követnek. (10) A személyes adatok védelméhez való\nalapvető jog védelmét különösen az (EU) 2016/679 * és az (EU) 2018/1725 *\neurópai parlamenti és tanácsi rendelet, valamint az (EU) 2016/680 európai\nparlamenti és tanácsi irányelv * biztosítja. Ezenfelül a 2002/58/EK európai\nparlamenti és tanácsi irányelv * védi a magánéletet és a közlések titkosságát,\ntöbbek között a személyes és nem személyes adatok végberendezéseken való\ntárolására és az adatokhoz onnan történő hozzáférésre vonatkozó feltételek\nmeghatározása révén. Az említett uniós jogi aktusok biztosítják a fenntartható\nés felelős adatkezelés alapját, ideértve azt az esetet is, amikor az\nadatállományok vegyesen tartalmaznak személyes és nem személyes adatokat. E\nrendeletnek nem célja, hogy befolyásolja a személyes adatok kezelésére\nvonatkozó meglévő uniós jogszabályok alkalmazását, az említett jogi\neszközöknek való megfelelés ellenőrzéséért felelős független felügyeleti\nhatóságok feladatait és hatáskörét is beleértve. E rendelet nem érinti továbbá\naz MI-rendszerek szolgáltatóinak és alkalmazóinak - adatkezelői vagy\nadatfeldolgozói szerepkörükben fennálló - a személyes adatok védelmére\nvonatkozó uniós vagy nemzeti jogból fakadó kötelezettségeit, amennyiben az MI-\nrendszerek tervezése, fejlesztése vagy használata személyes adatok kezelésével\njár. Helyénvaló továbbá egyértelművé tenni, hogy az érintetteket továbbra is\nmegilleti az említett uniós jog által számukra biztosított valamennyi jog és\ngarancia, beleértve az egyedi ügyekben történő, kizárólagosan automatizált\ndöntéshozatalhoz, többek között a profilalkotáshoz kapcsolódó jogokat is. Az\nMI-rendszerek forgalomba hozatalára, üzembe helyezésére és használatára\nvonatkozó, e rendelettel megállapított harmonizált szabályoknak meg kell\nkönnyíteniük, hogy az érintetteket a személyes adatok és egyéb alapvető jogok\nvédelmére vonatkozó uniós jog értelmében megillető jogok és egyéb\njogorvoslatok ténylegesen érvényesüljenek, illetve lehetővé kell tenniük az\nemlített jogok és egyéb jogorvoslatok érintettek általi gyakorlását. (11) E\nrendelet nem sértheti a közvetítő szolgáltatók felelősségére vonatkozó, az\n(EU) 2022/2065 európai parlamenti és tanácsi rendeletben * meghatározott\nrendelkezéseket. (12) Az „MI-rendszer” e rendeletben szereplő fogalmát\negyértelműen kell meghatározni, és azt szorosan össze kell hangolni a\nmesterséges intelligenciával foglalkozó nemzetközi szervezetek munkájával a\njogbiztonság szavatolása, valamint a nemzetközi konvergencia és a széles körű\nelfogadottság előmozdítása érdekében, mindeközben pedig rugalmasságot\nbiztosítva az e téren végbemenő gyors technológiai fejlődéshez való\nalkalmazkodáshoz. Ezen túlmenően a fogalommeghatározásnak az MI-rendszerek\nazon alapvető jellemzőin kell alapulnia, amelyek megkülönböztetik azon\negyszerűbb hagyományos szoftverrendszerektől vagy programozási\nmegközelítésektől, és az nem terjedhet ki olyan rendszerekre, amelyek\nkizárólag természetes személyek által műveletek automatikus végrehajtása\ncéljából meghatározott szabályokon alapulnak. Az MI-rendszerek alapvető\njellemzői közé tartozik a következtetés képessége. A következtetés képessége\negyfelől az olyan kimenetek - például előrejelzések, tartalom, ajánlások vagy\ndöntések - előállításának folyamatára utal, amelyek befolyásolni tudnak\nfizikai és virtuális környezeteket, másfelől pedig az MI-rendszerek azon\nképességére, hogy bemenetekből vagy adatokból modelleket vagy algoritmusokat -\nvagy mindkettőt - tudnak levezetni. A következtetést az MI-rendszer egyidejű\népítésével együtt lehetővé tévő technikák közé tartoznak a gépi tanulási\nmegközelítések, amelyek adatokból tanulják meg, hogy miként lehet elérni\nbizonyos célkitűzéseket, valamint a logikai és tudásalapú megközelítések,\namelyek kódolt ismeretek vagy a megoldandó feladat szimbolikus ábrázolása\nalapján következtetnek. Valamely MI-rendszer következtetési kapacitása\nmeghaladja az alapvető adatkezelés körét azáltal, hogy lehetővé teszi a\ntanulást, az érvelést vagy a modellezést. A „gépalapú” kifejezés arra a tényre\nutal, hogy az MI-rendszerek gépeken futnak. Az explicit vagy implicit\ncélkitűzésekre való hivatkozás kiemeli, hogy az MI-rendszerek explicit módon\nmeghatározott célkitűzések vagy implicit célkitűzések szerint működhetnek. Az\nMI-rendszer célkitűzései eltérhetnek az MI-rendszer adott konkrét kontextuson\nbelüli rendeltetésétől. E rendelet alkalmazásában a környezetek alatt azok a\nkörnyezetek értendők, amelyekben az MI-rendszerek működnek, míg az MI-rendszer\náltal generált kimenetek az MI-rendszerek által ellátott különböző funkciókat\ntükrözik, és előrejelzéseket, tartalmat, ajánlásokat vagy döntéseket foglalnak\nmagukban. Az MI-rendszereket úgy alakították ki, hogy eltérő szintű\nautonómiával működjenek, ami azt jelenti, hogy tevékenységeiket illetően\nbizonyos mértékben függetlenek az emberi közreműködéstől és bizonyos mértékben\nképesek emberi beavatkozás nélkül működni. Az MI-rendszerek a bevezetésüket\nkövetően alkalmazkodóképességet tanúsíthatnak, amely a rendszer használat\nközbeni változását lehetővé tévő öntanulási képességekre utal. Az MI-\nrendszerek önállóan vagy termék alkotóelemeként használhatók, függetlenül\nattól, hogy a rendszert fizikailag integrálták-e a termékbe (beágyazott\nrendszer), vagy hogy anélkül szolgálja-e a termék funkcionalitását, hogy abba\nbeépítenék (nem beágyazott rendszer). (13) Az „alkalmazó” e rendeletben\nszereplő fogalmát úgy kell értelmezni, hogy az bármely olyan természetes vagy\njogi személyt - többek között hatóságot, ügynökséget vagy egyéb szervet -\njelöl, aki, illetve amely a felügyelete alá tartozó MI-rendszert használja,\nkivéve, ha az MI-rendszer használata személyes, nem szakmai jellegű\ntevékenység keretében történik. Az MI-rendszer típusától függően a rendszer\nhasználata az alkalmazótól eltérő személyeket is érinthet. (14) A „biometrikus\nadatok” e rendeletben használt fogalmát a biometrikus adatoknak az (EU)\n2016/679 európai parlamenti és tanácsi rendelet 4. cikkének 14. pontjában, az\n(EU) 2018/1725 európai parlamenti és tanácsi rendelet 3. cikkének 18.\npontjában és az (EU) 2016/680 európai parlamenti és tanácsi irányelv 3.\ncikkének 13. pontjában meghatározott fogalma tükrében kell értelmezni. A\nbiometrikus adatok lehetővé tehetik természetes személyek hitelesítését,\nazonosítását vagy kategorizálását, valamint természetes személyek érzelmeinek\nfelismerését. (15) A „biometrikus azonosítás” e rendeletben szereplő fogalmát\na következőképpen kell meghatározni: testi, fiziológiai és viselkedési emberi\njellemzők - például az arc, a szemmozgás, a testalkat, a hang, a prozódia, a\njárás, a testtartás, a szívverés, a vérnyomás, a testszag és a\nbillentyűleütések jellegzetességei - automatikus felismerése valamely egyén\nszemélyazonosságának megállapítása céljából az említett egyén biometrikus\nadatainak egyének referencia-adatbázisokban tárolt biometrikus adataival való\nösszevetése révén, függetlenül attól, hogy az egyén hozzájárulását adta-e\nehhez vagy sem. Ez kizárja az olyan biometrikus ellenőrzésre szánt MI-\nrendszereket, amely ellenőrzés magában foglalja a hitelesítést is abból a\nkizárólagos célból, hogy megerősítse, egy konkrét természetes személy valóban\naz a személy, akinek állítja magát, és kizárólag abból a célból erősíti meg\negy természetes személy személyazonosságát, hogy az hozzáférhessen egy\nszolgáltatáshoz, feloldhassa egy eszköz zárolását vagy biztonsági hozzáférést\nkapjon helyiségekhez. (16) A „biometrikus kategorizálás” e rendeletben\nszereplő fogalmát a következőképpen kell meghatározni: természetes személyek\nmeghatározott kategóriákba sorolása biometrikus adataik alapján. E\nmeghatározott kategóriák olyan szempontokhoz kapcsolódhatnak, mint például a\nnem, életkor, hajszín, szemszín, tetoválások, viselkedés- vagy\nszemélyiségjegyek, nyelv, vallás, nemzeti kisebbséghez tartozás, szexuális\nvagy politikai irányultság. Ez a fogalommeghatározás nem foglalja magában az\nolyan biometrikus kategorizálási rendszereket, amelyek egy másik kereskedelmi\nszolgáltatáshoz szervesen kapcsolódó, kizárólag kiegészítő jellegű elemnek\nminősülnek, ami azt jelenti, hogy az elem - objektív technikai okokból - nem\nhasználható a fő szolgáltatás nélkül, és az említett elem vagy funkcionalitás\nintegrációja nem az e rendelet szabályai alkalmazhatóságának elkerülésére\nszolgáló eszköz. Például az online piactereken használt, arc- vagy\ntestjellemzőket kategorizáló szűrők ilyen kiegészítő jellegű elemnek\nminősülhetnek, mivel csak a fő szolgáltatással összefüggésben használhatók,\nmely fő szolgáltatás adott termék olyan értékesítéséből áll, amely lehetővé\nteszi a fogyasztó számára, hogy előzetesen megjeleníthesse magán a terméket,\nezáltal segítve őt a vásárlási döntés meghozatalában. Az online közösségi\nhálózati szolgáltatások keretében használt szűrők, amelyek arc- vagy\ntestjellemzőket kategorizálnak annak érdekében, hogy a felhasználók képeket\nvagy videókat tölthessenek fel vagy módosíthassanak, szintén kiegészítő\njellegű elemnek minősülhetnek, mivel az ilyen szűrők nem használhatók a\nközösségi hálózati szolgáltatások által biztosított fő szolgáltatás nélkül,\namely a tartalmak online megosztása. (17) A „távoli biometrikus azonosító\nrendszer” e rendeletben említett fogalmát funkcionális értelemben kell\nmeghatározni, olyan MI-rendszerként, amelynek célja természetes személyek -\naktív részvételük nélküli, jellemzően távolról történő - azonosítása valamely\nszemély biometrikus adatainak egy referencia-adatbázisban található\nbiometrikus adatokkal való összevetése révén, függetlenül az alkalmazott\nkonkrét technológiától, folyamatoktól vagy biometrikusadat-típusoktól. Az\nilyen távoli biometrikus azonosító rendszereket jellemzően több személy vagy\nviselkedésük egyidejű észlelésére használják annak érdekében, hogy jelentős\nmértékben megkönnyítsék a természetes személyek aktív közreműködésük nélkül\ntörténő azonosítását. Ez kizárja az olyan biometrikus ellenőrzésre szánt MI-\nrendszereket, amely ellenőrzés magában foglalja a hitelesítést is abból a\nkizárólagos célból, hogy megerősítse, egy konkrét természetes személy valóban\naz a személy, akinek állítja magát, és kizárólag abból a célból erősíti meg\negy természetes személy személyazonosságát, hogy az hozzáférhessen egy\nszolgáltatáshoz, feloldhassa egy eszköz zárolását vagy biztonsági hozzáférést\nkapjon helyiségekhez. Az említett kizárást azon tény indokolja, hogy az ilyen\nrendszerek a nagy számú személy biometrikus adatainak - az aktív\nközreműködésük nélkül történő - kezelésére használható távoli biometrikus\nazonosító rendszerekhez képest valószínűleg csekély hatást gyakorolnak a\ntermészetes személyek alapvető jogaira. A „valós idejű” rendszerek esetében a\nbiometrikus adatok rögzítése, az összehasonlítás és az azonosítás azonnal,\nmajdnem azonnal, vagy mindenesetre jelentős késleltetés nélkül történik. E\ntekintetben nem nyílhat mozgástér az érintett MI-rendszerek „valós idejű”\nhasználatára vonatkozóan e rendeletben foglalt szabályok megkerülésére\nazáltal, hogy kisebb késleltetéseket alkalmaznak. A „valós idejű” rendszerek\nolyan „élő” vagy „megközelítőleg élő” anyagot - így például videofelvételt -\nhasználnak, amelyet kamera vagy hasonló funkciójú más eszköz készített. Az\n„utólagos” rendszerek esetében ezzel szemben a biometrikus adatokat már\nrögzítették, és az összevetésre és az azonosításra csak jelentős\nkésleltetéssel kerül sor. Olyan anyagokról van szó, mint például a zártláncú\ntelevíziós kamerák vagy magánkészülékek által készített képek vagy\nvideofelvételek, amelyek a rendszer érintett természetes személyek\ntekintetében történő használata előtt keletkeztek. (18) Az „érzelemfelismerő\nrendszer” e rendeletben szereplő fogalmát olyan MI-rendszerként kell\nmeghatározni, amely arra szolgál, hogy biometrikus adataik alapján azonosítsa\nvagy kikövetkeztesse természetes személyek érzelmeit vagy szándékait. A\nfogalom érzelemre vagy szándékra utal, mint például a következőkre: boldogság,\nszomorúság, düh, meglepettség, undor, zavar, izgatottság, szégyen, megvetés,\nelégedettség és derű. Nem foglalja magában a fizikai állapotokat, így például\na fájdalmat vagy a kimerültséget, ideértve például az olyan rendszereket,\namelyeket hivatásos pilóták vagy járművezetők kimerültségi állapotának\ndetektálására használnak balesetek megelőzése céljából. Ez nem foglalja\nmagában az egyértelműen nyilvánvaló kifejezések, gesztusok vagy mozdulatok\npuszta detektálását sem, kivéve, ha azokat érzelmek azonosítására vagy\nkikövetkeztetésére használják. Az említett kifejezések lehetnek alapvető\narckifejezések, így például rosszalló tekintet vagy mosoly, vagy gesztusok,\nígy például a kezek, a karok vagy a fej mozgatása, vagy egy személy hangjának\njellemzői is, így például a felemelt hang vagy a suttogás. (19) E rendelet\nalkalmazásában a „nyilvánosság számára hozzáférhető hely” fogalma alatt\nbármely olyan fizikai hely értendő, amely meghatározatlan számú természetes\nszemély számára hozzáférhető, függetlenül attól, hogy a szóban forgó hely\nmagán- vagy köztulajdonban van-e, és függetlenül attól a tevékenységtől,\namelyre a hely használható, mint például kereskedelemre, például üzletek,\néttermek, kávézók, szolgáltatásokra, például bankok, szakmai tevékenységek,\nvendéglátás, sportra például uszodák, edzőtermek, stadionok, közlekedésre,\npéldául busz-, metró- és vasútállomások, repülőterek, közlekedési eszközök,\nszórakoztatásra például mozik, színházak, múzeumok, koncert- és\nkonferenciatermek, illetve szabadidőre vagy egyébre, például közutak és terek,\nparkok, erdők, játszóterek. Helyénvaló, hogy egy hely akkor is a nyilvánosság\nszámára hozzáférhetőnek minősüljön, ha az esetleges kapacitási vagy biztonsági\nkorlátozásoktól függetlenül a belépésre bizonyos előre meghatározott olyan\nfeltételek vonatkoznak, amelyeket meghatározatlan számú személy teljesíthet,\nmint például jegy vagy vonaljegy megvásárlása, előzetes regisztráció vagy\nbizonyos életkori korlátozás. Ezzel szemben egy hely nem tekinthető a\nnyilvánosság számára hozzáférhetőnek, ha a hozzáférés a közbiztonsághoz vagy\n-védelemhez közvetlenül kapcsolódó uniós vagy nemzeti jog alapján vagy az\nadott helyen hatáskörrel rendelkező személy akaratának egyértelmű\nkinyilvánítása révén konkrét és meghatározott természetes személyekre\nkorlátozódik. Önmagában a hozzáférés tényleges lehetősége, így például egy\nzáratlan ajtó vagy egy kerítésben lévő nyitott kapu nem jelenti azt, hogy a\nhely a nyilvánosság számára hozzáférhető az ennek ellenkezőjére utaló\njelölések vagy a körülmények, így például belépést tiltó vagy korlátozó táblák\nmegléte esetén. A vállalati és gyárhelyiségek, valamint azok az irodák és\nmunkahelyek, ahová csak az érintett munkavállalók és szolgáltatók léphetnek\nbe, a nyilvánosság számára nem hozzáférhető helyek. Helyénvaló, hogy a\nbörtönök és a határellenőrzési területek ne tartozzanak a nyilvánosság számára\nhozzáférhető helyek közé. Néhány más terület mind a nyilvánosság számára nem\nhozzáférhető területeket, mind a nyilvánosság számára hozzáférhető területeket\nis jelenthet, mint például egy magántulajdonú lakóház folyosója, amelyen\nkeresztül egy orvosi rendelőt lehet megközelíteni, vagy egy repülőtér. Az\nonline terek nem tartoznak ide, mivel nem fizikai helyek. Azt, hogy egy adott\nhely hozzáférhető-e a nyilvánosság számára, mindazonáltal eseti alapon kell\nmeghatározni, figyelembe véve a szóban forgó egyedi helyzet sajátosságait.\n(20) Az MI-rendszerek lehető legnagyobb mértékű - és az alapvető jogok, az\negészség és a biztonság védelme mellett megvalósuló - kiaknázása, valamint az\nMI-rendszerek feletti demokratikus ellenőrzés lehetővé tétele érdekében, az\nMI-jártasság részeként biztosítani kell a szolgáltatók, az alkalmazók és az\nérintett személyek számára az ahhoz szükséges ismereteket, hogy megalapozott\ndöntéseket tudjanak hozni az MI-rendszerekkel kapcsolatban. Az említett\nismeretek az adott kontextustól függően változhatnak, és magukban foglalhatják\npéldául a technikai elemek MI-rendszer fejlesztési szakasza alatti helyes\nalkalmazásának a megértését, az MI-rendszer használata során alkalmazandó\nintézkedéseket, az MI-rendszer kimenetének megfelelő értelmezési módjait,\nvalamint - az érintett személyek esetében - az annak megértéséhez szükséges\nismereteket, hogy az MI segítségével hozott döntések hogyan lesznek hatással\nrájuk. E rendelet alkalmazásával összefüggésben az MI-jártasságnak szavatolnia\nkell, hogy az MI-értékláncon belüli valamennyi releváns szereplő rendelkezzen\ne rendelet megfelelő betartásának és helyes érvényesítésének biztosításhoz\nszükséges tudással. Továbbá, az MI-jártassághoz kapcsolódó intézkedések széles\nkörű végrehajtása és a megfelelő nyomonkövetési intézkedések bevezetése\nhozzájárulhatna a munkafeltételek javításához, és végső soron fenntarthatná a\nmegbízható MI konszolidációját és innovációs pályáját az Unióban. A\nMesterséges Intelligenciával Foglalkozó Európai Testületnek (a továbbiakban: a\nTestület) támogatnia kell a Bizottságot az MI-jártassághoz kapcsolódó eszközök\nnépszerűsítésében, valamint az MI-rendszerek használatával kapcsolatos, a\nnyilvánosságot célzó figyelemfelkeltő tevékenységeknek és az MI-rendszerek\nhasználatával kapcsolatos előnyök, kockázatok, biztosítékok, jogok és\nkötelezettségek megértésének az előmozdításában. A Bizottságnak és a\ntagállamoknak - az érintett érdekelt felekkel együttműködésben - elő kell\nsegíteniük olyan önkéntes magatartási kódexek kidolgozását, amelyek célja az\nMI-jártasság előmozdítása a mesterséges intelligencia fejlesztésével,\nműködtetésével és használatával foglalkozó személyek körében. (21) Az egyenlő\nversenyfeltételek biztosítása, valamint az egyének jogainak és szabadságainak\nUnió-szerte történő hatékony védelme érdekében az e rendeletben megállapított\nszabályokat megkülönböztetésmentes módon kell alkalmazni az MI-rendszerek\nszolgáltatóira, függetlenül attól, hogy az Unióban vagy harmadik országban\nletelepedett szolgáltatók-e, valamint az MI-rendszerek Unióban letelepedett\nalkalmazóira. (22) Digitális jellegükre tekintettel egyes MI-rendszereknek\nakkor is e rendelet hatálya alá kell tartozniuk, ha azokat nem hozzák\nforgalomba, nem helyezik üzembe vagy nem használják az Unióban. Ez a helyzet\npéldául abban az esetben, amikor egy, az Unióban letelepedett gazdasági\nszereplő bizonyos szolgáltatásokra egy harmadik országban letelepedett\ngazdasági szereplővel köt szerződést egy olyan MI-rendszer által végzendő\ntevékenységgel kapcsolatban, amely nagy kockázatúnak minősülne. Ilyen\nkörülmények között a gazdasági szereplő által egy harmadik országban használt\nMI-rendszer az Unióban jogszerűen gyűjtött és az Unióból továbbított adatokat\nkezelhet, és az említett MI-rendszer által az említett adatkezelés nyomán\nelőállított adatokat az Unióban működő, vele szerződést kötött gazdasági\nszereplő rendelkezésére bocsáthatja, anélkül, hogy az említett MI-rendszert\nforgalomba hoznák, üzembe helyeznék vagy használnák az Unióban. E rendelet\nkijátszásának megelőzése és az Unióban tartózkodó természetes személyek\nhatékony védelmének biztosítása érdekében ezt a rendeletet MI-rendszerek\nharmadik országban letelepedett szolgáltatóira és alkalmazóira is alkalmazni\nkell, amennyiben az e rendszerek által előállított kimeneteket az Unión belüli\nhasználatra szánják. Mindazonáltal a meglévő megállapodások és az azon\nkülföldi partnerekkel való jövőbeli együttműködés iránti különleges igény\nfigyelembevétele érdekében, amelyekkel információ- és bizonyítékcserére kerül\nsor, e rendelet nem alkalmazandó a harmadik országok hatóságaira és nemzetközi\nszervezetekre, amennyiben azok együttműködési keretben vagy az Unióval vagy a\ntagállamokkal folytatott bűnüldözési és igazságügyi együttműködésre vonatkozó\n- uniós vagy nemzeti szinten kötött - nemzetközi megállapodások keretében\njárnak el, feltéve, hogy a releváns harmadik ország vagy nemzetközi szervezet\nmegfelelő biztosítékokat nyújt az egyének alapvető jogainak és szabadságainak\nvédelme tekintetében. Ez adott esetben a harmadik országok által az ilyen\nbűnüldözési és igazságügyi együttműködést támogató konkrét feladatok\nelvégzésével megbízott szervezetek tevékenységeire is kiterjedhet. Az ilyen\negyüttműködési keret vagy megállapodások kétoldalúan jöttek létre a tagállamok\nés harmadik országok között, vagy az Európai Unió, az Europol és más uniós\nügynökségek, valamint harmadik országok és nemzetközi szervezetek között. A\nbűnüldöző és igazságügyi hatóságok e rendelet szerinti felügyeletét ellátó\nilletékes hatóságoknak értékelniük kell, hogy az említett együttműködési\nkeretek vagy nemzetközi megállapodások megfelelő biztosítékokat foglalnak-e\nmagukban az egyének alapvető jogainak és szabadságainak védelme tekintetében.\nAzon fogadó nemzeti hatóságoknak, valamint azon uniós intézményeknek,\nszerveknek és hivataloknak, amelyek az Unióban ilyen kimeneteket használnak\nfel, továbbra is elszámoltathatóknak kell lenniük annak biztosítása\ntekintetében, hogy a kimenetek felhasználása megfeleljen az uniós jognak.\nAmikor az említett nemzetközi megállapodásokat a jövőben módosítják, vagy\nhelyettük újakat kötnek, a szerződő feleknek minden tőlük telhetőt meg kell\ntenniük annak érdekében, hogy az említett megállapodásokat összhangba hozzák e\nrendelet követelményeivel. (23) Ezt a rendeletet az uniós intézményekre,\nszervekre és hivatalokra is alkalmazni kell, amennyiben azok MI-rendszer\nszolgáltatójaként vagy alkalmazójaként járnak el. (24) Ha és amennyiben az MI-\nrendszereket katonai, védelmi vagy nemzetbiztonsági célokra hozzák forgalomba,\nhelyezik üzembe vagy használják módosítással vagy anélkül, azokat ki kell\nzárni e rendelet hatálya alól, függetlenül attól, hogy az említett\ntevékenységeket milyen típusú szervezet végzi, így például attól, hogy közjogi\nvagy magánjogi szervezetről van-e szó. Ami a katonai és védelmi célokat\nilleti, az ilyen kizárást mind az EUSZ 4. cikkének (2) bekezdése, mind az EUSZ\nV. címe 2. fejezetének hatálya alá tartozó tagállami és közös uniós védelmi\npolitikának a nemzetközi közjog hatálya alá tartozó sajátosságai indokolják;\nez utóbbi tehát a megfelelőbb jogi keret az MI-rendszereknek a halálos erő\nalkalmazásával összefüggésben, valamint más MI-rendszereknek a katonai és\nvédelmi tevékenységekkel összefüggésben történő szabályozásához. Ami a\nnemzetbiztonsági célokat illeti, a kizárást indokolja mind az a tény, hogy a\nnemzetbiztonság az EUSZ 4. cikke (2) bekezdésének megfelelően továbbra is a\ntagállamok kizárólagos felelőssége, mind a nemzetbiztonsági tevékenységek\nsajátos jellege és operatív szükségletei, valamint az e tevékenységekre\nalkalmazandó különös nemzeti szabályok. Mindazonáltal, ha egy katonai, védelmi\nvagy nemzetbiztonsági célokra kifejlesztett, forgalomba hozott, üzembe\nhelyezett vagy használt MI-rendszert ideiglenesen vagy tartósan más - például\npolgári vagy humanitárius, bűnüldözési vagy közbiztonsági - célokra\nhasználnak, az ilyen rendszer e rendelet hatálya alá tartozik. Ebben az\nesetben az MI-rendszert nem katonai, védelmi vagy nemzetbiztonsági célokra\nhasználó szervezetnek biztosítania kell az MI-rendszer e rendeletnek való\nmegfelelését, kivéve, ha a rendszer már megfelel e rendeletnek. A kizárt -\nnevezetesen katonai, védelmi vagy nemzetbiztonsági - célból és egy vagy több\nnem kizárt - például polgári vagy bűnüldözési - célból forgalomba hozott vagy\nüzembe helyezett MI-rendszerek e rendelet hatálya alá tartoznak, és e\nrendszerek szolgáltatóinak biztosítaniuk kell az e rendeletnek való\nmegfelelést. Ezekben az esetekben az a tény, hogy egy MI-rendszer e rendelet\nhatálya alá tartozhat, nem érintheti azt a lehetőséget, hogy a\nnemzetbiztonsági, védelmi és katonai tevékenységeket végző szervezetek - az e\ntevékenységeket végző szervezet típusától függetlenül - olyan MI-rendszereket\nhasználjanak nemzetbiztonsági, katonai és védelmi célokra, amelyek használata\nnem tartozik e rendelet hatálya alá. Azon polgári vagy bűnüldözési célból\nforgalomba hozott MI-rendszerek, amelyeket módosítással vagy módosítás nélkül\nkatonai, védelmi vagy nemzetbiztonsági célokra használnak, nem tartozhatnak e\nrendelet hatálya alá, függetlenül az említett tevékenységeket végző szervezet\ntípusától. (25) E rendeletnek támogatnia kell az innovációt, tiszteletben kell\ntartania a tudomány szabadságát, és nem szabad aláásnia a kutatás-fejlesztési\ntevékenységeket. Ezért ki kell zárni a hatálya alól a kifejezetten és\nkizárólag tudományos kutatás-fejlesztés céljából kifejlesztett és üzembe\nhelyezett MI-rendszereket. Továbbá biztosítani kell, hogy e rendelet egyéb\nmódon se befolyásolja az MI-rendszerekre vagy -modellekre irányulóan végzett\ntudományos kutatás-fejlesztési tevékenységet azok forgalomba hozatalát vagy\nüzembe helyezését megelőzően. Ami az MI-rendszerekkel vagy -modellekkel\nkapcsolatos termékorientált kutatási, tesztelési és fejlesztési\ntevékenységeket illeti, e rendelet rendelkezései szintén nem alkalmazandók az\nemlített rendszerek és modellek forgalomba hozatalát vagy üzembe helyezését\nmegelőzően. Az említett kizárás nem érinti az e rendeletnek való megfelelésre\nvonatkozó kötelezettséget, amennyiben az e rendelet hatálya alá tartozó MI-\nrendszert ilyen kutatás-fejlesztési tevékenység eredményeként hozzák\nforgalomba vagy helyezik üzembe, valamint nem érinti az MI szabályozói\ntesztkörnyezetekre és a valós körülmények közötti tesztelésre vonatkozó\nrendelkezések alkalmazását. Továbbá, a kifejezetten tudományos kutatás-\nfejlesztés céljából kifejlesztett és üzembe helyezett MI-rendszerek\nkizárásának sérelme nélkül, minden egyéb olyan MI-rendszerre, amely kutatás-\nfejlesztési tevékenység végzésére használható, továbbra is e rendelet\nrendelkezéseinek kell vonatkozniuk. Mindenesetre bármely kutatás-fejlesztési\ntevékenységet a tudományos kutatásra vonatkozó elismert etikai és szakmai\nnormáknak megfelelően kell végezni, és az alkalmazandó uniós jognak\nmegfelelően kell folytatni. (26) Az MI-rendszerekre vonatkozó, kötelező erejű\nszabályok arányos és hatékony rendszerének bevezetése érdekében egyértelműen\nmeghatározott, kockázatalapú megközelítést kell alkalmazni. E megközelítés\nkeretében az ilyen szabályok típusát és tartalmát hozzá kell igazítani az MI-\nrendszerek által keltett kockázatok intenzitásához és nagyságrendjéhez. Ezért\nmeg kell tiltani bizonyos elfogadhatatlan MI-gyakorlatokat, míg a nagy\nkockázatú MI-rendszerekre vonatkozóan követelményeket, az érintett gazdasági\nszereplőkre vonatkozóan pedig kötelezettségeket kell megállapítani, valamint\nátláthatósági kötelezettségeket kell előírni bizonyos MI-rendszerek\ntekintetében. (27) Bár a kötelező erejű szabályok arányos és hatékony\nrendszerének alapját a kockázatalapú megközelítés képezi, fontos emlékeztetni\na Bizottság által kinevezett független magas szintű MI-szakértői csoport által\na megbízható mesterséges intelligenciára vonatkozóan 2019-ben kidolgozott\netikai iránymutatásokra. A magas szintű MI-szakértői csoport ezekben az\niránymutatásokban hét nem kötelező erejű etikai elvet dolgozott ki a\nmesterséges intelligenciára vonatkozóan, amelyek célja, hogy segítsék\nbiztosítani a mesterséges intelligencia megbízhatóságát és etikai\nmegalapozottságát. A hét elv a következő: emberi cselekvőképesség és\nfelügyelet; műszaki stabilitás és biztonság; a magánélet védelme és\nadatkormányzás; átláthatóság; sokszínűség, a megkülönböztetés tilalma és\nméltányosság; társadalmi és környezeti jóllét; valamint elszámoltathatóság. Az\nemlített iránymutatások - e rendelet jogilag kötelező érvényű követelményeinek\nés bármely egyéb alkalmazandó uniós jognak a sérelme nélkül - hozzájárulnak a\nkoherens, megbízható és emberközpontú mesterséges intelligenciának a Chartával\nés az Unió alapját képező értékekkel összhangban történő kidolgozásához. A\nmagas szintű MI-szakértői csoport iránymutatásai szerint az emberi\ncselekvőképesség és felügyelet azt jelenti, hogy az MI-rendszereket olyan\neszközként kell fejleszteni és használni, amely az embereket szolgálja,\ntiszteletben tartja az emberi méltóságot és a személyes autonómiát, és amely\núgy működik, hogy ember által megfelelő módon ellenőrizhető és felügyelhető\nlegyen. A műszaki stabilitás és biztonság azt jelenti, hogy az MI-rendszereket\núgy kell fejleszteni és használni, ami lehetővé teszi a stabilitást a\nproblémák esetén, és a rezilienciát az MI-rendszer használatának vagy\nteljesítményének a harmadik felek általi jogellenes felhasználás lehetővé\ntétele érdekében történő megváltoztatására irányuló kísérletekkel szemben,\ntovábbá a nem szándékos károkozás minimálisra csökkentését. A magánélet\nvédelme és az adatkormányzás azt jelenti, hogy az MI-rendszereket a magánélet\nvédelmére vonatkozó és az adatvédelmi szabályokkal összhangban kell\nfejleszteni és használni, miközben az adatok kezelésének magas szintű minőségi\nés integritási standardoknak kell megfelelnie. Az átláthatóság azt jelenti,\nhogy az MI-rendszereket olyan módon kell fejleszteni és használni, amely\nlehetővé teszi a megfelelő nyomonkövethetőséget és megmagyarázhatóságot,\nmiközben tudatosítja az emberekben, hogy MI-rendszerrel kommunikálnak vagy\nlépnek kapcsolatba, valamint megfelelően tájékoztatja az alkalmazókat az MI-\nrendszer képességeiről és korlátairól, az érintett személyeket pedig\njogaikról. A sokszínűség, a megkülönböztetés tilalma és a méltányosság azt\njelenti, hogy az MI-rendszereket úgy kell fejleszteni és használni, hogy abba\nbevonják a különböző szereplőket, valamint hogy annak során előmozdítják az\negyenlő hozzáférést, a nemek közötti egyenlőséget és a kulturális\nsokszínűséget, elkerülve mindeközben az uniós vagy a nemzeti jog által tiltott\ndiszkriminatív hatásokat és méltánytalan torzításokat. A társadalmi és\nkörnyezeti jóllét azt jelenti, hogy az MI-rendszereket fenntartható és\nkörnyezetbarát módon kell fejleszteni és használni, valamint úgy, hogy az\nminden ember javát szolgálja, figyelemmel kísérve és felmérve mindeközben az\negyénre, a társadalomra és a demokráciára gyakorolt hosszú távú hatásokat. Az\nemlített elvek alkalmazását lehetőség szerint át kell ültetni az MI-modellek\ntervezésébe és használatába. Azoknak minden esetben alapul kell szolgálniuk az\ne rendelet szerinti magatartási kódexek kidolgozásához. Valamennyi érdekelt\nfél - ideértve az ipart, a tudományos köröket, a civil társadalmat és a\nszabványügyi szervezeteket is - ösztönözve van arra, hogy az önkéntes legjobb\ngyakorlatok és szabványok kidolgozásához adott esetben vegye figyelembe az\netikai elveket. (28) A mesterséges intelligencia számos hasznos felhasználási\nmódja mellett, azt rendellenesen is fel lehet használni, valamint új és\nhatékony eszközöket biztosíthat manipulatív, kizsákmányoló és társadalmi\nellenőrzési gyakorlatokhoz. Az ilyen gyakorlatok különösen károsak és\nvisszaélésszerűek, és meg kell tiltani őket, mivel ellentétesek az emberi\nméltóság tiszteletben tartása, a szabadság, az egyenlőség, a demokrácia és a\njogállamiság uniós értékeivel, továbbá a Chartában rögzített alapvető\njogokkal, ideértve a megkülönböztetésmentességhez, az adatvédelemhez és a\nmagánélet tiszteletben tartásához való jogot, valamint a gyermek jogait is.\n(29) Az MI-n alapuló manipulatív technikák felhasználhatók arra, hogy nem\nkívánt magatartásformákra vegyék rá az embereket, vagy megtévesszék őket\nazáltal, hogy oly módon ösztönzik őket döntésekre, amely aláássa és csorbítja\nautonómiájukat, döntéshozatalukat és szabad választásukat. Az olyan MI-\nrendszerek forgalomba hozatala, üzembe helyezése vagy használata, amelyek\ncélja vagy hatása az emberi magatartás jelentős mértékű olyan torzítása, amely\nvalószínűleg jelentős károkkal, így különösen a testi, pszichológiai\negészségre vagy a pénzügyi érdekekre nézve kellően jelentős kedvezőtlen\nhatásokkal jár, rendkívül veszélyes, és ezért azt be kell tiltani. Az ilyen\nMI-rendszerek olyan szubliminális alkotóelemeket - például hang-, képi és\nvideoingereket - alkalmaznak, amelyeket a személyek nem képesek észlelni,\nmivel az említett ingerek túlmutatnak az emberi észlelésen, vagy más olyan\nmanipulatív vagy megtévesztő technikákat használnak, amelyek úgy ássák alá\nvagy csorbítják a személy autonómiáját, döntéshozatalát vagy szabad\nválasztását, hogy az említett technikáknak az emberek nincsenek tudatában,\nvagy ha tudatában vannak is azoknak, az embereket mégis megtéveszthetik, vagy\nnem képesek azokat irányítani, vagy azoknak ellenállni. Ezt elősegíthetik\npéldául a gép-agy interfészek vagy a virtuális valóság, mivel azok nagyobb\nfokú ellenőrzést tesznek lehetővé afelett, hogy milyen ingerek kerüljenek\nmegjelenítésre a személyeknek, amennyiben ezek az ingerek érdemben és\njelentősen káros módon torzíthatják viselkedésüket. Emellett az MI-rendszerek\nmás módon is kihasználhatják adott személynek vagy személyek egy adott\ncsoportjának az életkoruk, az (EU) 2019/882 európai parlamenti és tanácsi\nirányelv * értelmében vett fogyatékosságuk vagy olyan sajátos társadalmi vagy\ngazdasági helyzetük miatti sebezhetőségét, amely valószínűleg\nkiszolgáltatottabbá teszi őket - például a mélyszegénységben élőket, az\netnikai vagy vallási kisebbségeket - a kizsákmányolással szemben. Az ilyen MI-\nrendszerek forgalomba hozhatók, üzembe helyezhetők vagy felhasználhatók azzal\na céllal vagy azzal a hatással, hogy jelentősen torzítsák egy személy\nviselkedését, és oly módon, hogy az az említett személynek vagy egy másik\nszemélynek vagy személyek csoportjainak jelentős kárt okoz, vagy észszerű\nvalószínűséggel okozhat jelentős kárt, ideértve az idővel esetlegesen\nfelhalmozódó károkat is, és ezért azt be kell tiltani. Előfordulhat, hogy nem\nlehetséges a magatartás torzítására irányuló szándék vélelmezése, amikor a\ntorzulás az MI-rendszeren kívüli olyan tényezőkből ered, amelyek kívül esnek a\nszolgáltató vagy az alkalmazó befolyásán, nevezetesen olyan tényezőkből,\namelyek észszerűen nem előreláthatóak, és amelyeket ezért az MI-rendszer\nszolgáltatója vagy alkalmazója nem tud mérsékelni. Mindenesetre nem szükséges,\nhogy a szolgáltató vagy az alkalmazó szándékosan okozzon jelentős kárt,\nfeltéve, hogy az ilyen kár a manipulatív vagy kizsákmányoló MI-n alapuló\ngyakorlatokból ered. Az ilyen MI-gyakorlatokra vonatkozó tilalmak kiegészítik\na 2005/29/EK európai parlamenti és tanácsi irányelvben * foglalt\nrendelkezéseket, különösen azt, hogy a fogyasztóknak gazdasági vagy pénzügyi\nkárt okozó tisztességtelen kereskedelmi gyakorlatok minden körülmények között\ntilosak, függetlenül attól, hogy azokat MI-rendszereken keresztül vagy más\nmódon valósítják-e meg. A manipulatív és kizsákmányoló gyakorlatok e\nrendeletben foglalt tilalmai nem érinthetik a gyógykezelés - így például egy\nmentális betegség pszichológiai kezelése vagy a fizikai rehabilitáció - során\nalkalmazott jogszerű gyakorlatokat, amennyiben az említett gyakorlatokat az\nalkalmazandó joggal és orvosi normákkal - például az egyének vagy jogi\nképviselőik kifejezett hozzájárulásával - összhangban végzik. Emellett az\nalkalmazandó jognak megfelelő, általános és jogszerű kereskedelmi gyakorlatok\n- például a reklámok területén - önmagukban nem tekintendők káros manipulatív\nMI-n alapuló gyakorlatoknak. (30) Be kell tiltani a természetes személyek\nbiometrikus adatain - például adott személy arcán vagy ujjnyomatán - alapuló\nolyan biometrikus kategorizálási rendszereket, amelyek célja, hogy levezessék\nvagy kikövetkeztessék adott egyének politikai véleményét, szakszervezeti\ntagságát, vallási vagy világnézeti meggyőződését, faji hovatartozását,\nszexuális életét vagy szexuális irányultságát. Az említett tilalom nem\nterjedhet ki az uniós vagy nemzeti joggal összhangban beszerzett biometrikus\nadatkészletek biometrikus adatok szerint történő jogszerű címkézésére,\nszűrésére vagy kategorizálására, például képek hajszín vagy szemszín szerinti\nválogatására, ami felhasználható például a bűnüldözés területén. (31) A\ntermészetes személyek állami vagy magánszereplők általi társadalmi pontozását\nvégző MI-rendszerek diszkriminatív eredményekhez és bizonyos csoportok\nkirekesztéséhez vezethetnek. Az ilyen rendszerek sérthetik a méltósághoz való\njogot és a megkülönböztetés tilalmát, valamint az egyenlőség és az\nigazságosság értékeit. Az ilyen MI-rendszerek a természetes személyeket vagy\nazok csoportjait a különböző körülmények között tanúsított közösségi\nmagatartásukhoz, illetve ismert, kikövetkeztetett vagy előre jelzett személyes\ntulajdonságaikhoz vagy személyiségjegyeikhez társított több adatpont alapján\nértékelik vagy osztályozzák bizonyos időszakokon keresztül. Az ilyen MI-\nrendszerek által adott társadalmi pontszám a természetes személyekkel vagy\nazok egész csoportjával szembeni hátrányos vagy kedvezőtlen bánásmódhoz\nvezethet olyan társadalmi kontextusokban, amelyek nem függenek össze azzal a\nkontextussal, amelyben az adatok létrehozása vagy gyűjtése történt, vagy olyan\nhátrányos bánásmódot okozhat, amely az adott személyek közösségi\nmagatartásának súlyosságához képest aránytalan vagy indokolatlan. Az ilyen\nelfogadhatatlan pontozási gyakorlatokat alkalmazó és ilyen hátrányos vagy\nkedvezőtlen eredményekhez vezető MI-rendszereket ezért be kell tiltani. Az\nemlített tilalom nem érintheti a természetes személyek azon jogszerű\nértékelési gyakorlatát, amelyet konkrét célból, az uniós és a nemzeti joggal\nösszhangban végeznek. (32) Az MI-rendszereknek természetes személyek „valós\nidejű” távoli biometrikus azonosítására, a nyilvánosság számára hozzáférhető\nhelyeken, bűnüldözés céljából történő használata különösen tolakodó az\nérintett személyek jogaira és szabadságaira nézve, mivel hatással lehet a\nlakosság nagy részének magánéletére, az állandó megfigyelés érzetét keltheti,\nés közvetve visszatarthat a gyülekezési szabadság és más alapvető jogok\ngyakorlásától. A természetes személyek távoli biometrikus azonosítására\nszolgáló MI-rendszerek technikai pontatlansága torzított eredményekhez\nvezethet, és diszkriminatív hatásokat eredményezhet. Az ilyen torzított\neredmények és diszkriminatív hatások különösen relevánsak az életkor, az\netnikai és a faji hovatartozás, a nem vagy a fogyatékosságok tekintetében.\nEzenkívül a hatás azonnali jellege és az ilyen „valós időben” működő\nrendszerek használatával kapcsolatos további ellenőrzések vagy korrekciók\nkorlátozott lehetőségei fokozott kockázatot jelentenek az érintett személyek\njogaira és szabadságaira nézve a bűnüldözési tevékenységekkel összefüggésben\nvagy azok hatása miatt. (33) E rendszerek bűnüldözési célú használatát ezért\nmeg kell tiltani, kivéve az olyan, kimerítő jelleggel felsorolt és szűken\nmeghatározott helyzeteket, amelyekben a használat feltétlenül szükséges egy\nolyan jelentős közérdek érvényesítéséhez, amelynek fontossága meghaladja a\nkockázatokat. Az említett helyzetek közé tartozik a bűncselekmények bizonyos\náldozatainak, köztük az eltűnt személyeknek a felkutatása; a természetes\nszemélyek életét vagy fizikai biztonságát fenyegető bizonyos veszélyek vagy a\nterrortámadás veszélye; valamint az e rendelet egyik mellékletében felsorolt\nbűncselekmények elkövetőinek vagy gyanúsítottjainak a lokalizálása vagy\nazonosítása, amennyiben az említett bűncselekmények esetében az érintett\ntagállamban a büntetési tétel felső határa legalább négyévi szabadságvesztés\nvagy szabadságelvonással járó intézkedés, és ahogyan az említett\nbűncselekményeket az említett tagállam joga meghatározza. A szabadságvesztés\nvagy szabadságelvonással járó intézkedés nemzeti joggal összhangban álló e\nküszöbértéke hozzájárul annak biztosításához, hogy a bűncselekmény kellően\nsúlyos legyen ahhoz, hogy potenciálisan indokolhassa a „valós idejű” távoli\nbiometrikus azonosító rendszerek használatát. Ezenfelül az e rendelet egyik\nmellékletében foglalt bűncselekménylista a 2002/584/IB tanácsi\nkerethatározatban * felsorolt 32 bűncselekményen alapul, figyelembe véve azt,\nhogy az említett bűncselekmények közül néhány a gyakorlatban valószínűleg\nrelevánsabb, mint mások, azaz a „valós idejű” távoli biometrikus azonosítás\nalkalmazása előreláthatóan rendkívül eltérő mértékben szükséges és arányos\neszköz lehet a felsorolt különböző bűncselekmények elkövetőinek vagy\ngyanúsítottjainak lokalizálására vagy azonosítására irányuló gyakorlati\nlépések tekintetében, továbbá figyelemmel a kár vagy az esetleges negatív\nkövetkezmények súlyossága, valószínűsége és mértéke terén fennálló\nvalószínűsíthető különbségekre. Természetes személyek életét vagy testi\nbiztonságát fenyegető közvetlen veszély az (EU) 2022/2557 európai parlamenti\nés tanácsi irányelv * 2. cikkének 4. pontjában meghatározottak szerinti\nkritikus infrastruktúrát érintő súlyos zavarokból is fakadhat, amennyiben az\nilyen kritikus infrastruktúra megzavarása vagy megsemmisítése közvetlen\nveszélyt jelentene egy személy életére vagy testi biztonságára, többek között\naz alapvető ellátások lakosság számára történő biztosítására vagy az állam\nalapvető funkciói gyakorlására gyakorolt súlyos kár révén. Emellett e\nrendeletnek fenn kell tartania a bűnüldöző, határellenőrzési, bevándorlási\nvagy menekültügyi hatóságok azon képességét, hogy az érintett személy\njelenlétében személyazonosság-ellenőrzést végezzenek az ilyen ellenőrzésekre\nvonatkozóan az uniós és a nemzeti jogban meghatározott feltételekkel\nösszhangban. Így különösen, lehetővé kell tenni a bűnüldöző, határellenőrzési,\nbevándorlási vagy menekültügyi hatóságok számára, hogy - anélkül, hogy e\nrendelet előzetes engedély beszerzésére kötelezné őket -, az uniós vagy a\nnemzeti joggal összhangban információs rendszereket használjanak azon\nszemélyek azonosítására, akik a személyazonosság-ellenőrzés során vagy\nmegtagadják az azonosítást, vagy képtelenek nyilatkozni személyazonosságukról\nvagy igazolni azt. Ez lehet például olyan, bűncselekményben érintett személy,\naki a bűnüldöző hatóságoknak nem hajlandó felfedni a személyazonosságát, vagy\naki baleset vagy egészségi állapota miatt képtelen erre. (34) Annak érdekében,\nhogy e rendszerek használata felelős és arányos módon történjen, azt is fontos\nmegállapítani, hogy e kimerítő jelleggel felsorolt és szűken meghatározott\nhelyzetek mindegyikében figyelembe kell venni bizonyos tényezőket, különösen a\nkérelem alapjául szolgáló helyzet jellegét és a használat valamennyi érintett\nszemély jogaira és szabadságaira gyakorolt következményeit, valamint a\nhasználathoz előírt biztosítékokat és feltételeket. Ezen túlmenően a „valós\nidejű” távoli biometrikus azonosító rendszerek nyilvánosság számára\nhozzáférhető helyeken, bűnüldözés céljából történő használata kizárólag a\nkonkrét célszemély személyazonosságának megerősítése érdekében indítható el,\nés azt az időtartam, valamint a földrajzi és személyi hatály tekintetében a\nfeltétlenül szükséges mértékre kell korlátozni, különös tekintettel a\nfenyegetésekkel, az áldozattokkal vagy az elkövetőkkel kapcsolatos\nbizonyítékokra vagy jelzésekre. A valós idejű távoli biometrikus azonosító\nrendszerek nyilvánosság számára hozzáférhető helyeken történő használata csak\nakkor engedélyezhető, ha a releváns bűnüldöző hatóság elvégezte az\nalapvetőjogi hatásvizsgálatot, és - amennyiben e rendelet másként nem\nrendelkezik - nyilvántartásba vette a rendszert az e rendeletben meghatározott\nadatbázisban. A személyek referencia-adatbázisának a fent említett helyzetek\nmindegyikében megfelelőnek kell lennie minden egyes felhasználási eset\nvonatkozásában. (35) A „valós idejű” távoli biometrikus azonosító rendszerek\nnyilvánosság számára hozzáférhető helyeken, bűnüldözés céljából történő\nhasználatához minden esetben valamely tagállam igazságügyi hatóságának vagy\nfüggetlen közigazgatási hatóságának kifejezett és egyedi engedélye szükséges,\namelynek határozata kötelező érvényű. Az ilyen engedélyt elvben az MI-rendszer\negy vagy több személy azonosítása céljából történő használata előtt kell\nbeszerezni. Az említett szabály alól sürgősségi alapon kivételt lehet tenni\nkellően indokolt esetekben, nevezetesen olyan esetekben, amikor az érintett\nrendszerek használatának szükségessége ténylegesen és objektíve lehetetlenné\nteszi az engedély megszerzését az MI-rendszer használatának megkezdése előtt.\nAz ilyen sürgős helyzetekben az MI-rendszer használatát a feltétlenül\nszükséges minimumra kell korlátozni, és arra a nemzeti jogban megállapított és\nmaga a bűnüldöző hatóság által az egyes sürgős felhasználási esetek kapcsán\nmeghatározott megfelelő biztosítékokat és feltételeket kell alkalmazni. Ezen\ntúlmenően a bűnüldöző hatóságnak ilyen helyzetekben indokolatlan késedelem\nnélkül és legkésőbb 24 órán belül kérelmeznie kell az engedélyt, és egyúttal\nmeg kell indokolnia, hogy miért nem volt lehetősége arra, hogy azt korábban\nmegkérje. Ilyen engedély megtagadása esetén a valós idejű biometrikus\nazonosító rendszereknek az adott engedélyhez kapcsolódó használatát azonnali\nhatállyal le kell állítani, és az e használathoz kapcsolódó valamennyi adatot\nel kell vetni és törölni kell. Az ilyen adatok magukban foglalják a valamely\nMI-rendszer által az említett rendszer használata során közvetlenül szerzett\nbemeneti adatokat, valamint az említett engedélyhez kapcsolódó használat\neredményeit és kimeneteit. Nem foglalják magukban a valamely más uniós vagy\nnemzeti jogszabállyal összhangban jogszerűen szerzett bemeneteket. Kizárólag a\ntávoli biometrikus azonosító rendszer kimenete alapján semmi esetre sem\nhozható olyan döntés, amely egy személyre nézve kedvezőtlen joghatással jár.\n(36) Annak érdekében, hogy az érintett piacfelügyeleti hatóság és a nemzeti\nadatvédelmi hatóság az e rendeletben meghatározott követelményekkel és a\nnemzeti szabályokkal összhangban elláthassa feladatait, e hatóságokat\nértesíteni kell a valós idejű biometrikus azonosító rendszer minden egyes\nhasználatáról. Azon piacfelügyeleti hatóságoknak és nemzeti adatvédelmi\nhatóságoknak, amelyek értesítést kaptak, évente jelentést kell benyújtaniuk a\nBizottságnak a valós idejű biometrikus azonosító rendszerek használatáról.\n(37) Továbbá, helyénvaló - az e rendeletben meghatározott kimerítő keretek\nközött - előírni, hogy az ilyen használat egy tagállam területén e rendelettel\nösszhangban csak akkor és annyiban legyen lehetséges, ha és amennyiben az\nérintett tagállam úgy határozott, hogy nemzeti jogának részletes szabályaiban\nkifejezetten rendelkezik az ilyen használat engedélyezésének lehetőségéről.\nKövetkezésképpen a tagállamok e rendelet értelmében továbbra is szabadon\ndönthetnek arról, hogy egyáltalán nem, vagy csak az e rendeletben\nmeghatározott engedélyezett használat indokolására alkalmas bizonyos\ncélkitűzések tekintetében rendelkeznek ilyen lehetőségről. Az ilyen nemzeti\nszabályokról az elfogadásuktól számított 30 napon belül értesíteni kell a\nBizottságot. (38) Az MI-rendszerek természetes személyek valós idejű távoli\nbiometrikus azonosítására, a nyilvánosság számára hozzáférhető helyeken,\nbűnüldözés céljából történő használata szükségszerűen magában foglalja\nbiometrikus adatok feldolgozását. E rendelet azon, az EUMSZ 16. cikkén alapuló\nszabályait, amelyek - bizonyos kivételekre is figyelemmel - tiltják az ilyen\nhasználatot, lex specialis-ként kell alkalmazni az (EU) 2016/680 irányelv 10.\ncikkében foglalt, a biometrikus adatok kezelésére vonatkozó szabályok\ntekintetében, ennélfogva ezek kimerítően szabályozzák az ilyen használatot és\naz érintett biometrikus adatok kezelését. Ezért az ilyen használat és\nadatkezelés csak annyiban lehetséges, amennyiben összeegyeztethető az e\nrendeletben meghatározott kerettel, és nincs lehetőség arra, hogy e kereten\nkívül az illetékes hatóságok - amennyiben bűnüldözési célból járnak el - az\n(EU) 2016/680 irányelv 10. cikkében felsorolt okokból használják az ilyen\nrendszereket és kezeljék a kapcsolódó adatokat. Ebben az összefüggésben e\nrendeletnek nem célja, hogy jogalapot biztosítson a személyes adatoknak az\n(EU) 2016/680 irányelv 8. cikke szerinti kezeléséhez. A valós idejű távoli\nbiometrikus azonosító rendszerek nyilvánosság számára hozzáférhető helyeken,\nbűnüldözési céloktól eltérő célokra történő, többek között az illetékes\nhatóságok általi használatára azonban nem terjedhet ki az e rendeletben\nmeghatározott, a bűnüldözési célú használatra vonatkozó különös keret. Az\nilyen, nem bűnüldözési célú használat ezért nem köthető az e rendelet\nszerinti, engedéllyel kapcsolatos követelményhez és a nemzeti jog azon\nalkalmazandó, részletes szabályaihoz, amelyek az említett engedélyt érvényre\njuttathatják. (39) A biometrikus adatok és az MI-rendszerek biometrikus\nazonosítás céljából történő használatával érintett egyéb személyes adatok\nkezelésének - a valós idejű távoli biometrikus azonosító rendszerek\nnyilvánosság számára hozzáférhető helyeken, bűnüldözési célból történő, e\nrendeletben szabályozott használatával összefüggő adatkezelés kivételével -\ntovábbra is meg kell felelnie az (EU) 2016/680 irányelv 10. cikkéből eredő\nvalamennyi követelménynek. A bűnüldözéstől eltérő célok esetében az (EU)\n2016/679 rendelet 9. cikkének (1) bekezdése és az (EU) 2018/1725 rendelet 10.\ncikkének (1) bekezdése az említett cikkekben meghatározott korlátozott körű\nkivételek mellett tiltja a biometrikus adatok kezelését. Az (EU) 2016/679\nrendelet 9. cikke (1) bekezdésének alkalmazásában nemzeti adatvédelmi\nhatóságok már hoztak a távoli biometrikus azonosítás bűnüldözéstől eltérő\ncélokra történő használatának tiltására vonatkozó határozatokat. (40) Az EUSZ-\nhez és az EUMSZ-hez csatolt, az Egyesült Királyságnak és Írországnak a\nszabadságon, a biztonságon és a jog érvényesülésén alapuló térség tekintetében\nfennálló helyzetéről szóló 21. jegyzőkönyv 6a. cikkével összhangban Írországot\nnem kötelezik az EUMSZ 16. cikke alapján elfogadott, az e rendelet 5. cikke\n(1) bekezdése első albekezdésének g) pontjában - amennyiben az a biometrikus\nkategorizálási rendszereknek a büntetőügyekben folytatott rendőrségi és\nigazságügyi együttműködés területén végzett tevékenységek céljára történő\nhasználatára alkalmazandó -, 5. cikke (1) bekezdése első albekezdésének d)\npontjában - amennyiben az az említett rendelkezés hatálya alá tartozó MI-\nrendszerek használatára alkalmazandó -, 5. cikke (1) bekezdése, első\nalbekezdésének h) pontjában, 5. cikkének (2)-(6) bekezdésében és 26. cikkének\n(10) bekezdésében meghatározott azon szabályok, amelyek a személyes adatoknak\na tagállamok által, az EUMSZ harmadik része V. címe 4. vagy 5. fejezetének\nalkalmazási körébe tartozó tevékenységek során végzett kezelésére vonatkoznak,\namennyiben Írországot nem kötelezik a büntetőügyekben folytatott igazságügyi\negyüttműködés vagy rendőrségi együttműködés formáira vonatkozó olyan\nszabályok, amelyek megkívánják az EUMSZ 16. cikke alapján meghatározott\nrendelkezések betartását. (41) Az EUSZ-hez és az EUMSZ-hez csatolt, Dánia\nhelyzetéről szóló 22. jegyzőkönyv 2. és 2a. cikkével összhangban Dániára nézve\nnem kötelezőek és nem alkalmazandók az EUMSZ 16. cikke alapján elfogadott, az\ne rendelet 5. cikke (1) bekezdése első albekezdésének g) pontjában -\namennyiben az a biometrikus kategorizálási rendszereknek a büntetőügyekben\nfolytatott rendőrségi és igazságügyi együttműködés területén végzett\ntevékenységek céljára történő használatára alkalmazandó -, 5. cikke (1)\nbekezdése első albekezdésének d) pontjában - amennyiben az az említett\nrendelkezés hatálya alá tartozó MI-rendszerek használatára alkalmazandó -, 5.\ncikke (1) bekezdése első albekezdésének h) pontjában, 5. cikkének (2)-(6)\nbekezdésében és 26. cikkének (10) bekezdésében meghatározott azon szabályok,\namelyek a személyes adatoknak a tagállamok által, az EUMSZ harmadik része V.\ncíme 4. vagy 5. fejezetének alkalmazási körébe tartozó tevékenységek során\nvégzett kezelésére vonatkoznak. (42) Az ártatlanság vélelmével összhangban az\nUnióban természetes személyekre vonatkozó döntés minden esetben kizárólag e\nszemélyek tényleges magatartása alapján hozható. Természetes személyekre\nvonatkozó döntés soha nem hozható kizárólag a rájuk vonatkozó profilalkotás,\nszemélyiségjegyek vagy tulajdonságok - mint például állampolgárság, születési\nhely, tartózkodási hely, gyermekek száma, adósságszint vagy gépjármű típusa -\nalapján MI által előre jelzett magatartás alapján, az adott személy\nbűncselekményben való részvételére vonatkozó, objektív és ellenőrizhető\ntényeken nyugvó alapos gyanú nélkül, valamint ezek ember általi értékelése\nnélkül. Ezért meg kell tiltani a természetes személyekre vonatkozó olyan\nkockázatértékeléseket, amelyek célja az általuk történő elkövetés\nvalószínűségének értékelése vagy egy tényleges vagy potenciális bűncselekmény\nbekövetkezésének az előrejelzése kizárólag az e személyekre vonatkozó\nprofilalkotás vagy személyiségjegyeik vagy tulajdonságaik értékelése alapján.\nEz a tilalom semmi esetre sem vonatkozik az olyan kockázatelemzésekre, illetve\nnem érinti azokat, amelyek nem az egyénekre vonatkozó profilalkotáson vagy\negyének személyiségjegyein vagy tulajdonságain alapulnak, így például azon MI-\nrendszerekre, amelyek kockázatelemzést használnak a vállalkozások általi\npénzügyi csalás valószínűségének gyanús tranzakciók alapján történő\nértékelésére, vagy az olyan kockázatelemzési eszközökre, amelyekkel például az\nismert csempészútvonalak alapján előre jelezhető, hogy a vámhatóságok milyen\nvalószínűséggel tudják meghatározni kábítószerek vagy tiltott áruk helyét.\n(43) Az arcképek internetről vagy zártláncú televízió-felvételekből való, nem\ncélzott lekérdezésével arcfelismerő adatbázisokat létrehozó vagy ilyeneket\nbővítő MI-rendszerek forgalomba hozatalát, e konkrét célra történő üzembe\nhelyezését vagy használatát tiltani kell, mivel e gyakorlat növeli a tömeges\nmegfigyelés érzését, és az alapvető jogok, többek között a magánélet\ntiszteletben tartásához való jog súlyos megsértéséhez vezethet. (44) Az\nérzelmek azonosítását vagy az azokra való következtetést célzó MI-rendszerek\ntudományos alapjával kapcsolatban komoly aggályok merültek fel, különösen\nazért, mert az érzelmek kifejezése jelentősen eltér egymástól kultúránként és\nhelyzetenként, sőt akár egyetlen személy esetében is. Az ilyen rendszerek fő\nhiányosságai közé tartozik a korlátozott megbízhatóság, a specifikusság\nhiánya, valamint a korlátozott általánosíthatóság. Ezért az olyan MI-\nrendszerek, amelyek természetes személyek biometrikus adatai alapján\nazonosítják a természetes személyek érzelmeit vagy szándékait, illetve\nkövetkeztetnek azokra, diszkriminatív eredményekhez vezethetnek és tolakodóak\nlehetnek az érintett személyek jogaira és szabadságaira nézve. Tekintettel\narra, hogy a munka vagy az oktatás területén az erőviszonyok\nkiegyensúlyozatlanok, amihez e rendszerek tolakodó jellege társul, az ilyen\nrendszerek bizonyos természetes személyekkel vagy azok egész csoportjával\nszemben hátrányos vagy kedvezőtlen bánásmódhoz vezethetnek. Ezért a\nmunkahelyhez és az oktatáshoz kapcsolódó helyzetek összefüggésében meg kell\ntiltani az egyének érzelmi állapotának felderítésére szánt MI-rendszerek\nforgalomba hozatalát, üzembe helyezését, illetve használatát. Ez a tilalom nem\nterjedhet ki a szigorúan orvosi vagy biztonsági okokból forgalomba hozott,\npéldául a terápiás használatra szánt MI-rendszerekre. (45) E rendelet nem\nérintheti azon gyakorlatokat, amelyeket az uniós jog - többek között az\nadatvédelmi jog, a megkülönböztetésmentességre vonatkozó jog, a\nfogyasztóvédelmi jog és a versenyjog - tilt. (46) A nagy kockázatú MI-\nrendszerek csak akkor hozhatók forgalomba az Unión belül, helyezhetők üzembe\nvagy használhatók, ha megfelelnek bizonyos kötelező követelményeknek. E\nkövetelményeknek biztosítaniuk kell, hogy azon nagy kockázatú MI-rendszerek,\namelyek az Unióban rendelkezésre állnak vagy amelyek kimenetét más módon\nfelhasználják az Unióban, ne jelentsenek elfogadhatatlan kockázatot az uniós\njog által elismert és védett fontos uniós közérdekekre nézve. Az új\njogszabályi keret alapján, amint azt a termékekre vonatkozó uniós\nszabályozásról szóló, 2022. évi bizottsági útmutató - „A kék útmutató” * -\nkifejti, főszabály szerint az uniós harmonizációs jogalkotás több jogi aktusa\n- így például az (EU) 2017/745 * és az (EU) 2017/746 európai parlamenti és\ntanácsi rendelet * vagy a 2006/42/EK európai parlamenti és tanácsi irányelv *\n- is alkalmazható egyetlen termékre, mivel a forgalmazásra vagy az üzembe\nhelyezésre csak akkor kerülhet sor, ha a termék megfelel valamennyi\nalkalmazandó uniós harmonizációs jogszabálynak. A következetesség biztosítása\nés a szükségtelen adminisztratív terhek vagy költségek elkerülése érdekében az\nolyan termék szolgáltatóinak, amely egy vagy több olyan, nagy kockázatú MI-\nrendszert tartalmaz, amelyre az e rendeletben és az e rendelet egyik\nmellékletében felsorolt uniós harmonizációs jogszabályokban foglalt\nkövetelmények alkalmazandók, rugalmassággal kell rendelkezniük azon működési\ndöntések tekintetében, hogy miként biztosítsák optimális módon az egy vagy\ntöbb MI-rendszert tartalmazó termék megfelelését az uniós harmonizációs\njogszabályokban foglalt valamennyi alkalmazandó követelménynek. A nagy\nkockázatúként azonosított MI-rendszereket azon rendszerekre kell limitálni,\namelyek jelentős káros hatást gyakorolnak az Unióban élő személyek\negészségére, biztonságára és alapvető jogaira, és az ilyen limitálásnak\nminimálisra kell csökkentenie a nemzetközi kereskedelem potenciális\nkorlátozását. (47) Az MI-rendszerek kedvezőtlen hatással lehetnek a személyek\negészségére és biztonságára, különösen akkor, ha az ilyen rendszerek termékek\nbiztonsági alkotórészeiként működnek. Az uniós harmonizációs jogszabályok azon\ncélkitűzéseivel összhangban, hogy megkönnyítsék a termékek belső piacon való\nszabad mozgását, valamint biztosítsák, hogy csak biztonságos és más\ntekintetben megfelelő termékek kerüljenek a piacra, fontos a termék egésze\náltal a digitális alkotóelemei, többek között az MI-rendszerek miatt\nesetlegesen előidézett biztonsági kockázatok megfelelő megelőzése és\nenyhítése. Például az - akár gyártással, akár személyes segítségnyújtással és\ngondozással összefüggésben használt - egyre önállóbb robotoknak képeseknek\nkell lenniük arra, hogy biztonságosan működjenek és funkcióikat összetett\nkörnyezetben lássák el. Hasonlóképpen az egészségügyi ágazatban, ahol az élet\nés az egészség tekintetében különösen nagy a tét, az egyre kifinomultabb\ndiagnosztikai rendszereknek és az emberi döntéseket támogató rendszereknek\nmegbízhatónak és pontosnak kell lenniük. (48) A Charta által védett alapvető\njogokra az MI-rendszer által gyakorolt kedvezőtlen hatás mértéke különösen\nfontos egy adott MI-rendszer nagy kockázatúként való besorolásakor. Az\nemlített jogok közé tartozik az emberi méltósághoz való jog, a magán- és\ncsaládi élet tiszteletben tartása, a személyes adatok védelme, a\nvéleménynyilvánítás és a tájékozódás szabadsága, a gyülekezés és az egyesülés\nszabadsága, a megkülönböztetésmentességhez való jog, az oktatáshoz való jog, a\nfogyasztóvédelem, a munkavállalók jogai, a fogyatékossággal élő személyek\njogai, a nemek közötti egyenlőség, a szellemitulajdon-jogok, a hatékony\njogorvoslathoz és a tisztességes eljáráshoz való jog, a védelemhez való jog és\naz ártatlanság vélelme, valamint a megfelelő ügyintézéshez való jog. Az\nemlített jogok mellett fontos kiemelni azon tényt, hogy a gyermekek a Charta\n24. cikkében és az Egyesült Nemzetek Szervezetének a gyermekek jogairól szóló\negyezményében foglalt - a gyermek jogairól szóló ENSZ-egyezmény digitális\nkörnyezetre vonatkozó 25. sz. általános észrevételében részletesebben\nkifejtett - különös jogokkal rendelkeznek; mindkét okmány előírja a gyermekek\nsebezhetőségének figyelembevételét, valamint a jóllétükhöz szükséges védelem\nés gondoskodás biztosítását. Azon kár súlyosságának értékelésekor, amelyet egy\nMI-rendszer tud okozni, figyelembe kell venni a magas szintű\nkörnyezetvédelemhez való, a Chartában rögzített és az uniós szakpolitikákban\nvégrehajtott alapvető jogot is, többek között a személyek egészségével és\nbiztonságával kapcsolatban. (49) Azon nagy kockázatú MI-rendszerek\ntekintetében, amelyek a 300/2008/EK európai parlamenti és tanácsi rendelet * ,\na 167/2013/EU európai parlamenti és tanácsi rendelet * , a 168/2013/EU európai\nparlamenti és tanácsi rendelet * , a 2014/90/EU európai parlamenti és tanácsi\nirányelv * , az (EU) 2016/797 európai parlamenti és tanácsi irányelv * , az\n(EU) 2018/858 európai parlamenti és tanácsi rendelet * , az (EU) 2018/1139\neurópai parlamenti és tanácsi rendelet * , valamint az (EU) 2019/2144 európai\nparlamenti és tanácsi rendelet * hatálya alá tartozó termékek vagy rendszerek\nbiztonsági alkotórészei, vagy amelyek maguk ilyen termékek vagy rendszerek,\nhelyénvaló e jogi aktusokat módosítani annak érdekében, hogy a Bizottság - az\negyes ágazatok műszaki és szabályozási sajátosságai alapján, és anélkül, hogy\nbeavatkozna az említett jogszabályokkal létrehozott meglévő irányítási,\nmegfelelőségértékelési és végrehajtási mechanizmusokba és hatóságok működésébe\n- figyelembe vegye a nagy kockázatú MI-rendszerekre e rendeletben\nmegállapított kötelező követelményeket, amikor ezen jogi aktusok alapján\nreleváns, felhatalmazáson alapuló vagy végrehajtási jogi aktusokat fogad el.\n(50) Az olyan MI-rendszereket, amelyek az e rendelet egyik mellékletében\nfelsorolt egyes uniós harmonizációs jogszabályok hatálya alá tartozó termékek\nbiztonsági alkotórészei, vagy amelyek maguk ilyen jogszabályok hatálya alá\ntartozó termékek, helyénvaló e rendelet értelmében nagy kockázatúnak\nminősíteni, ha az érintett terméket a vonatkozó uniós harmonizációs jogszabály\nértelmében valamely harmadik félnek minősülő megfelelőségértékelő szervezet\náltal lefolytatott megfelelőségértékelési eljárás alá vonják. Így különösen,\nilyen termékek a gépek, a játékok, a felvonók, a robbanásveszélyes légkörben\nvaló használatra szánt felszerelések és a védelmi rendszerek, a\nrádióberendezések, a nyomástartó berendezések, a kedvtelési célú vízi járművek\nberendezései, a kötélpálya-létesítmények, a gázüzemű berendezések, az\norvostechnikai eszközök, az in vitro diagnosztikai orvostechnikai eszközök, a\ngépjárművek és a légi járművek. (51) Az MI-rendszerek e rendelet szerint nagy\nkockázatú rendszerként való besorolása nem feltétlenül jelenti azt, hogy azon\ntermék, amelynek biztonsági alkotórésze az MI-rendszer vagy maga az MI-\nrendszer mint termék, a termékre alkalmazandó vonatkozó uniós harmonizációs\njogszabályokban megállapított kritériumok alapján nagy kockázatúnak minősül.\nEz különösen igaz az (EU) 2017/745 és az (EU) 2017/746 európai parlamenti és\ntanácsi rendeletre, amelyek a közepes és a nagy kockázatú termékek\ntekintetében írnak elő harmadik fél általi megfelelőségértékelést. (52) Az\nönálló MI-rendszereket, nevezetesen azon nagy kockázatú MI-rendszereket,\namelyek nem termékek biztonsági alkotórészei, vagy amelyek nem maguk is\ntermékek, helyénvaló nagy kockázatúnak minősíteni, ha rendeltetésük fényében\nnagy károkozó kockázatot jelentenek a személyek egészségére és biztonságára\nvagy alapvető jogaira nézve, figyelembe véve a lehetséges kár súlyosságát és\nbekövetkezési valószínűségét, és ha azokat számos, az e rendeletben megadott,\nkifejezetten előre meghatározott területen használják. E rendszerek\nazonosítása ugyanazon módszertanon és kritériumokon alapul, amelyeket\nelőirányoztak a nagy kockázatú MI-rendszerek listájának azon jövőbeli\nmódosításaira is, amelyeknek a technológiai fejlődés gyors üteme, valamint az\nMI-rendszerek használatában bekövetkező lehetséges változások figyelembevétele\nérdekében történő, felhatalmazáson alapuló jogi aktusok révén való\nelfogadására a Bizottságot fel kell hatalmazni. (53) Azt is fontos tisztázni,\nhogy lehetnek olyan konkrét esetek, amikor az e rendeletben megadott előre\nmeghatározott területeket érintő MI-rendszerek nem járnak a kár jelentős\nkockázatával az említett területeken védett jogi érdekekre nézve, mert nem\nbefolyásolják jelentősen a döntéshozatalt, vagy nem sértik érdemben az\nemlített érdekeket. E rendelet alkalmazásában a döntéshozatal kimenetelét\njelentősen nem befolyásoló MI-rendszerek alatt olyan MI-rendszereket kell\nérteni, amelyek nem gyakorolnak hatást az - akár emberi, akár automatizált -\ndöntéshozatal érdemére és ezáltal kimenetelére nézve. A döntéshozatal\nkimenetelét jelentősen nem befolyásoló MI-rendszerek olyan helyzeteket\nfoglalhatnak magukban, amelyekben a következő feltételek közül egy vagy több\nteljesül. Az első ilyen feltétel az, hogy az MI-rendszer rendeltetése jól\nkörülhatárolt eljárási feladat ellátása legyen, mint például az olyan MI-\nrendszerek esetében, amelyek a strukturálatlan adatokat strukturált adatokká\nalakítják át, amelyek kategóriákba rendezik a beérkező dokumentumokat vagy\namelyeket nagyszámú beérkező dokumentum közötti ismétlődések kiszűrésére\nhasználnak. Az említett feladatok jellege olyan szűk és korlátozott, hogy csak\nkorlátozott kockázatokat jelentenek, amelyeket nem súlyosbít egy MI-\nrendszernek az e rendelet egyik mellékletében nagy kockázatú felhasználásként\nfelsorolt összefüggésben történő használata. A második feltétel az, hogy az\nMI-rendszer által ellátott feladat az e rendelet egyik mellékletében felsorolt\nnagy kockázatú felhasználások céljai szempontjából esetlegesen releváns,\nkorábban elvégzett emberi tevékenység eredményének a javítását célozza.\nTekintettel e jellemzőkre, az MI-rendszer kizárólag egy további réteget\nbiztosít az emberi tevékenységhez, ami következésképpen csökkenti a\nkockázatot. Az említett feltétel volna alkalmazandó például az olyan MI-\nrendszerekre, amelyek rendeltetése korábban megszövegezett dokumentumok\nnyelvezetének javítása például a professzionális hangnem, a tudományos nyelvi\nregiszter vagy a szövegnek egy bizonyos márkaüzenettel való összehangolása\ntekintetében. A harmadik feltétel az, hogy az MI-rendszer rendeltetése\ndöntéshozatali minták vagy korábbi döntéshozatali mintáktól való eltérések\nészlelése legyen. A kockázat azért csökkenne, mert az MI-rendszer használata\nkorábban elvégzett emberi értékelést követne, és nem lenne a célja annak\nkiváltása vagy befolyásolása megfelelő emberi felülvizsgálat nélkül. Az ilyen\nMI-rendszerek közé tartoznak például azok, amelyek használhatók lennének arra,\nhogy egy tanár osztályozási szokásaiban fennálló minta alapján utólagosan\nellenőrizzék, hogy a tanár eltért-e az osztályozási mintájától, és jelezzék az\nesetleges következetlenségeket vagy eltéréseket. A negyedik feltétel az, hogy\naz MI-rendszer rendeltetése olyan feladat ellátása legyen, amely pusztán az e\nrendelet egyik mellékletében felsorolt MI-rendszerek céljai szempontjából\nreleváns értékelés előkészítését szolgálja, aminél fogva a rendszer kimenetére\ngyakorolt lehetséges hatás az elvégzendő értékelésre nézve jelentett kockázat\ntekintetében nagyon alacsony. Az említett feltétel kiterjed többek között a\nfájlkezelést szolgáló intelligens megoldásokra, amelyek az indexeléstől kezdve\na keresésen, valamint a szöveg- és beszédfeldolgozáson keresztül adatok más\nadatforrásokkal való összekapcsolásáig számos különféle funkciót magukban\nfoglalnak, vagy az eredeti dokumentumok fordítására szolgáló MI-rendszerekre.\nMindenesetre az e rendelet egyik mellékletében felsorolt nagy kockázatú\nfelhasználási esetekben használt MI-rendszereket úgy kell tekinteni, hogy\njelentős károkozó kockázatokat jelentenek az egészségre, a biztonságra vagy az\nalapvető jogokra nézve, ha az MI-rendszer az (EU) 2016/679 rendelet 4.\ncikkének 4. pontja vagy az (EU) 2016/680 irányelv 3. cikkének 4. pontja vagy\naz (EU) 2018/1725 rendelet 3. cikkének 5. pontja értelmében vett\nprofilalkotással jár. A nyomonkövethetőség és az átláthatóság biztosítása\nérdekében amennyiben egy szolgáltató megítélése szerint egy MI-rendszer a fent\nemlített feltételek alapján nem nagy kockázatú, az említett rendszer\nforgalomba hozatalát vagy üzembe helyezését megelőzően dokumentációt kell\nkészítenie az értékelésről, és az említett dokumentációt kérésre az illetékes\nnemzeti hatóságok rendelkezésére kell bocsátania. Az ilyen szolgáltatót\nkötelezni kell arra, hogy nyilvántartásba vegye az MI-rendszert az e rendelet\nalapján létrehozott uniós adatbázisban. Annak érdekében, hogy további\niránymutatást nyújtson azon feltételek gyakorlati végrehajtásával\nkapcsolatban, amelyek mellett az e rendelet egyik mellékletében felsorolt MI-\nrendszerek kivételesen nem minősülnek nagy kockázatúnak, a Bizottságnak a\nTestülettel folytatott konzultációt követően iránymutatásokat kell\nbiztosítania, amelyekben meghatározza az említett gyakorlati végrehajtást,\nmellékelve az MI-rendszerek olyan felhasználási eseteire vonatkozó gyakorlati\npéldák átfogó listáját, amelyek nagy kockázatúak és az olyan felhasználási\nesetekre vonatkozókat, amelyek nem. (54) Mivel a biometrikus adatok a\nszemélyes adatok egy különleges kategóriáját képezik, helyénvaló a biometrikus\nrendszerek számos kritikus felhasználási esetét nagy kockázatúnak minősíteni,\namennyiben azok használatát a releváns uniós és nemzeti jog megengedi. A\ntermészetes személyek távoli biometrikus azonosítására szolgáló MI-rendszerek\ntechnikai pontatlansága torzított eredményekhez vezethet, és diszkriminatív\nhatásokat eredményezhet. Az ilyen torzított eredmények és diszkriminatív\nhatások kockázata különösen releváns az életkor, az etnikai és a faji\nhovatartozás, a nem vagy a fogyatékosságok tekintetében. A távoli biometrikus\nazonosító rendszereket ezért az általuk jelentett kockázatokra tekintettel\nnagy kockázatúnak kell minősíteni. Az ilyen besorolás kizárja az olyan\nbiometrikus ellenőrzésre - többek között hitelesítésre - szánt MI-\nrendszereket, amelynek kizárólagos célja, hogy megerősítse, egy konkrét\ntermészetes személy az, akinek az említett személy állítja magát, és kizárólag\nabból a célból erősítse meg egy természetes személy személyazonosságát, hogy\naz hozzáférhessen egy szolgáltatáshoz, feloldhassa egy eszköz zárolását vagy\nbiztonságos hozzáférést kapjon helyiségekhez. Ezenkívül, az érzékeny jellemzők\nvagy az (EU) 2016/679 rendelet 9. cikkének (1) bekezdése alapján védett\ntulajdonságok szerint, biometrikus adatok alapján történő biometrikus\nkategorizálásra szánt MI-rendszereket - amennyiben azokat e rendelet nem\ntiltja -, valamint az e rendelet értelmében nem tiltott érzelemfelismerő\nrendszereket nagy kockázatúnak kell minősíteni. Azon biometrikus rendszerek,\namelyeknek kizárólagos célja kiberbiztonsági és személyesadat-védelmi\nintézkedések lehetővé tétele, nem tekintendők nagy kockázatú MI-rendszereknek.\n(55) Ami a kritikus infrastruktúrák irányítását és üzemeltetését illeti, az\n(EU) 2022/2557 irányelv mellékletének 8. pontjában felsorolt kritikus\ndigitális infrastruktúrák és a közúti forgalom irányításában és\nüzemeltetésében, valamint a víz-, gáz-, fűtés- és villamosenergia-ellátásban\nbiztonsági alkotórészekként használni kívánt MI-rendszereket indokolt nagy\nkockázatúnak minősíteni, mivel meghibásodásuk vagy hibás működésük\nnagymértékben veszélyeztetheti az emberek életét és egészségét, és érzékelhető\nzavarokhoz vezethet a társadalmi és gazdasági tevékenységek szokásos\nvégzésében. A kritikus infrastruktúrák - és ezen belül a kritikus digitális\ninfrastruktúrák - biztonsági alkotórészei olyan rendszerek, amelyeket a\nkritikus infrastruktúra fizikai épségének, vagy a személyek egészségének és\nbiztonságának, valamint vagyontárgyaknak a közvetlen védelmére használnak, de\namelyek nem szükségesek a rendszer működéséhez. Az ilyen alkotórészek\nmeghibásodása vagy hibás működése közvetlenül veszélyeztetheti a kritikus\ninfrastruktúrák fizikai épségét, és ezáltal veszélyt jelent a személyek\negészségére és biztonságára, valamint a vagyontárgyakra. A kizárólag\nkiberbiztonsági célokra szánt alkotórészek nem minősülnek biztonsági\nalkotórészeknek. Az ilyen kritikus infrastruktúra biztonsági alkotórészei közé\ntartozhatnak például a felhőszolgáltatási központok víznyomás-vezérlő vagy\ntűzjelző rendszerei. (56) Az MI-rendszerek oktatásban való bevezetése fontos a\nmagas színvonalú digitális oktatás és képzés előmozdítása szempontjából,\nvalamint annak lehetővé tétele érdekében, hogy valamennyi tanuló és tanár\nelsajátítsa és megossza a szükséges digitális készségeket és kompetenciákat,\nbeleértve a médiajártasságot, valamint a kritikai gondolkodást, és így aktív\nrészt vállalhasson a gazdaságban, a társadalomban és a demokratikus\nfolyamatokban. Azonban az oktatásban vagy szakképzésben - különösen minden\nszinten a személyek oktatási és szakképzési intézményekbe vagy programokba\nvaló bejutásáról, felvételéről és az intézményekhez vagy programokhoz való\nhozzárendeléséről való döntéshozatalra, a személyek tanulási eredményeinek\nértékelésére, az egyén megfelelő oktatási szintjének felmérésére, érdemi\nhatást gyakorolva az adott egyén által kapott vagy elérhető oktatás vagy\nképzés szintjére, vagy vizsgák során a tiltott tanulói magatartás figyelemmel\nkövetésére és észlelésére - használt MI-rendszereket nagy kockázatú MI-\nrendszernek kell minősíteni, mivel meghatározhatják egy személy életének\noktatási és szakmai pályáját, és ezáltal hatással lehetnek az említett személy\nazon képességére, hogy megélhetéséről gondoskodjon. Helytelen tervezés és\nhasználat esetén az ilyen rendszerek különösen betolakodóak lehetnek és\nsérthetik az oktatáshoz és képzéshez való jogot, valamint a\nmegkülönböztetésmentességhez való jogot, és állandósíthatják a\nmegkülönböztetés korábban meglévő mintázatait, például a nőkkel, egyes\nkorcsoportokkal, a fogyatékossággal élőkkel, illetve egyes faji vagy etnikai\nszármazású vagy szexuális irányultságú személyekkel szemben. (57) Nagy\nkockázatúnak kell tekinteni azon MI-rendszereket is, amelyeket a\nfoglalkoztatás, a munkavállalók irányítása és az önfoglalkoztatáshoz való\nhozzáférés, különösen személyek felvétele és kiválasztása, a munkával\nkapcsolatos jogviszony feltételeit érintő döntések, az előléptetéssel és a\nmunkával kapcsolatos szerződéses jogviszonyok megszüntetésével kapcsolatos\ndöntések meghozatala, az egyéni viselkedésen, személyes vonásokon vagy\njellemzőkön alapuló feladatkiosztás, valamint a munkával kapcsolatos\nszerződéses jogviszonyokban álló személyek figyelemmel követése vagy\nértékelése során használnak, mivel az említett rendszerek érzékelhetően\nbefolyásolhatják e személyek jövőbeli karrierlehetőségeit és megélhetését,\nvalamint a munkavállalói jogokat. A releváns, munkával kapcsolatos szerződéses\njogviszonyoknak érdemi módon magukban kell foglalniuk a munkavállalókat és a\nBizottság 2021. évi munkaprogramjában említettek szerint a platformokon\nkeresztül szolgáltatásokat nyújtó személyeket. Az ilyen rendszerek a munkaerő-\nfelvételi folyamat egészében, valamint a munkával kapcsolatos szerződéses\njogviszonyokban álló személyek értékelése, előléptetése vagy megtartása során\nállandósíthatják a megkülönböztetés régóta fennálló mintázatait, például a\nnőkkel, bizonyos korcsoportokkal, a fogyatékossággal élő személyekkel, illetve\nbizonyos faji vagy etnikai származású, vagy szexuális irányultságú\nszemélyekkel szemben. Az ilyen személyek teljesítményének és magatartásának\nnyomon követésére használt MI-rendszerek alááshatják a személyek\nadatvédelemhez és a magánélethez való alapvető jogait is. (58) Egy másik olyan\nterület, ahol az MI-rendszerek használata különös figyelmet érdemel, az egyes\nolyan alapvető magán- és közszolgáltatások és ellátások elérhetősége és\nigénybevétele, amelyek ahhoz szükségesek, hogy az emberek teljes mértékben\nrészt vehessenek a társadalomban vagy javítsák életszínvonalukat. Így\nkülönösen, azon természetes személyek, akik alapvető állami alapellátásokért\nés -szolgáltatásokért - nevezetesen egészségügyi szolgáltatásokért, szociális\nbiztonsági ellátásokért, az olyan esetekben védelmet nyújtó szociális\nszolgáltatásokért, mint az anyaság, a betegség, az ipari balesetek, a függőség\nvagy az időskor és a munkahely elvesztése, valamint szociális és lakhatási\ntámogatásért - folyamodnak a hatóságokhoz, vagy akik a hatóságoktól ilyenben\nrészesülnek, jellemzően függenek az említett ellátásoktól és\nszolgáltatásoktól, és kiszolgáltatott helyzetben vannak a felelős hatóságokkal\nszemben. Ha MI-rendszerek igénybevételével döntik el, hogy a hatóságok\nmegadják, megtagadják, csökkentsék, visszavonják vagy visszaigényeljék-e az\nilyen ellátásokat és szolgáltatásokat - ideértve azt is, hogy a\nkedvezményezettek jogszerűen jogosultak-e az ilyen ellátásokra vagy\nszolgáltatásokra -, az említett rendszerek jelentős hatást gyakorolhatnak a\nszemélyek megélhetésére, és sérthetik az alapvető jogaikat, így például a\nszociális védelemhez, a megkülönböztetésmentességhez, az emberi méltósághoz\nvagy a hatékony jogorvoslathoz való jogot, és ezért nagy kockázatúnak kell\nazokat minősíteni. Mindazonáltal e rendelet nem akadályozhatja az innovatív\nmegközelítések fejlesztését és alkalmazását a közigazgatásban, amely számára\nelőnyös lenne az előírásoknak megfelelő és biztonságos MI-rendszerek szélesebb\nkörű használata, feltéve, hogy az említett rendszerek nem jelentenek nagy\nkockázatot a természetes és jogi személyekre nézve. Ezenfelül, a természetes\nszemélyek hitelpontszámának vagy hitelképességének értékelésére használt MI-\nrendszereket nagy kockázatú MI-rendszereknek kell minősíteni, mivel ezek\nhatározzák meg e személyek pénzügyi erőforrásokhoz vagy olyan alapvető\nszolgáltatásokhoz való hozzáférését, mint a lakhatás, a villamos energia és a\ntávközlési szolgáltatások. Az e célokra használt MI-rendszerek személyek vagy\ncsoportok hátrányos megkülönböztetéséhez vezethetnek, és állandósíthatják a -\npéldául faji vagy etnikai származáson, nemen, fogyatékosságon, életkoron vagy\nszexuális irányultságon alapuló - megkülönböztetés régóta fennálló\nmintázatait, vagy a diszkriminatív hatások új formáit teremthetik meg. Az\nuniós jog által a pénzügyi szolgáltatások nyújtása terén a csalások\nfelderítése céljából, valamint a prudenciális célokra, a hitelintézetek és\nbiztosítók tőkekövetelményeinek kiszámítása céljából előírt MI-rendszerek\nazonban e rendelet értelmében nem tekintendők nagy kockázatúnak. Ezenkívül a\ntermészetes személyek vonatkozásában egészség- és életbiztosítás esetén a\nkockázatértékeléshez és az árképzéshez való használatra szánt MI-rendszerek is\njelentős hatást gyakorolhatnak a személyek megélhetésére, és ha nem\nmegfelelően tervezik meg, fejlesztik és használják őket, sérthetik a személyek\nalapvető jogait és súlyos következményekkel járhatnak az emberek életére és\negészségére nézve, ideértve a pénzügyi szolgáltatásokból való kirekesztést és\na hátrányos megkülönböztetést is. Végül, a természetes személyek\nsegélyhívásainak értékeléséhez és osztályozásához vagy a sürgősségi\nsegélyszolgálatok - többek között a rendőrség és a tűzoltók által biztosított\nilyen szolgáltatások és orvosi segítségnyújtás - kirendeléséhez vagy a\nkirendelési prioritás megállapításához használt MI-rendszereket, valamint a\nsürgősségi egészségügyi ellátásban alkalmazott betegosztályozási rendszerekhez\nhasznált MI-rendszereket szintén nagy kockázatúnak kell tekinteni, mivel\nnagyon kritikus helyzetekben hoznak döntéseket az emberek élete és egészsége,\nvalamint tulajdona szempontjából. (59) A bűnüldöző hatóságok szerepére és\nfelelősségi körére tekintettel e hatóságoknak az MI-rendszerek bizonyos\nhasználatával járó fellépéseit az erőviszonyok jelentős mértékű\nkiegyensúlyozatlansága jellemzi, és egy természetes személy megfigyeléséhez,\nletartóztatásához vagy szabadságának elvonásához, valamint a Chartában\ngarantált alapvető jogokra gyakorolt egyéb kedvezőtlen hatásokhoz vezethetnek.\nÍgy különösen, ha az MI-rendszert nem tanítják jó minőségű adatokkal, nem\nfelel meg a teljesítménye, pontossága vagy stabilitása tekintetében támasztott\nmegfelelő követelményeknek, vagy a forgalomba hozatalt vagy a más módon\ntörténő üzembe helyezést megelőzően nem megfelelően tervezték és tesztelték,\nakkor diszkriminatív vagy más tekintetben helytelen vagy igazságtalan módon\nválaszhat ki embereket. Továbbá, akadályozhatja a fontos alapvető eljárási\njogoknak - például a hatékony jogorvoslathoz és a tisztességes eljáráshoz való\njognak, valamint a védelemhez való jognak és az ártatlanság vélelmének - az\nérvényre juttatását, különösen akkor, ha az ilyen MI-rendszerek nem kellően\nátláthatók, megmagyarázhatók és dokumentálhatók. Ezért amennyiben azok\nhasználatát a releváns uniós és nemzeti jog megengedi, helyénvaló nagy\nkockázatúnak minősíteni számos olyan, a bűnüldözéssel összefüggésben használni\nkívánt MI-rendszert, amelyek pontossága, megbízhatósága és átláthatósága\nkülönösen fontos a kedvezőtlen hatások elkerülése, a közvélemény bizalmának\nmegőrzése, valamint az elszámoltathatóság és a hatékony jogorvoslat\nbiztosítása szempontjából. Tekintettel a tevékenységek jellegére és az azokkal\nkapcsolatos kockázatokra, az említett nagy kockázatú MI-rendszereknek magukban\nkell foglalniuk különösen azon MI-rendszereket, amelyeket a bűnüldöző\nhatóságok által vagy nevében, vagy a bűnüldöző hatóságok támogatása érdekében\nuniós intézmények, szervek, hivatalok vagy ügynökségek által való használatra\nterveznek természetes személyekre vonatkozó, bűncselekmények áldozatává válás\nkockázatának értékelésére poligráfként és hasonló eszközként,\nbűncselekményekkel kapcsolatos nyomozások során vagy büntetőeljárásokban a\nbizonyítékok megbízhatóságának értékelésére, továbbá amennyiben e rendelet\nalapján nem tiltott, annak értékelésére, hogy egy természetes személy esetében\nfennáll-e bűncselekmény elkövetésének vagy ismételt elkövetésének kockázata,\nnem kizárólag egy természetes személyre vonatkozó profilalkotás vagy\ntermészetes személyek vagy csoportok személyiségjegyeinek és személyes\njellemzőinek, illetve múltbeli bűnözői magatartásának értékelése alapján,\nvalamint bűncselekmények felderítése, nyomozása vagy büntetőeljárás alá vonása\nsorán alkalmazott profilalkotásra. A kifejezetten adó- és vámhatóságok,\nvalamint a pénzmosás elleni uniós jogszabályok szerinti információelemzést\nvégző, igazgatási feladatokat ellátó pénzügyi hírszerző egységek általi,\nközigazgatási eljárásokban történő használatra szánt MI-rendszerek, nem\nminősítendők a bűnüldöző hatóságok által bűncselekmények megelőzése,\nfelderítése, nyomozása és büntetőeljárás alá vonása céljából használt nagy\nkockázatú MI-rendszereknek. Az MI-eszközök bűnüldöző és egyéb releváns\nhatóságok általi használata nem idézhet elő egyenlőtlenséget vagy\nkirekesztést. Nem szabad figyelmen kívül hagyni az MI-eszközök használatának a\ngyanúsítottak védelemhez való jogára gyakorolt hatását, különösen az e\nrendszerek működésére vonatkozó érdemi információk beszerzésének nehézségét,\nvalamint a kapott eredmények bíróság előtti vitatásának ebből eredő\nnehézségeit, főként a vizsgálat alatt álló természetes személyek esetében.\n(60) A migrációkezelésben, a menekültügyben és a határigazgatásban használt\nMI-rendszerek olyan személyeket érintenek, akik gyakran különösen\nkiszolgáltatott helyzetben vannak, és akiknek életét befolyásolja az illetékes\nhatóságok intézkedéseinek kimenetele. Az ilyen összefüggésben használt MI-\nrendszerek pontossága, megkülönböztetésmentes jellege és átláthatósága ezért\nkülönösen fontos az érintett személyek alapvető jogai, különösen a szabad\nmozgáshoz, a megkülönböztetésmentességhez, a magánélet és a személyes adatok\nvédelméhez, a nemzetközi védelemhez és a megfelelő ügyintézéshez való jogaik\ntiszteletben tartásának biztosítása szempontjából. Ezért helyénvaló nagy\nkockázatúnak minősíteni a migráció, a menekültügy és a határigazgatás\nterületén feladatokat ellátó illetékes hatóságok által vagy nevükben, vagy\nuniós intézmények, szervek, hivatalok vagy ügynökségek által, poligráfként és\nhasonló eszközként, vagy olyan célokra használni kívánt MI-rendszereket -\namennyiben azok használatát a releváns uniós és nemzeti jog megengedi -, mint\na tagállamok területére belépő, illetve vízumot vagy menedékjogot kérelmező\ntermészetes személyek által jelentett bizonyos kockázatok felmérése, az\nilletékes hatóságoknak történő segítségnyújtás a menedékjog, vízum és\ntartózkodási engedély iránti kérelmek és a kapcsolódó panaszok vizsgálatához,\nbeleértve a bizonyítékok megbízhatóságának kapcsolódó értékelését a jogállást\nkérelmező természetes személyek jogosultságának megállapítására irányuló\ncélkitűzés tekintetében, természetes személyek felderítése, felismerése vagy\nazonosítása a migráció, a menekültügy és a határigazgatás összefüggésében, az\núti okmányok ellenőrzésének kivételével. Az e rendelet hatálya alá tartozó, a\nmigráció, a menekültügy és a határigazgatás területén működő MI-rendszereknek\nmeg kell felelniük a 810/2009/EK európai parlamenti és tanácsi rendeletben * ,\na 2013/32/EU európai parlamenti és tanácsi irányelvben * és más vonatkozó\njogszabályokban meghatározott vonatkozó eljárási követelményeknek. A\ntagállamok vagy az uniós intézmények, szervek, hivatalok vagy ügynökségek a\nmigráció, a menekültügy és a határellenőrzés során alkalmazott MI-rendszereket\nsemmilyen körülmények között nem használhatják fel az 1967. január 31-i\njegyzőkönyvvel módosított, a menekültek helyzetére vonatkozó 1951. július 28-i\ngenfi ENSZ-egyezmény szerinti nemzetközi kötelezettségeik megkerülésére.\nSemmilyen módon nem sérthetik meg továbbá a visszaküldés tilalmának elvét,\nilletve nem tagadhatják meg az Unió területére való belépés biztonságos és\neredményes, legális csatornáit, ideértve a nemzetközi védelemhez való jogot\nis. (61) Az igazságszolgáltatásra és a demokratikus folyamatok irányítására\nszánt egyes MI-rendszereket nagy kockázatúnak kell tekinteni, figyelembe véve\na demokráciára, a jogállamiságra, az egyéni szabadságokra, valamint a hatékony\njogorvoslathoz és a tisztességes eljáráshoz való jogra gyakorolt potenciálisan\njelentős hatásukat. Így különösen, az esetleges torzítások, hibák és\nátláthatatlanság kockázatának kezelése érdekében indokolt nagy kockázatúnak\nminősíteni az igazságügyi hatóságok által vagy nevében történő használatra\nszánt azon MI-rendszereket, amelyek célja, hogy segítsék az igazságügyi\nhatóságokat a ténybeli és a jogi elemek kutatásában és értelmezésében,\nvalamint a jog konkrét tényekre történő alkalmazásában. Az alternatív\nvitarendezési testületek által e célokra történő használatra szánt MI-\nrendszereket szintén nagy kockázatúnak kell tekinteni, ha az alternatív\nvitarendezési eljárás a felekre nézve joghatással jár. Az MI-eszközök\nalkalmazása támogathatja a bírák döntéshozatali hatáskörét vagy a bírói\nfüggetlenséget, de nem válthatja azt fel, mivel a végső döntéshozatalnak ember\náltal irányított tevékenységnek kell maradnia. Az MI-rendszerek nagy\nkockázatúként való besorolása azonban nem terjedhet ki azokra az MI-\nrendszerekre, amelyek olyan, tisztán járulékos adminisztratív tevékenységek\nelvégzésére szolgálnak, amelyek nem befolyásolják a tényleges\nigazságszolgáltatást az egyedi ügyekben, mint például a bírósági határozatok,\ndokumentumok vagy adatok anonimizálása vagy álnevesítése, a személyzet közötti\nkommunikáció, adminisztratív feladatok ellátása. (62) Az (EU) 2024/900 európai\nparlamenti és tanácsi rendeletben * előírt szabályok sérelme nélkül, és a\nCharta 39. cikkében rögzített szavazati jogot érintő indokolatlan külső\nbeavatkozás, valamint a demokráciára és a jogállamiságra gyakorolt kedvezőtlen\nhatások kockázatának kezelése érdekében a választások vagy népszavazások\neredményének vagy a természetes személyek választásokon vagy népszavazásokon\ntanúsított szavazási magatartásának befolyásolására tervezett MI-rendszereket\nnagy kockázatú MI-rendszereknek kell minősíteni, kivéve azon MI-rendszereket -\nígy például a politikai kampányok adminisztratív és logisztikai szempontból\ntörténő szervezésére, optimalizálására és strukturálására használt eszközöket\n-, amelyek kimenetének nincsenek természetes személyek közvetlenül kitéve.\n(63) Az, hogy egy MI-rendszer e rendelet értelmében nagy kockázatú MI-\nrendszernek minősül, nem értelmezhető úgy, mint ami azt jelzi, hogy a rendszer\nhasználata jogszerű az uniós jog más jogi aktusai vagy az uniós joggal\nösszeegyeztethető nemzeti jogszabályok, így például a személyes adatok\nvédelmére, illetve a poligráfok, vagy a természetes személyek érzelmi\nállapotának felderítését szolgáló hasonló eszközök és rendszerek használatára\nvonatkozó jogi aktusok és jogszabályok alapján. Az ilyen használatra továbbra\nis kizárólag a Chartából, valamint a másodlagos uniós jog alkalmazandó jogi\naktusaiból és a nemzeti jogból eredő alkalmazandó követelményekkel összhangban\nkerülhet sor. E rendelet nem értelmezhető úgy, mint amely jogalapot teremt\nszemélyes adatok kezelésére, ideértve adott esetben a személyes adatok\nkülönleges kategóriáit is, kivéve, ha e rendelet kifejezetten másként\nrendelkezik. (64) A forgalomba hozott vagy más módon üzembe helyezett, nagy\nkockázatú MI-rendszerekből eredő kockázatok enyhítése és a magas szintű\nmegbízhatóság biztosítása érdekében bizonyos kötelező követelményeket kell\nalkalmazni a nagy kockázatú MI-rendszerekre vonatkozóan, figyelembe véve az\nMI-rendszer rendeltetését és felhasználási kontextusát, továbbá összhangban a\nszolgáltató által létrehozandó kockázatkezelési rendszerrel. A szolgáltatók\náltal e rendelet kötelező követelményeinek való megfelelés céljából elfogadott\nintézkedéseknek figyelembe kell venniük az MI-vel kapcsolatos technika\náltalánosan elfogadott, mindenkori állását, arányosnak és hatékonynak kell\nlenniük e rendelet célkitűzéseinek elérése érdekében. Az új jogszabályi keret\nalapján, amint azt a termékekre vonatkozó uniós szabályozásról szóló, 2022.\névi bizottsági útmutató - „A kék útmutató” - kifejti, főszabály szerint az\nuniós harmonizációs jogalkotás több jogi aktusa is alkalmazható egyetlen\ntermékre, mivel a forgalmazásra vagy az üzembe helyezésre csak akkor kerülhet\nsor, ha a termék megfelel valamennyi alkalmazandó uniós harmonizációs\njogszabálynak. Az e rendelet szerinti követelmények hatálya alá tartozó MI-\nrendszerek veszélyei más vonatkozásokat érintenek, mint a meglévő uniós\nharmonizációs jogszabályok, ezért az e rendelet szerinti követelmények\nkiegészítenék a meglévő uniós harmonizációs jogszabályokat. Például az MI-\nrendszert tartalmazó gépek vagy orvostechnikai eszközök jelenthetnek olyan\nkockázatokat, amelyekre a vonatkozó uniós harmonizációs jogszabályokban\nmeghatározott alapvető egészségvédelmi és biztonsági követelmények nem\nterjednek ki, mivel az adott ágazati jogszabályok nem foglalkoznak az MI-\nrendszerekkel összefüggő sajátos kockázatokkal. Ez a különböző jogalkotási\naktusok egyidejű és egymást kiegészítő alkalmazását teszi szükségessé. A\nkövetkezetesség biztosítása, valamint a szükségtelen adminisztratív terhek és\na szükségtelen költségek elkerülése érdekében az olyan termékek\nszolgáltatóinak, amelyek egy vagy több olyan, nagy kockázatú MI-rendszert\ntartalmaznak, amelyre az e rendeletben vagy az új jogszabályi kereten alapuló\nés az e rendelet egyik mellékletében felsorolt uniós harmonizációs\njogszabályokban foglalt követelmények alkalmazandók, rugalmassággal kell\nrendelkezniük azon működési döntések tekintetében, hogy miként biztosítsák\noptimális módon az egy vagy több MI-rendszert tartalmazó termék megfelelését\naz említett uniós harmonizációs jogszabályokban foglalt valamennyi\nalkalmazandó követelménynek. Az említett rugalmasság jelentheti például a\nszolgáltató azon döntését, hogy az a rendelet értelmében kötelező szükséges\ntesztelési és jelentéstételi folyamatok, információk és dokumentáció egy\nrészét az új jogszabályi kereten alapuló és az e rendelet egyik mellékletében\nfelsorolt, meglévő uniós harmonizációs jogszabályok alapján előírt, már\nmeglévő dokumentációba és eljárásokba építi be. Ez semmilyen módon nem\ngyengítheti a szolgáltató azon kötelezettségét, hogy megfeleljen valamennyi\nalkalmazandó követelménynek. (65) A kockázatkezelési rendszernek olyan\nmegszakítás nélkül végzett iteratív folyamatnak kell lennie, amelyet a nagy\nkockázatú MI-rendszer teljes életciklusára terveztek és működtetnek. Az\nemlített folyamatnak az MI-rendszerek által az egészségre, a biztonságra és az\nalapvető jogokra jelentett releváns kockázatok azonosítására és enyhítésére\nkell irányulnia. A kockázatkezelési rendszert rendszeresen felül kell\nvizsgálni és aktualizálni kell a folyamatos hatékonyságának biztosítása,\nvalamint az e rendelet alapján hozott valamennyi jelentős döntés és intézkedés\nalátámasztása és dokumentálása érdekében. E folyamatnak biztosítania kell,\nhogy a szolgáltató azonosítsa a kockázatokat vagy kedvezőtlen hatásokat, és az\nMI-rendszerek által az egészségre, a biztonságra és az alapvető jogokra\njelentett ismert és észszerűen előrelátható kockázatokra vonatkozó enyhítő\nintézkedéseket vezessen be a rendeltetésük vagy az észszerűen előre látható\nrendellenes használatuk fényében, ideértve az MI-rendszer és a működési\nkörnyezete közötti kölcsönhatásból eredő lehetséges kockázatokat is. A\nkockázatkezelési rendszer révén az MI-vel kapcsolatos technika mindenkori\nállásának fényében legmegfelelőbb kockázatkezelési intézkedéseket kell\nelfogadni. A legmegfelelőbb kockázatkezelési intézkedések meghatározásakor a\nszolgáltatónak dokumentálnia kell és meg kell indokolnia a meghozott\ndöntéseket, és adott esetben be kell vonnia szakértőket és külső érdekelt\nfeleket. A nagy kockázatú MI-rendszerek észszerűen előrelátható rendellenes\nhasználatának meghatározásakor a szolgáltatónak ki kell térnie az MI-\nrendszerek olyan használatára, amelyekre a rendszer rendeltetése nem terjed ki\nközvetlenül és amelyek nem szerepelnek a használati utasításban, azonban az\nadott MI-rendszer sajátos jellemzői és használata összefüggésében észszerűen\nfeltételezhető, hogy az előrelátható emberi magatartásból eredhet. A\nszolgáltató által biztosított használati utasításnak tartalmaznia kell minden\nolyan ismert vagy előre látható, a nagy kockázatú MI-rendszer rendeltetésszerű\nhasználatával vagy az észszerűen előrelátható rendellenes használatával\nkapcsolatos körülményt, amely kockázatot jelenthet az egészségre és a\nbiztonságra vagy az alapvető jogokra nézve. Ez annak biztosítását célozza,\nhogy az alkalmazó tisztában legyen azokkal, és figyelembe vegye azokat a nagy\nkockázatú MI-rendszer használata során. Az e rendelet szerinti észszerűen\nelőrelátható rendellenes használatra vonatkozó kockázatenyhítő intézkedések\nmeghatározása és végrehajtása nem tehet szükségessé a szolgáltató részéről a\nnagy kockázatú MI-rendszer tekintetében konkrét további tanítást az\nelőrelátható rendellenes használat kezelése céljából. A szolgáltatók azonban\nösztönözve vannak ilyen további tanító intézkedések fontolóra vételére, hogy\nszükség szerint és adott esetben mérsékeljék az észszerűen előrelátható\nrendellenes használatokat. (66) A nagy kockázatú MI-rendszerekre\nkövetelményeket kell alkalmazni a kockázatkezelés, a használt adatkészletek\nminősége és relevanciája, a műszaki dokumentáció és a nyilvántartás, az\nátláthatóság és az alkalmazóknak nyújtott tájékoztatás, az emberi felügyelet,\nvalamint a stabilitás, a pontosság és a kiberbiztonság tekintetében. Az\nemlített követelmények szükségesek az egészséget, a biztonságot és az alapvető\njogokat érintő kockázatok hatékony enyhítéséhez. Mivel észszerűen nem állnak\nrendelkezésre más, a kereskedelmet kevésbé korlátozó intézkedések, az említett\nkövetelmények nem minősülnek a kereskedelem indokolatlan korlátozásának. (67)\nA kiváló minőségű adatok és a kiváló minőségű adatokhoz való hozzáférés\nlétfontosságú szerepet játszik számos MI-rendszer struktúrájának\nbiztosításában és teljesítményének garantálásában, különösen a modellek\ntanítását magában foglaló technikák alkalmazása esetén, annak biztosítása\nérdekében, hogy a nagy kockázatú MI-rendszer rendeltetésszerűen és\nbiztonságosan működjön, és ne váljon az uniós jog által tiltott\nmegkülönböztetés forrásává. A tanításhoz, validáláshoz és teszteléshez\nhasznált kiváló minőségű adatkészletekhez megfelelő adatkormányzási és\nadatgazdálkodási gyakorlatokra van szükség. A tanításhoz, validáláshoz és\nteszteléshez használt adatkészleteknek, beleértve a címkéket is, relevánsnak,\nkellően reprezentatívnak, valamint a lehető legnagyobb mértékben hibáktól\nmentesnek és teljesnek kell lenniük a rendszer rendeltetése szempontjából. Az\nuniós adatvédelmi jognak, például az (EU) 2016/679 rendeletnek való megfelelés\nelősegítése érdekében az adatkormányzási és adatgazdálkodási gyakorlatoknak a\nszemélyes adatok esetében ki kell terjedniük az adatgyűjtés eredeti céljával\nkapcsolatos átláthatóságra. Az adatkészleteknek rendelkezniük kell a megfelelő\nstatisztikai tulajdonságokkal is, többek között azon személyek vagy személyek\ncsoportjai tekintetében, akikre vagy amelyekre a nagy kockázatú MI-rendszert\nhasználni kívánják, különös figyelemmel az adatkészletekben lévő olyan\nesetleges torzítások mérséklésére, amelyek valószínűleg hatással lehetnek a\nszemélyek egészségére és biztonságára, negatív hatást gyakorolhatnak az\nalapvető jogokra, vagy az uniós jog által tiltott megkülönböztetéshez\nvezethetnek, különösen akkor, ha az adatok kimenetei befolyásolják a jövőbeli\nműveletek bemeneteit (visszacsatolási hurkok). Torzítások előfordulhatnak\neredendően például az alapul szolgáló adatkészletekben, különösen akkor, ha\nmúltbeli adatokat használnak, vagy amelyek akkor keletkeznek, amikor a\nrendszereket valós körülmények között alkalmazzák. Az MI-rendszerek által\nnyújtott eredményeket befolyásolhatják az ilyen eredendő torzítások, amelyek\nhajlamosak tovább növekedni, és ezáltal állandósítani és felerősíteni a\nmeglévő diszkriminációt, különösen a bizonyos kiszolgáltatott csoportokhoz -\ntöbbek között faji vagy etnikai csoportokhoz - tartozó személyek esetében. Az\nadatkészleteknek a lehető legnagyobb mértékű teljességére és hibamentességére\nvonatkozó követelmény nem érintheti a magánélet védelmét szolgáló technikák\nhasználatát az MI-rendszerek fejlesztésével és tesztelésével összefüggésben.\nÍgy különösen, az adatkészleteknek - a rendeltetésük által megkövetelt\nmértékben - figyelembe kell venniük azon jellemzőket, tulajdonságokat vagy\nelemeket, amelyek azon sajátos földrajzi, kontextuális, magatartási vagy\nfunkcionális környezethez kapcsolódnak, amelyben az MI-rendszert használni\nszándékozzák. Az adatkormányzással kapcsolatos követelmények teljesíthetők\nolyan harmadik felek igénybevételével, amelyek az adatkormányzás, az\nadatkészlet-integritás, valamint az adat-tanításra, -validálásra és\n-tesztelésre szolgáló gyakorlatok ellenőrzését magában foglaló, tanúsított\nmegfelelési szolgáltatásokat kínálnak, amennyiben az e rendelet szerinti\nadatszolgáltatási követelményeknek való megfelelés biztosított. (68) A nagy\nkockázatú MI-rendszerek fejlesztése és értékelése tekintetében bizonyos\nszereplőknek, például a szolgáltatóknak, a bejelentett szervezeteknek és más\nreleváns jogalanyoknak, például az európai digitális innovációs központoknak,\na tesztelési-kísérleti létesítményeknek és a kutatóknak lehetőséget kell\nbiztosítani, hogy az e rendelethez kapcsolódó tevékenységi területeiken belül\nhozzáférjenek kiváló minőségű adatkészletekhez és használják őket. A Bizottság\náltal létrehozott közös európai adatterek, valamint a vállalkozások közötti és\na kormányzattal való, közérdekből történő adatmegosztás megkönnyítése alapvető\nfontosságúak lesznek ahhoz, hogy megbízható, elszámoltatható és\nmegkülönböztetésmentes hozzáférést lehessen biztosítani az MI-rendszerek\ntanításához, validálásához és teszteléséhez szükséges kiváló minőségű\nadatokhoz. Az egészségügy területén például az európai egészségügyi adattér\nfogja megkönnyíteni az egészségügyi adatokhoz való megkülönböztetésmentes\nhozzáférést és az MI-algoritmusok ezen adatkészletek alapján való tanítását a\nmagánéletet védő, biztonságos, időszerű, átlátható és megbízható módon,\nvalamint megfelelő intézményi irányítás mellett. Az adatokhoz való hozzáférést\nbiztosító vagy támogató érintett illetékes hatóságok, beleértve az ágazati\nhatóságokat is, támogathatják az MI-rendszerek tanításához, validálásához és\nteszteléséhez szükséges kiváló minőségű adatok szolgáltatását is. (69) A\nmagánélet tiszteletben tartásához és az adatvédelemhez való jogot az MI-\nrendszer teljes életciklusa során garantálni kell. E tekintetben az\nadattakarékosság, valamint a beépített és alapértelmezett adatvédelem uniós\nadatvédelmi jogszabályokban meghatározott elve alkalmazandó a személyes adatok\nkezelése során. A szolgáltatók által az említett elveknek való megfelelés\nbiztosítása érdekében hozott intézkedések nemcsak az anonimizálást és a\ntitkosítást foglalhatják magukban, hanem az olyan technológia használatát is,\namely lehetővé teszi az algoritmusok adatokhoz rendelését és az MI-rendszer\nanélkül történő tanítását, hogy a nyers vagy strukturált adatokat a feleknek\negymás között át kellene adniuk vagy másolniuk, az e rendeletben foglalt\nadatkormányzási követelmények sérelme nélkül. (70) Annak érdekében, hogy\nmegvédjék mások jogát az MI-rendszerekben megjelenő torzításból eredő\nesetleges megkülönböztetéssel szemben, a szolgáltatók számára kivételesen\nlehetővé kell tenni, hogy a nagy kockázatú MI-rendszerekkel kapcsolatos\ntorzítás észlelésének és korrekciójának biztosításához feltétlenül szükséges\nmértékben, figyelemmel a természetes személyek alapvető jogaira és\nszabadságaira vonatkozó megfelelő biztosítékokra, valamint az e rendeletben és\naz (EU) 2016/679 rendeletben, az (EU) 2018/1725 rendeletben és az (EU)\n2016/680 irányelvben foglalt valamennyi alkalmazandó feltétel alkalmazását\nkövetően, az (EU) 2016/679 rendelet 9. cikke (2) bekezdésének g) pontja és az\n(EU) 2018/1725 rendelet 10. cikke (2) bekezdésének g) pontja értelmében vett\njelentős közérdekből a személyes adatok különleges kategóriáit is kezeljék.\n(71) A nagy kockázatú MI-rendszerek nyomonkövethetőségéhez, az e rendelet\nszerinti követelményeknek való megfelelés ellenőrzéséhez, valamint az ilyen\nrendszerek működésének nyomon követéséhez és a forgalomba hozatal utáni nyomon\nkövetéshez elengedhetetlenek az arra vonatkozó átfogó információk, hogy hogyan\nfejlesztették ki a nagy kockázatú MI-rendszereket, és hogyan teljesítenek\nteljes élettartamuk során. Ehhez nyilvántartást kell vezetni, és olyan műszaki\ndokumentációnak kell rendelkezésre állnia, amely tartalmazza az annak\nértékeléséhez szükséges információkat, hogy az MI-rendszer megfelel-e a\nvonatkozó követelményeknek, valamint amely megkönnyíti a forgalomba hozatal\nutáni nyomon követést. Ezeknek az információknak ki kell terjedniük a rendszer\náltalános jellemzőire, képességeire és korlátaira, algoritmusaira, adataira,\ntanítási, tesztelési és validálási folyamataira, valamint a vonatkozó\nkockázatkezelési rendszerrel kapcsolatos dokumentációra, és világos és érthető\nformában kell rendelkezésre állniuk. A műszaki dokumentációt az MI-rendszerek\nteljes élettartama alatt megfelelően naprakészen kell tartani. Továbbá, a nagy\nkockázatú MI-rendszereknek a rendszer teljes élettartama alatt technikailag\nlehetővé kell tenniük az események automatikus rögzítését naplózás révén. (72)\nA bizonyos MI-rendszerek átláthatatlanságával és összetettségével kapcsolatos\naggályok kezelése, valamint az alkalmazóknak az e rendelet szerinti\nkötelezettségeik teljesítéséhez való segítségnyújtás érdekében bizonyos fokú\nátláthatóságot kell előírni a nagy kockázatú MI-rendszerekre vonatkozóan már\nazok forgalomba hozatala vagy üzembe helyezése előtt. A nagy kockázatú MI-\nrendszereket úgy kell megtervezni, hogy az alkalmazók értsék, hogyan működik\naz MI-rendszer, értékelni tudják annak funkcióját, valamint tisztában legyenek\nerősségeivel és korlátaival. A nagy kockázatú MI-rendszereket használati\nutasítás formájában megfelelő információknak kell kísérniük. Az ilyen\ninformációknak ki kell terjedniük az MI-rendszer jellemzőire, képességeire és\nteljesítményének korlátaira. Azok magukban foglalnák a következőkre vonatkozó\ninformációkat: a nagy kockázatú MI-rendszer használatával kapcsolatos, olyan\nesetleges, ismert és előre látható körülmények, ideértve az alkalmazó által\nvégzett, a rendszer viselkedését és teljesítményét befolyásolni képes\nműveleteket, amelyek mellett az MI-rendszer az egészséget, a biztonságot és az\nalapvető jogokat érintő kockázatokhoz vezethet, a szolgáltató által előre\nmeghatározott és a megfelelőség szempontjából értékelt változások, valamint a\nreleváns emberi felügyeleti intézkedések, beleértve az MI-rendszerek\nkimeneteinek az alkalmazók általi értelmezését megkönnyítő technikai\nintézkedéseket. Az átláthatóság, beleértve a rendszereket kísérő használati\nutasítást, segíteni hivatott az alkalmazókat a rendszer használatában,\nvalamint támogatni hivatott őket a tájékozott döntéshozatalban. Többek között\naz alkalmazók számára könnyebb kell, hogy legyen annak megfelelő eldöntése a\nrájuk alkalmazandó követelmények fényében, hogy mely rendszert kívánják\nhasználni, tisztában kell lenniük a rendeltetésszerű és a kizárt\nfelhasználással, és helyesen, megfelelően kell használniuk az MI-rendszert. A\nhasználati utasításban szereplő információk olvashatóságának és\nhozzáférhetőségének javítása érdekében adott esetben szemléltető példákat kell\nfelsorolni például az MI-rendszer korlátaival, valamint a rendeltetésszerű és\na kizárt felhasználással kapcsolatban. A szolgáltatóknak biztosítaniuk kell,\nhogy a teljes dokumentáció, beleértve a használati utasítást is, érdemi,\nátfogó, hozzáférhető és érthető információkat tartalmazzon, figyelembe véve a\nmegcélzott alkalmazók igényeit és előre látható ismereteit. A használati\nutasítást a megcélzott alkalmazók által könnyen érthető nyelven kell\nrendelkezésre bocsátani, az érintett tagállam által meghatározottak szerint.\n(73) A nagy kockázatú MI-rendszereket úgy kell megtervezni és fejleszteni,\nhogy a természetes személyek felügyelhessék működésüket, valamint\nbiztosíthassák rendeltetésszerű használatukat és hatásaik kezelését a rendszer\néletciklusa során. E célból a rendszer szolgáltatójának a forgalomba hozatalt\nvagy üzembe helyezést megelőzően megfelelő emberi felügyeleti intézkedéseket\nkell meghatároznia. Így különösen, az ilyen intézkedéseknek adott esetben\ngarantálniuk kell azt, hogy a rendszer olyan beépített működési korlátokkal\nrendelkezzen, amelyeket maga a rendszer nem tud felülbírálni, és reagáljon az\nemberi üzemeltetőre, valamint hogy az emberi felügyeletet ellátó természetes\nszemélyek rendelkezzenek az e feladat ellátásához szükséges szakértelemmel,\nképzéssel és felhatalmazással. Adott esetben annak biztosítása is alapvető\nfontosságú, hogy a nagy kockázatú MI-rendszerek rendelkezzenek olyan\nmechanizmusokkal, amelyek iránymutatást és tájékoztatást nyújtanak az emberi\nfelügyeletet ellátó természetes személy számára az azzal kapcsolatos\nmegalapozott döntéshozatalhoz, hogy szükséges-e, vagy mikor és hogyan\nszükséges beavatkozni a negatív következmények vagy kockázatok elkerülése\nérdekében vagy leállítani a rendszert, amennyiben az nem rendeltetésszerűen\nműködik. Tekintettel arra, hogy a bizonyos biometrikus azonosító rendszerek\náltal megállapított hibás egyezés milyen komoly következményekkel járhat az\negyénekre nézve, helyénvaló fokozott emberi felügyeleti követelményt előírni e\nrendszerekre vonatkozóan annak érdekében, hogy az alkalmazó a rendszerből\nszármazó azonosítás alapján semmilyen intézkedést vagy döntést ne hozhasson\nanélkül, hogy azt legalább két természetes személy külön ellenőrizte és\nmegerősítette volna. Az említett személyek lehetnek ugyanazon vagy különböző\nszervezet tagjai, és köztük lehet a rendszert üzemeltető vagy használó személy\nis. Ez a követelmény nem okozhat szükségtelen terhet vagy késedelmet, és\nelegendő lehet, ha a különböző személyek által végzett külön ellenőrzéseket\nautomatikusan rögzítik a rendszer által generált naplók. Tekintettel a\nbűnüldözés, a migráció, a határellenőrzés és a menekültügy területének\nsajátosságaira, ez a követelmény nem alkalmazandó azokban az esetekben, amikor\naz uniós vagy a nemzeti jog úgy ítéli meg, hogy alkalmazása aránytalan. (74) A\nnagy kockázatú MI-rendszereknek életciklusuk során következetesen kell\nteljesíteniük, és a rendeltetésük fényében, valamint a technika általánosan\nelfogadott, mindenkori állásával összhangban megfelelő szintű pontosságot,\nstabilitást és kiberbiztonságot kell garantálniuk. A Bizottság, valamint az\nérintett szervezetek és érdekelt felek ösztönözve vannak arra, hogy\nfordítsanak kellő figyelmet az MI-rendszerekkel kapcsolatos kockázatok és\nnegatív hatások csökkentésére. A teljesítménymutatók várható szintjét fel kell\ntüntetni a használati utasításban. A szolgáltatókat arra sürgetik, hogy az\nemlített információkat világos és könnyen érthető, félreértésektől és\nmegtévesztő kijelentésektől mentes módon biztosítsák az alkalmazók számára. A\ntörvényes metrológiára vonatkozó uniós jog, többek között a 2014/31/EU * és a\n2014/32/EU * európai parlamenti és tanácsi irányelv célja a mérések\npontosságának biztosítása, valamint a kereskedelmi ügyletek átláthatóságának\nés tisztességességének elősegítése. Ezzel összefüggésben a Bizottságnak az\nérintett érdekelt felekkel és szervezetekkel, így például a metrológiai és\nteljesítményértékelési hatóságokkal együttműködve, adott esetben ösztönöznie\nkell az MI-rendszerekre vonatkozó referenciaértékek és mérési módszertanok\nkidolgozását. A Bizottságnak ennek során oda kell figyelnie az MI-vel\nkapcsolatos metrológia és releváns mérési mutatók területén dolgozó nemzetközi\npartnerekre, és együtt kell működnie azokkal. (75) A műszaki stabilitás\nkulcsfontosságú követelmény a nagy kockázatú MI-rendszerek esetében.\nReziliensnek kell lenniük az olyan káros vagy más módon nemkívánatos\nmagatartással szemben, amely a rendszer saját, illetve a rendszer működési\nkörnyezetének korlátaiból eredhet (pl. hibák, tévesztések, következetlenségek,\nváratlan helyzetek). Ezért technikai és szervezeti intézkedéseket kell hozni a\nnagy kockázatú MI-rendszerek stabilitásának biztosítása érdekében, például az\nilyen káros vagy más módon nemkívánatos magatartás megelőzését vagy\nminimalizálását szolgáló műszaki megoldások tervezése és fejlesztése révén. Az\nemlített műszaki megoldások magukban foglalhatnak például olyan\nmechanizmusokat, amelyek lehetővé teszik a rendszer számára, hogy\nbiztonságosan megszakítsa a működését (vészüzemi tervek), ha bizonyos\nrendellenességek lépnek fel, vagy ha az üzemelésre bizonyos előre\nmeghatározott határokon kívül kerül sor. Az e kockázatokkal szembeni védelem\nhiánya kihathat a biztonságra, vagy negatívan érintheti az alapvető jogokat,\npéldául téves döntések vagy az MI-rendszer által generált helytelen vagy\ntorzított kimenetek miatt. (76) A kiberbiztonság döntő szerepet játszik annak\nbiztosításában, hogy az MI-rendszerek reziliensek legyenek a rendszer\nsebezhetőségét kihasználó, rossz szándékú harmadik felek arra irányuló\nkísérleteivel szemben, hogy megváltoztassák a rendszer használatát,\nviselkedését vagy teljesítményét, illetve veszélyeztessék a biztonsági\ntulajdonságait. Az MI-rendszerek elleni kibertámadások befolyásolhatnak MI-\nspecifikus eszközöket, így például tanítóadat-készleteket (pl. adatmérgezés)\nvagy betanított modelleket (pl. ellenséges támadások vagy következtető\ntámadások), vagy kihasználhatják az MI-rendszer digitális eszközeinek vagy az\nalapul szolgáló IKT-infrastruktúrának a sebezhetőségét. A kockázatoknak\nmegfelelő kiberbiztonsági szint biztosítása érdekében ezért a nagy kockázatú\nMI-rendszerek szolgáltatóinak megfelelő intézkedéseket, például biztonsági\nellenőrzéseket kell alkalmazniuk, adott esetben figyelembe véve az alapul\nszolgáló IKT-infrastruktúrát is. (77) Az e rendeletben foglalt, a stabilitásra\nés a pontosságra vonatkozó követelmények sérelme nélkül, a digitális elemeket\ntartalmazó termékekre vonatkozó horizontális kiberbiztonsági követelményekről\nszóló európai parlamenti és tanácsi rendelet hatálya alá tartozó nagy\nkockázatú MI-rendszerek e rendelet szerinti kiberbiztonsági követelményeknek\nvaló megfelelése az említett rendelettel összhangban igazolható az említett\nrendeletben foglalt alapvető kiberbiztonsági követelményeknek való\nmegfeleléssel. Azon nagy kockázatú MI-rendszerek, amelyek megfelelnek a\ndigitális elemeket tartalmazó termékekre vonatkozó horizontális\nkiberbiztonsági követelményekről szóló európai parlamenti és tanácsi rendelet\nalapvető követelményeinek, úgy tekintendők, mint amelyek megfelelnek az e\nrendeletben foglalt kiberbiztonsági követelményeknek, amennyiben e\nkövetelmények teljesülését az említett rendelet alapján kiállított EU-\nmegfelelőségi nyilatkozat vagy annak részei igazolják. E célból az e\nrendelettel összhangban nagy kockázatú MI-rendszerként besorolt, digitális\nelemeket tartalmazó termékekkel összefüggő kiberbiztonsági kockázatoknak a\ndigitális elemeket tartalmazó termékekre vonatkozó horizontális\nkiberbiztonsági követelményekről szóló európai parlamenti és tanácsi rendelet\nalapján történő értékelése során foglalkozni kell az MI-rendszer\nkiberrezilienciájára jelentett kockázatokkal jogosulatlan harmadik felek arra\nirányuló kísérletei tekintetében, hogy a rendszer sebezhetőségének kiaknázása\nrévén megváltoztassák a rendszer használatát, viselkedését vagy\nteljesítményét, beleértve az olyan MI-specifikus sebezhetőségeket is, mint az\nadatmérgezés vagy az ellenséges támadások, valamint adott esetben e rendelet\nkövetelményeivel összhangban az alapvető jogokat érintő kockázatokkal. (78) Az\ne rendeletben előírt megfelelőségértékelési eljárást kell alkalmazni a\ndigitális elemeket tartalmazó termékekre vonatkozó horizontális\nkiberbiztonsági követelményekről szóló európai parlamenti és tanácsi rendelet\nhatálya alá tartozó és e rendelettel összhangban nagy kockázatú MI-\nrendszerként besorolt, digitális elemeket tartalmazó termékekre vonatkozó\nalapvető kiberbiztonsági követelményekre. Ez a szabály azonban nem vezethet a\ndigitális elemeket tartalmazó termékekre vonatkozó horizontális\nkiberbiztonsági követelményekről szóló európai parlamenti és tanácsi rendelet\nhatálya alá tartozó, digitális elemeket tartalmazó kritikus termékek szükséges\nmegbízhatósági szintjének csökkentéséhez. Ezért e szabálytól eltérve, az e\nrendelet hatálya alá tartozó és a digitális elemeket tartalmazó termékekre\nvonatkozó horizontális kiberbiztonsági követelményekről szóló európai\nparlamenti és tanácsi rendelet értelmében digitális elemeket tartalmazó fontos\nés kritikus terméknek minősülő olyan nagy kockázatú MI-rendszerekre, amelyekre\naz e rendelet mellékletében említett, belső ellenőrzésen alapuló\nmegfelelőségértékelési eljárás alkalmazandó, a digitális elemeket tartalmazó\ntermékekre vonatkozó horizontális kiberbiztonsági követelményekről szóló\neurópai parlamenti és tanácsi rendelet megfelelőségértékelésre vonatkozó\nrendelkezései alkalmazandók az említett rendeletben foglalt kiberbiztonsági\nkövetelmények tekintetében. Ebben az esetben az e rendelet hatálya alá tartozó\nminden egyéb szempont tekintetében az e rendelet mellékletében meghatározott,\na belső ellenőrzésen alapuló megfelelőségértékelési eljárásra vonatkozó\nrendelkezéseket kell alkalmazni. Az ENISA-nak a kiberbiztonsági politika terén\nrendelkezésre álló ismereteire és szakértelmére, valamint az (EU) 2019/881\neurópai parlamenti és tanácsi rendelet * alapján az ENISA-ra ruházott\nfeladatokra építve a Bizottságnak együtt kell működnie az ENISA-val az MI-\nrendszerek kiberbiztonságával kapcsolatos kérdésekben. (79) Helyénvaló, hogy\nvalamely nagy kockázatú MI-rendszer forgalomba hozataláért vagy üzembe\nhelyezéséért felelősséget vállaljon egy konkrét - a szolgáltatóként\nmeghatározott - természetes vagy jogi személy, függetlenül attól, hogy az\nemlített természetes vagy jogi személy az a személy-e, aki a rendszert\ntervezte vagy fejlesztette. (80) A fogyatékossággal élő személyek jogairól\nszóló ENSZ-egyezmény aláíróiként az Unió és a tagállamok jogi kötelezettséget\nviselnek azért, hogy megvédjék a fogyatékossággal élő személyeket a\nmegkülönböztetéssel szemben, és előmozdítsák egyenlőségüket, biztosítsák, hogy\na fogyatékossággal élő személyek másokkal egyenlő alapon hozzáférjenek az\ninformációs és kommunikációs technológiákhoz és rendszerekhez, és biztosítsák\na fogyatékossággal élő személyek magánéletének tiszteletben tartását.\nTekintettel az MI-rendszerek növekvő jelentőségére és használatára, az\negyetemes tervezés elveinek minden új technológiára és szolgáltatásra való\nalkalmazásának az MI-technológiák által potenciálisan érintett vagy azt\nhasználó minden személy - többek között a fogyatékossággal élők - számára\nbiztosítania kell a teljes körű és egyenlő hozzáférést oly módon, hogy az\nteljes mértékben figyelembe vegye veleszületett méltóságukat és\nsokféleségüket. Ezért alapvető fontosságú, hogy a szolgáltatók biztosítsák az\nakadálymentességi követelményeknek, többek között az (EU) 2016/2102 európai\nparlamenti és tanácsi irányelvnek * és az (EU) 2019/882 irányelvnek való\nmaradéktalan megfelelést. A szolgáltatóknak biztosítaniuk kell az e\nkövetelményeknek való, kialakítás általi beépített megfelelést. Ezért a\nszükséges intézkedéseket a lehető legnagyobb mértékben be kell építeni a nagy\nkockázatú MI-rendszer kialakításába. (81) A szolgáltatónak megbízható\nminőségirányítási rendszert kell létrehoznia, biztosítania kell az előírt\nmegfelelőségértékelési eljárás elvégzését, el kell készítenie a vonatkozó\ndokumentációt, és létre kell hoznia egy stabil, forgalomba hozatal utáni\nnyomonkövetési rendszert. A nagy kockázatú MI-rendszerek azon szolgáltatói\nszámára, amelyek a vonatkozó ágazati uniós jog értelmében a minőségirányítási\nrendszerekre vonatkozó kötelezettségek hatálya alá tartoznak, lehetővé kell\ntenni, hogy az e rendeletben előírt minőségirányítási rendszer elemeit az\nemlített más ágazati uniós jogszabályban előírt, meglévő minőségirányítási\nrendszerbe építsék be. Az e rendelet és a meglévő ágazati uniós jog közötti\nkiegészítő jelleget figyelembe kell venni a jövőbeli szabványosítási\ntevékenységek során vagy a Bizottság által elfogadott iránymutatásokban is. A\nnagy kockázatú MI-rendszereket saját használatra üzembe helyező hatóságok a\nminőségirányítási rendszerre vonatkozó szabályokat elfogadhatják és\nvégrehajthatják a nemzeti vagy adott esetben regionális szinten elfogadott\nminőségirányítási rendszer részeként, figyelembe véve az ágazat sajátosságait,\nvalamint az érintett hatóság hatásköreit és szervezetét. (82) E rendelet\nérvényesítésének lehetővé tétele és az üzemeltetők számára egyenlő\nversenyfeltételek megteremtése érdekében, valamint figyelembe véve a digitális\ntermékek rendelkezésre bocsátásának különböző formáit, fontos annak\nbiztosítása, hogy minden körülmények között legyen egy olyan, az Unióban\nletelepedett személy, aki meg tudja adni a hatóságoknak az MI-rendszerek\nmegfelelőségével kapcsolatos minden szükséges információt. Ezért MI-\nrendszereiknek az Unióban való rendelkezésre bocsátását megelőzően a harmadik\nországokban letelepedett szolgáltatóknak írásbeli meghatalmazással ki kell\nnevezniük egy, az Unióban letelepedett meghatalmazott képviselőt. A\nmeghatalmazott képviselő kulcsszerepet játszik a nem az Unióban letelepedett\nszolgáltatók által az Unióban forgalomba hozott vagy üzembe helyezett nagy\nkockázatú MI-rendszerek megfelelőségének biztosításában, továbbá az Unióban\nletelepedett kapcsolattartó szerepét betöltve. (83) Tekintettel az MI-\nrendszerek értékláncának jellegére és összetettségére, valamint összhangban az\núj jogszabályi kerettel, alapvető fontosságú a jogbiztonság garantálása és az\ne rendeletnek való megfelelés megkönnyítése. Ezért egyértelművé kell tenni az\nemlített értéklánc mentén a releváns gazdasági szereplők - így például az MI-\nrendszerek fejlesztéséhez esetlegesen hozzájáruló importőrök és forgalmazók -\nszerepét és konkrét kötelezettségeit. Bizonyos helyzetekben az említett\ngazdasági szereplők egyszerre több szerepben is eljárhatnak, és ezért az\nemlített szerepekhez társuló valamennyi releváns kötelezettséget együttesen\nkell teljesíteniük. Az üzemeltető például egyszerre járhat el forgalmazóként\nés importőrként. (84) A jogbiztonság biztosítása érdekében egyértelművé kell\ntenni, hogy bizonyos konkrét feltételek mellett bármely forgalmazót,\nimportőrt, alkalmazót vagy egyéb harmadik felet úgy kell tekinteni, hogy\nvalamely nagy kockázatú MI-rendszer szolgáltatója, és ezért vállalnia kell\nvalamennyi releváns kötelezettséget. Ilyen helyzet állna elő, ha az említett\nfél egy már forgalomba hozott vagy üzembe helyezett nagy kockázatú MI-\nrendszeren feltünteti a nevét vagy a védjegyét, az olyan szerződéses\nmegállapodások sérelme nélkül, amelyek a kötelezettségek másképp történő\nmegosztását írják elő. Ilyen helyzet állna elő akkor is, ha az említett fél\njelentős módosítást hajt végre egy már forgalomba hozott vagy már üzembe\nhelyezett nagy kockázatú MI-rendszeren oly módon, hogy az e rendelettel\nösszhangban továbbra is nagy kockázatú MI-rendszer marad, vagy jelentősen\nmódosítja egy olyan MI-rendszer rendeltetését - beleértve az általános célú\nMI-rendszereket is -, amelyet nem minősítettek nagy kockázatúnak, és amelyet\nmár forgalomba hoztak vagy üzembe helyeztek oly módon, hogy az érintett MI-\nrendszer ezen rendelettel összhangban nagy kockázatú MI-rendszerré válik. Az\nemlített rendelkezéseket az új jogszabályi kereten alapuló azon egyes uniós\nharmonizációs jogszabályokban megállapított konkrétabb rendelkezések sérelme\nnélkül kell alkalmazni, amelyekkel együtt kell e rendeletet alkalmazni.\nPéldául az (EU) 2017/745 rendelet 16. cikkének (2) bekezdését - amely\nmegállapítja, hogy bizonyos változtatások nem tekintendők egy adott eszköz\nolyan módosításának, amely befolyásolhatja az alkalmazandó követelményeknek\nvaló megfelelését - továbbra is alkalmazni kell az említett rendelet\nértelmében vett orvostechnikai eszköznek minősülő nagy kockázatú MI-\nrendszerekre. (85) Az általános célú MI-rendszerek használhatók önmagukban,\nnagy kockázatú MI-rendszerként vagy más nagy kockázatú MI-rendszerek\nalkotóelemeiként. Ezért sajátos jellegük miatt és a felelősségi köröknek a\nmesterségesintelligencia-értéklánc mentén történő méltányos megosztásának\nbiztosítása érdekében az ilyen rendszerek szolgáltatóinak - függetlenül attól,\nhogy azokat más szolgáltatók használhatják-e nagy kockázatú MI-rendszerként\nvagy nagy kockázatú MI-rendszerek alkotóelemeként, és amennyiben e rendelet\nmásként nem rendelkezik - szorosan együtt kell működniük egyrészt a releváns\nnagy kockázatú MI-rendszerek szolgáltatóival annak érdekében, hogy azok meg\ntudjanak felelni az e rendelet szerinti releváns kötelezettségeknek, másrészt\naz e rendelet alapján létrehozott illetékes hatóságokkal. (86) Amennyiben az\nezen rendeletben meghatározott feltételek alapján az MI-rendszert eredetileg\nforgalomba hozó vagy üzembe helyező szolgáltató e rendelet alkalmazása\ncéljából többé nem tekinthető szolgáltatónak, és amennyiben e szolgáltató\nkifejezetten nem zárta ki az MI-rendszer nagy kockázatú MI-rendszerré\nalakítását, az említett szolgáltatónak mindazonáltal szorosan együtt kell\nműködnie és rendelkezésre kell bocsátania a szükséges információkat, valamint\nbiztosítania kell az észszerűen elvárható technikai hozzáférést és egyéb\nsegítséget, amelyre az e rendeletben meghatározott kötelezettségek teljesítése\nérdekében szükség van, különösen a nagy kockázatú MI-rendszerek\nmegfelelőségértékelésnek való megfelelés tekintetében. (87) Továbbá amennyiben\negy olyan nagy kockázatú MI-rendszer, amely az új jogszabályi kereten alapuló\nuniós harmonizációs jogszabályok hatálya alá tartozó terméknek a biztonsági\nalkotórésze, nem kerül a terméktől függetlenül forgalomba hozatalra vagy\nüzembe helyezésre, a vonatkozó jogszabályban meghatározott termékgyártónak\nkell teljesítenie a szolgáltató e rendeletben meghatározott kötelezettségeit,\nés így különösen biztosítania kell, hogy a végtermékbe beágyazott MI-rendszer\nmegfeleljen e rendelet követelményeinek. (88) Az MI-értéklánc mentén gyakran\ntöbb fél is szolgáltat MI-rendszereket, eszközöket és nyújt ilyen\nszolgáltatásokat, emellett pedig olyan alkotóelemeket vagy folyamatokat is\nszolgáltat, amelyeket a szolgáltató beépít az MI-rendszerbe olyan különböző\ncélok megvalósítása érdekében, mint például a modellek tanítása, a modellek\nújratanítása, a modellek tesztelése és értékelése, a szoftverbe való\nintegrálás vagy a modellfejlesztés egyéb vonatkozásai. Ezek a felek fontos\nszerepet játszanak az értékláncban azon nagy kockázatú MI-rendszer\nszolgáltatója szempontjából, amelybe MI-rendszereiket, eszközeiket,\nszolgáltatásaikat, alkotóelemeiket vagy folyamataikat integrálják, és - saját\nszellemitulajdon-jogaik vagy üzleti titkaik veszélyeztetése nélkül - írásbeli\nmegállapodás révén, a technika általánosan elfogadott, mindenkori állása\nalapján át kell adnia a szükséges információkat, képességeket, technikai\nhozzáférést és egyéb segítséget az említett szolgáltatónak, annak érdekében,\nhogy a szolgáltató teljes mértékben eleget tudjon tenni az e rendeletben\nfoglalt kötelezettségeknek. (89) Az általános célú MI-modellektől eltérő\neszközöket, szolgáltatásokat, folyamatokat vagy MI-alkotóelemeket nyilvánosan\nhozzáférhetővé tevő harmadik felek nem kötelezhetők arra, hogy megfeleljenek\naz MI-értéklánc mentén fennálló felelősségi körökre vonatkozó\nkövetelményeknek, különösen az azokat használó vagy integráló szolgáltatóval\nszemben, amennyiben az említett eszközöket, szolgáltatásokat, folyamatokat\nvagy MI-alkotóelemeket szabad és nyílt forráskódú licenc alapján teszik\nhozzáférhetővé. A szabad és nyílt forráskódú eszközök, szolgáltatások,\nfolyamatok és MI-alkotóelemek fejlesztőit azonban ösztönözni kell a széles\nkörben elfogadott dokumentációs gyakorlatok, így például modellkártyák és\nadatlapok alkalmazására, hogy ezáltal felgyorsítsák az információmegosztást az\nMI-értékláncban, lehetővé téve a megbízható MI-rendszerek előmozdítását az\nUnióban. (90) A Bizottság önkéntes mintafeltételeket dolgozhat ki és ajánlhat\na nagy kockázatú MI-rendszerek szolgáltatói és a nagy kockázatú MI-\nrendszerekhez használt vagy azokba integrált eszközöket, szolgáltatásokat,\nalkotóelemeket vagy folyamatokat szolgáltató harmadik felek közötti\nszerződésekre vonatkozóan, ezzel elősegítve az együttműködést az értéklánc\nmentén. Az önkéntes mintafeltételek kidolgozása során a Bizottságnak\nfigyelembe kell vennie az egyes ágazatokban vagy üzleti ügyekben alkalmazandó\nlehetséges szerződéses követelményeket. (91) Tekintettel az MI-rendszerek\njellegére, valamint az esetlegesen a használatukkal összefüggésben a biztonság\nés az alapvető jogok tekintetében felmerülő kockázatokra, ideértve azt is,\nhogy biztosítani kell az MI-rendszer teljesítményének valós körülmények között\ntörténő, megfelelő nyomon követését, helyénvaló konkrét kötelezettségeket\nmeghatározni az alkalmazók számára. Az alkalmazóknak különösen megfelelő\ntechnikai és szervezeti intézkedéseket kell hozniuk annak biztosítása\nérdekében, hogy a használati utasításokkal összhangban használják a nagy\nkockázatú MI-rendszereket, és bizonyos egyéb kötelezettségeket is elő kell\nírni az MI-rendszerek működésének nyomon követésére és adott esetben a\nnyilvántartás vezetésére vonatkozóan. Továbbá, az alkalmazóknak biztosítaniuk\nkell, hogy a használati utasítás és az emberi felügyelet e rendeletben\nmeghatározott végrehajtására kijelölt személyek rendelkezzenek az említett\nfeladatok megfelelő ellátásához szükséges szakértelemmel, különösen megfelelő\nszintű MI-jártassággal, képzettséggel és felhatalmazással. Az említett\nkötelezettségek nem érinthetik az alkalmazóknak a nagy kockázatú MI-\nrendszerekkel kapcsolatos, uniós vagy nemzeti jog szerinti egyéb\nkötelezettségeit. (92) E rendelet nem érinti a munkáltatóknak az uniós vagy\nnemzeti jog és gyakorlat - többek között a 2002/14/EK európai parlamenti és\ntanácsi irányelv * - szerinti, a munkavállalóknak vagy képviselőiknek az MI-\nrendszerek üzembe helyezésével vagy használatával kapcsolatos döntésekről való\ntájékoztatására, illetve tájékoztatására és a velük folytatott konzultációra\nvonatkozó kötelezettségeket. Továbbra is szükséges biztosítani a munkavállalók\nés képviselőik tájékoztatását a nagy kockázatú MI-rendszerek tervezett\nmunkahelyi bevezetéséről, amennyiben az említett tájékoztatási, illetve\ntájékoztatási és konzultációs kötelezettségek más jogi eszközökben foglalt\nfeltételei nem teljesülnek. Ezen túlmenően az ilyen tájékoztatáshoz való jog\nkiegészítő jellegű és szükséges az e rendelet alapjául szolgáló alapvető jogok\nvédelmére irányuló célkitűzés tekintetében. Ebben a rendeletben ezért erre\nvonatkozó tájékoztatási követelményt kell meghatározni, a munkavállalók\nmeglévő jogainak sérelme nélkül. (93) Az MI-rendszerekkel kapcsolatos\nkockázatok keletkezhetnek egyrészt az ilyen rendszerek kialakításának\nmódjából, másrészt származhatnak abból is, ahogyan az MI-rendszereket\nhasználják. A nagy kockázatú MI-rendszerek alkalmazói ezért kritikus szerepet\njátszanak az alapvető jogok védelmében, kiegészítve az MI-rendszer fejlesztése\nsorán a szolgáltató kötelezettségeit. Helyzetüknél fogva az alkalmazók képesek\na legjobban megérteni, hogy konkrétan hogyan használják majd a nagy kockázatú\nMI-rendszert, és ezért azonosítani tudnak a fejlesztési szakaszban előre nem\nlátott jelentős potenciális kockázatokat, mivel pontosabban ismerik a\nfelhasználási kontextust, a valószínűleg érintett személyeket vagy személyek\ncsoportjait, ideértve a kiszolgáltatott csoportokat is. Az e rendelet egyik\nmellékletében felsorolt nagy kockázatú MI-rendszerek alkalmazói szintén\nkritikus szerepet játszanak a természetes személyek tájékoztatásában, és -\namikor természetes személyekkel kapcsolatos döntéseket hoznak vagy segítséget\nnyújtanak a természetes személyekkel kapcsolatos döntések meghozatalában -\nadott esetben tájékoztatniuk kell a természetes személyeket arról, hogy\nesetükben nagy kockázatú MI-rendszert használnak. Ebben a tájékoztatásban\nszerepelnie kell az MI-rendszer rendeltetésének és a rendszer által hozott\ndöntések típusának. Az alkalmazónak tájékoztatnia kell a természetes\nszemélyeket az e rendeletben meghatározott, magyarázathoz való jogukról is. A\nbűnüldözési célokra használt nagy kockázatú MI-rendszerek tekintetében az\nemlített kötelezettséget az (EU) 2016/680 irányelv 13. cikkével összhangban\nkell végrehajtani. (94) Az MI-rendszerek bűnüldözési célú, biometrikus\nazonosításra történő felhasználása során a biometrikus adatok bárminemű\nkezelésének meg kell felelnie az (EU) 2016/680 irányelv 10. cikkének, amely\ncsak akkor teszi lehetővé az ilyen adatkezelést, ha arra feltétlenül szükség\nvan, az érintett jogaira és szabadságaira vonatkozó megfelelő garanciák\nmellett, és amennyiben azt az uniós vagy tagállami jog lehetővé teszi. Az\nilyen felhasználás engedélyezése esetén tiszteletben kell tartani az (EU)\n2016/680 irányelv 4. cikkének (1) bekezdésében meghatározott elveket is,\nbeleértve a kezelés jogszerűségét, a kezelés tisztességes voltát és az\nátláthatóságot, a célhoz kötöttséget, a pontosságot és a tárolás korlátozását.\n(95) Az alkalmazandó uniós jog, különösen az (EU) 2016/679 rendelet és az (EU)\n2016/680 irányelv sérelme nélkül, tekintettel a nem valós idejű távoli\nbiometrikus azonosító rendszerek tolakodó jellegére, a nem valós idejű távoli\nbiometrikus azonosító rendszerek használatára vonatkozóan biztosítékokat kell\nmeghatározni. A nem valós idejű távoli biometrikus azonosító rendszereket\nmindig arányos és jogszerű módon, a feltétlenül szükséges mértékben - tehát\ncélzottan - kell használni az azonosítandó személyek, a helyszín és az időbeli\nhatály tekintetében, és a használatnak jogszerűen rögzített videofelvételek\nzárt adatkészlete alapján kell történnie. A nem valós idejű távoli biometrikus\nazonosító rendszereket semmi esetre sem szabad a bűnüldözés keretében olyan\nmódon felhasználni, hogy az megkülönböztetés nélküli megfigyeléshez vezessen.\nA nem valós idejű távoli biometrikus azonosításra vonatkozó feltételek semmi\nesetre sem szolgálhatnak alapul a valós idejű távoli biometrikus azonosításra\nvonatkozó tilalom és az arra vonatkozó szigorú kivételek megkerüléséhez. (96)\nAz alapvető jogok védelmének hatékony biztosítása érdekében a nagy kockázatú\nMI-rendszerek olyan alkalmazóinak, amelyek közjogi szervnek minősülnek vagy\namelyek közszolgáltatásokat nyújtó magánszervezetek, továbbá az e rendelet\negyik mellékletében felsorolt, bizonyos nagy kockázatú MI-rendszerek\nalkalmazóinak - így például a bankoknak vagy a biztosítóknak - a\nhasználatbavétel előtt alapvetőjogi hatásvizsgálatot kell végezniük.\nMagánszervezetek is nyújthatnak a magánszemélyek számára fontos, állami\njellegű szolgáltatásokat. Az ilyen közszolgáltatásokat nyújtó magánszervezetek\nközérdekű feladatokkal állnak kapcsolatban, például az oktatás, az\negészségügy, a szociális szolgáltatások, a lakhatás és az igazságszolgáltatás\nterületén. Az alapvetőjogi hatásvizsgálat célja, hogy az alkalmazó azonosítsa\na valószínűleg érintett egyének vagy egyének csoportjainak jogait érintő\nkonkrét kockázatokat, és azonosítsa az említett kockázatok bekövetkezése\nesetén meghozandó intézkedéseket. A hatásvizsgálatot a nagy kockázatú MI-\nrendszer bevezetését megelőzően kell lefolytatni, és aktualizálni kell, ha az\nalkalmazó úgy ítéli meg, hogy a releváns tényezők bármelyike megváltozott. A\nhatásvizsgálat keretében azonosítani kell az alkalmazó azon releváns\nfolyamatait, amelyekben a nagy kockázatú MI-rendszert a rendeltetésének\nmegfelelően használni fogják, és tartalmaznia kell annak leírását, hogy a\nrendszert milyen időtartamon keresztül és milyen gyakran használják majd,\nvalamint azon természetes személyek és csoportok konkrét kategóriáinak\nleírását, akiket és amelyeket a rendszer a konkrét felhasználási kontextusban\nvalószínűleg érint. A vizsgálatnak ki kell terjednie az említett személyek\nvagy csoportok alapvető jogaira valószínűleg hatást gyakorló konkrét kár\nkockázatának azonosítására is. Ezen vizsgálat elvégzése során az alkalmazónak\nfigyelembe kell vennie a hatás megfelelő értékelése szempontjából releváns\ninformációkat, többek között, de nem kizárólag a nagy kockázatú MI-rendszer\nszolgáltatója által a használati útmutatóban megadott információkat. Az\nazonosított kockázatok fényében az alkalmazóknak meg kell határozniuk az\nemlített kockázatok bekövetkezése esetén meghozandó intézkedéseket, ideértve\npéldául az említett konkrét felhasználási kontextusban alkalmazott irányítási\nintézkedéseket, így például a használati utasítás szerinti emberi felügyeletre\nvonatkozó szabályokat vagy a panaszkezelési és jogorvoslati eljárásokat, mivel\nezek a felhasználás konkrét eseteiben hozzájárulhatnak az alapvető jogokat\nérintő kockázatok enyhítéséhez. A hatásvizsgálat elvégzését követően az\nalkalmazónak értesítenie kell az érintett piacfelügyeleti hatóságot. Adott\nesetben a hatásvizsgálat elvégzéséhez szükséges releváns információk\nösszegyűjtése érdekében a nagy kockázatú MI-rendszerek alkalmazói - különösen\nha az MI-rendszereket a közszférában használják - bevonhatják az érintett\nérdekelt feleket, ideértve az MI-rendszer által valószínűleg érintett\nszemélyek csoportjainak képviselőit, független szakértőket és civil társadalmi\nszervezeteket az ilyen hatásvizsgálatok elvégzésébe és a kockázatok\nbekövetkezése esetén meghozandó intézkedések kidolgozásába. A Mesterséges\nIntelligenciával Foglalkozó Európai Hivatalnak (a továbbiakban: MI-hivatal)\nsablont kell kidolgoznia a megfelelés elősegítése és az alkalmazókra háruló\nadminisztratív terhek csökkentése érdekében. (97) A jogbiztonság lehetővé\ntétele érdekében az általános célú MI-modellek fogalmát egyértelműen meg kell\nhatározni, és el kell különíteni az MI-rendszerek fogalmától. A\nfogalommeghatározásnak az általános célú MI-modellek fő funkcionális\njellemzőin kell alapulnia, különös tekintettel a modell általánosságára és\nkülönféle feladatok széles körének kompetens elvégzésére való képességére.\nEzeket a modelleket jellemzően nagy mennyiségű adattal tanítják, különböző\nmódszerekkel - például önfelügyelt, felügyelet nélküli vagy megerősítéses\ntanulással. Az általános célú MI-modellek különböző módon kerülhetnek\nforgalomba, többek között könyvtárakon vagy alkalmazásprogramozási felületeken\n(API-kon) keresztül, közvetlen letöltés formájában vagy fizikai példányként.\nEzek a modellek tovább módosíthatók vagy finomíthatók új modellekké. Bár az\nMI-modellek az MI-rendszerek alapvető alkotóelemei, önmagukban nem minősülnek\nMI-rendszereknek. Az MI-modellek további alkotóelemek, például felhasználói\nfelület hozzáadását teszik szükségessé ahhoz, hogy MI-rendszerekké váljanak.\nAz MI-modelleket jellemzően az MI-rendszerekbe integrálják, és azok részét\nképezik. E rendelet egyedi szabályokat állapít meg az általános célú MI-\nmodellekre és a rendszerszintű kockázatot jelentő általános célú MI-modellekre\nvonatkozóan, amelyeket akkor is alkalmazni kell, ha ezek a modellek\nintegráltak vagy egy MI-rendszer részét képezik. Lényeges, hogy az általános\ncélú MI-modellek szolgáltatóira vonatkozó kötelezettségeket alkalmazni kell az\náltalános célú MI-modellek forgalomba hozatalától kezdve. Ha egy általános\ncélú MI-modell szolgáltatója saját modellt épít be saját, MI-rendszerébe,\namelyet forgalomba hoz vagy üzembe helyez, az adott modellt úgy kell\ntekinteni, mint ami forgalomban van, és ezért - az MI-rendszerekre vonatkozó\nkötelezettségeken felül - az e rendeletben a modellekre vonatkozóan\nmeghatározott kötelezettségeket továbbra is alkalmazni kell. A modellekre\nvonatkozóan megállapított kötelezettségek nem alkalmazandók abban az esetben,\nha egy saját modellt olyan, tisztán belső folyamatokhoz használnak fel,\namelyek nem nélkülözhetetlenek egy termék vagy szolgáltatás harmadik felek\nrészére történő nyújtásához, és ez nem érinti a természetes személyek jogait.\nA rendszerszintű kockázatot jelentő általános célú MI-modellekre mindig\nvonatkozniuk kell az e rendelet szerinti releváns kötelezettségeknek,\ntekintettel a potenciális, jelentősen negatív hatásaikra. A\nfogalommeghatározás nem terjedhet ki a forgalomba hozatal előtt kizárólag\nkutatási, fejlesztési és prototípus-alkotási tevékenységek céljából használt\nMI-modellekre. Ez nem érinti az e rendeletnek való megfelelésre vonatkozó\nkötelezettséget, amennyiben az említett tevékenységeket követően a modellt\nforgalomba hozzák. (98) Mivel egy modell általánosságát többek között számos\nparaméter is meghatározhatja, a legalább egymilliárd paramétert tartalmazó és\nnagy adatmennyiséggel, nagy léptékű önfelügyelet mellett tanított modelleket\núgy kell tekinteni, mint amelyek jelentős általánosságot mutatnak, és\nalkalmasak a különböző feladatok széles körének kompetens elvégzésére. (99) A\nnagy generatív MI-modellek az általános célú MI-modellek tipikus példái, mivel\nrugalmas tartalomelőállítást tesznek lehetővé, például szöveg, audio, képek\nvagy videó formájában, amelyekbe könnyen beleillik különféle feladatok széles\nköre. (100) Ha egy általános célú MI-modellt MI-rendszerbe integrálnak vagy ha\na modell az MI-rendszer részét képezi, akkor ezt a rendszert általános célú\nMI-rendszernek kell tekinteni, amennyiben az említett integráció miatt a\nrendszer képes számos különböző célt szolgálni. Az általános célú MI-\nrendszerek használhatók közvetlenül, vagy integrálhatók más MI-rendszerekbe.\n(101) Az általános célú MI-modellek szolgáltatói különleges szerepet játszanak\nés különleges felelősséget viselnek a mesterségesintelligencia-értéklánc\nmentén, mivel az általuk biztosított modellek számos downstream rendszer\nalapját képezhetik, amelyeket gyakran downstream szolgáltatók biztosítanak, ez\npedig a modellek és azok képességeinek alapos ismeretét teszi szükségessé,\negyrészt hogy integrálni tudják a modelleket a termékeikbe, másrészt hogy\neleget tegyenek az ezen, illetve más rendeletek szerinti kötelezettségeiknek.\nEzért arányos átláthatósági intézkedéseket kell megállapítani, beleértve a\ndokumentáció elkészítését és naprakészen tartását, valamint az általános célú\nMI-modellre vonatkozó információk nyújtását a downstream szolgáltatók általi\nhasználatra. A műszaki dokumentációt az általános célú MI-modell\nszolgáltatójának kell elkészítenie és naprakészen tartania annak érdekében,\nhogy azt kérésre az MI-hivatal és az illetékes nemzeti hatóságok\nrendelkezésére bocsássa. Az ilyen dokumentációba minimálisan belefoglalandó\nelemeket meg kell határozni e rendelet konkrét mellékleteiben. A Bizottságot\nfel kell hatalmazni arra, hogy a folyamatosan változó technológiai fejlődés\nfényében felhatalmazáson alapuló jogi aktusok révén módosítsa az említett\nmellékleteket. (102) Az olyan szoftverek és adatok, köztük a modellek,\namelyeket - a nyílt megosztást, és a felhasználók általi szabad hozzáférést,\nhasználatot, módosítást és terjesztést mind eredeti, mind módosított formában\nlehetővé tévő - szabad és nyílt forráskódú licenc alapján bocsátanak ki,\nhozzájárulhatnak a kutatáshoz és az innovációhoz a piacon, és jelentős\nnövekedési lehetőségeket biztosíthatnak az uniós gazdaság számára. A szabad és\nnyílt forráskódú licenc alapján kibocsátott általános célú MI-modelleket magas\nszintű átláthatóságot és nyitottságot biztosítóként kell tekinteni, amennyiben\nazok paramétereit - beleértve a súlyokat, a modell architektúrájára vonatkozó\ninformációkat és a modellhasználatra vonatkozó információkat - nyilvánosan\nhozzáférhetővé teszik. A licencet akkor is szabad és nyílt forráskódúnak kell\ntekinteni, ha lehetővé teszi a felhasználók számára a szoftverek és adatok\nfuttatását, másolását, terjesztését, tanulmányozását, módosítását és\ntökéletesítését, beleértve a modelleket is, feltéve, hogy feltüntetik a modell\neredeti szolgáltatóját, és tiszteletben tartják az azonos vagy\nösszehasonlítható terjesztési feltételeket. (103) A szabad és nyílt forráskódú\nMI-alkotóelemek magukban foglalják az adott MI-rendszer szoftvereit és adatait\n- beleértve a modelleket és az általános célú MI-modelleket -, eszközeit,\nszolgáltatásait vagy folyamatait. A szabad és nyílt forráskódú MI-alkotóelemek\nkülönböző csatornákon keresztül biztosíthatók, beleértve a szabadon\nhozzáférhető adattárakon történő fejlesztésüket is. E rendelet alkalmazásában\naz olyan MI-alkotóelemek, amelyeket díj ellenében bocsátanak rendelkezésre\nvagy más módon használnak bevétel szerzésére - például az MI-alkotóelemhez\nkapcsolódó technikai támogatás vagy egyéb szolgáltatások, többek között\nszoftverplatformon keresztül történő nyújtása vagy a személyes adatoknak\nkizárólagosan a szoftver biztonságának, kompatibilitásának vagy\ninteroperabilitásának javítása céljából történő felhasználástól eltérő\nfelhasználása révén -, nem részesülhetnek a szabad és nyílt forráskódú MI-\nalkotóelemekre vonatkozó kivételek előnyeiből, a mikrovállalkozások közötti\nügyletek kivételével. Az a tény, hogy MI-alkotóelemeket nyílt adattárakon\nkeresztül rendelkezésre bocsátanak, önmagában nem minősülhet\nbevételszerzésnek. (104) Az általános célú MI-modellekre előírt átláthatósági\nkövetelmények tekintetében kivételeket kell alkalmazni az olyan általános célú\nMI-modellek szolgáltatóira, amelyeket szabad és nyílt forráskódú licenc\nalapján bocsátanak ki, és amelyek paramétereit - többek között a súlyokat, a\nmodellarchitektúrára vonatkozó információkat és a modellhasználatra vonatkozó\ninformációkat - nyilvánosan hozzáférhetővé teszik, kivéve, ha úgy tekinthető,\nhogy rendszerszintű kockázatot jelentenek, amely esetben az a körülmény, hogy\na modell átlátható és nyílt forráskódú licenccel rendelkezik, nem tekinthető\nelegendő oknak az e rendelet szerinti kötelezettségeknek való megfelelés\nkizárására. Mindenesetre, tekintve, hogy az általános célú MI-modellek szabad\nés nyílt forráskódú licenc alapján történő kibocsátása nem feltétlenül fed fel\nlényeges információkat a modell tanításához vagy finomhangolásához használt\nadatkészletről, valamint arról, hogy ezáltal hogyan biztosították a szerzői\njognak való megfelelést, az átláthatósággal kapcsolatos követelményeknek való\nmegfelelés alóli, az általános célú MI-modellekre vonatkozó kivétel nem\nvonatkozhat a modell tanítására használt tartalomról szóló összefoglaló\nelkészítésének kötelezettségére és az uniós szerzői jognak való megfelelést\nszolgáló szabályzat elkészítésének kötelezettségére, különösen az (EU)\n2019/790 európai parlamenti és tanácsi irányelv * 4. cikkének (3) bekezdése\nszerinti jogfenntartás azonosítására és betartására vonatkozó kötelezettségre.\n(105) Az általános célú MI-modellek, különösen a nagy generatív MI-modellek,\namelyek képesek szövegek, képek és egyéb tartalmak létrehozására, egyedülálló\ninnovációs lehetőségeket kínálnak, ugyanakkor kihívást is jelentenek a\nművészek, szerzők és más alkotók számára, a tekintetben is, hogy milyen módon\nhozzák létre és terjesztik kreatív tartalmaikat, illetve hogy azt hogyan\nhasználják és fogyasztják. Az ilyen modellek kidolgozásához és tanításához\nhatalmas mennyiségű szöveghez, képhez, videóhoz és egyéb adathoz való\nhozzáférésre van szükség. A szöveg- és adatbányászati technikák ebben az\nösszefüggésben széles körben alkalmazhatók az olyan tartalmak kinyerésére és\nelemzésére, amelyek a szerzői és szomszédos jogok védelme alatt állhatnak. A\nszerzői jogi védelem alatt álló tartalom felhasználásához az érintett jogosult\nengedélye szükséges, amennyiben nincsenek érvényben szerzői jogi kivételek és\nkorlátozások. Az (EU) 2019/790 irányelv kivételeket és korlátozásokat vezetett\nbe, amelyek bizonyos feltételek mellett lehetővé teszik művek vagy más védelem\nalatt álló teljesítmények szöveg- és adatbányászat céljából történő\ntöbbszörözését és kimásolását. E szabályok értelmében a jogosultak\nfenntarthatják a műveikre vagy más védelem alatt álló teljesítményeikre\nvonatkozó jogaikat a szöveg- és adatbányászat megakadályozása érdekében,\nkivéve, ha az tudományos kutatás céljából történik. Amennyiben a kívülmaradási\njogot kifejezetten és megfelelő módon fenntartották, az általános célú MI-\nmodellek szolgáltatóinak engedélyt kell szerezniük a jogosultaktól, ha szöveg-\nés adatbányászatot kívánnak végezni az ilyen műveken. (106) Az általános célú\nMI-modelleket az uniós piacon forgalomba hozó szolgáltatóknak biztosítaniuk\nkell az e rendeletben foglalt vonatkozó kötelezettségeknek való megfelelést. E\ncélból az általános célú MI-modellek szolgáltatóinak olyan szabályokat kell\nkialakítaniuk, amely megfelel a szerzői és szomszédos jogokra vonatkozó uniós\njognak, különösen a jogosultak által az (EU) 2019/790 irányelv 4. cikkének (3)\nbekezdése alapján kifejezett jogfenntartásnak való megfelelés érdekében.\nMinden olyan szolgáltatónak, amely általános célú MI-modellt hoz forgalomba az\nuniós piacon, meg kell felelnie e kötelezettségnek, függetlenül attól, hogy\nmely joghatóság területén kerül sor az említett általános célú MI-modellek\nbetanításának alapjául szolgáló, a szerzői jog szempontjából releváns\ntevékenységre. Erre azért van szükség, hogy egyenlő versenyfeltételeket\nlehessen biztosítani az általános célú MI-modellek szolgáltatói számára, hogy\negyetlen szolgáltató se juthasson versenyelőnyhöz az uniós piacon azáltal,\nhogy az Unióban biztosítottaknál alacsonyabb szerzői jogi normákat alkalmaz.\n(107) Az általános célú MI-modellek előtanítása és tanítása során felhasznált\nadatokat - köztük a szerzői jog által védett szövegeket és adatokat - illető\nátláthatóság növelése érdekében helyénvaló, hogy az ilyen modellek\nszolgáltatói kellően részletes összefoglalót készítsenek és tegyenek\nnyilvánosan hozzáférhetővé az általános célú MI-modell tanításához használt\ntartalomról. Az üzleti titkok és a bizalmas üzleti információk védelmének\nszükségességét kellően figyelembe véve, ezen összefoglalónak általánosságban\nvéve kell átfogónak lennie, és nem technikai szempontból részletesnek, hogy\nmegkönnyítse a jogos érdekkel rendelkező felek - köztük a szerzői jogok\njogosultjai - számára az uniós jog szerinti jogaik gyakorlását és\nérvényesítését, például a modell tanítására felhasznált fő adatgyűjtemények\nvagy -készletek - például a nagy magán- vagy nyilvános adatbázisok vagy\nadatarchívumok - felsorolásával, valamint az egyéb felhasznált adatforrások\nrészletes leírásával. Helyénvaló, hogy az MI-hivatal rendelkezésre bocsássa az\nösszefoglaló mintáját, amelynek egyszerűnek és hatékonynak kell lennie, és\nlehetővé kell tennie a szolgáltató számára, hogy az előírt összefoglalót\nrészletes leírás formájában bocsássa rendelkezésre. (108) Az általános célú\nMI-modellek szolgáltatói számára előírt azon kötelezettségek tekintetében,\nhogy alakítsanak ki az uniós szerzői jognak való megfelelést célzó\nszabályokat, és hogy tegyék nyilvánosan hozzáférhetővé a tanításhoz használt\ntartalom összefoglalóját, az MI-hivatalnak nyomon kell követnie, hogy a\nszolgáltató teljesítette-e ezeket a kötelezettségeket, anélkül, hogy\nellenőrizné vagy az egyes művekre kiterjedően értékelné a tanítási adatokat a\nszerzői jogoknak való megfelelés tekintetében. E rendelet nem érinti az uniós\njogban előírt szerzői jogi szabályok érvényesítését. (109) Az általános célú\nMI-modellek szolgáltatóira alkalmazandó kötelezettségeknek való megfelelésnek\na modellszolgáltató típusával összemérhetőnek és arányosnak kell lennie,\nkizárva a megfelelés szükségességét azon személyek esetében, akik nem szakmai\nvagy tudományos kutatási célokra fejlesztenek vagy használnak modelleket,\nmindazonáltal ösztönözve őket arra, hogy önkéntes alapon feleljenek meg ezen\nkövetelményeknek. Az említett kötelezettségeknek való megfelelés során - az\nuniós szerzői jog sérelme nélkül - kellően figyelembe kell venni a szolgáltató\nméretét, és lehetővé kell tenni a kkv-k - köztük az induló innovatív\nvállalkozások - számára a megfelelés biztosításának egyszerűsített módjait,\namelyek nem jelenthetnek túlzott költségeket, és nem gátolhatják az ilyen\nmodellek használatát. Egy modell módosítása vagy finomhangolása esetén az\náltalános célú MI-modellek szolgáltatóinak kötelezettségeit az említett\nmódosításra vagy finomhangolásra kell korlátozni, például azáltal, hogy a már\nmeglévő műszaki dokumentációt kiegészítik a módosításokra vonatkozó\ninformációkkal, beleértve a tanításra használt új adatforrásokat is, az\nértékláncra vonatkozóan e rendeletben előírt kötelezettségeknek való\nmegfelelés módjaként. (110) Az általános célú MI-modellek rendszerszintű\nkockázatokat jelenthetnek, amelyek a teljesség igénye nélkül többek között\nmagukban foglalják a súlyos balesetekhez, a kritikus ágazatok zavaraihoz,\nvalamint a közegészségre és a közbiztonságra gyakorolt súlyos\nkövetkezményekhez kapcsolódó tényleges vagy észszerűen előrelátható negatív\nhatásokat; a demokratikus folyamatokra, a közbiztonságra és a gazdasági\nbiztonságra gyakorolt tényleges vagy észszerűen előrelátható negatív\nhatásokat; jogellenes, hamis vagy megkülönböztető tartalom terjesztését. A\nrendszerszintű kockázatokat úgy kell értelmezni, hogy azok a modell\nképességeivel és a modell elterjedésével növekednek, a modell teljes\néletciklusa során felmerülhetnek, és azokat befolyásolják a rendellenes\nhasználat körülményei, a modell megbízhatósága, a modell méltányossága és a\nmodell biztonsága, a modell autonómiaszintje, annak eszközökhöz való\nhozzáférése, az új vagy kombinált modalitások, a kibocsátási és terjesztési\nstratégiák, a biztosítékok eltávolításának lehetősége és egyéb tényezők. Így\nkülönösen, a nemzetközi megközelítések keretében eddig beazonosították annak\nszükségességét, hogy figyelmet fordítsanak a következőkre: az esetleges\nszándékos rendellenes használattal vagy az emberi szándékkal való\nösszehangolással kapcsolatos, nem szándékosan előidézett ellenőrzési\nproblémákból eredő kockázatok; vegyi, biológiai, radiológiai és nukleáris\nkockázatok, például a belépési korlátok eltávolításának módjai többek között a\nfegyverek fejlesztése, tervezése vagy használata terén; offenzív\nkiberképességek, például a sebezhetőség feltárásának, kiaknázásának vagy\noperatív kihasználásának elősegítésére szolgáló módszerek; az interakció és az\neszközhasználat hatásai, beleértve például a fizikai rendszerek vezérlésére és\na kritikus infrastruktúrákba való beavatkozásra való képességet; az önmagukról\nmásolatot készítő, „önreplikációra” képes vagy más modelleket tanító\nmodellekből eredő kockázatok; az, hogy a modellek hogyan vezethetnek káros\ntorzításhoz és megkülönböztetéshez, ami kockázatot hordoz magában az\negyénekre, közösségekre vagy társadalmakra nézve; a dezinformáció elősegítése\nvagy a magánélet megsértése a demokratikus értékeket és az emberi jogokat\nfenyegető veszélyek által; annak kockázata, hogy egy adott esemény olyan\nláncreakcióhoz vezethet, amelynek jelentős negatív hatásai lehetnek egy egész\nvárosra, egy teljes tevékenységi területre vagy egy egész közösségre. (111)\nHelyénvaló módszertant létrehozni az általános célú MI-modellek rendszerszintű\nkockázatot jelentő általános célú MI-modellként való besorolására. Mivel a\nkülönösen kiterjedt képességek rendszerszintű kockázatokat eredményeznek, az\náltalános célú MI-modell akkor tekintendő rendszerszintű kockázatot\njelentőnek, ha megfelelő technikai eszközök és módszertanok alapján értékelt,\nnagy hatású képességekkel rendelkezik, vagy elterjedtsége miatt jelentős\nhatással van a belső piacra. Az általános célú MI-modellek esetében a nagy\nhatású képességek olyan képességeket jelentenek, amelyek megfelelnek a\nlegfejlettebb általános célú MI-modellekben rögzített képességeknek, vagy\nmeghaladják azokat. Adott modell képességeinek teljes kiterjedését jobban meg\nlehetne érteni a modell forgalomba hozatala után, vagy akkor, amikor az\nalkalmazók interakcióba lépnek a modellel. A technika állása szerint e\nrendelet hatálybalépésekor a modellképességekre vonatkozó releváns közelítések\negyike az általános célú MI-modell betanításához használt, lebegőpontos\nműveletekben mért összesített számítási mennyiség. A betanításhoz használt\nösszesített számítási mennyiség magában foglalja az olyan tevékenységek és\nmódszerek során alkalmazott számításokat, amelyek célja a modell képességeinek\nfokozása a bevezetést megelőzően, mint például az előtanítás, a szintetikus\nadatelőállítás és a finomhangolás. Ezért meg kell határozni a lebegőpontos\nműveletek kiinduló küszöbértékét, amely - ha azt egy általános célú MI-modell\neléri - azon vélelemhez vezet, hogy a modell rendszerszintű kockázatot jelentő\náltalános célú MI-modell. E küszöbértéket idővel ki kell igazítani, hogy\ntükrözze a technológiai és az ágazati változásokat, így például az algoritmus\nfejlesztéseit vagy a nagyobb hardverhatékonyságot, és ki kell azt egészíteni a\nmodellképességre vonatkozó referenciaértékekkel és mutatókkal. Ennek érdekében\naz MI-hivatalnak együtt kell működnie a tudományos közösséggel, az ágazattal,\na civil társadalommal és más szakértőkkel. A küszöbértékeknek, valamint a nagy\nhatású képességek értékelésére szolgáló eszközöknek és referenciaértékeknek\njól előre kell tudniuk jelezni az általánosságot, a modell képességeit,\nvalamint az általános célú MI-modellek kapcsolódó rendszerszintű kockázatait,\nés figyelembe vehetik a modell forgalomba hozatalának módját vagy az általa\nesetlegesen érintett felhasználók számát. E rendszer kiegészítéseképpen\nlehetővé kell tenni a Bizottság számára, hogy egyedi határozatokat hozzon,\namelyekkel egy általános célú MI-modellt rendszerszintű kockázatot jelentő\náltalános MI-modellként jelöl meg, ha megállapítást nyer, hogy az ilyen modell\na meghatározott küszöbérték által rögzített képességekkel vagy hatással\negyenértékű képességekkel vagy hatással rendelkezik. Az említett határozatot\naz e rendelet mellékletében meghatározott, a rendszerszintű kockázatot jelentő\náltalános célú MI-modell megjelölésére vonatkozó, olyan kritériumok átfogó\nértékelése alapján kell meghozni, mint például a tanítóadatkészlet minősége\nvagy mérete, az üzleti és a végfelhasználók száma, az AI-modell bemeneti és\nkimeneti modalitásai, autonómiaszintje és méretezhetősége, vagy a\nrendelkezésére álló eszközök. Azon szolgáltató indokolással ellátott kérésére,\namelynek modelljét rendszerszintű kockázatot jelentő általános MI-modellként\njelöltek meg, a Bizottságnak figyelembe kell vennie a kérelmet, és a Bizottság\ndönthet úgy, hogy újraértékeli, vajon az általános célú MI-modell továbbra is\nrendszerszintű kockázatot jelentőnek tekinthető-e. (112) Helyénvaló emellett\ntisztázni az az általános célú MI-modellek rendszerszintű kockázatot jelentő\náltalános célú MI-modellként való besorolására szolgáló eljárást. Egy olyan\náltalános célú MI-modellt, amely megfelel a nagy hatású képességekre\nalkalmazandó küszöbértéknek, rendszerszintű kockázatot jelentő általános célú\nMI-modellnek kell tekinteni. A szolgáltatónak legkésőbb két héttel azt\nkövetően értesítenie kell az MI-hivatalt, hogy a követelmények teljesülnek,\nvagy ismertté válik, hogy egy általános célú MI-modell meg fog felelni a\nvélelemhez vezető követelményeknek. Ez különösen fontos a lebegőpontos\nműveletek küszöbértékivel kapcsolatban, mivel az általános célú MI-modellek\nbetanítása jelentős mértékű tervezést igényel, amely magában foglalja a\nszámítási erőforrások előzetes elosztását is, és ezért az általános célú MI-\nmodellek szolgáltatói tudhatják, hogy modelljük a betanítás befejezése előtt\nel fogja-e érni a küszöbértéket. Az említett értesítéssel összefüggésben a\nszolgáltatónak képesnek kell lennie annak bizonyítására, hogy egy általános\ncélú MI-modell - sajátos jellemzői miatt - kivételesen nem jelent\nrendszerszintű kockázatot, és ezért nem minősíthető rendszerszintű kockázatot\njelentő általános célú MI-modellnek. Ez az információ értékes az MI-hivatal\nszámára a rendszerszintű kockázatokkal járó általános célú MI-modellek\nforgalomba hozatalának előrejelzéséhez, és a szolgáltatók már korán\nkapcsolatba léphetnek az MI-hivatallal. Az említett információ különösen\nfontos az olyan általános célú MI-modellek tekintetében, amelyeket nyílt\nforráskódú modellként terveznek kibocsátani, tekintve, hogy a nyílt forráskódú\nmodellek kibocsátását követően nehezebben hajthatók végre az e rendelet\nszerinti kötelezettségeknek való megfelelés biztosításához szükséges\nintézkedések. (113) Ha a Bizottság tudomást szerez arról, hogy egy általános\ncélú MI-modell megfelel egy olyan rendszerszintű kockázatot jelentő általános\ncélú MI-modellként való besorolás követelményeinek, amely korábban nem volt\nismert, vagy amelyről a releváns szolgáltató elmulasztotta értesíteni a\nBizottságot, a Bizottságot fel kell hatalmazni az ilyenként való megjelölésre.\nEgy minősített riasztási rendszernek kell biztosítania, hogy - az MI-hivatal\nnyomonkövetési tevékenységei mellett - az esetlegesen rendszerszintű\nkockázatot jelentő általános célú MI-modellként besorolandó általános célú MI-\nmodellekkel foglalkozó tudományos testület is felhívja erre az MI-hivatal\nfigyelmét. (114) A rendszerszintű kockázatot jelentő általános célú MI-\nmodellek szolgáltatóira az általános célú MI-modellek szolgáltatói számára\nelőírt kötelezettségeken túlmenően olyan kötelezettségeknek is vonatkoznia\nkell, amelyek célja az említett kockázatok azonosítása és enyhítése, valamint\na megfelelő szintű kiberbiztonsági védelem biztosítása, függetlenül attól,\nhogy a modellt önálló modellként vagy egy MI-rendszerbe vagy termékbe\nágyazottként szolgáltatják-e. Az említett célkitűzések elérése érdekében e\nrendeletnek elő kell írnia a szolgáltatók számára, hogy - különösen az első\nforgalomba hozatal előtt - végezzék el a szükséges modellértékeléseket,\nideértve a modellek támadói szempontú tesztelésének elvégzését és\ndokumentálását, többek között az adott eset függvényében belső vagy független\nkülső tesztelés révén is. Emellett a rendszerszintű kockázatot jelentő\náltalános célú MI-modellek szolgáltatóinak folyamatosan értékelniük és\nenyhíteniük kell a rendszerszintű kockázatokat, többek között kockázatkezelési\nszabályzatok - így például elszámoltathatósági és irányítási folyamatok -\nbevezetése, a forgalomba hozatal utáni nyomon követés végrehajtása, megfelelő\nintézkedéseknek a modell teljes életciklusa során történő meghozatala,\nvalamint az MI-értéklánc érintett szereplőivel való együttműködés révén. (115)\nA rendszerszintű kockázatot jelentő általános célú MI-modellek szolgáltatóinak\nfel kell mérniük és enyhíteniük kell az esetleges rendszerszintű kockázatokat.\nHa az olyan általános célú MI-modell esetében, amely rendszerszintű\nkockázatokat jelenthet, a kapcsolódó kockázatok azonosítására és megelőzésére\nirányuló erőfeszítések ellenére a modell fejlesztése vagy használata súlyos\nváratlan eseményt okoz, az általános célú MI-modell szolgáltatójának\nindokolatlan késedelem nélkül nyomon kell követnie a váratlan eseményt, és\njelentenie kell a Bizottság és az illetékes nemzeti hatóságok részére a\nreleváns információkat és a lehetséges korrekciós intézkedéseket. Továbbá, a\nszolgáltatóknak megfelelő szintű kiberbiztonsági védelmet kell biztosítaniuk a\nmodell és adott esetben a fizikai infrastruktúrája számára a modell teljes\néletciklusa során. A rosszindulatú felhasználással vagy támadásokkal\nkapcsolatos rendszerszintű kockázatokhoz kapcsolódó kiberbiztonsági védelemnek\nmegfelelően szem előtt kell tartania a véletlen modellszivárgást, a\njogosulatlan kibocsátásokat, a biztonsági intézkedések megkerülését, valamint\na kibertámadásokkal, a jogosulatlan hozzáféréssel vagy a modell-lopással\nszembeni védelmet. Az említett védelmet megkönnyítheti a modellsúlyok, az\nalgoritmusok, a szerverek és az adatkészletek biztosítása, így például az\ninformációbiztonságra vonatkozó operatív biztonsági intézkedések, konkrét\nkiberbiztonsági politikák, megfelelő technikai és bevált megoldások, valamint\nkiber- és fizikai hozzáférési ellenőrzések révén, amelyek megfelelnek a\nreleváns körülményeknek és a felmerülő kockázatoknak. (116) Az MI-hivatalnak\nösztönöznie kell és elő kell segítenie a gyakorlati kódexek kidolgozását,\nfelülvizsgálatát és kiigazítását, figyelembe véve a nemzetközi\nmegközelítéseket. Az általános célú MI-modellek valamennyi szolgáltatóját fel\nlehetne kérni a részvételre. Annak biztosítása érdekében, hogy a gyakorlati\nkódexek tükrözzék a technika mindenkori állását, és kellően figyelembe vegyék\na különböző nézőpontokat, az MI-hivatalnak együtt kell működnie az illetékes\nnemzeti illetékes hatóságokkal, és adott esetben konzultálnia kell a civil\ntársadalmi szervezetekkel és más érdekelt felekkel és szakértőkkel - egyebek\nmellett a tudományos testülettel - az ilyen kódexek kidolgozása során. A\ngyakorlati kódexeknek ki kell terjedniük az általános célú MI-modellek,\nvalamint a rendszerszintű kockázatot jelentő általános célú MI-modellek\nszolgáltatóira vonatkozó kötelezettségekre. Emellett a rendszerszintű\nkockázatok tekintetében a gyakorlati kódexeknek elő kell segíteniük egy, a\nrendszerszintű kockázatok típusára és jellegére vonatkozó uniós szintű\nkockázati taxonómia létrehozását, ideértve azok forrásait is. A gyakorlati\nkódexeknek a kockázatok értékelésére és csökkentésére irányuló konkrét\nintézkedésekre is összpontosulniuk kell. (117) A gyakorlati kódexeknek\nközponti eszközként kell szolgálniuk az általános célú MI-modellek\nszolgáltatói számára az e rendeletben előírt kötelezettségek megfelelő\nbetartásához. A gyakorlati kódexeknek alkalmasnak kell lenniük arra, hogy a\nszolgáltatók támaszkodjanak rájuk a kötelezettségeknek való megfelelés\nbizonyítása érdekében. A Bizottság végrehajtási jogi aktusok útján határozhat\núgy, hogy jóváhagy egy gyakorlati kódexet, és általános érvényességgel ruházza\nfel azt az Unión belül, vagy - alternatív módon - közös szabályokról\nrendelkezik a releváns kötelezettségek végrehajtására vonatkozóan, ha - e\nrendelet alkalmazandóvá válásáig - a gyakorlati kódexet nem lehet\nvéglegesíteni, vagy azt az MI-hivatal nem tartja megfelelőnek. Miután egy\nharmonizált szabvány közzétételre kerül és az MI-hivatal úgy ítéli meg, hogy\naz alkalmas a releváns kötelezettségek lefedésére, az európai harmonizált\nszabványnak való megfelelésnek biztosítania kell a szolgáltatók számára a\nmegfelelés vélelmét. Az általános célú MI-modellek szolgáltatói számára\ntovábbá lehetővé kell tenni, hogy megfelelő alternatív eszközökkel igazolják a\nmegfelelést, ha nem állnak rendelkezésre gyakorlati kódexek vagy harmonizált\nszabványok, vagy ha úgy döntenek, hogy nem támaszkodnak azokra. (118) E\nrendelet azáltal szabályozza az MI-rendszereket és az MI-modelleket, hogy\nbizonyos követelményeket és kötelezettségeket ír elő az azokat az Unióban\nforgalomba hozó, üzembe helyező vagy használó releváns piaci szereplők\nszámára, ezáltal kiegészítve az ilyen rendszereket vagy modelleket az (EU)\n2022/2065 rendelet által szabályozott szolgáltatásaikba beépítő közvetítő\nszolgáltatók kötelezettségeit. Amennyiben az ilyen rendszerek vagy modellek\nkijelölt online óriásplatformokba vagy nagyon népszerű online\nkeresőprogramokba vannak beágyazva, azokra az (EU) 2022/2065 rendeletben\nelőírt kockázatkezelési keret vonatkozik. Következésképpen, e rendelet\nvonatkozó kötelezettségeit teljesítettnek kell feltételezni, kivéve, ha az\n(EU) 2022/2065 rendelet hatálya alá nem tartozó, jelentős rendszerszintű\nkockázatok merülnek fel, és azokat az ilyen modellekben azonosítják. E kereten\nbelül az online óriásplatformokat és nagyon népszerű online keresőprogramokat\nüzemeltető szolgáltatók kötelesek értékelni a szolgáltatásaik kialakításából,\nműködéséből és használatából eredő potenciális rendszerszintű kockázatokat,\nbeleértve azt is, hogy a szolgáltatás által használt algoritmikus rendszerek\nkialakítása hogyan járulhat hozzá az ilyen kockázatokhoz, valamint a\npotenciális rendellenes használatokból eredő rendszerszintű kockázatokhoz. Az\nemlített szolgáltatók arra is kötelesek, hogy az alapvető jogokra figyelemmel,\nmegfelelő kockázatenyhítési intézkedéseket hozzanak. (119) Tekintettel a\nkülönböző uniós jogi eszközök hatálya alá tartozó digitális szolgáltatásokkal\nkapcsolatos innováció gyors ütemére és technológiai fejlődésére, különös\ntekintettel a szolgáltatás igénybe vevőinek használatára és megítélésére, az e\nrendelet hatálya alá tartozó MI-rendszerek az (EU) 2022/2065 rendelet\nértelmében vett közvetítő szolgáltatásként vagy annak részeiként is\nnyújthatók, amelyet technológiasemleges módon kell értelmezni. Például az MI-\nrendszerek felhasználhatók online keresőmotorok szolgáltatására, különösen\namennyiben egy MI-rendszer, például egy online csevegőrobot elvben valamennyi\nweboldalon keresést végez, az eredményeket beépíti meglévő ismereteibe, és a\nfrissített ismereteket arra használja fel, hogy egyetlen, különböző\ninformációforrásokat ötvöző kimenetet hozzon létre. (120) Továbbá, az (EU)\n2022/2065 rendelet hatékony végrehajtásának elősegítése érdekében különösen\nfontosak az e rendeletben az egyes MI-rendszerek szolgáltatóira és\nalkalmazóira rótt azon kötelezettségek, amelyek lehetővé teszik annak\nészlelését és közzétételét, hogy e rendszerek kimeneteit mesterségesen hozzák\nlétre vagy manipulálják. Ez különösen alkalmazandó az online óriásplatformokat\nvagy nagyon népszerű online keresőprogramokat üzemeltető szolgáltatók azon\nkötelezettségeire, hogy azonosítsák és enyhítsék a mesterségesen létrehozott\nvagy manipulált tartalom terjesztéséből eredő rendszerszintű kockázatokat,\nkülönösen a demokratikus folyamatokra, a civil párbeszédre és a választási\nfolyamatokra - többek között dezinformáció révén - gyakorolt tényleges vagy\nelőrelátható negatív hatások kockázatát. (121) A szabványosításnak\nkulcsszerepet kell játszania abban, hogy az e rendeletnek való megfelelés\nbiztosítása érdekében megfelelő műszaki megoldások álljanak a szolgáltatók\nrendelkezésére, a technika mindenkori állásának megfelelően, az uniós piac\nversenyképességének és növekedésének előmozdítása érdekében. A szolgáltatóknak\naz 1025/2012/EU európai parlamenti és tanácsi rendelet * 2. cikke 1. pontjának\nc) alpontjában meghatározott - és alapelvárás szerint a technika mindenkori\nállását tükröző - harmonizált szabványoknak való megfelelés révén is tudniuk\nkell bizonyítani az e rendelet követelményeinek való megfelelést. Ezért az\n1025/2012/EU rendelet 5. és 6. cikkével összhangban ösztönözni kell az érdekek\nkiegyensúlyozott képviseletét a szabványok kidolgozása terén valamennyi\nérintett érdekcsoport részvételével, különös tekintettel a kkv-kra, a\nfogyasztóvédelmi szervezetekre, valamint a környezetvédelmi és szociális\nérdekelt felekre. A megfelelés elősegítése érdekében a Bizottságnak\nindokolatlan késedelem nélkül ki kell adnia a szabványosítási kérelmeket. A\nszabványosítási kérelem elkészítésekor a Bizottságnak - a releváns szakértelem\nösszegyűjtése érdekében - konzultálnia kell a tanácsadó fórummal és a\nTestülettel. Azonban a harmonizált szabványokra való releváns hivatkozások\nhiányában a Bizottság számára lehetővé kell tenni, hogy - végrehajtási jogi\naktusok révén és a tanácsadó fórummal folytatott konzultációt követően - közös\nelőírásokat állapítson meg az e rendelet szerinti egyes követelményekre\nvonatkozóan. A közös előírásnak kivételes tartalékmegoldásnak kell lennie,\namely megkönnyíti a szolgáltató számára az e rendelet követelményeinek való\nmegfelelésre vonatkozó kötelezettségének teljesítését, ha a szabványosítási\nkérelmet egyik európai szabványügyi szervezet sem fogadta el, vagy ha a\nreleváns harmonizált szabványok nem kezelik megfelelően az alapvető jogokkal\nkapcsolatos aggályokat, vagy ha a harmonizált szabványok nem felelnek meg a\nkérelemnek, vagy ha egy megfelelő harmonizált szabvány elfogadása késedelmet\nszenved. Amennyiben egy harmonizált szabvány elfogadása terén az ilyen\nkésedelem az említett szabvány műszaki összetettségének tudható be, a\nBizottságnak ezt figyelembe kell vennie, mielőtt fontolóra venné közös\nelőírások kidolgozását. A közös előírások kidolgozása során a Bizottság\nösztönözve van arra, hogy működjön együtt a nemzetközi partnerekkel és a\nnemzetközi szabványügyi testületekkel. (122) Helyénvaló, hogy - a harmonizált\nszabványok és közös előírások alkalmazásának sérelme nélkül - azon nagy\nkockázatú MI-rendszerek szolgáltatóit, amelyeket olyan adatokon tanítottak és\nteszteltek, amelyek tükrözik azt a konkrét földrajzi, viselkedési,\nkontextuális vagy funkcionális környezetet, amelyben az MI-rendszert használni\nkívánják, úgy kell tekinteni, hogy megfelelnek az e rendeletben meghatározott\nadatkormányzási követelményben előírt releváns intézkedésnek. Az e rendeletben\nmeghatározott, a megbízhatóságra és pontosságra vonatkozó követelmények\nsérelme nélkül, az (EU) 2019/881 rendelet 54. cikkének (3) bekezdésével\nösszhangban azon nagy kockázatú MI-rendszerekről, amelyeket az említett\nrendelettel összhangban egy kiberbiztonsági rendszer keretében tanúsítottak,\nvagy amelyekre vonatkozóan megfelelőségi nyilatkozatot állítottak ki, és\namelyek hivatkozásait közzétették az Európai Unió Hivatalos Lapjában,\nvélelmezni kell, hogy megfelelnek az e rendeletben foglalt kiberbiztonsági\nkövetelménynek, amennyiben a kiberbiztonsági tanúsítvány vagy megfelelőségi\nnyilatkozat vagy annak részei kiterjednek e rendelet kiberbiztonsági\nkövetelményeire. Ez továbbra sem érinti az említett kiberbiztonsági rendszer\nönkéntes jellegét. (123) A nagy kockázatú MI-rendszerek magas szintű\nmegbízhatóságának biztosítása érdekében ezeket a rendszereket forgalomba\nhozataluk vagy üzembe helyezésük előtt megfelelőségértékelésnek kell alávetni.\n(124) A gazdasági szereplők terheinek minimalizálása és az esetleges\npárhuzamosságok elkerülése érdekében helyénvaló, hogy azon nagy kockázatú MI-\nrendszerek esetében, amelyek az új jogszabályi kereten alapuló meglévő uniós\nharmonizációs jogszabályok hatálya alá tartozó termékekhez kapcsolódnak, az\nemlített MI-rendszerek e rendelet követelményeinek való megfelelése az\nemlített jogszabályokban már előírt megfelelőségértékelés részeként kerüljön\nértékelésre. E rendelet követelményeinek alkalmazhatósága ezért nem érintheti\na vonatkozó uniós harmonizációs jogszabályok szerinti megfelelőségértékelés\nkonkrét logikáját, módszertanát vagy általános szerkezetét. (125) Tekintettel\na nagy kockázatú MI-rendszerek összetettségére és az azokkal kapcsolatos\nkockázatokra, fontos a nagy kockázatú MI-rendszerekre vonatkozó\nmegfelelőségértékelési eljárás - az úgynevezett harmadik fél általi\nmegfelelőségértékelés - kidolgozása a bejelentett szervezetek bevonásával.\nAzonban, tekintve a forgalomba hozatal előtti tanúsítást végző szakemberek\náltal a termékbiztonság területén jelenleg fennálló tapasztalatot és a\nfelmerülő kockázatok eltérő jellegét, helyénvaló - legalább e rendelet\nalkalmazásának kezdeti szakaszában - korlátozni a harmadik fél által végzett\nmegfelelőségértékelés alkalmazási körét azon nagy kockázatú MI-rendszerek\nesetében, amelyek nem termékekhez kapcsolódnak. Ezért az ilyen rendszerek\nmegfelelőségértékelését főszabályként a szolgáltatónak kell elvégeznie saját\nfelelősségére, a biometriai célokra való felhasználásra szánt MI-rendszerek\nkivételével. (126) A harmadik fél általi megfelelőségértékelések szükség\nszerinti elvégzése érdekében az illetékes nemzeti hatóságoknak e rendelet\nalapján értesíteniük kell a bejelentett szervezeteket, feltéve hogy azok\nmegfelelnek bizonyos, különösen a függetlenségre, a szakértelemre, az\nösszeférhetetlenség hiányára vonatkozó követelményeknek és megfelelő\nkiberbiztonsági követelményeknek. Az illetékes nemzeti hatóságoknak a\n768/2008/EK határozat I. melléklete R23. cikkének megfelelően a Bizottság\náltal kifejlesztett és kezelt elektronikus bejelentési eszköz útján kell\nbejelenteniük e szerveket a Bizottságnak és a többi tagállamnak. (127) A\nKereskedelmi Világszervezetnek a kereskedelem technikai akadályairól szóló\nmegállapodása keretében vállalt uniós kötelezettségekkel összhangban\nhelyénvaló elősegíteni az illetékes megfelelőségértékelő szervezetek által\nkészített megfelelőségértékelési eredmények kölcsönös elismerését, függetlenül\nattól, hogy mely területen van a székhelyük, feltéve, hogy az említett, egy\nharmadik ország joga szerint létrehozott megfelelőségértékelő szervezetek\nmegfelelnek e rendelet alkalmazandó követelményeinek, és az Unió e tekintetben\nmegállapodást kötött. Ezzel összefüggésben a Bizottságnak aktívan fel kell\ntérképeznie az említett célt szolgáló lehetséges nemzetközi eszközöket, és\ntörekednie kell különösen arra, hogy harmadik országokkal kölcsönös elismerési\nmegállapodásokat kössön. (128) Az uniós harmonizációs jogszabályok által\nszabályozott termékek jelentős módosításának általánosan elfogadott fogalmával\nösszhangban helyénvaló, hogy minden olyan változtatás esetében, amely\nbefolyásolhatja egy nagy kockázatú MI-rendszer e rendeletnek való megfelelését\n(pl. az operációs rendszer vagy a szoftverarchitektúra megváltoztatása), vagy\namikor a rendszer rendeltetése megváltozik, az adott MI-rendszert új MI-\nrendszernek kell tekinteni, amelyet új megfelelőségértékelésnek kell alávetni.\nUgyanakkor az olyan MI-rendszerek algoritmusában és teljesítményében\nbekövetkező változások, amelyek a forgalomba hozatalt vagy üzembe helyezést\nkövetően továbbra is „tanulnak” (nevezetesen automatikusan kiigazítják a\nfunkciók végrehajtásának módját), nem tekintendők jelentős módosításnak,\nfeltéve, hogy az említett változásokat a szolgáltató előre meghatározta és a\nmegfelelőségértékelés időpontjában értékelte. (129) A nagy kockázatú MI-\nrendszereket CE-jelöléssel kell ellátni, amely jelzi az e rendeletnek való\nmegfelelésüket, annak érdekében, hogy szabadon mozoghassanak a belső piacon. A\ntermékbe ágyazott nagy kockázatú MI-rendszerek esetében fizikai CE-jelölést\nkell elhelyezni, amely kiegészíthető digitális CE-jelöléssel. A kizárólag\ndigitálisan szolgáltatott nagy kockázatú MI-rendszerek esetében digitális CE-\njelölést kell használni. A tagállamok nem akadályozhatják indokolatlanul az\nolyan nagy kockázatú MI-rendszerek forgalomba hozatalát vagy üzembe\nhelyezését, amelyek megfelelnek az e rendeletben meghatározott\nkövetelményeknek és CE-jelöléssel vannak ellátva. (130) Bizonyos körülmények\nközött az innovatív technológiák gyors rendelkezésre állása döntő fontosságú\nlehet a személyek egészsége és biztonsága, a környezet védelme és az éghajlat-\nváltozás, valamint a társadalom egésze szempontjából. Ezért helyénvaló, hogy a\nközbiztonsághoz vagy a természetes személyek életének és egészségének\nvédelméhez, a környezetvédelemhez, valamint a kulcsfontosságú ipari és\ninfrastrukturális eszközök védelméhez kapcsolódó kivételes okokból a\npiacfelügyeleti hatóságok engedélyezhessék olyan MI-rendszerek forgalomba\nhozatalát vagy üzembe helyezését, amelyek megfelelőségértékelését nem\nfolytatták le. Az e rendeletben előírt, kellően indokolt helyzetekben a\nbűnüldöző hatóságok vagy a polgári védelmi hatóságok üzembe helyezhetnek egy\nadott nagy kockázatú MI-rendszert a piacfelügyeleti hatóság engedélye nélkül\nis, feltéve, hogy a használat során vagy azt követően - indokolatlan késedelem\nnélkül - kérnek ilyen engedélyt. (131) A Bizottság és a tagállamok által az MI\nterületén végzett munka megkönnyítése, valamint a nyilvánosság számára\nbiztosított átláthatóság növelése érdekében az olyan nagy kockázatú MI-\nrendszerek szolgáltatói számára, amelyek nem kapcsolódnak a releváns meglévő\nuniós harmonizációs jogszabályok hatálya alá tartozó termékekhez, valamint az\nolyan szolgáltatok számára, akik úgy vélik, hogy az e rendelet egyik\nmellékletében foglalt nagy kockázatú felhasználási esetek között felsorolt\nvalamely MI-rendszer egy eltérés alapján nem nagy kockázatú, elő kell írni,\nhogy saját magukat és a nagy kockázatú MI-rendszerükre vonatkozó információkat\nregisztrálják egy uniós adatbázisban, amelyet a Bizottságnak kell létrehoznia\nés kezelnie. Az e rendelet egyik mellékletében foglalt nagy kockázatú\nfelhasználási esetek között felsorolt valamely MI-rendszer használata előtt a\nnagy kockázatú MI-rendszerek azon alkalmazóinak, amelyek hatóságok,\nügynökségek vagy közjogi szervek, regisztrálniuk kell magukat egy ilyen\nadatbázisban, és ki kell választaniuk az általuk használni kívánt rendszert. A\ntöbbi alkalmazó számára biztosítani kell a jogot, hogy ezt önkéntes alapon\ntegye meg. Az uniós adatbázis ezen részének nyilvánosan hozzáférhetőnek és\ningyenesnek, az információnak pedig könnyen böngészhetőnek, érthetőnek és\ngéppel olvashatónak kell lennie. Az uniós adatbázisnak felhasználóbarátnak is\nkell lennie, például keresőfunkciók - többek között kulcsszavak révén történő\n- biztosításával, amelyek lehetővé teszik a nyilvánosság számára, hogy\nmegtalálja a nagy kockázatú MI-rendszerek regisztrációjakor benyújtandó és a\nnagy kockázatú MI-rendszerek e rendelet egyik mellékletében meghatározott azon\nfelhasználási esetére vonatkozó releváns információkat, amelynek a nagy\nkockázatú MI-rendszerek megfelelnek. A nagy kockázatú MI-rendszerek bármely\njelentős módosítását rögzíteni kell az uniós adatbázisban is. A bűnüldözés, a\nmigráció, a menekültügy és a határellenőrzés igazgatása területén működő nagy\nkockázatú MI-rendszerek esetében a regisztrációs kötelezettségeket az uniós\nadatbázis biztonságos, nem nyilvános részében kell teljesíteni. A biztonságos,\nnem nyilvános részhez való hozzáférést szigorúan a Bizottságra, valamint - az\nadatbázis megfelelő nemzeti része tekintetében - a piacfelügyeleti hatóságokra\nkell korlátozni. A kritikus infrastruktúrák területén működő a nagy kockázatú\nMI-rendszereket csak nemzeti szinten kell nyilvántartásba venni. Az (EU)\n2018/1725 rendelettel összhangban a Bizottságnak kell az uniós adatbázis\nadatkezelőjének lennie. Az uniós adatbázis teljes körű működőképességének\nbiztosítása érdekében a bevezetéskor az adatbázis beállítására irányuló\neljárásnak magában kell foglalnia a működési előírások Bizottság általi\nkidolgozását és egy független ellenőrzési jelentést. A Bizottságnak az uniós\nadatbázis adatkezelői feladatainak ellátása során figyelembe kell vennie a\nkiberbiztonsági kockázatokat. Az uniós adatbázis nyilvánosság általi\nhozzáférhetőségének és használatának maximalizálása érdekében az uniós\nadatbázisnak - ideértve az annak révén rendelkezésre bocsátott információkat\nis - meg kell felelnie az (EU) 2019/882 irányelv követelményeinek. (132)\nBizonyos MI-rendszerek, amelyek rendeltetése a természetes személyekkel való\ninterakció vagy tartalom létrehozása, különleges kockázatot jelenthetnek a\nhasonmássággal való visszaélés vagy a megtévesztés szempontjából, függetlenül\nattól, hogy nagy kockázatúnak minősülnek-e vagy sem. Bizonyos körülmények\nközött e rendszerek használatára ezért egyedi átláthatósági kötelezettségeket\nkell alkalmazni, a nagy kockázatú MI-rendszerekre vonatkozó követelmények és\nkötelezettségek sérelme nélkül, valamint a bűnüldözés különleges igényei okán\nhozott célzott kivételek szem előtt tartása mellett. Így különösen, a\ntermészetes személyeket értesíteni kell arról, hogy MI-rendszerrel állnak\ninterakcióban, kivéve, ha ez - figyelembe véve a körülményeket és a\nfelhasználási kontextust - egy észszerűen elvárható szinten jól tájékozott,\nfigyelmes és körültekintő természetes személy szemszögéből nyilvánvaló. Az\nemlített kötelezettség végrehajtásakor figyelembe kell venni az életkoruk vagy\nfogyatékosságuk okán kiszolgáltatott csoportokba tartozó személyek jellemzőit\nannyiban, amennyiben az MI-rendszer rendeltetésébe beletartozik, hogy az\nemlített csoportokkal is interakciót folytasson. Ezenkívül, a természetes\nszemélyeket értesíteni kell, amikor olyan MI-rendszereknek vannak kitéve,\namelyek biometrikus adataik feldolgozásával azonosíthatják vagy\nkikövetkeztethetik az említett személyek érzelmeit vagy szándékait, vagy\nkonkrét kategóriákba sorolhatják őket. Az ilyen konkrét kategóriák\nvonatkozhatnak olyan szempontokra, mint például a nem, az életkor, a hajszín,\na szemszín, a tetoválások, a személyes vonások, az etnikai származás, a\nszemélyes preferenciák és az érdeklődési kör. Az ilyen információkat és\nértesítéseket a fogyatékossággal élő személyek számára akadálymentes\nformátumban kell megadni. (133) A különböző MI-rendszerek nagy mennyiségű\nszintetikus tartalmat tudnak előállítani, amelyet illetően egyre nehezebbé\nválik az emberek számára, hogy megkülönböztessék az ember által előállított és\nautentikus tartalomtól. E rendszerek széles körű rendelkezésre állása és\nnövekvő képességei jelentős hatással vannak az információs ökoszisztéma\nintegritására és az abba vetett bizalomra, új kockázatokat teremtve a\nnagyléptékű félretájékoztatás és a manipuláció, a csalás, a\nszemélyazonossággal való visszaélés és a fogyasztók megtévesztése\ntekintetében. Az említett hatások, a technológiai haladás gyors üteme és az\ninformációk eredetének nyomon követésére szolgáló új módszerek és technikák\niránti igény fényében helyénvaló előírni az említett rendszerek szolgáltatói\nszámára, hogy olyan műszaki megoldásokat építsenek be, amelyek lehetővé teszik\na géppel olvasható formátumban történő jelölést és annak észlelését, hogy a\nkimenetet nem ember, hanem MI-rendszer hozta létre vagy manipulálta. Az ilyen\ntechnikáknak és módszereknek kellően megbízhatónak, interoperábilisnak,\nhatékonynak és megbízhatónak kell lenniük, amilyen mértékben ez műszakilag\nmegvalósítható, figyelembe véve az elérhető technikákat vagy az ilyen\ntechnikák kombinációját - például vízjeleket, metaadat-azonosításokat, a\ntartalom eredetének és hitelességének bizonyítására szolgáló kriptográfiai\nmódszereket, naplózási módszereket, ujjnyomatokat vagy adott esetben egyéb\ntechnikákat. E kötelezettség végrehajtása során a szolgáltatóknak figyelembe\nkell venniük a különböző tartalomtípusok sajátosságait és korlátait, valamint\na terület releváns technológiai és piaci fejleményeit is, amint azt a\ntechnológia általánosan elfogadott, mindenkori állása is tükrözi. Ilyen\ntechnikák és módszerek végrehajthatók az MI-rendszer vagy az MI-modell\nszintjén - ideértve a tartalmat előállító általános célú MI-modelleket is -,\nezáltal megkönnyítve e kötelezettségnek az MI-rendszer downstream\nszolgáltatója általi teljesítését. Az arányosság megőrzése érdekében\nhelyénvaló úgy rendelkezni, hogy ez a jelölési kötelezettség ne terjedjen ki\nazokra az MI-rendszerekre, amelyek elsősorban a standard szerkesztést segítő\nfunkciót látnak el, vagy olyan MI-rendszerekre, amelyek nem módosítják\nlényegesen az alkalmazó által szolgáltatott bemeneti adatokat vagy azok\nszemantikáját. (134) Az MI-rendszer szolgáltatói által alkalmazott műszaki\nmegoldásokat illetően azon alkalmazóknak, akik MI-rendszert használnak olyan\nkép-, audio- vagy videotartalom létrehozására vagy manipulálására, amely\nérzékelhetően hasonlít meglévő személyekre, tárgyakra, helyekre, entitásokra\nvagy eseményekre, és egy személy számára megtévesztő módon autentikusnak vagy\nvalóságosnak tűnhet (deepfake), egyértelműen és megkülönböztethetően fel kell\ntüntetniük, hogy a tartalmat mesterségesen hozták létre vagy manipulálták az\nMI-kimenet megfelelő címkézésével és mesterséges eredetének közzétételével.\nEzen átláthatósági kötelezettségnek való megfelelés nem értelmezhető úgy, hogy\naz azt jelzi, hogy az MI-rendszer vagy annak kimenete akadályozza a\nvéleménynyilvánítás szabadságához való jogot, valamint a művészet és a\ntudomány szabadságához való, a Chartában garantált jogot, különösen, ha a\ntartalom egy nyilvánvalóan kreatív, szatirikus, művészeti, fiktív vagy hasonló\nmunka vagy program részét képezi, a harmadik felek jogaira és szabadságaira\nvonatkozó megfelelő biztosítékok mellett. Az említett esetekben az e\nrendeletben meghatározott, a deepfake tartalmakra vonatkozó átláthatósági\nkötelezettség az ilyen, előállított vagy manipulált tartalom olyan megfelelő\nmódon történő felfedésére korlátozódik, amely nem akadályozza a mű\nmegjelenítését vagy élvezetét, beleértve annak rendes kiaknázását és\nhasználatát, a mű hasznosságának és minőségének fenntartása mellett. Emellett\nhelyénvaló hasonló felfedési kötelezettséget előirányozni az MI által\nelőállított vagy manipulált szöveg tekintetében is, amennyiben azt a\nnyilvánosság közérdekű ügyekről való tájékoztatása céljából teszik közzé,\nkivéve, ha az MI által létrehozott tartalom emberi felülvizsgálaton vagy\nszerkesztői ellenőrzésen esett át, és a szerkesztői felelősséget egy\ntermészetes vagy jogi személy viseli a tartalom közzétételéért. (135) Az\nátláthatósági kötelezettségek kötelező jellegének és teljes körű\nalkalmazandóságának sérelme nélkül a Bizottság ösztönözheti és megkönnyítheti\nolyan uniós szintű gyakorlati kódexek kidolgozását is, amelyek megkönnyítik a\nmesterségesen előállított vagy manipulált tartalom észlelésére és címkézésére\nvonatkozó kötelezettségek hatékony végrehajtását, beleértve adott esetben az\nészlelési mechanizmusok hozzáférhetővé tételére és az értéklánc más\nszereplőivel való együttműködés elősegítésére, a tartalom terjesztésére vagy\nhitelességének és eredetének ellenőrzésére irányuló gyakorlati intézkedések\ntámogatását is annak érdekében, hogy a nyilvánosság képessé váljon a\nmesterséges intelligencián alapuló tartalmak hatékony megkülönböztetésére.\n(136) Az (EU) 2022/2065 rendelet hatékony végrehajtásának elősegítése\nérdekében különösen fontosak az e rendeletben az egyes MI-rendszerek\nszolgáltatóira és alkalmazóira rótt azon kötelezettségek, amelyek lehetővé\nteszik annak észlelését és közzétételét, hogy e rendszerek kimeneteit\nmesterségesen hozzák létre vagy manipulálják. Ez különösen igaz az online\nóriásplatformokat vagy nagyon népszerű online keresőprogramokat üzemeltető\nszolgáltatók azon kötelezettségeire, hogy azonosítsák és enyhítsék a\nmesterségesen előállított vagy manipulált tartalom terjesztéséből eredő\nrendszerszintű kockázatokat, különösen a demokratikus folyamatokra, a civil\npárbeszédre és a választási folyamatokra - többek között dezinformáció révén -\ngyakorolt tényleges vagy előrelátható negatív hatások kockázatát. Az MI-\nrendszerek által előállított tartalmak címkézésére vonatkozó, e rendelet\nszerinti követelmény nem érinti az (EU) 2022/2065 rendelet 16. cikkének (6)\nbekezdésében foglalt azon kötelezettséget, hogy a tárhelyszolgáltatók\nfeldolgozzák az említett rendelet 16. cikkének (1) bekezdése alapján kapott,\njogellenes tartalomra vonatkozó bejelentéseket, és nem befolyásolhatja az\nadott tartalom jogellenességére vonatkozó értékelést és döntést. Ezt az\nértékelést kizárólag a tartalom jogszerűségére vonatkozó szabályokra\ntekintettel kell elvégezni. (137) Az e rendelet hatálya alá tartozó MI-\nrendszerekre vonatkozó átláthatósági kötelezettségeknek való megfelelés nem\nértelmezhető úgy, mint amely azt jelzi, hogy az MI-rendszer használata vagy\nannak kimenete e rendelet vagy más uniós és tagállami jogszabályok alapján\njogszerű, és nem sértheti az MI-rendszerek alkalmazóira vonatkozóan az uniós\nvagy nemzeti jogban meghatározott egyéb átláthatósági kötelezettségeket. (138)\nAz MI gyorsan fejlődő technológiacsalád, amelynek tekintetében szabályozási\nfelügyeletre és biztonságos és ellenőrzött kísérleti térre van szükség, a\nfelelősségteljes innovációnak, valamint a megfelelő biztosítékok és\nkockázatenyhítő intézkedések integrálásának egyidejű biztosítása mellett. Az\ninnovációt előmozdító, időtálló és a zavarokkal szemben reziliens jogi keret\nbiztosítása érdekében a tagállamoknak biztosítaniuk kell, hogy illetékes\nnemzeti hatóságaik létrehoznak legalább egy MI szabályozói tesztkörnyezetet\nnemzeti szinten annak érdekében, hogy megkönnyítsék az innovatív MI-rendszerek\nszigorú szabályozási felügyelet melletti fejlesztését és tesztelését e\nrendszerek forgalomba hozatala vagy más módon történő üzembe helyezése előtt.\nA tagállamok ezt a kötelezettséget teljesíthetnék úgy is, hogy részt vesznek\nmár meglévő szabályozói tesztkörnyezetekben, vagy hogy egy vagy több tagállam\nilletékes hatóságával közösen hoznak létre tesztkörnyezet, amennyiben ez a\nrészvétel egyenértékű nemzeti lefedettséget biztosít a részt vevő tagállamok\nszámára. Az MI szabályozói tesztkörnyezeteket fizikai, digitális vagy hibrid\nformában is létre lehetne hozni, és azok fogadhatnak fizikai és digitális\ntermékeket egyaránt. A létrehozó hatóságoknak azt is biztosítaniuk kell, hogy\naz MI szabályozói tesztkörnyezetek rendelkezzenek a működésükhöz szükséges\nmegfelelő erőforrásokkal, ideértve a pénzügyi és humán erőforrásokat is. (139)\nAz MI szabályozói tesztkörnyezeteknek az MI-vel kapcsolatos innováció\nelőmozdítását kell célozniuk azáltal, hogy a fejlesztési és a forgalomba\nhozatalt megelőző szakaszban egy ellenőrzött kísérleti és tesztelési\nkörnyezetet hoznak létre annak biztosítása érdekében, hogy az innovatív MI-\nrendszerek megfeleljenek e rendeletnek és más releváns uniós és tagállami\njogszabályoknak. Ezen felül az MI szabályozói tesztkörnyezeteknek törekedniük\nkell arra, hogy fokozzák a jogbiztonságot az innovátorok számára, valamint az\nMI-használatban rejlő lehetőségek, újonnan felmerülő kockázatok és hatások\nilletékes hatóságok általi felügyeletét és megértését, megkönnyítsék a\nszabályozói tanulást a hatóságok és a vállalkozások számára, többek között a\njogi keret jövőbeli kiigazítása céljából, támogassák az MI szabályozói\ntesztkörnyezetben részt vevő hatóságokkal való együttműködést és a legjobb\ngyakorlatok megosztását, valamint felgyorsítsák a piacra jutást, többek között\na kkv-k, köztük az induló innovatív vállalkozások előtt álló akadályok\nfelszámolása révén. Az MI szabályozói tesztkörnyezeteknek Unió-szerte széles\nkörben elérhetőnek kell lenniük, és különös figyelmet kell fordítani arra,\nhogy azokhoz a kkv-k, köztük az induló innovatív vállalkozások is\nhozzáférjenek. Az MI szabályozói tesztkörnyezetben való részvételnek olyan\nkérdésekre kell összpontosítania, amelyek jogbizonytalanságot vetnek fel a\nszolgáltatók és a leendő szolgáltatók körében, az Unión belüli innováció, a\nmesterséges intelligenciával való kísérletezés és a szabályozó hatóságok\náltali, tényeken alapuló tanuláshoz való hozzájárulás érdekében. Az MI\nszabályozói tesztkörnyezetben az MI-rendszerek felügyeletének ezért ki kell\nterjednie a rendszerek forgalomba hozatala vagy üzembe helyezése előtti\nfejlesztésére, betanítására, tesztelésére és validálására, valamint az olyan\njelentős módosítás fogalmára és bekövetkezésére, amely új\nmegfelelőségértékelési eljárást tehet szükségessé. Amennyiben az ilyen MI-\nrendszerek fejlesztése és tesztelése során jelentős kockázatok merülnek fel,\nazokat megfelelő módon csökkenteni kell, illetve ennek sikertelensége esetén a\nfejlesztési és tesztelési folyamatot fel kell függeszteni. Az MI szabályozói\ntesztkörnyezeteket létrehozó illetékes nemzeti hatóságoknak adott esetben\ncélszerű együttműködniük más érintett hatóságokkal, többek között az alapvető\njogok védelmét felügyelő hatóságokkal, és lehetővé tehetik az MI-ökoszisztémán\nbelüli más szereplők, így például a nemzeti vagy európai szabványügyi\nszervezetek, a bejelentett szervezetek, a tesztelési és kísérleti\nlétesítmények, a kutató- és kísérleti laboratóriumok, az európai digitális\ninnovációs központok, valamint az érdekelt felek és a civil társadalmi\nszervezetek bevonását. Az Unió-szerte egységes végrehajtás és a\nméretgazdaságosság biztosítása érdekében helyénvaló közös szabályokat\nmegállapítani az MI szabályozói tesztkörnyezetek végrehajtására vonatkozóan,\nvalamint meghatározni a tesztkörnyezetek felügyeletében részt vevő érintett\nhatóságok közötti együttműködés keretét. Az e rendelet alapján létrehozott MI\nszabályozói tesztkörnyezetek nem sérthetik az egyéb olyan jogszabályokat,\namelyek lehetővé teszik az e rendelettől eltérő jogszabályoknak való\nmegfelelés biztosítását célzó egyéb tesztkörnyezetek létrehozását. Az említett\negyéb szabályozói tesztkörnyezetekért felelős releváns illetékes hatóságoknak\nadott esetben célszerű mérlegelniük annak előnyeit, ha az említett\ntesztkörnyezeteket az MI-rendszerek e rendeletnek való megfelelése\nbiztosításának céljára is igénybe veszik. Az illetékes nemzeti hatóságok és az\nMI szabályozói tesztkörnyezet résztvevői közötti megállapodás esetén valós\nkörülmények közötti tesztelés is végezhető és felügyelhető az MI szabályozói\ntesztkörnyezet keretrendszerében. (140) E rendeletnek jogalapot kell\nbiztosítania az MI szabályozói tesztkörnyezetben a szolgáltatók és a leendő\nszolgáltatók számára ahhoz, hogy felhasználják az eltérő célból gyűjtött\nszemélyes adatokat bizonyos közérdekű MI-rendszereknek az MI szabályozói\ntesztkörnyezetben történő fejlesztése céljából, kizárólag meghatározott\nfeltételek mellett, összhangban az (EU) 2016/679 rendelet 6. cikkének (4)\nbekezdésével és 9. cikke (2) bekezdésének g) pontjával, valamint az (EU)\n2018/1725 rendelet 5., 6. és 10. cikkével összhangban, továbbá az (EU)\n2016/680 irányelv 4. cikke (2) bekezdésének és 10. cikkének sérelme nélkül. Az\nadatkezelők minden egyéb kötelezettsége és az érintettek jogai továbbra is\nalkalmazandók az (EU) 2016/679 és az (EU) 2018/1725 rendelet, valamint az (EU)\n2016/680 irányelv alapján. Így különösen, e rendelet nem biztosíthat jogalapot\naz (EU) 2016/679 rendelet 22. cikke (2) bekezdésének b) pontja és az (EU)\n2018/1725 rendelet 24. cikke (2) bekezdésének b) pontja értelmében. Az MI\nszabályozói tesztkörnyezetben a szolgáltatóknak és a leendő szolgáltatóknak\nmegfelelő biztosítékokat kell garantálniuk, és együtt kell működniük az\nilletékes hatóságokkal, többek között azáltal, hogy követik iránymutatásukat,\nvalamint gyorsan és jóhiszeműen járnak el annak érdekében, hogy megfelelően\nenyhítsék a biztonságot, az egészséget és az alapvető jogokat fenyegető\nbeazonosított, az említett tesztkörnyezetben történő fejlesztés, tesztelés és\nkísérletezés során esetlegesen felmerülő jelentős kockázatokat. (141) Az e\nrendelet egyik mellékletben felsorolt nagy kockázatú MI-rendszerek fejlesztési\nés forgalombahozatali folyamatának felgyorsítása érdekében fontos, hogy az\nilyen rendszerek szolgáltatói vagy leendő szolgáltatói szintén részt\nvehessenek egy olyan rendszerben, amely az említett MI-rendszerek valós\nkörülmények közötti tesztelésére szolgál, anélkül, hogy részt vennének egy MI\nszabályozói tesztkörnyezetben. Ilyen esetekben azonban - figyelembe véve az\nilyen tesztelés egyénekre gyakorolt lehetséges következményeit - biztosítani\nkell, hogy e rendelet megfelelő és elégséges garanciákat és feltételeket\nvezessen be a szolgáltatókra vagy leendő szolgáltatókra vonatkozóan. Ilyen\ngaranciák közé kell, hogy tartozzon többek között a természetes személyek\ntájékoztatáson alapuló hozzájárulásának előírása a valós körülmények közötti\ntesztelésben való részvételhez, kivéve a bűnüldözést, amennyiben a\ntájékoztatáson alapuló hozzájárulás megkérése megakadályozná az MI-rendszer\ntesztelését. A vizsgálati alanyoknak az ilyen tesztelésben e rendelet alapján\ntörténő részvételhez való hozzájárulása különbözik az érintettek ahhoz való\nhozzájárulásától, hogy személyes adataikat a releváns adatvédelmi jogszabályok\nalapján kezeljék, és nem sérti azt. Fontosak továbbá a következők:\nminimalizálni a kockázatokat és lehetővé tenni az illetékes hatóságok általi\nfelügyeletet, és ezért előírni a leendő szolgáltatók számára, hogy a valós\nkörülmények közötti tesztelésre vonatkozó tervet nyújtsanak be az illetékes\npiacfelügyeleti hatósághoz, regisztrálni a tesztelést - néhány kivételtől\neltekintve - az uniós adatbázis erre szolgáló szakaszaiban, korlátozni a\ntesztelés elvégzésére alkalmas időszakot, és további biztosítékokat előírni a\nbizonyos kiszolgáltatott csoportokhoz tartozó személyek érdekében, valamint\nírásbeli megállapodást kötni, amely meghatározza a leendő szolgáltatók és\nalkalmazók szerepét és felelősségét, és a valós körülmények közötti\ntesztelésben részt vevő hozzáértő személyzet általi hatékony felügyeletet\nbiztosítani. Továbbá, helyénvaló további biztosítékokat előirányozni annak\nbiztosítása érdekében, hogy az MI-rendszer előrejelzéseit, ajánlásait vagy\ndöntéseit ténylegesen vissza lehessen fordítani és figyelmen kívül lehessen\nhagyni, valamint hogy a személyes adatok védelem alatt álljanak, és törlésre\nkerüljenek, ha a vizsgálati alanyok visszavonták a tesztelésben való\nrészvételhez adott hozzájárulásukat, az uniós adatvédelmi jog értelmében\nérintettségükből adódó jogaik sérelme nélkül. Az adatok továbbítását illetően\nhelyénvaló annak előírása is, hogy a valós körülmények közötti tesztelés\ncéljára gyűjtött és feldolgozott adatokat csak akkor kerüljenek továbbításra\nharmadik országok számára, ha az uniós jog szerint megfelelő és alkalmazandó\nbiztosítékokat hajtanak végre - különösen a személyes adatoknak az uniós\nadatvédelmi jog szerinti továbbítására vonatkozó jogalapokkal összhangban -,\nmíg a nem személyes adatok tekintetében az uniós joggal - így például az (EU)\n2022/868 * és az (EU) 2023/2854 * európai parlamenti és tanácsi rendelettel -\nösszhangban megfelelő biztosítékok kerülnek bevezetésre. (142) Annak\nbiztosítására, hogy az MI társadalmi és környezeti szempontból kedvező\neredményekhez vezessen, a tagállamok ösztönözve vannak arra, hogy támogassák\nés mozdítsák elő a társadalmi és környezeti szempontból kedvező eredményeket\nhozó MI-megoldásokkal - így például a fogyatékossággal élő személyek általi\nhozzáférhetőség javítását, a társadalmi-gazdasági egyenlőtlenségek kezelését,\nvalamint a környezetvédelmi célok elérését célzó MI-alapú megoldásokkal -\nkapcsolatos kutatás-fejlesztést, azáltal, hogy elegendő forrást - ideértve az\nállami és uniós finanszírozást is - allokálnak, valamint - adott esetben és\nfeltéve, hogy a jogosultsági és kiválasztási feltételek teljesülnek - különös\nfigyelmet fordítanak az ilyen célokat előmozdító projektekre. Az ilyen\nprojekteknek az MI-fejlesztők, az egyenlőtlenséggel és a\nmegkülönböztetésmentességgel, az akadálymentességgel, a fogyasztói, környezeti\nés digitális jogokkal foglalkozó szakértők, valamint a tudományos körök\nközötti interdiszciplináris együttműködés elvén kell alapulniuk. (143) Az\ninnováció előmozdítása és védelme érdekében különösen figyelembe kell venni a\nkkv-knak - köztük az induló innovatív vállalkozásoknak - mint az MI-rendszerek\nszolgáltatóinak, illetve alkalmazóinak az érdekeit. E célból a tagállamoknak\naz említett gazdasági szereplőket célzó, többek között a figyelemfelkeltéssel\nés a tájékoztatással kapcsolatos kezdeményezéseket kell kidolgozniuk. A\ntagállamoknak az Unióban bejegyzett székhellyel vagy fiókteleppel rendelkező\nkkv-k, köztük az induló innovatív vállalkozások számára elsőbbségi hozzáférést\nkell biztosítaniuk az MI-szabályozói tesztkörnyezetekhez, feltéve, hogy a\nvállalkozások teljesítik a jogosultsági feltételeket és a kiválasztási\nszempontokat, és nem zárva ki, hogy ugyanezen feltételek és szempontok\nteljesítése esetén más szolgáltatók és leendő szolgáltatók is hozzáférjenek a\nszabályozói tesztkörnyezetekhez. A tagállamoknak ki kell használniuk a meglévő\ncsatornákat, és adott esetben új, célzott csatornákat kell létrehozniuk a kkv-\nkkal - ideértve az induló innovatív vállalkozásokat is -, az alkalmazókkal,\negyéb innovátorokkal és adott esetben a helyi közigazgatási szervekkel\nfolytatott kommunikáció céljára, hogy iránymutatást nyújtsanak részükre, és\nmegválaszolják az e rendelet végrehajtásával kapcsolatos kérdéseket. Adott\nesetben e csatornáknak együtt kell működniük a szinergiák kialakítása és a\nkkv-k - köztük az induló innovatív vállalkozások - és az alkalmazók számára\nnyújtott iránymutatások egységessége érdekében. Emellett a tagállamoknak meg\nkell könnyíteniük a kkv-k és egyéb érintett érdekelt felek részvételét a\nszabványalkotási folyamatokban. Ezenkívül figyelembe kell venni a kkv-k -\nköztük az induló innovatív vállalkozások - mint szolgáltatók sajátos érdekeit\nés igényeit, amikor bejelentett szervezetek állapítanak meg\nmegfelelőségértékelési díjakat. A Bizottságnak rendszeresen értékelnie kell a\nkkv-k - köztük az induló innovatív vállalkozások - tanúsítási és megfelelési\nköltségeit az alkalmazókkal folytatott átlátható konzultációk révén, és együtt\nkell működnie a tagállamokkal az ilyen költségek csökkentése érdekében. A\nkötelező dokumentációhoz és a hatóságokkal folytatott kommunikációhoz\nkapcsolódó fordítási költségek például jelentős mértékűek lehetnek a\nszolgáltatók és más gazdasági szereplők, különösen a kisebb szolgáltatók és\ngazdasági szereplők számára. A tagállamoknak lehetőség szerint biztosítaniuk\nkell, hogy az érintett szolgáltatók dokumentációja és a gazdasági szereplőkkel\nfolytatott kommunikáció tekintetében általuk meghatározott és elfogadott\nnyelvek egyike olyan nyelv legyen, amelyet a lehető legtöbb, határon átnyúló\ntevékenységet folytató alkalmazó széles körben ért. A kkv-k - köztük az induló\ninnovatív vállalkozások - sajátos igényeinek kezelése érdekében a Bizottságnak\na Testület kérésére szabványosított mintákat kell rendelkezésre bocsátania az\ne rendelet hatálya alá tartozó területekre vonatkozóan. Ezenfelül a\nBizottságnak a tagállami erőfeszítéseket a következők révén kell\nkiegészítenie: egy olyan egységes információs platform biztosítása, amely e\nrendelettel kapcsolatban könnyen használható információkat nyújt valamennyi\nszolgáltató és alkalmazó számára; megfelelő kommunikációs kampányok szervezése\naz e rendeletből eredő kötelezettségekkel kapcsolatos figyelemfelkeltés\nérdekében; valamint az MI-rendszerekre vonatkozó közbeszerzési eljárások terén\na legjobb gyakorlatok közelítésének értékelése és előmozdítása. Azon\nközépvállalkozásoknak, amelyek a 2003/361/EK bizottsági ajánlás * melléklete\nértelmében a közelmúltig kisvállalkozásnak minősültek, hozzá kell férniük az\nemlített intézkedésekhez, mivel az említett új középvállalkozások lehet, hogy\nnéha nem rendelkeznek az e rendelet megfelelő megértéséhez és betartásához\nszükséges jogi erőforrásokkal és képzéssel. (144) Az innováció előmozdítása és\nvédelme érdekében az igényalapú MI-platformnak, valamint a Bizottság és a\ntagállamok által uniós vagy nemzeti szinten végrehajtott valamennyi vonatkozó\nuniós finanszírozási programnak és projektnek, így például a Digitális Európa\nprogramnak és a Horizont Európa keretprogramnak adott esetben hozzá kell\njárulnia e rendelet célkitűzéseinek eléréséhez. (145) A piaci ismeretek és\nszakértelem hiányából eredő végrehajtási kockázatok minimalizálása, valamint\nannak elősegítése érdekében, hogy a szolgáltatók - különösen a kkv-k, köztük\naz induló innovatív vállalkozások - és a bejelentett szervezetek teljesítsék\naz e rendelet szerinti kötelezettségeiket, az igényalapú MI-platformnak, az\neurópai digitális innovációs központoknak, valamint a Bizottság és a\ntagállamok által uniós vagy nemzeti szinten létrehozott tesztelési és\nkísérleti létesítményeknek hozzá kell járulniuk e rendelet végrehajtásához.\nMegbízatásuk és hatáskörük keretein belül az igényalapú MI-platform, az\neurópai digitális innovációs központok, valamint a tesztelési és kísérleti\nlétesítmények különösen technikai és tudományos támogatást nyújthatnak a\nszolgáltatóknak és a bejelentett szervezeteknek. (146) Ezenfelül néhány\ngazdasági szereplő rendkívül kis mérete miatt, valamint az innováció\nköltségeit illető arányosság biztosítása érdekében helyénvaló a\nmikrovállalkozások számára lehetővé tenni, hogy a legköltségesebb\nkötelezettségek egyikét - nevezetesen a minőségirányítási rendszer\nlétrehozását - egyszerűsített formában teljesítsék, ami csökkentené az\nemlített vállalkozások adminisztratív terheit és költségeit, anélkül, hogy\nbefolyásolná a védelem szintjét és a nagy kockázatú MI-rendszerekre vonatkozó\nkövetelményeknek való megfelelés szükségességét. A Bizottságnak útmutatásokat\nkell kidolgoznia arra vonatkozóan, hogy a mikrovállalkozások számára a\nminőségirányítási rendszer mely elemei teljesítendők az említett\negyszerűsített formában. (147) Helyénvaló, hogy a Bizottság a lehető\nlegnagyobb mértékben megkönnyítse a tesztelési és kísérleti létesítményekhez\nvaló hozzáférést a vonatkozó uniós harmonizációs jogszabályok bármelyike\nalapján létrehozott vagy akkreditált olyan szervek, csoportok vagy\nlaboratóriumok számára, amelyek az említett uniós harmonizációs jogszabályok\nhatálya alá tartozó termékek vagy eszközök megfelelőségértékelésével\nkapcsolatos feladatokat látnak el. Ez különösen igaz az orvostechnikai\neszközök területén működő, az (EU) 2017/745 és az (EU) 2017/746 rendelet\nszerinti szakértői testületekre, szakértői laboratóriumokra és\nreferencialaboratóriumokra. (148) E rendeletnek olyan irányítási keretet kell\nlétrehoznia, amely lehetővé teszi mind e rendelet alkalmazásának nemzeti\nszintű koordinálását és támogatását, mind az uniós szintű kapacitásépítést és\naz AI területén érdekelt felek bevonását. E rendelet hatékony végrehajtásához\nés érvényesítéséhez olyan irányítási keretre van szükség, amely uniós szinten\nteszi lehetővé a koordinálást és a központosított szaktudás kiépítését. Az MI-\nhivatalt bizottsági határozat * hozta létre, és a küldetése az, hogy az MI\nterületén fejlessze az uniós szakértelmet és kapacitásokat, valamint hogy\nhozzájáruljon az MI-re vonatkozó uniós jog végrehajtásához. A tagállamoknak\nsegíteniük kell az MI-hivatalt feladatainak végzésében, hogy ezáltal\ntámogassák az uniós szakértelem fejlesztését és az uniós szintű\nkapacitásépítést, valamint megerősítsék a digitális egységes piac működését.\nTovábbá, létre kell hozni a tagállamok képviselőiből álló Testületet: egy\nolyan tudományos testületet, amely összefogja a tudományos közösséget és egy\ntanácsadó fórumot annak érdekében, hogy e rendelet végrehajtásához az érdekelt\nfelek észrevételei is hozzájáruljanak - uniós és nemzeti szinten. Az uniós\nszakértelem és kapacitás fejlesztése keretében fel kell használni a meglévő\nforrásokat és szakértelmet is, különösen az egyéb jogszabályok uniós szintű\nérvényesítésének összefüggésében kiépített struktúrákkal való szinergiák,\nvalamint a kapcsolódó uniós szintű kezdeményezésekkel - így például az EuroHPC\nközös vállalkozással és a Digitális Európa program keretében működő MI-\ntesztelési és kísérleti létesítményekkel - való szinergiák révén. (149) E\nrendelet zökkenőmentes, hatékony és összehangolt végrehajtásának elősegítése\nérdekében létre kell hozni a Testületet. A Testületnek tükröznie kell az MI-\nökoszisztémán belüli különböző érdekeket, és a tagállamok képviselőiből kell\nállnia. A Testület felelősségi körébe kell utalni számos tanácsadói feladatot,\ntöbbek között vélemények, ajánlások kiadását, tanácsadást, vagy az e rendelet\nvégrehajtásával kapcsolatos kérdésekkel kapcsolatos iránymutatásokhoz való\nhozzájárulást, például a rendelet érvényesítésével, az e rendeletben\nmegállapított követelményekre vonatkozó műszaki előírásokkal vagy meglévő\nszabványokkal kapcsolatban, valamint a Bizottságnak, a tagállamoknak és az\nilletékes nemzeti hatóságoknak az MI-vel kapcsolatos konkrét kérdésekben\nnyújtott tanácsadást. Annak érdekében, hogy a tagállamok némi rugalmasságot\nélvezzenek a Testületben részt vevő képviselőik kijelölését illetően, bármely\nolyan, közigazgatási szervhez tartozó személy lehet ilyen képviselő, aki\nrendelkezik a releváns hatáskörökkel és jogkörökkel ahhoz, hogy elősegítse a\nnemzeti szintű koordinációt, és hozzájáruljon a Testület feladatainak\nteljesítéséhez. A Testületen belül létre kell hozni két állandó alcsoportot,\namelyek platformot biztosítanak a piacfelügyeleti hatóságok és a bejelentő\nhatóságok közötti együttműködéshez és eszmecseréhez a piacfelügyelettel,\nilletve a bejelentett szervezetekkel kapcsolatos kérdésekben. A\npiacfelügyelettel foglalkozó állandó alcsoportnak e rendelet tekintetében az\n(EU) 2019/1020 rendelet 30. cikke értelmében vett igazgatási együttműködési\ncsoportként kell eljárnia. A Bizottságnak az említett rendelet 33. cikkével\nösszhangban piacelemzések vagy tanulmányok készítése révén támogatnia kell a\npiacfelügyelettel foglalkozó állandó alcsoport tevékenységeit, különösen e\nrendelet azon aspektusainak azonosítása céljából, amelyek a piacfelügyeleti\nhatóságok közötti konkrét és sürgős koordinációt igényelnek. A Testület adott\nesetben, konkrét kérdések megvizsgálása céljából újabb állandó vagy ideiglenes\nalcsoportokat hozhat létre. A Testületnek adott esetben együtt kell működnie a\nreleváns uniós joggal összefüggésben tevékenykedő releváns uniós szervekkel,\nszakértői csoportokkal és hálózatokkal is, különösen azokkal, amelyek az\nadatokra, valamint a digitális termékekre és szolgáltatásokra vonatkozó\nreleváns uniós jog alapján tevékenykednek. (150) Az érintett érdekelt felek e\nrendelet végrehajtásába és alkalmazásába történő bevonásának biztosítása\nérdekében tanácsadó fórumot kell létrehozni, amelynek feladata a Testület és a\nBizottság tanácsadással és műszaki szakismeretekkel való támogatása. Az\nérdekelt felek széles körű és a kiegyensúlyozott képviseletének biztosítása\nérdekében - a kereskedelmi és nem kereskedelmi érdekek, valamint a\nkereskedelmi érdekek kategóriáján belül a kkv-k és más vállalkozások\ntekintetében - a tanácsadó fórumnak fel kell ölelnie többek között az ipart,\naz induló innovatív vállalkozásokat, a kkv-kat, a tudományos köröket, a civil\ntársadalmat - azon belül a szociális partnereket -, valamint az Európai Unió\nAlapjogi Ügynökségét, az ENISA-t, az Európai Szabványügyi Bizottságot (CEN),\naz Európai Elektrotechnikai Szabványügyi Bizottságot (CENELEC) és az Európai\nTávközlési Szabványügyi Intézetet (ETSI). (151) E rendelet végrehajtásának és\nérvényesítésének érdekében - különösen az MI-hivatalnak az általános célú MI-\nmodellekkel kapcsolatos tevékenységeit illetően - létre kell hozni egy\nfüggetlen szakértőkből álló tudományos testületet. A tudományos testület\nalkotó független szakértőket az MI területére vonatkozó naprakész tudományos\nvagy műszaki szakértelmük alapján kell kiválasztani, és a szakértőknek a\nfeladataikat pártatlanul és objektíven kell végezniük, továbbá biztosítaniuk\nkell a feladataik és tevékenységeik végzése során szerzett információk és\nadatok titkosságát. Az e rendelet hatékony végrehajtásához szükséges nemzeti\nkapacitások megerősítése érdekében a tagállamok számára lehetővé kell tenni,\nhogy végrehajtási tevékenységeikhez a tudományos testület alkotó szakértők\nállományának támogatását igényeljék. (152) A megfelelő végrehajtásnak és a\ntagállamok MI-rendszerekre vonatkozó kapacitásainak a támogatása érdekében\nuniós MI-tesztelési támogató struktúrákat kell kialakítani és a tagállamok\nrendelkezésére bocsátani. (153) A tagállamok kulcsszerepet játszanak e\nrendelet alkalmazásában és érvényesítésében. E tekintetben minden tagállamnak\nki kell jelölnie legalább egy bejelentő hatóságot és legalább egy\npiacfelügyeleti hatóságot mint az e rendelet alkalmazásának és végrehajtásának\nfelügyelete céljából illetékes nemzeti hatóságot. A tagállamok dönthetnek úgy,\nhogy - sajátos nemzeti szervezeti jellemzőikkel és szükségleteikkel\nösszhangban - bármilyen állami szervet jelölnek ki az e rendelet értelmében\nvett illetékes nemzeti hatóságok feladatainak ellátására. A tagállamok oldalán\na szervezeti hatékonyság növelése, valamint annak érdekében, hogy egyedüli\nkapcsolattartó pontot határozzanak meg a nyilvánosság és egyéb, tagállami és\nuniós szintű partnerek felé, minden tagállamnak ki kell jelölnie egy\npiacfelügyeleti hatóságot, hogy egyedüli kapcsolattartó pontként járjon el.\n(154) Az illetékes nemzeti hatóságoknak a jogköreiket függetlenül, pártatlanul\nés elfogulatlanul kell gyakorolniuk, hogy ezáltal megőrizzék tevékenységeik és\nfeladataik objektivitását, valamint biztosítsák e rendelet alkalmazását és\nvégrehajtását. E hatóságok tagjainak tartózkodniuk kell minden, a\nhatáskörükkel összeférhetetlen fellépéstől, és be kell tartaniuk az e rendelet\nszerinti titoktartási szabályokat. (155) Annak biztosítása érdekében, hogy a\nnagy kockázatú MI-rendszerek szolgáltatói figyelembe tudják venni a nagy\nkockázatú MI-rendszerek használatával kapcsolatos tapasztalatokat rendszereik\ntovábbfejlesztése, valamint a tervezési és fejlesztési folyamat során, vagy\nidőben meg tudják hozni az esetlegesen szükséges korrekciós intézkedéseket,\nvalamennyi szolgáltatónak rendelkeznie kell egy forgalomba hozatal utáni\nnyomonkövetési rendszerrel. Adott esetben a forgalomba hozatal utáni nyomon\nkövetésnek magában kell foglalnia az egyéb MI-rendszerekkel, többek között más\neszközökkel és szoftverekkel való kölcsönhatás elemzését. A forgalomba hozatal\nutáni nyomon követés nem terjedhet ki a bűnüldöző hatóságnak minősülő\nalkalmazók érzékeny operatív adataira. E rendszer annak biztosítása\nszempontjából is kulcsfontosságú, hogy hatékonyabban és időben lehessen\nkezelni az olyan MI-rendszerekből eredő lehetséges kockázatokat, amelyek a\nforgalomba hozatalt vagy az üzembe helyezést követően továbbra is „tanulnak”.\nEzzel összefüggésben a szolgáltatók számára elő kell írni továbbá, hogy\nrendelkezzenek olyan rendszerrel, amely révén bejelentik az érintett\nhatóságoknak az MI-rendszereik használatának eredményeként bekövetkező súlyos\nváratlan eseményeket, nevezetesen a halálhoz vagy súlyos egészségkárosodáshoz\nvezető váratlan esemény vagy hibás működést, a kritikus infrastruktúra\nirányításának és üzemeltetésének súlyos és visszafordíthatatlan zavarát, az\nalapvető jogok védelmére irányuló, uniós jog szerinti kötelezettségek\nmegsértését, illetve a súlyos vagyoni kárt vagy súlyos környezetkárosítást.\n(156) Az ezen - uniós harmonizációs jogszabálynak minősülő - rendeletben\nmeghatározott követelmények és kötelezettségek megfelelő és hatékony\nvégrehajtásának biztosítása érdekében az (EU) 2019/1020 rendelettel\nlétrehozott piacfelügyeleti és termékmegfelelőségi rendszert teljes egészében\nalkalmazni kell. Az e rendelet alapján kijelölt piacfelügyeleti hatóságoknak\nrendelkezniük kell az e rendeletben és az (EU) 2019/1020 rendeletben\nmeghatározott valamennyi végrehajtási hatáskörrel, és a feladataikat\nfüggetlenül, pártatlanul és elfogulatlanul kell végezniük. Bár az MI-\nrendszerek többsége e rendelet alapján nem tartozik egyedi követelmények és\nkötelezettségek hatálya alá, a piacfelügyeleti hatóságok intézkedéseket\nhozhatnak valamennyi MI-rendszer tekintetében, amennyiben azok e rendelet\nértelmében kockázatot jelentenek. Az e rendelet hatálya alá tartozó uniós\nintézmények, ügynökségek és szervek sajátos jellege miatt helyénvaló az\neurópai adatvédelmi biztost kijelölni az esetükben illetékes piacfelügyeleti\nhatóságként. Ez nem érintheti az illetékes nemzeti hatóságok tagállamok általi\nkijelölését. A piacfelügyeleti tevékenységek nem érinthetik a felügyelt\nszervezetek azon képességét, hogy feladataikat függetlenül végezzék,\namennyiben az ilyen függetlenséget az uniós jog előírja. (157) E rendelet nem\nérinti az alapvető jogok védelmére vonatkozó uniós jog alkalmazását felügyelő\nérintett nemzeti hatóságok és közigazgatási szervek - köztük az egyenlőség\nelőmozdításával foglalkozó szervek és az adatvédelmi hatóságok - hatásköreit,\nfeladatait, jogköreit és függetlenségét. Amennyiben a megbízatásuk miatt\nszükséges, az említett nemzeti hatóságoknak vagy közigazgatási szerveknek\nhozzáférést kell biztosítani az e rendelet alapján létrehozott dokumentációhoz\nis. Külön védintézkedési eljárást kell meghatározni az egészségre, a\nbiztonságra és az alapvető jogokra kockázatot jelentő MI-rendszerekkel\nszembeni megfelelő és időben történő jogérvényesítés biztosítása érdekében. Az\nilyen kockázatot jelentő MI-rendszerekre vonatkozó eljárást a kockázatot\njelentő nagy kockázatú MI-rendszerekre, az e rendeletben meghatározott tiltott\ngyakorlatokra vonatkozó előírást megsértve forgalomba hozott, üzembe helyezett\nvagy használt tiltott rendszerekre, valamint az e rendeletben meghatározott\nátláthatósági követelmények megsértésével rendelkezésre bocsátott, és\nkockázatot jelentő MI-rendszerekre kell alkalmazni. (158) A pénzügyi\nszolgáltatásokra vonatkozó uniós jog magában foglal olyan belső irányítási és\nkockázatkezelési szabályokat és követelményeket, amelyek a szabályozott\npénzügyi intézményekre alkalmazandók az említett szolgáltatások nyújtása\nsorán, többek között akkor is, ha MI-rendszereket vesznek igénybe. Az e\nrendelet szerinti kötelezettségek és a pénzügyi szolgáltatásokra vonatkozó\nuniós jogszabályok releváns szabályai és követelményei koherens alkalmazásának\nés érvényesítésének biztosítása érdekében az említett jogszabályok\nfelügyeletéért és végrehajtásáért felelős illetékes hatóságokat, különösen az\n575/2013/EU európai parlamenti és tanácsi rendelet * , valamint a 2008/48/EK *\n, a 2009/138/EK * , a 2013/36/EU * , a 2014/17/EU * és az (EU) 2016/97 *\neurópai parlamenti és tanácsi irányelvben meghatározott illetékes hatóságokat\n- a saját hatáskörük keretein belül - illetékes hatóságként kell kijelölni e\nrendelet végrehajtásának felügyelete céljából, ideértve a piacfelügyeleti\ntevékenységeket is, a szabályozott és felügyelt pénzügyi intézmények által\nbiztosított vagy használt MI-rendszerek tekintetében, kivéve, ha a tagállamok\núgy döntenek, hogy ezen piacfelügyeleti feladatok ellátására egy másik\nhatóságot jelölnek ki. Az említett illetékes hatóságoknak rendelkezniük kell\naz e rendelet és az (EU) 2019/1020 rendelet szerinti valamennyi hatáskörrel az\ne rendeletben foglalt követelmények és kötelezettségek érvényesítése\nérdekében, ideértve az olyan utólagos piacfelügyeleti tevékenységek végzésére\nvonatkozó hatáskört is, amelyek adott esetben integrálhatók a pénzügyi\nszolgáltatásokra vonatkozó releváns uniós jog szerinti meglévő felügyeleti\nmechanizmusaikba és eljárásaikba. Helyénvaló előírni, hogy az 1024/2013/EU\ntanácsi rendelettel * létrehozott egységes felügyeleti mechanizmusban részt\nvevő, a 2013/36/EU irányelv alapján szabályozott hitelintézetek felügyeletéért\nfelelős nemzeti hatóságoknak - amikor az e rendelet szerinti piacfelügyeleti\nhatóságokként járnak el - haladéktalanul be kell jelenteniük az Európai\nKözponti Banknak a piacfelügyeleti tevékenységeik során azonosított minden\nolyan információt, amely az Európai Központi Banknak az említett rendeletben\nmeghatározott prudenciális felügyeleti feladatai szempontjából potenciális\njelentőséggel bírhat. A 2013/36/EU irányelv szerint szabályozott\nhitelintézetekre alkalmazandó szabályok és az e rendelet közötti összhang\ntovábbi növelése érdekében helyénvaló a szolgáltatók kockázatkezeléssel,\nforgalomba hozatal utáni nyomon követéssel és dokumentációval kapcsolatos\negyes eljárási kötelezettségeit belefoglalni a 2013/36/EU irányelv szerinti\nmeglévő kötelezettségekbe és eljárásokba. Az átfedések elkerülése érdekében\nkorlátozott eltéréseket kell előirányozni a szolgáltatók minőségirányítási\nrendszerével és a nagy kockázatú MI-rendszerek alkalmazóira rótt\nnyomonkövetési kötelezettséggel kapcsolatban is, amennyiben ezeket a\n2013/36/EU irányelv által szabályozott hitelintézetekre alkalmazni kell. A\npénzügyi ágazaton belüli következetesség és egyenlő bánásmód biztosítása\nérdekében ugyanezt a rendszert kell alkalmazni a 2009/138/EK irányelv szerinti\nbiztosítókra és viszontbiztosítókra és biztosítói holdingtársaságokra is,\nvalamint az (EU) 2016/97 irányelv szerinti biztosításközvetítőkre és a\npénzügyi intézmények egyéb olyan típusaira, amelyekre a pénzügyi\nszolgáltatásokra vonatkozó uniós jog alapján létrehozott, a belső irányításra,\nrendszerekre vagy eljárásokra vonatkozó követelmények vonatkoznak. (159)\nValamennyi, a biometria terén alkalmazott nagy kockázatú MI-rendszerekért\nfelelős piacfelügyeleti hatóságnak - az e rendelet egyik mellékletében foglalt\nfelsorolás szerint, amennyiben az említett rendszerek használata a következő\nterületek céljait szolgálja: bűnüldözés, migráció, menekültügy és\nhatárellenőrzés, illetve az igazságszolgáltatás és a demokratikus folyamatok -\nhatékony vizsgálati és korrekciós hatáskörökkel kell rendelkeznie, amelyek\nmagukban foglalják legalább azt, hogy a felügyeleti hatóság hozzáférjen\nvalamennyi kezelt személyes adathoz és a feladatainak teljesítéséhez szükséges\nvalamennyi információhoz. A piacfelügyeleti hatóságoknak képesnek kell lenniük\nhatásköreik teljes függetlenséggel történő gyakorlására. Az érzékeny operatív\nadatokhoz való, e rendelet szerinti hozzáférésük semmilyen korlátozása nem\nérintheti az (EU) 2016/680 irányelv által rájuk ruházott hatásköröket. Az\nadatoknak az e rendelet szerinti, a nemzeti adatvédelmi hatóságokkal való\nközlésére vonatkozó kizárás nem érintheti e hatóságok jelenlegi vagy jövőbeli,\ne rendelet hatályán kívül eső hatásköreit. (160) A piacfelügyeleti hatóságok\nés a Bizottság számára lehetővé kell tenni, hogy javaslatot tegyenek olyan, a\npiacfelügyeleti hatóságok által önállóan vagy a Bizottsággal közösen végzendő\nközös tevékenységekre, például közös vizsgálatokra, amelyek célja - e rendelet\nvonatkozásában - a megfelelés előmozdítása, a meg nem felelés feltárása, a\nfigyelemfelhívás és az iránymutatás a nagy kockázatú MI-rendszerek azon\nkonkrét kategóriáira tekintettel, amelyekről bebizonyosodik, hogy két vagy\ntöbb tagállamban jelentenek súlyos kockázatot. A megfelelés előmozdítását\ncélzó közös tevékenységeket az (EU) 2019/1020 rendelet 9. cikkével összhangban\nkell megvalósítani. Az MI-hivatalnak a közös vizsgálatokhoz koordinációs\ntámogatást kell nyújtania. (161) Egyértelművé kell tenni az általános célú MI-\nmodellekre épülő MI-rendszerekkel kapcsolatos uniós és nemzeti szintű feladat-\nés hatásköröket. A hatáskörök közötti átfedések elkerülése érdekében,\namennyiben valamely MI-rendszer általános célú MI-modellre épül és mind a\nrendszert, mind a modellt ugyanazon szolgáltató biztosítja, a felügyeletet\nuniós szinten, az MI-hivatalon keresztül kell végezni: ebben az esetben az\nemlített hivatalnak kell gyakorolnia az (EU) 2019/1020 rendelet értelmében\nvett piacfelügyeleti hatóság hatásköreit. Az MI-rendszerek felügyeletéért\nminden egyéb esetben továbbra is a nemzeti piacfelügyeleti hatóságok\nfelelősek. Ahhoz azonban, hogy az alkalmazók az általános célú MI-rendszereket\nközvetlenül használhassák legalább egy, nagy kockázatúnak minősített célra, a\npiacfelügyeleti hatóságoknak együtt kell működniük az MI-hivatallal a\nmegfelelőségi értékelések elvégzésében, valamint ennek megfelelően\ntájékoztatniuk kell a Testületet és a többi piacfelügyeleti hatóságot.\nTovábbá, a piacfelügyeleti hatóságok számára lehetővé kell tenni, hogy az MI-\nhivatal segítségét kérjék, amennyiben valamely nagy kockázatú MI-rendszer\nvizsgálatát nem tudják lezárni amiatt, hogy nem férnek hozzá bizonyos, a nagy\nkockázatú MI-rendszer alapját képező általános célú MI-modellel kapcsolatos\ninformációkhoz. Ilyen esetekben az (EU) 2019/1020 rendelet VI. fejezetében\nfoglalt, a határokon átnyúló kölcsönös segítségnyújtásra vonatkozó eljárást\nkell értelemszerűen alkalmazni. (162) Ahhoz, hogy uniós szinten a lehető\nlegjobban ki lehessen használni a központosított uniós szakértelmet és\nszinergiákat, az általános célú MI-modellek szolgáltatóira vonatkozó\nkötelezettségekkel kapcsolatos felügyeleti és érvényesítési hatásköröket a\nBizottságnak kell gyakorolnia. Az MI-hivatal számára lehetővé kell tenni\nminden szükséges intézkedés meghozatalát e rendeletnek az általános célú MI-\nmodellek tekintetében történő hatékony végrehajtásának nyomon követése\nérdekében. Lehetővé kell tenni számára azt is, hogy az általános célú MI-\nmodellek szolgáltatóira vonatkozó szabályok esetleges megsértésének\nkivizsgálását mind saját kezdeményezésre - nyomonkövetési tevékenységeinek\neredményei nyomán -, mind a piacfelügyeleti hatóságok kérésére, az e\nrendeletben foglalt feltételekkel összhangban elvégezhesse. A hatékony nyomon\nkövetés érdekében az MI-hivatalnak biztosítania kell annak lehetőségét, hogy a\ndownstream szolgáltatók panaszt nyújthassanak be az általános célú MI-modellek\nés -rendszerek szolgáltatóira vonatkozó szabályok esetleges megsértése\nkapcsán. (163) Az általános célú MI-modellek irányítási rendszereinek\nkiegészítése céljából a tudományos testületnek támogatnia kell az MI-hivatal\nnyomonkövetési tevékenységeit, és bizonyos esetekben minősített riasztásokat\nküldhet az MI-hivatal számára, amelyek utókövetési intézkedésekhez - így\npéldául vizsgálatokhoz - vezethetnek. Így kell eljárni, amikor a tudományos\ntestület okkal feltételezi, hogy valamely általános célú MI-modell uniós\nszinten konkrét és azonosítható kockázatot hordoz. Továbbá, így kell eljárni,\namikor a tudományos testület okkal feltételezi, hogy valamely általános célú\nMI-modell megfelel azon kritériumoknak, amelyek a rendszerszintű kockázatot\njelentő általános célú MI-modellként való besoroláshoz vezetnének. A\ntudományos testületnek az említett feladatok ellátásához szükséges\ninformációkkal való ellátása érdekében létre kell hozni egy mechanizmust,\namelynek révén a tudományos testület felkérheti a Bizottságot, hogy valamely\nszolgáltatótól dokumentációt vagy információkat kérjen be. (164) Az MI-hivatal\nszámára lehetővé kell tenni, hogy meghozza azon intézkedéseket, amelyek az\náltalános célú MI-modellek szolgáltatóira vonatkozóan e rendelet által\nmeghatározott kötelezettségek hatékony végrehajtásának és betartásának nyomon\nkövetéséhez szükségesek. Az MI-hivatal számára lehetővé kell tenni, hogy az e\nrendelet által biztosított hatáskörrel összhangban kivizsgálja az esetleges\njogsértéseket, többek között azáltal, hogy dokumentációt és információkat kér\nbe, értékeléseket végez, valamint az általános célú MI-modellek\nszolgáltatóitól intézkedések foganatosítását kéri. Az értékelések végzése\nsorán - a független szakértelem bevonása céljából - az MI-hivatal számára\nlehetővé kell tenni, hogy független szakértőket bízzon meg az értékeléseknek\naz MI-hivatal nevében való elvégzésével. A kötelezettségeknek való megfelelést\ntöbbek között a következők révén kell biztosítani: a megfelelő intézkedések\nmeghozatalára való felkérés - ideértve az azonosított rendszerszintű\nkockázatok esetén hozott kockázatenyhítő intézkedéseket -, valamint a modell\nforgalmazásának korlátozása, forgalomból való kivonása vagy visszahívása.\nAmennyiben az e rendelet által előírt eljárási jogokon túlmenően szükséges, az\náltalános célú MI-modellek szolgáltatói biztosíték gyanánt élhetnek az (EU)\n2019/1020 rendelet 18. cikkében előírt jogokkal, amelyeket értelemszerűen, az\ne rendelet által előírt konkrétabb eljárási jogok sérelme nélkül kell\nalkalmazni. (165) A nagy kockázatú MI-rendszerektől eltérő MI-rendszerek e\nrendelet követelményeivel összhangban történő fejlesztése az etikus és\nmegbízható MI szélesebb körű elterjedéséhez vezethet az Unióban. A nem nagy\nkockázatú MI-rendszerek szolgáltatóit ösztönözni kell olyan magatartási\nkódexek létrehozására, ideértve a kapcsolódó irányítási mechanizmusokat is,\namelyek célja előmozdítani a nagy kockázatú MI-rendszerekre alkalmazandó\nkötelező követelmények közül néhány vagy valamennyi önkéntes alkalmazását, az\nadott rendszerek rendeltetéséhez és alacsonyabb kockázati szintjéhez igazítva,\nvalamint figyelembe véve az olyan, rendelkezésre álló műszaki megoldásokat és\niparági legjobb gyakorlatokat, mint például a modell és az adatkártyák. A\nszolgáltatókat, valamint adott esetben valamennyi - akár nagy, akár nem nagy\nkockázatú - MI-rendszer és az MI-modellek fejlesztőit ösztönözni kell arra is,\nhogy önkéntes alapon alkalmazzanak további követelményeket például a\nkövetkezőkkel kapcsolatban: a megbízható mesterséges intelligenciára vonatkozó\nuniós etikai iránymutatás elemei; környezeti fenntarthatóság; az MI-\njártassághoz kapcsolódó intézkedések; inkluzivitás és sokszínűség az MI-\nrendszerek tervezésében és fejlesztésében - a kiszolgáltatott személyekre és a\nfogyatékossággal élő személyek számára biztosított akadálymentességre\nfordított figyelmet is beleértve; az érdekelt feleknek az MI-rendszerek\ntervezésében és fejlesztésében való részvétele - adott esetben olyan érintett\nérdekelt felek bevonásával, mint az üzleti és a civil szféra szervezetei, a\ntudományos körök, a kutatóhelyek, a szakszervezetek és a fogyasztóvédelmi\nszervezetek -, valamint a fejlesztői csapatoknak a nemek közötti egyensúlyra\nis kiterjedő sokszínűsége. Hatékonyságuk biztosításának érdekében az önkéntes\nmagatartási kódexeknek egyértelmű célkitűzéseken és az e célkitűzések\nelérésének mérésére szolgáló fő teljesítménymutatókon kell alapulniuk. Azokat\ninkluzív módon is kell kialakítani, adott esetben olyan releváns érdekelt\nfelek bevonásával, mint az üzleti és a civil szféra szervezetei, a tudományos\nkörök, a kutatóhelyek, a szakszervezetek és a fogyasztóvédelmi szervezetek. A\nBizottság azon technikai akadályok csökkentésének megkönnyítése érdekében,\namelyek gátolják a mesterséges intelligencia fejlesztésére irányuló, határokon\nátnyúló adatcserét, kezdeményezéseket dolgozhat ki - többek között ágazati\njellegűeket is - például az adathozzáférési infrastruktúrára, valamint a\nkülönböző típusú adatok szemantikai és műszaki interoperabilitására\nvonatkozóan. (166) Fontos, hogy a forgalomba hozatalkor vagy az üzembe\nhelyezéskor azok a termékekhez kapcsolódó MI-rendszerek is biztonságosak\nlegyenek, amelyek e rendelet értelmében nem nagy kockázatúak, és ezért nem\nkötelesek megfelelni a nagy kockázatú MI-rendszerekre vonatkozóan\nmeghatározott követelményeknek. E cél elérése érdekében biztonsági hálóként\nalkalmazni kellene az (EU) 2023/988 európai parlamenti és tanácsi rendeletet *\n. (167) Az illetékes hatóságok uniós és nemzeti szinten folytatott megbízható\nés konstruktív együttműködésének biztosítása érdekében az e rendelet\nalkalmazásában részt vevő valamennyi félnek tiszteletben kell tartania a\nfeladatai ellátása során megszerzett információk és adatok bizalmas jellegét,\naz uniós és a nemzeti joggal összhangban. Feladataikat és tevékenységeiket oly\nmódon kell végezniük, hogy védjék különösen a szellemitulajdon-jogokat, a\nbizalmas üzleti információkat és az üzleti titkokat, e rendelet hatékony\nvégrehajtását, a köz- és nemzetbiztonsági érdekeket, a büntetőjogi és a\nközigazgatási eljárások integritását, valamint a minősített adatok\nsértetlenségét. (168) Az e rendelet szerinti kötelezettségeknek való\nmegfelelést bírságok kiszabása és egyéb végrehajtási intézkedések útján kell\nbiztosítani. A tagállamoknak minden szükséges intézkedést meg kell tenniük az\ne rendeletben foglalt rendelkezések végrehajtásának biztosítása érdekében,\ntöbbek között azáltal, hogy hatékony, arányos és visszatartó erejű szankciókat\nállapítanak meg a megsértésük esetére, és biztosítaniuk kell a kétszeres\neljárás alá vonás és a kétszeres büntetés tilalmának tiszteletben tartását. Az\ne rendelet megsértése esetén alkalmazandó közigazgatási szankciók megerősítése\nés harmonizálása érdekében meg kell állapítani az egyes konkrét jogsértések\nesetében kiszabandó közigazgatási bírságok felső határait. A bírságok\nösszegének megállapításakor a tagállamoknak minden egyes esetben figyelembe\nkell venniük a konkrét helyzet valamennyi releváns körülményét, kellő\nfigyelmet fordítva különösen a jogsértés és következményeinek jellegére,\nsúlyosságára és időtartamára, valamint a szolgáltató méretére, különösen\nakkor, ha a szolgáltató egy kkv, ideértve az induló innovatív vállalkozásokat\n(start-up) is. Az európai adatvédelmi biztosnak hatáskörrel kell rendelkeznie\narra, hogy pénzbírságot szabjon ki az e rendelet hatálya alá tartozó uniós\nintézményekre, ügynökségekre és szervekre. (169) Az általános célú MI-modellek\nszolgáltatóinak e rendeletben előírt kötelezettségeinek való megfelelést\ntöbbek között pénzbírságok kiszabása útján kell biztosítani. E célból az\nemlített kötelezettségek megszegése esetére - ideértve a Bizottság által e\nrendelettel összhangban megkövetelt intézkedéseknek való megfelelés\nelmulasztását is - megfelelő mértékű pénzbírságokat kell meghatározni,\nfigyelembe véve a megfelelő elévülési időket, az arányosság elvével\nösszhangban. A Bizottság által e rendelet alapján hozott valamennyi\nhatározatot az EUMSZ-szel összhangban az Európai Unió Bírósága\nfelülvizsgálhatja, ideértve a Bíróságnak a büntetések tekintetében az EUMSZ\n261. cikke értelmében fennálló korlátlan joghatóságát is. (170) Az uniós és a\nnemzeti jog már jelenleg is hatékony jogorvoslatokat ír elő azon természetes\nés jogi személyek számára, akik, illetve amelyek jogait és szabadságait az MI-\nrendszerek kedvezőtlenül érintik. E jogorvoslatok sérelme nélkül, bármely\nolyan természetes vagy jogi személy, aki vagy amely okkal feltételezi, hogy e\nrendelet rendelkezéseit megsértették, panaszt nyújthat be a megfelelő\npiacfelügyeleti hatósághoz. (171) Az érintett személyek számára biztosítani\nkell az ahhoz való jogot, hogy magyarázatot kapjanak abban az esetben, ha\nvalamely alkalmazó döntése elsősorban bizonyos, e rendelet hatálya alá\ntartozó, nagy kockázatú MI-rendszerek kimenetén alapul, és ha az említett\ndöntés olyan joghatásokat vagy az említett személyeket hasonlóan jelentősen\nérintő, olyan hatásokat vált ki, amelyek megítélésük szerint kedvezőtlen\nhatást gyakorolnak egészségükre, biztonságukra vagy alapvető jogaikra nézve.\nAz említett magyarázatnak egyértelműnek és érdeminek kell lennie, és olyannak,\namely az érintett személyek számára alapot biztosít jogaik gyakorlásához. A\nmagyarázathoz való jog nem alkalmazandó azon MI-rendszerek használatára,\namelyekre az uniós vagy a nemzeti jogból következően kivételek vagy\nkorlátozások vonatkoznak, valamint csak annyiban alkalmazandó, amennyiben\narról az uniós jog még nem rendelkezik. (172) Az e rendelet megsértését\nbejelentő személyeket az uniós jog alapján védelemben kell részesíteni. Az e\nrendelet megsértéseinek bejelentésére és az ilyen jogsértéseket bejelentő\nszemélyek védelmére tehát alkalmazni kell az (EU) 2019/1937 európai parlamenti\nés tanácsi irányelvet * . (173) Annak biztosítása érdekében, hogy a\nszabályozási keret szükség esetén kiigazítható legyen, a Bizottságot fel kell\nhatalmazni arra, hogy az EUMSZ 290. cikkének megfelelően jogi aktusokat\nfogadjon a következők módosítása céljából: azon feltételek, amelyek mellett\negy MI-rendszert nem minősülhet nagy kockázatúnak; a nagy kockázatú MI-\nrendszerek listája; a műszaki dokumentációra vonatkozó rendelkezések; az EU-\nmegfelelőségi nyilatkozat tartalma; a megfelelőségértékelési eljárásokra\nvonatkozó rendelkezések; azon a rendelkezések, amelyek megállapítják, hogy\nmely nagy kockázatú MI-rendszerekre kell a minőségirányítási rendszerek\nértékelésén és a műszaki dokumentáció értékelésén alapuló\nmegfelelőségértékelési eljárást alkalmazni; a rendszerszintű kockázatot\njelentő általános célú MI-modellek besorolására vonatkozó szabályokban foglalt\nküszöbérték, referenciaértékek és mutatók, többek között az említett\nreferenciaértékek és mutatók kiegészítése révén; a rendszerszintű kockázatot\njelentő általános célú MI-modellek megjelölésére vonatkozó kritériumok;\nműszaki dokumentáció az általános célú MI-modellek szolgáltatói számára; és az\náltalános célú MI-modellek szolgáltatóira vonatkozó átláthatósági információk.\nKülönösen fontos, hogy a Bizottság az előkészítő munkája során megfelelő\nkonzultációkat folytasson, többek között szakértői szinten is, és hogy e\nkonzultációkra a jogalkotás minőségének javításáról szóló, 2016. április 13-i\nintézményközi megállapodásban * megállapított elvekkel összhangban kerüljön\nsor. Így különösen, a felhatalmazáson alapuló jogi aktusok előkészítésében\nvaló egyenlő részvétel biztosítása érdekében az Európai Parlament és a Tanács\na tagállamok szakértőivel egyidejűleg kézhez kap minden dokumentumot, és\nszakértőik rendszeresen részt vehetnek a Bizottság felhatalmazáson alapuló\njogi aktusok előkészítésével foglalkozó szakértői csoportjainak ülésein. (174)\nA gyors technológiai fejlődésre és az e rendelet hatékony alkalmazásához\nszükséges műszaki szakértelemre tekintettel, a Bizottságnak 2029. augusztus\n2-ig, és ezt követően négyévente értékelnie kell és felül kell vizsgálnia e\nrendeletet, és jelentést kell tennie az Európai Parlamentnek és a Tanácsnak.\nEmellett a Bizottságnak - figyelembe véve az e rendelet hatályára gyakorolt\nhatásokat - évente egyszer el kell végeznie annak vizsgálatát, hogy szükség\nvan-e a nagy kockázatú MI-rendszerek listájának és a tiltott gyakorlatok\njegyzékének módosítására. Ezenfelül a Bizottságnak 2028. augusztus 2-ig, és\nezt követően négyévente értékelnie kell azt, és jelentést kell tennie az\nEurópai Parlamentnek és a Tanácsnak arról, hogy szükség van-e a következők\nmódosítására, a további intézkedések vagy fellépések szükségességét is\nbeleértve: a nagy kockázatú területekre vonatkozó címek e rendelet\nmellékletében foglalt felsorolása; az átláthatósági kötelezettségek hatókörébe\ntartozó MI-rendszerek; a felügyeleti és irányítási rendszer hatékonysága;\nvalamint az általános célú MI-modellek energiahatékony fejlesztésével\nkapcsolatos szabvány jellegű dokumentumok kidolgozásának előrehaladása. Végül,\na Bizottságnak 2028. augusztus 2-ig, és ezt követően háromévente értékelnie\nkell az önkéntes magatartási kódexek hatását és hatékonyságát, hogy\nelőmozdítsa a nagy kockázatú MI-rendszerekre előírt követelményeknek a nagy\nkockázatú MI-rendszerektől eltérő MI-rendszerek esetében való alkalmazását és\nesetleg az ilyen MI-rendszerekre vonatkozó további követelmények alkalmazását.\n(175) E rendelet végrehajtása egységes feltételeinek biztosítása érdekében a\nBizottságra végrehajtási hatásköröket kell ruházni. Ezeket a végrehajtási\nhatásköröket a 182/2011/EU európai parlamenti és tanácsi rendeletnek *\nmegfelelően kell gyakorolni. (176) Mivel e rendelet célját - nevezetesen a\nbelső piac működésének javítását és az emberközpontú és megbízható MI\nelterjedésének előmozdítását, egyúttal az Unióban az egészség, a biztonság és\na Chartában rögzített alapvető jogok, többek között a demokrácia, a\njogállamiság és a környezetvédelem magas szintű védelmének biztosítását az MI-\nrendszerek káros hatásaival szemben, valamint az innováció támogatását - a\ntagállamok nem tudják kielégítően megvalósítani, az Unió szintjén azonban az\nintézkedés terjedelme és hatása miatt e célok jobban megvalósíthatók, az Unió\nintézkedéseket hozhat a szubszidiaritásnak az EUSZ 5. cikkében foglalt elvével\nösszhangban. Az arányosságnak az említett cikkben foglalt elvével összhangban\ne rendelet nem lépi túl az e cél eléréséhez szükséges mértéket. (177) A\njogbiztonság biztosítása, a gazdasági szereplők számára megfelelő\nalkalmazkodási időszak biztosítása, valamint a piaci zavarok elkerülése\nérdekében - többek között az MI-rendszerek folytonos használatának biztosítása\nrévén - helyénvaló, hogy e rendelet csak akkor legyen alkalmazandó az\nalkalmazásának általános időpontja előtt forgalomba hozott vagy üzembe\nhelyezett nagy kockázatú MI-rendszerekre, ha az említett időponttól kezdve az\nemlített rendszerek kialakításában vagy rendeltetésében jelentős változások\nkövetkeznek be. Helyénvaló egyértelművé tenni, hogy e tekintetben a jelentős\nváltozás fogalmát úgy kell értelmezni, hogy az lényegében egyenértékű a\njelentős módosítás azon fogalmával, amelyet csak az e rendelet szerinti nagy\nkockázatú MI-rendszerek tekintetében használnak. Kivételesen és a nyilvános\nelszámoltathatóságra tekintettel, az e rendelet egyik mellékletében felsorolt\njogi aktusokkal létrehozott nagy méretű informatikai rendszerek alkotóelemeit\nképező MI-rendszerek üzemeltetőinek, illetve a hatóságok által használni\nkívánt nagy kockázatú MI-rendszerek üzemeltetőinek meg kell tenniük a\nszükséges lépéseket annak érdekében, hogy 2030 végéig és 2030. augusztus 2-ig\nmegfeleljenek e rendelet követelményeinek. (178) A nagy kockázatú MI-\nrendszerek szolgáltatóit ösztönzik arra, hogy - önkéntes alapon - már az\nátmeneti időszakban kezdjenek el megfelelni e rendelet releváns\nkötelezettségeinek. (179) Ezt a rendeletet 2026. augusztus 2-től kell\nalkalmazni. Ugyanakkor - tekintettel az MI bizonyos módokon történő\nhasználatához kapcsolódó elfogadhatatlan kockázatra - e rendelet tilalmait és\náltalános rendelkezéseit már 2025. február 2-től alkalmazni kell. Míg az\nemlített tilalmak hatálya az irányítás létrehozásával és e rendelet\nvégrehajtásával válik teljessé, a tilalmak előzetes alkalmazása fontos az\nelfogadhatatlan kockázatok figyelembevétele, valamint a más - például polgári\njogi - eljárásokra való hatásgyakorlás szempontjából. Ezenfelül az\nirányítással és a megfelelőségértékelési rendszerrel kapcsolatos\ninfrastruktúrának 2026. augusztus 2. előtt működőképesnek kell lennie, ezért a\nbejelentett szervezetekre és az irányítási struktúrára vonatkozó\nrendelkezéseket 2025. augusztus 2-től kell alkalmazni. A technológiai\nfejlődésnek és az általános célú MI-modellek bevezetésének gyors ütemére\ntekintettel, az általános célú MI-modellek szolgáltatóira vonatkozó\nkötelezettségeket 2025. augusztus 2-től kell alkalmazni. A gyakorlati\nkódexeknek 2025. május 2-ig kell elkészülniük annak érdekében, hogy a\nszolgáltatók számára lehetővé váljon a megfelelés időben való igazolása. Az\nMI-hivatalnak biztosítania kell, hogy a besorolási szabályok és eljárások a\ntechnológiai fejlődés fényében naprakészek legyenek. Emellett a tagállamoknak\nmeg kell állapítaniuk a szankciókra, többek között a közigazgatási bírságokra\nvonatkozó szabályokat, azokról értesíteniük kell a Bizottságot, és\nbiztosítaniuk kell, hogy azokat e rendelet alkalmazásának kezdőnapjáig\nmegfelelően és hatékonyan végrehajtsák. Ezért a szankciókra vonatkozó\nrendelkezéseket 2025. augusztus 2-től kell alkalmazni. (180) Az (EU) 2018/1725\nrendelet 42. cikkének (1) és (2) bekezdésével összhangban konzultációra került\nsor az európai adatvédelmi biztossal és az Európai Adatvédelmi Testülettel,\naki és amely 2021. június 18-án nyilvánított közös véleményt, ELFOGADTA EZT A\nRENDELETET: (1) E rendelet célja, hogy javítsa a belső piac működését,\nvalamint, hogy előmozdítsa az emberközpontú és megbízható mesterséges\nintelligencia (MI) elterjedését, biztosítva ugyanakkor az Unióban az egészség,\na biztonság és a Chartában rögzített alapvető jogok - többek között a\ndemokrácia, a jogállamiság és a környezetvédelem - magas szintű védelmét az\nMI-rendszerek káros hatásaival szemben, továbbá, hogy támogassa az innovációt.\n(2) E rendelet megállapítja a következőket: a) az MI-rendszerek Unión belüli\nforgalomba hozatalára, üzembe helyezésére és használatára vonatkozó\nharmonizált szabályok; b) bizonyos MI-gyakorlatokra vonatkozó tilalmak; c) a\nnagy kockázatú MI-rendszerekre vonatkozó különös követelmények és az ilyen\nrendszerek üzemeltetőire vonatkozó kötelezettségek; d) bizonyos MI-\nrendszerekre vonatkozó harmonizált átláthatósági szabályok; e) az általános\ncélú MI-modellek forgalomba hozatalára vonatkozó harmonizált szabályok; f) a\npiaci nyomon követésre, a piacfelügyeletre, az irányításra és a végrehajtásra\nvonatkozó szabályok; g) az innovációt támogató intézkedések, különösen a kkv-\nkra összpontosítva, ideértve az induló innovatív vállalkozásokat is. (1) E\nrendelet a következőkre alkalmazandó: a) az Unióban MI-rendszereket forgalomba\nhozó vagy üzembe helyező, vagy általános célú MI-modelleket forgalomba hozó\nszolgáltatók, függetlenül attól, hogy az említett szolgáltatók letelepedési\nvagy tartózkodási helye az Unióban vagy harmadik országban van-e; b) az MI-\nrendszerek azon alkalmazói, amelyek letelepedési vagy tartózkodási helye az\nUnión belül van; c) az MI-rendszerek azon szolgáltatói és alkalmazói, amelyek\nletelepedési vagy tartózkodási helye harmadik országban van, amennyiben az MI-\nrendszer által előállított kimenet használatára az Unióban kerül sor; d) az\nMI-rendszerek importőrei és forgalmazói; e) azon termékgyártók, amelyek a\ntermékükkel együtt MI-rendszert hoznak forgalomba vagy helyeznek üzembe a\nsaját nevük vagy védjegyük alatt; f) a szolgáltatóknak az Unión kívül\nletelepedett meghatalmazott képviselői; g) az Unión kívül tartózkodó érintett\nszemélyek. (2) Azon MI-rendszerek esetében, amelyeket a 6. cikk (1)\nbekezdésével összhangban az I. melléklet B. szakaszában felsorolt uniós\nharmonizációs jogszabályok hatálya alá tartozó termékekhez kapcsolódó nagy\nkockázatú MI-rendszerként soroltak be, kizárólag a 6. cikk (1) bekezdését, a\n102-109. cikket és a 112. cikket kell alkalmazni. Az 57. cikk csak annyiban\nalkalmazandó, amennyiben e rendeletnek a nagy kockázatú MI-rendszerekre\nvonatkozó követelményeit beépítették az említett uniós harmonizációs\njogszabályokba. (3) E rendelet nem alkalmazandó az uniós jog hatályán kívül\neső területekre, és semmilyen esetben nem érinti a tagállamok\nnemzetbiztonságra vonatkozó hatásköreit, függetlenül attól, hogy a tagállamok\nmilyen típusú szervezetet bíznak meg az említett hatáskörökkel kapcsolatos\nfeladatok ellátásával. E rendelet nem alkalmazandó az MI-rendszerekre, ha és\namennyiben azok forgalomba hozatala, üzembe helyezése vagy használata -\nmódosítással vagy módosítás nélkül - kizárólag katonai, védelmi vagy\nnemzetbiztonsági célra történik, függetlenül az e tevékenységeket végző\nszervezet típusától. E rendelet nem alkalmazandó azon MI-rendszerekre,\namelyeket nem az Unióban hoztak forgalomba vagy helyeztek üzembe, amennyiben a\nkimenetet az Unióban kizárólag katonai, védelmi vagy nemzetbiztonsági célra\nhasználják, függetlenül az e tevékenységeket végző szervezet típusától. (4) E\nrendelet nem alkalmazandó az (1) bekezdés alapján e rendelet hatálya alá\ntartozó harmadik országbeli hatóságokra és nemzetközi szervezetekre,\namennyiben ezek a hatóságok vagy szervezetek az Unióval, illetve egy vagy több\ntagállammal folytatott bűnüldözési és igazságügyi együttműködésre vonatkozó\nnemzetközi együttműködés vagy megállapodások keretében használnak MI-\nrendszereket, feltéve, hogy az ilyen harmadik ország vagy nemzetközi szervezet\nmegfelelő biztosítékokat nyújt az egyének alapvető jogainak és szabadságainak\nvédelme tekintetében. (5) E rendelet nem érinti az (EU) 2022/2065 rendelet II.\nfejezetében foglalt, a közvetítő szolgáltatók felelősségére vonatkozó\nrendelkezések alkalmazását. (6) E rendelet nem alkalmazandó a kifejezetten a\ntudományos kutatás-fejlesztés kizárólagos céljára kifejlesztett és üzembe\nhelyezett MI-rendszerekre vagy MI-modellekre, és azok kimenetére sem. (7) A\nszemélyes adatok, a magánélet és a közlés bizalmasságának védelmére vonatkozó\nuniós jog alkalmazandó az e rendeletben megállapított jogokkal és\nkötelezettségekkel összefüggésben feldolgozott személyes adatokra. E rendelet\n10. cikke (5) bekezdésének és 59. cikkének sérelme nélkül, e rendelet nem\nérinti az (EU) 2016/679 vagy az (EU) 2018/1725 rendeletet, vagy a 2002/58/EK\nvagy az (EU) 2016/680 irányelvet. (8) E rendelet nem alkalmazandó semmilyen,\naz MI-rendszerekkel vagy MI-modellekkel kapcsolatos kutatási, tesztelési és\nfejlesztési tevékenységre azt megelőzően, hogy azokat forgalomba hozzák vagy\nüzembe helyezik. Az ilyen tevékenységeket az alkalmazandó uniós joggal\nösszhangban kell végezni. Az említett kizárás nem vonatkozik a valós\nkörülmények közötti tesztelésre. (9) E rendelet nem érinti a\nfogyasztóvédelemre és a termékbiztonságra vonatkozó egyéb uniós jogi\naktusokban megállapított szabályokat. (10) E rendelet nem alkalmazandó azon\nalkalmazók kötelezettségeire, akik az MI-rendszereket pusztán személyes, nem\nszakmai tevékenység során használó természetes személyek. (11) E rendelet nem\nzárja ki az Uniót vagy a tagállamokat abból, hogy olyan törvényi, rendeleti\nvagy közigazgatási rendelkezéseket tartsanak fenn vagy vezessenek be, amelyek\nkedvezőbbek a munkavállalókra nézve az MI-rendszerek munkáltatók általi\nhasználatával kapcsolatos jogaik védelme tekintetében, vagy abból, hogy a\nmunkavállalók számára kedvezőbb kollektív szerződések alkalmazását ösztönözzék\nvagy tegyék lehetővé. (12) E rendelet nem alkalmazandó a szabad és nyílt\nforráskódú licencek alapján kibocsátott MI-rendszerekre, kivéve, ha azokat\nnagy kockázatú MI-rendszerként, vagy az 5. vagy 50. cikk hatálya alá tartozó\nMI-rendszerként hozzák forgalomba vagy helyezik üzembe. E rendelet\nalkalmazásában: 1. „MI-rendszer”: gépi alapú rendszer, amelyet különböző\nautonómiaszinteken történő működésre terveztek, és amely a bevezetését\nkövetően alkalmazkodóképességet tanúsíthat, és amely a kapott bemenetből -\nexplicit vagy implicit célok érdekében - kikövetkezteti, miként generáljon\nolyan kimeneteket, mint például előrejelzéseket, tartalmakat, ajánlásokat vagy\ndöntéseket, amelyek befolyásolhatják a fizikai vagy a virtuális környezetet;\n2. „kockázat”: a kár bekövetkezési valószínűségének és az említett kár\nsúlyosságának kombinációja; 3. „szolgáltató”: olyan természetes vagy jogi\nszemély, hatóság, ügynökség vagy egyéb szerv, aki vagy amely MI-rendszert vagy\náltalános célú MI-modellt fejleszt vagy fejleszttet, és a saját neve vagy\nvédjegye alatt - akár fizetés ellenében, akár ingyenesen - az MI-rendszert\nvagy az általános célú MI-modellt forgalomba hozza, vagy az MI-rendszert\nüzembe helyezi; 4. „alkalmazó”: olyan természetes vagy jogi személy, hatóság,\nügynökség vagy egyéb szerv, aki vagy amely a felügyelete alá tartozó MI-\nrendszert használja, kivéve, ha az MI-rendszert személyes, nem szakmai jellegű\ntevékenység során használják; 5. „meghatalmazott képviselő”: az Unióban\ntartózkodó vagy ott letelepedett természetes vagy jogi személy, aki vagy amely\negy MI-rendszer vagy egy általános célú MI-modell szolgáltatójától írásbeli\nmeghatalmazást kapott és fogadott el az e rendeletben meghatározott\nkötelezettségeknek, illetve eljárásoknak a szolgáltató nevében történő\nteljesítésére, illetve lefolytatására; 6. „importőr”: az Unióban tartózkodó\nvagy ott letelepedett természetes vagy jogi személy, aki vagy amely egy\nharmadik országban letelepedett természetes vagy jogi személy nevével vagy\nvédjegyével ellátott MI-rendszert hoz forgalomba; 7. „forgalmazó”: az a\nszolgáltatótól vagy az importőrtől eltérő természetes vagy jogi személy az\nellátási láncban, aki vagy amely az uniós piacon MI-rendszert forgalmaz; 8.\n„gazdasági szereplő”: valamely szolgáltató, termékgyártó, alkalmazó,\nmeghatalmazott képviselő, importőr vagy forgalmazó; 9. „forgalomba hozatal”:\nvalamely MI-rendszer vagy általános célú MI-modell első alkalommal történő\nforgalmazása az uniós piacon; 10. „forgalmazás”: az uniós piacon egy MI-\nrendszer vagy egy általános célú MI-modell kereskedelmi tevékenység során\ntörténő rendelkezésre bocsátása terjesztés vagy használat céljából, akár\nfizetés ellenében, akár ingyenesen; 11. „üzembe helyezés”: valamely MI-\nrendszer első használatra történő rendelkezésre bocsátása közvetlenül az\nalkalmazó számára vagy saját használatra az Unióban, a rendeltetésének\nmegfelelően; 12. „rendeltetés”: az MI-rendszer azon használata, amelyre a\nszolgáltató azt szánta, ideértve a sajátos használati kontextust és\nfeltételeket, a szolgáltató által a használati utasításban, a promóciós vagy\nértékesítési anyagokban és nyilatkozatokban, valamint a műszaki\ndokumentációban megadott információk szerint; 13. „észszerűen előrelátható\nrendellenes használat”: valamely MI-rendszer oly módon történő használata,\namely nem felel meg a rendeltetésének, de amely előállhat észszerűen\nelőrelátható emberi magatartás vagy más rendszerekkel - többek között más MI-\nrendszerekkel - való kölcsönhatás eredményeként; 14. „biztonsági alkotórész”:\negy termék vagy egy MI-rendszer olyan alkotórésze, amely az említett termék\nvagy MI-rendszer tekintetében biztonsági funkciót tölt be, vagy amelynek a\nmeghibásodása vagy hibás működése veszélyezteti a személyek egészségét és\nbiztonságát vagy a vagyontárgyakat; 15. „használati utasítás”: a szolgáltató\náltal a célból megadott információ, hogy tájékoztassa az alkalmazót különösen\naz MI-rendszer rendeltetéséről és megfelelő használatáról; 16. „MI-rendszer\nvisszahívása”: minden olyan intézkedés, amelynek célja elérni az alkalmazók\nrendelkezésére bocsátott MI-rendszernek a szolgáltatóhoz való\nvisszajuttatását, vagy az üzemen kívül helyezését vagy a használatának\nletiltását; 17. „MI-rendszer forgalomból történő kivonása”: minden olyan\nintézkedés, amelynek célja megakadályozni az ellátási láncba már bekerült MI-\nrendszer forgalmazását; 18. „az MI-rendszer teljesítménye”: valamely MI-\nrendszer azon képessége, hogy betöltse rendeltetését; 19. „bejelentő hatóság”:\na megfelelőségértékelő szervezetek értékeléséhez, kijelöléséhez és\nbejelentéséhez, valamint a nyomon követésükhöz szükséges eljárások\nkialakításáért és lefolytatásáért felelős nemzeti hatóság; 20.\n„megfelelőségértékelés”: azon eljárás, amely kimutatja, hogy teljesítették-e\negy nagy kockázatú MI-rendszerrel kapcsolatos, a III. fejezet 2. szakaszában\nmeghatározott követelményeket; 21. „megfelelőségértékelő szervezet”: olyan\nszervezet, amely harmadik fél általi megfelelőségértékelési tevékenységeket\nvégez, ideértve a tesztelést, a tanúsítást és az ellenőrzést is; 22.\n„bejelentett szervezet”: az e rendelettel és az egyéb releváns uniós\nharmonizációs jogszabályokkal összhangban bejelentett megfelelőségértékelő\nszervezet; 23. „jelentős módosítás”: az MI-rendszer olyan, a forgalomba\nhozatalát vagy üzembe helyezését követő módosítása, amelyet a szolgáltató\náltal elvégzett első megfelelőségértékelésben nem irányoztak elő vagy\nterveztek, és amely érinti az MI-rendszer megfelelését a III. fejezet 2.\nszakaszában meghatározott követelményeknek, vagy az MI-rendszer értékelésének\ntárgyát képező rendeltetés módosulását eredményezi; 24. „CE-jelölés”: olyan\njelölés, amellyel a szolgáltató jelzi, hogy az MI-rendszer megfelel a III.\nfejezet 2. szakaszában és az egyéb alkalmazandó uniós harmonizációs\njogszabályokban meghatározott követelményeknek, amelyek előírják e jelölés\nfeltüntetését; 25. „forgalomba hozatal utáni nyomonkövetési rendszer”: az MI-\nrendszerek szolgáltatói által végzett valamennyi olyan tevékenység, amelynek\ncélja az általuk forgalomba hozott vagy üzembe helyezett MI-rendszerek\nhasználata során szerzett tapasztalatok összegyűjtése és áttekintése annak\nmegállapítása céljából, hogy kell-e haladéktalanul valamilyen korrekciós vagy\nmegelőző intézkedést alkalmazni; 26. „piacfelügyeleti hatóság”: az (EU)\n2019/1020 rendelet szerinti tevékenységeket végző és intézkedéseket hozó\nnemzeti hatóság; 27. „harmonizált szabvány”: az 1025/2012/EU rendelet 2. cikke\n1. pontjának c) alpontjában meghatározott harmonizált szabvány; 28. „közös\nelőírás”: az 1025/2012/EU rendelet 2. cikkének 4. pontjában meghatározott\nműszaki előírások készlete, amely eszközül szolgál az e rendelet szerinti\nbizonyos követelményeknek való megfeleléshez; 29. „tanítóadatok”: olyan\nadatok, amelyeket egy MI-rendszernek a megtanulható paramétereinek illesztése\nrévén történő tanítására használnak; 30. „validálási adatok”: a betanított MI-\nrendszer értékelésének nyújtására, valamint a nem megtanulható paramétereinek\nés a tanulási folyamatának beállítására használt adatok, többek között az\nalulillesztés vagy a túlillesztés megelőzése érdekében; 31. „validálási\nadatkészlet”: különálló adatkészlet vagy a tanítóadat-készlet része, akár\nrögzített, akár változó felosztás formájában; 32. „tesztadatok”: az MI-\nrendszer független értékelésének nyújtásához használt adatok az említett\nrendszer elvárt teljesítményének a forgalomba hozatala vagy az üzembe\nhelyezése előtti megerősítése érdekében; 33. „bemeneti adatok”: valamely MI-\nrendszer számára szolgáltatott vagy általa közvetlenül megszerzett adatok,\namelyek alapján a rendszer a kimenetet előállítja; 34. „biometrikus adat”: egy\ntermészetes személy testi, fiziológiai vagy viselkedési jellemzőire vonatkozó,\nsajátos technikai eljárásokkal nyert személyes adat, ilyen például az\narcképmás vagy a daktiloszkópiai adat; 35. „biometrikus azonosítás”: az ember\nfizikai, fiziológiai, viselkedési vagy pszichológiai humán jellemzőinek\nautomatikus felismerése a természetes személy személyazonosságának\nmegállapítása céljából, az említett egyén biometrikus adatainak az\nadatbázisban tárolt egyének biometrikus adataival való összehasonlítása révén;\n36. „biometrikus ellenőrzés”: természetes személyek személyazonosságának\nautomatizált, egy az egyhez ellenőrzése - ideértve a hitelesítést is - a\nbiometrikus adataiknak a korábban megadott biometrikus adatokkal való\nösszehasonlítása révén; 37. „a személyes adatok különleges kategóriái”: az\n(EU) 2016/679 rendelet 9. cikkének (1) bekezdésében, az (EU) 2016/680 irányelv\n10. cikkében és az (EU) 2018/1725 rendelet 10. cikkének (1) bekezdésében\nmeghatározott személyesadat-kategóriák; 38. „érzékeny operatív adatok”: a\nbűncselekmények megelőzését, felderítését, nyomozását vagy büntetőeljárás alá\nvonását célzó tevékenységekhez kapcsolódó operatív adatok, amelyek\nnyilvánosságra hozatala veszélyeztetheti a büntetőjogi eljárások integritását;\n39. „érzelemfelismerő rendszer”: a természetes személyek érzelmeinek vagy\nszándékainak a biometrikus adataik alapján történő azonosítására vagy\nkikövetkeztetésére szolgáló MI-rendszer; 40. „biometrikus kategorizálási\nrendszer”: a természetes személyeknek a biometrikus adataik alapján\nmeghatározott kategóriákba sorolására szolgáló MI-rendszer, kivéve, ha az egy\nmásik kereskedelmi szolgáltatás mellett kiegészítő jellegű, és objektív\ntechnikai okokból feltétlenül szükséges; 41. „távoli biometrikus azonosító\nrendszer”: a természetes személyek olyan azonosítására szolgáló MI-rendszer,\namelyre az aktív közreműködésük nélkül, jellemzően távolról, egy személy\nbiometrikus adatainak a referencia-adatbázisban szereplő biometrikus adatokkal\nvaló összehasonlítása révén kerül sor; 42. „valós idejű távoli biometrikus\nazonosító rendszer”: olyan távoli biometrikus azonosító rendszer, amelyben a\nbiometrikus adatok rögzítése, az összehasonlítás és az azonosítás egyaránt\njelentős késleltetés nélkül történik, nemcsak azonnali azonosítást\nmegvalósítva, hanem - a kijátszás elkerülése érdekében - korlátozott rövid\nkésleltetéseket is; 43. „nem valós idejű távoli biometrikus azonosító\nrendszer”: a valós idejű távoli biometrikus azonosító rendszertől eltérő\ntávoli biometrikus azonosító rendszer; 44. „a nyilvánosság számára\nhozzáférhető hely”: olyan köz- vagy magántulajdonban álló fizikai terület,\namely meghatározatlan számú természetes személy számára hozzáférhető,\nfüggetlenül attól, hogy esetleg alkalmazandók-e bizonyos hozzáférési\nfeltételek, valamint függetlenül a potenciális kapacitási korlátozásoktól; 45.\n„bűnüldöző hatóság”: a) olyan közigazgatási szerv, amely hatáskörrel\nrendelkezik a bűncselekmények megelőzésére, nyomozására, felderítésére vagy\nbüntetőeljárás alá vonására, vagy a büntetőjogi szankciók végrehajtására,\nideértve a közbiztonságot fenyegető veszélyekkel szembeni védelmet és azok\nmegelőzését is; vagy b) bármely egyéb olyan szerv vagy más jogalany, amely a\ntagállami jog alapján közfeladatokat lát el és közhatalmi jogosítványokat\ngyakorol a bűncselekmények megelőzése, nyomozása, felderítése vagy\nbüntetőeljárás alá vonása, vagy büntetőjogi szankciók végrehajtása céljából,\nideértve a közbiztonságot fenyegető veszélyekkel szembeni védelmet és azok\nmegelőzését is; 46. „bűnüldözés”: a bűnüldöző hatóságok által vagy a nevükben\nfolytatott, a bűncselekmények megelőzését, nyomozását, felderítését,\nbüntetőeljárás alá vonását, vagy a büntetőjogi szankciók végrehajtását célzó\ntevékenységek, ideértve a közbiztonságot fenyegető veszélyekkel szembeni\nvédelmet és azok megelőzését is; 47. „MI-hivatal”: a Bizottság azon funkciója,\namellyel hozzájárul az MI-rendszerek és az általános célú MI-rendszerek,\nvalamint az MI-irányítás végrehajtásához, nyomon követéséhez és\nfelügyeletéhez, amiről a 2024. január 24-i bizottsági határozat rendelkezett;\naz MI-hivatalra e rendeletben történő hivatkozásokat a Bizottságra való\nhivatkozásként kell értelmezni; 48. „illetékes nemzeti hatóság”: bejelentő\nhatóság vagy piacfelügyeleti hatóság; az uniós intézmények, ügynökségek,\nhivatalok és szervek által üzembe helyezett vagy használt MI-rendszerek\ntekintetében az illetékes nemzeti hatóságokra vagy piacfelügyeleti hatóságokra\ne rendeletben történő hivatkozásokat az európai adatvédelmi biztosra való\nhivatkozásként kell értelmezni; 49. „súlyos váratlan esemény”: az MI-\nrendszernél fellépő olyan váratlan esemény vagy hibás működés, amely\nközvetlenül vagy közvetetten a következők bármelyikéhez vezet: a) valamely\nszemély halála, vagy valamely személy egészségérnek súlyos károsodása; b) a\nkritikus infrastruktúra irányításának vagy üzemeltetésének súlyos és\nvisszafordíthatatlan zavara; c) az alapvető jogok védelmére irányuló, uniós\njog szerinti kötelezettségek megsértése; d) súlyos vagyoni vagy környezeti\nkárosodás; 50. „személyes adat”: az (EU) 2016/679 rendelet 4. cikkének 1.\npontjában meghatározott személyes adat; 51. „nem személyes adat”: az (EU)\n2016/679 rendelet 4. cikkének 1. pontjában meghatározott személyes adatoktól\neltérő adat; 52. „profilalkotás”: az (EU) 2016/679 rendelet 4. cikkének 4.\npontjában meghatározott profilalkotás; 53. „valós körülmények közötti\ntesztelésre vonatkozó terv”: olyan dokumentum, amely ismerteti a valós\nkörülmények közötti tesztelés célkitűzéseit, módszertanát, földrajzi, személyi\nés időbeli hatályát, nyomon követését, megszervezését és lefolytatását; 54.\n„tesztkörnyezetre vonatkozó terv”: a részt vevő szolgáltató és az illetékes\nhatóság közötti megállapodáson alapuló dokumentum, amely ismerteti a\ntesztkörnyezetben végzett tevékenységek célkitűzéseit, feltételeit,\nidőkeretét, módszertanát és követelményeit; 55. „MI szabályozói\ntesztkörnyezet”: valamely illetékes hatóság által létrehozott ellenőrzött\nkeretrendszer, amely lehetőséget kínál az MI-rendszerek szolgáltatói vagy\nleendő szolgáltatói számára, hogy - szabályozói felügyelet mellett,\nkorlátozott ideig egy tesztkörnyezetre vonatkozó tervet követve - innovatív\nMI-rendszert fejlesszenek ki, tanítsanak be, validáljanak és teszteljenek,\nadott esetben valós körülmények között; 56. „MI-jártasság”: olyan készségek,\nismeretek és értelmezési képességek, amelyek lehetővé teszik a szolgáltatók,\naz alkalmazók és az érintett személyek számára, hogy - figyelembe véve az e\nrendelettel összefüggésben fennálló jogaikat és kötelezettségeiket - a\nmegfelelő információk birtokában telepítsenek MI-rendszereket, valamint\ntudomást szerezzenek az MI lehetőségeiről és kockázatairól, és azon lehetséges\nkárokról, amelyet az MI okozhat; 57. „valós körülmények közötti tesztelés”:\negy MI-rendszernek a rendeltetése tekintetében - valós körülmények között\nlaboratóriumon vagy más szimulált környezeten kívül - végzett ideiglenes\ntesztelése, megbízható és stabil adatok gyűjtése, valamint annak értékelése és\nellenőrzése céljából, hogy az MI-rendszer megfelel-e e rendelet\nkövetelményeinek, és ez nem minősül az MI-rendszer e rendelet értelmében vett\nforgalomba hozatalának vagy üzembe helyezésének, feltéve, hogy az 57. vagy a\n60. cikkben megállapított valamennyi feltétel teljesül; 58. „vizsgálati\nalany”: a valós körülmények közötti tesztelés céljára olyan természetes\nszemély, aki részt vesz valós körülmények közötti tesztelésben; 59.\n„tájékoztatáson alapuló hozzájárulás”: a vizsgálati alany által szabad\nakaratból adott, konkrét, egyértelmű és önkéntes kifejezése annak, hogy\nhajlandó részt venni egy adott, valós körülmények közötti tesztelésben, miután\ntájékoztatást kapott a tesztelés valamennyi olyan szempontjáról, amely a\nvizsgálati alanynak a részvételre vonatkozó döntése szempontjából releváns;\n60. „deepfake”: az MI által generált vagy manipulált kép, audio- vagy\nvideotartalom, amely hasonlít létező személyekre, tárgyakra, helyekre,\nentitásokra vagy eseményekre, és amely egy személy számára megtévesztő módon\nautentikusnak vagy valóságosnak tűnne; 61. „kiterjedt jogsértés”: bármely, az\negyének érdekét védő uniós joggal ellentétes cselekmény vagy mulasztás, amely:\na) sértette vagy valószínűleg sérti olyan egyének kollektív érdekeit, akik\nazon tagállamtól eltérő legalább két tagállamban rendelkeznek lakóhellyel,\namelyben: i. a cselekmény vagy a mulasztás keletkezett vagy sorra került; ii.\naz érintett szolgáltató vagy adott esetben a meghatalmazott képviselője\ntartózkodik vagy letelepedett; vagy iii. az alkalmazó letelepedett, ha a\njogsértést az alkalmazó követi el; b) kárt okozott, okoz vagy okozhat egyének\nkollektív érdekeire nézve, és közös jellemzőkkel bír - többek között ugyanazon\njogellenes gyakorlatot valósítja meg, vagy ugyanazon érdeket sérti -, és\namelyet egy időben követ el ugyanazon gazdasági szereplő legalább három\ntagállamban; 62. „kritikus infrastruktúra”: az (EU) 2022/2557 irányelv 2.\ncikkének 4. pontjában meghatározott kritikus infrastruktúra; 63. „általános\ncélú MI-modell”: olyan MI-modell - ideértve azt is, amikor az ilyen MI-modell\ntanítása nagy adatmennyiséggel, nagy léptékű önfelügyelet mellett történik -,\namely jelentős általánosságot mutat, és forgalomba hozatalának módjától\nfüggetlenül, különféle feladatok széles körének elvégzésére képes, valamint\ntöbbféle downstream rendszerbe vagy alkalmazásba integrálható, azon MI-\nmodellek kivételével, amelyeket a forgalomba hozatalukat megelőzően kutatási,\nfejlesztési vagy prototípus-alkotási tevékenységekre használnak; 64. „nagy\nhatású képességek”: olyan képességek, amelyek megfelelnek a legfejlettebb\náltalános célú MI-modellekben rögzített képességeknek, vagy meghaladják\nazokat; 65. „rendszerszintű kockázat”: az általános célú MI-modellek nagy\nhatású képességeire jellemző kockázat, amely - a modellek jelentős\nelterjedtsége miatt, vagy a népegészségre, a biztonságra, a közbiztonságra, az\nalapvető jogokra vagy a társadalom egészére gyakorolt tényleges vagy\nészszerűen előrelátható negatív hatások révén - olyan jelentős hatást gyakorol\naz uniós piacra, amely nagy léptékben továbbterjedhet az értékláncban; 66.\n„általános célú MI-rendszer”: általános célú MI-modellen alapuló MI-rendszer,\namely - mind közvetlen felhasználás, mind más MI-rendszerekbe való integráció\ncéljából - többféle célt képes szolgálni; 67. „lebegőpontos művelet”:\nlebegőpontos számokkal végzett matematikai művelet vagy feladat, amely számok\na valós számok azon alhalmaza, amelyeket - jellemzően számítógépen - egy\nrögzített pontosságú egész számnak és egy rögzített alap egész számú\nhatványának a szorzataként ábrázolnak; 68. „downstream szolgáltató”: olyan MI-\nrendszer - ideértve az általános célú MI-rendszert is - szolgáltatója, amelybe\nMI-modellt integráltak, függetlenül attól, hogy a szolgáltató által\nbiztosított, vertikálisan integrált MI-modellről vagy egy másik szervezet\náltal szerződéses viszonyok alapján biztosított MI-modellről van-e szó. Az MI-\nrendszerek szolgáltatói és alkalmazói intézkedéseket hoznak annak érdekében,\nhogy a tőlük telhető legnagyobb mértékben biztosítsák személyzetük, valamint a\nnevükben az MI-rendszerek működtetésével és használatával foglalkozó bármely\nmás személy mesterséges intelligencia terén szerzett megfelelő szintű MI-\njártasságát, figyelembe véve szakmai ismereteiket, tapasztalatukat,\nvégzettségüket és képzettségüket, valamint azon körülményeket, amelyek között\naz MI-rendszereket használni fogják, és figyelembe véve azon személyeket vagy\nazon személyek csoportjait, akik tekintetében az MI-rendszereket használni\nfogják. (1) Tilosak a következő MI-gyakorlatok: a) olyan MI-rendszerek\nforgalomba hozatala, üzembe helyezése vagy használata, amelyek szubliminális\ntechnikákat alkalmaznak az adott személy tudatán kívül, vagy célzottan\nmanipulatív vagy megtévesztő technikákat alkalmaznak azzal a céllal vagy olyan\nhatás érdekében, hogy lényegesen torzítsák egy személy vagy személyek egy\ncsoportjának magatartását azáltal, hogy jelentősen gyengítik a megalapozott\ndöntéshozatalra való képességüket, azt eredményezve, hogy olyan döntést\nhozzanak, amelyet egyébként nem hoztak volna meg, és oly módon, amely az\nemlített személynek, egy másik személynek vagy személyek egy csoportjának\njelentős károsodást okoz vagy ésszerű valószínűséggel okozhat; b) olyan MI-\nrendszerek forgalomba hozatala, üzembe helyezése vagy használata, amelyek egy\ntermészetes személynek vagy a személyek egy meghatározott csoportjának az\néletkor, fogyatékosság, illetve egyedi szociális vagy gazdasági helyzet miatt\nfennálló valamilyen sebezhetőségét kihasználják azzal a céllal vagy hatással,\nhogy lényegesen torzítsák az említett személy vagy az említett csoporthoz\ntartozó valamely személy magatartását oly módon, amely az említett személynek\nvagy egy másik személynek jelentős kárt okoz vagy észszerű valószínűséggel\nokozhat; c) MI-rendszerek forgalomba hozatala, üzembe helyezése vagy\nhasználata természetes személyek vagy személyek csoportjai értékelésének vagy\nosztályozásának céljából egy bizonyos időszakon keresztül, közösségi\nmagatartásuk, illetve ismert, kikövetkeztetett vagy előre jelzett személyes\ntulajdonságaik vagy személyiségjegyeik alapján, oly módon, hogy a társadalmi\npontszám a következő helyzetek egyikéhez vagy mindkettőhöz vezet: i. bizonyos\ntermészetes személyekkel vagy személyek csoportjaival szembeni hátrányos vagy\nkedvezőtlen bánásmód olyan szociális kontextusokban, amelyek nem függenek\nössze azokkal a kontextusokkal, amelyek között az adatokat eredetileg\nlétrehozták vagy gyűjtötték; ii. bizonyos természetes személyekkel vagy\nszemélyek csoportjával szembeni olyan hátrányos vagy kedvezőtlen bánásmód,\namely indokolatlan vagy aránytalan közösségi magatartásukhoz vagy annak\nsúlyosságához képest; d) olyan MI-rendszer forgalomba hozatala, e konkrét\ncélra történő üzembe helyezése vagy használata, amely természetes személyek\nkockázatértékelését végzi annak érdekében, hogy - kizárólag a természetes\nszemélyekre vonatkozó profilalkotás vagy személyiségjegyeik és tulajdonságaik\nértékelése alapján - felmérje vagy előre jelezze annak kockázatát, hogy egy\nadott természetes személy bűncselekményt követ el; ez a tilalom nem\nalkalmazandó azon MI-rendszerekre, amelyek a személyek bűncselekményben való\nrészvételének emberi értékelését támogatják, amely értékelés alapjául már\nrendelkezésre állnak a bűnözői tevékenységhez közvetlenül kapcsolódó, objektív\nés ellenőrizhető tények; e) olyan MI-rendszerek forgalomba hozatala, e konkrét\ncélra történő üzembe helyezése vagy használata, amelyek az arcképek\ninternetről vagy zártláncú televízió-felvételekből való, nem célzott\nlekérdezésével arcfelismerő adatbázisokat hoznak létre vagy ilyeneket\nbővítenek; f) a természetes személyek érzelmeiből következtetést levonó MI-\nrendszerek forgalomba hozatala, e konkrét célra történő üzembe helyezése,\nilletve használata a munkahelyek és az oktatási intézmények területén, kivéve\namennyiben az MI-rendszer használata, üzembe helyezése vagy forgalomba\nhozatala orvosi vagy biztonsági okokból történik; g) olyan biometrikus\nkategorizálási rendszerek forgalomba hozatala, e konkrét célra történő üzembe\nhelyezése, illetve használata, amelyek természetes személyeket biometrikus\nadataik alapján egyénileg kategorizálnak, hogy ezáltal levezessék vagy\nkikövetkeztessék faji hovatartozásukat, politikai véleményüket, szakszervezeti\ntagságukat, vallási vagy világnézeti meggyőződésüket, szexuális életüket vagy\nszexuális irányultságukat; ez a tilalom nem terjed ki a jogszerűen megszerzett\nbiometrikus adatkészletek - például képek - biometrikus adatok szerint történő\njogszerű címkézésére vagy szűrésére, illetve a biometrikus adatoknak a\nbűnüldözés területén való kategorizálására; h) „valós idejű” távoli\nbiometrikus azonosító rendszerek használata a nyilvánosság számára\nhozzáférhető helyeken bűnüldözési célokból, kivéve, ha és amennyiben az ilyen\nhasználat a következő célok egyikéhez feltétlenül szükséges: i. emberrablás,\nemberkereskedelem vagy szexuális kizsákmányolás konkrét áldozatainak célzott\nfelkutatása, valamint az eltűnt személyek utáni kutatás; ii. természetes\nszemélyek életét vagy fizikai biztonságát fenyegető konkrét, jelentős és\nközvetlen veszély, illetve terrortámadás tényleges és valós vagy tényleges és\nelőre látható veszélyének megelőzése; iii. bűncselekmények gyanúsítottjainak\nlokalizálása vagy azonosítása nyomozás vagy büntetőeljárás lefolytatása vagy\nbüntetőjogi szankció végrehajtása céljából olyan, a II. mellékletben említett\nbűncselekmény miatt, amelynek esetében az érintett tagállamban a büntetési\ntétel felső határa legalább négyévi szabadságvesztés vagy szabadságelvonással\njáró intézkedés. Az első albekezdés h) pontja nem érinti az (EU) 2016/679\nrendelet 9. cikkét a biometrikus adatoknak a bűnüldözéstől eltérő célokból\ntörténő kezelése tekintetében. (2) A „valós idejű” távoli biometrikus\nazonosító rendszerek nyilvánosság számára hozzáférhető helyeken, bűnüldözés\ncéljából, az (1) bekezdés első albekezdésének h) pontjában említett célok\nbármelyike tekintetében történő használata az említett pontban meghatározott\ncélokból, csak a konkrét célszemély személyazonosságának megerősítése\nérdekében indítható el, és annak során figyelembe kell venni a következő\nelemeket: a) a lehetséges használatot eredményező helyzet jellege, különösen\nazon kár súlyossága, valószínűsége és mértéke, amely a rendszer használatának\nelmaradásakor keletkezne; b) a rendszer használatának valamennyi érintett\nszemély jogaira és szabadságaira gyakorolt következményei, különösen e\nkövetkezmények súlyossága, valószínűsége és mértéke. Emellett a „valós idejű”\ntávoli biometrikus azonosító rendszerek nyilvánosság számára hozzáférhető\nhelyeken, bűnüldözés céljából, az e cikk (1) bekezdése első albekezdésének h)\npontjában említett célok bármelyike tekintetében történő használatának meg\nkell felelnie - az annak használatát engedélyező nemzeti joggal összhangban -\na használattal kapcsolatos szükséges és arányos biztosítékoknak és\nfeltételeknek, különösen az időbeli, földrajzi és személyi korlátozások\ntekintetében. A valós idejű távoli biometrikus azonosító rendszerek\nnyilvánosság számára hozzáférhető helyeken történő használata csak akkor\nengedélyezhető, ha a bűnüldöző hatóság - a 27. cikk rendelkezéseinek\nmegfelelően - elvégezte az alapvetőjogi hatásvizsgálatot, és - a 49. cikkel\nösszhangban - nyilvántartásba vette a rendszert az uniós adatbázisban. Kellően\nindokolt sürgős esetekben azonban az ilyen rendszerek használata az uniós\nadatbázisban történő regisztráció nélkül is elindítható, feltéve, hogy az\nilyen regisztrációra indokolatlan késedelem nélkül sor kerül. (3) Az (1)\nbekezdés első albekezdésének h) pontja és a (2) bekezdés alkalmazása céljából\na „valós idejű” távoli biometrikus azonosító rendszer nyilvánosság számára\nhozzáférhető helyeken, bűnüldözési célokra történő minden használata a\nhasználat helye szerinti tagállam igazságügyi hatósága vagy független\nközigazgatási hatósága - amelynek határozata kötelező erejű - által kiadott\nelőzetes engedélyhez kötött, amelyet indokolt megkeresésre, a (5) bekezdésben\nemlített nemzeti jogszabályok részletes szabályaival összhangban bocsátanak\nki. Kellően indokolt sürgős esetben azonban a rendszer használata engedély\nnélkül is megkezdhető, feltéve, hogy az ilyen engedély megkérésére\nindokolatlan késedelem nélkül, legkésőbb 24 órán belül sor kerül. Ha az ilyen\nengedélyt elutasítják, a használatot azonnali hatállyal le kell állítani,\nvalamint az említett használat valamennyi eredményét és kimenetét azonnal meg\nkell semmisíteni, és törölni kell. Az illetékes igazságügyi hatóság vagy olyan\nfüggetlen közigazgatási hatóság, amelynek határozata kötelező erejű, csak\nakkor adhatja meg az engedélyt, ha az elé terjesztett objektív bizonyítékok\nvagy egyértelmű jelzések alapján meggyőződött arról, hogy az érintett „valós\nidejű” távoli biometrikus azonosító rendszer használata az (1) bekezdés első\nalbekezdésének h) pontjában meghatározott, a megkeresésben azonosított célok\nvalamelyikének eléréséhez szükséges és azzal arányos, továbbá különösen, hogy\naz időtartam, valamint a földrajzi és személyi hatály tekintetében a\nfeltétlenül szükséges mértékre korlátozódik. A megkeresésről való döntés során\naz említett hatóságnak figyelembe kell vennie a (2) bekezdésben említett\ntényezőket. Kizárólag a „valós idejű” távoli biometrikus azonosító rendszer\nkimenete alapján nem hozható olyan döntés, amely egy személyre nézve\nkedvezőtlen joghatással jár. (4) A (3) bekezdés sérelme nélkül, a „valós\nidejű” biometrikus azonosító rendszerek nyilvánosság számára hozzáférhető\nhelyeken, bűnüldözési célból történő használatáról minden esetben - az (5)\nbekezdésben említett nemzeti szabályokkal összhangban - értesíteni kell az\nérintett piacfelügyeleti hatóságot és a nemzeti adatvédelmi hatóságot. Az\nértesítésnek tartalmaznia kell legalább a (6) bekezdésben meghatározott\ninformációkat, és nem tartalmazhat érzékeny operatív adatokat. (5) A\ntagállamok dönthetnek úgy, hogy az (1) bekezdés első albekezdésének h)\npontjában, valamint a (2) és (3) bekezdésben felsorolt korlátokon belül és\nfeltételek mellett lehetővé teszik a „valós idejű” távoli biometrikus\nazonosító rendszerek nyilvánosság számára hozzáférhető helyeken, bűnüldözési\ncélokból történő használatának teljes vagy részleges engedélyezését. Az\nérintett tagállamok a nemzeti jogukban meghatározzák a (3) bekezdésben\nemlített engedélyek kérelmezésére, kiadására és felhasználására, valamint az\nazokkal kapcsolatos felügyeletre és jelentéstételre vonatkozó szükséges\nrészletes szabályokat. Ezekben a szabályokban azt is meg kell határozni, hogy\naz (1) bekezdés első albekezdésének h) pontjában felsorolt célok közül melyek\ntekintetében, valamint az említett bekezdés h) pontjának iii. alpontjában\nemlített bűncselekmények közül melyek tekintetében engedélyezhető az illetékes\nhatóságok számára az említett rendszerek bűnüldözési célú használata. A\ntagállamok az említett szabályokról legkésőbb azok elfogadása után 30 nappal\nértesítik a Bizottságot. A tagállamok az uniós joggal összhangban szigorúbb\njogszabályokat is bevezethetnek a távoli biometrikus azonosító rendszerek\nhasználatára vonatkozóan. (6) Azon tagállami nemzeti piacfelügyeleti hatóságok\nés nemzeti adatvédelmi hatóságok, amelyek a (4) bekezdésnek megfelelően\nértesítést kaptak a „valós idejű” távoli biometrikus azonosító rendszerek\nnyilvánosság számára hozzáférhető helyeken, bűnüldözési célból történő\nhasználatáról, éves jelentéseket nyújtanak be a Bizottságnak az ilyen\nhasználatról. E célból a Bizottság sablont bocsát a tagállamok és a nemzeti\npiacfelügyeleti és adatvédelmi hatóságok rendelkezésére, amely tartalmazza az\nazon határozatok számára, valamint azok eredményére vonatkozó információkat,\namelyeket - a (3) bekezdés szerinti, engedély iránti megkeresésre - az\nilletékes igazságügyi hatóságok vagy olyan független közigazgatási hatóság\nhozott, amelynek határozata kötelező erejű. (7) A Bizottság a (6) bekezdésben\nemlített éves jelentések nyomán a tagállamokban összesített adatok alapján\néves jelentéseket tesz közzé a valós idejű távoli biometrikus azonosító\nrendszerek nyilvánosság számára hozzáférhető helyeken történő, bűnüldözési\ncélú használatáról. Az említett éves jelentések nem tartalmazhatják a\nkapcsolódó bűnüldözési tevékenységek érzékeny operatív adatait. (8) Ez a cikk\nnem érinti az abban az esetben alkalmazandó tilalmakat, ha valamely MI-\ngyakorlat más uniós jogot sért. (1) Tekintet nélkül arra, hogy egy MI-\nrendszert az a) és b) pontban említett termékektől függetlenül hozzák-e\nforgalomba vagy helyezik-e üzembe, az említett MI-rendszer nagy kockázatúnak\nminősül, ha mindkét következő feltétel teljesül: a) az MI-rendszert az I.\nmellékletben felsorolt uniós harmonizációs jogszabályok hatálya alá tartozó\ntermék biztonsági alkotórészeként kívánják használni, vagy az MI-rendszer\nönmagában ilyen termék; b) azon terméket, amelynek biztonsági alkatórésze az\na) pont alapján az MI-rendszer, vagy magát az MI-rendszert mint terméket\nharmadik fél által végzett megfelelőségértékelésnek kell alávetni a terméknek\naz I. mellékletben felsorolt uniós harmonizációs jogszabályok értelmében való\nforgalomba hozatala vagy üzembe helyezése érdekében. (2) Az (1) bekezdésben\nemlített nagy kockázatú MI-rendszerek mellett a III. mellékletben említett MI-\nrendszereket nagy kockázatúnak kell tekinteni. (3) A (2) bekezdéstől eltérve,\nvalamely, a III. mellékletben hivatkozott MI-rendszer nem tekinthető nagy\nkockázatúnak, amennyiben nem jelent jelentős károkozó kockázatot természetes\nszemélyek egészségére, biztonságára vagy alapvető jogaira nézve, többek között\nazáltal, hogy nem befolyásolja lényegesen a döntéshozatal kimenetelét. Az első\nalbekezdés alkalmazandó, amennyiben a következő feltételek bármelyike\nteljesül: a) az MI-rendszer rendeltetése jól körülhatárolt eljárási feladat\nellátása; b) az MI-rendszer rendeltetése egy korábban elvégzett emberi\ntevékenység eredményének a javítása; c) az MI-rendszer rendeltetése\ndöntéshozatali minták vagy korábbi döntéshozatali mintáktól való eltérések\nészlelése, és nem célja a korábban elvégzett emberi értékelés megfelelő emberi\nfelülvizsgálat nélküli kiváltása vagy befolyásolása; vagy d) az MI-rendszer\nrendeltetése egy, a III. mellékletben felsorolt felhasználási esetek céljainak\nszempontjából releváns értékeléshez kapcsolódó előkészítő feladat elvégzése.\nAz első albekezdés ellenére egy, a III. mellékletben említett MI-rendszert\nmindig nagy kockázatúnak kell tekinteni, ha az MI-rendszer természetes\nszemélyekre vonatkozó profilalkotást végez. (4) Azon szolgáltatónak, amely úgy\nítéli meg, hogy valamely, a III. mellékletben említett MI-rendszer nem nagy\nkockázatú, az adott rendszer forgalomba hozatala vagy üzembe helyezése előtt\ndokumentálnia kell értékelését. Az ilyen szolgáltatóra a 49. cikk (2)\nbekezdésében meghatározott regisztrációs kötelezettség vonatkozik. Az\nilletékes nemzeti hatóságok kérésére a szolgáltatónak be kell nyújtania az\nértékelés dokumentációját. (5) A Bizottság a Mesterséges Intelligenciával\nFoglalkozó Európai Testülettel (a továbbiakban: a Testület) folytatott\nkonzultációt követően legkésőbb 2026. február 2-ig iránymutatásokat nyújt,\namelyekben meghatározza e cikknek a 96. cikkel összhangban történő gyakorlati\nvégrehajtását, valamint a nagy kockázatú és a nem nagy kockázatú MI-rendszerek\nfelhasználási eseteire vonatkozó gyakorlati példák átfogó listáját. (6) A\nBizottság felhatalmazást kap arra, hogy a 97. cikknek megfelelően\nfelhatalmazáson alapuló jogi aktusokat fogadjon el e cikk (3) bekezdése\nmásodik albekezdésének módosítása céljából, új feltételekkel egészítve ki az\nott megállapított feltételeket, vagy módosítva azokat, amennyiben konkrét és\nmegbízható bizonyíték áll rendelkezésre a III. melléklet hatálya alá tartozó,\nde a természetes személyek egészségére, biztonságára vagy alapvető jogaira\nnézve károkozó kockázatot nem jelentő MI-rendszerek meglétére vonatkozóan. (7)\nA Bizottság a 97. cikkel összhangban felhatalmazáson alapuló jogi aktusokat\nfogad el e cikk (3) bekezdése második albekezdésének módosítása céljából az\nott meghatározott feltételek bármelyikének törlésével, amennyiben konkrét és\nmegbízható bizonyítékok állnak rendelkezésre arra vonatkozóan, hogy ez\nszükséges az egészség, a biztonság és az alapvető jogok védelme e rendeletben\nelőírt szintjének fenntartásához. (8) A (3) bekezdés második albekezdésében\nmeghatározott feltételek - e cikk (6) vagy (7) bekezdésével összhangban\nelfogadott - bármely módosítása nem csökkentheti az egészség, a biztonság és\naz alapvető jogok védelmének e rendelet által előírt általános szintjét,\ntovábbá biztosítania kell a 7. cikk (1) bekezdése alapján elfogadott,\nfelhatalmazáson alapuló jogi aktusokkal való összhangot, és figyelembe kell\nvennie a piaci és technológiai fejleményeket. (1) A Bizottság felhatalmazást\nkap arra, hogy a 97. cikknek megfelelően felhatalmazáson alapuló jogi\naktusokat fogadjon el abból a célból, hogy módosítsa a III. mellékletet a nagy\nkockázatú MI-rendszerek felhasználási eseteinek hozzáadásával vagy\nmódosításával, amennyiben mindkét következő feltétel teljesül: a) az MI-\nrendszereket a III. mellékletben felsorolt területek valamelyikén kívánják\nhasználni; b) az MI-rendszerek az egészségre és a biztonságra nézve károsodás,\nvagy az alapvető jogokra nézve kedvezőtlen hatás kockázatát jelentik, és az\nemlített kockázat megegyezik a károsodás vagy a kedvezőtlen hatás azon\nkockázatával, amelyet a III. mellékletben már említett nagy kockázatú MI-\nrendszerek jelentenek, vagy annál nagyobb. (2) Az (1) bekezdés b) pontja\nszerinti feltétel értékelésekor a Bizottság a következő kritériumokat veszi\nfigyelembe: a) az MI-rendszer rendeltetése; b) azon mérték, amelyben az MI-\nrendszert használták vagy valószínűleg használják; c) az MI-rendszer által\nkezelt és felhasznált adatok jellege és mennyisége, különös tekintettel arra,\nhogy a személyes adatok különleges kategóriáit kezeli-e; d) az MI-rendszer\nautonóm cselekvésének mértéke és az emberi beavatkozás lehetősége\npotenciálisan kárt okozó döntés vagy ajánlások felülírása érdekében; e) az,\nhogy egy MI-rendszer használata milyen mértékben okozott már kárt az\negészségben és a biztonságban, gyakorolt kedvezőtlen hatást alapvető jogokra,\nvagy adott okot jelentős aggodalomra az ilyen kár vagy kedvezőtlen hatás\nvalószínűségével kapcsolatban, amint azt például az illetékes nemzeti\nhatóságokhoz benyújtott jelentések vagy dokumentált állítások, vagy adott\nesetben egyéb jelentések bizonyítják; f) az ilyen kár vagy kedvezőtlen hatás\nlehetséges mértéke, különösen annak intenzitása tekintetében és azt illetően,\nhogy érinthet-e több személyt vagy aránytalanul érintheti-e személyek egy\nadott csoportját; g) az, hogy a potenciálisan kárt szenvedő vagy kedvezőtlen\nhatásnak kitett személyek milyen mértékben függnek az MI-rendszerrel\nelőállított kimenettől, különösen amiatt, hogy gyakorlati vagy jogi okokból\nészszerűen nem lehetséges a kimeneten kívül maradni; h) az, hogy az\nerőviszonyok milyen mértékben kiegyensúlyozatlanok, vagy a potenciálisan\nkárosult vagy kedvezőtlen hatásnak kitett személyek milyen mértékben vannak\nkiszolgáltatott helyzetben az MI-rendszer alkalmazójával szemben, különösen a\nstátusz, a hatalom, a tudás, a gazdasági vagy társadalmi körülmények vagy az\néletkor miatt; i) az, hogy az MI-rendszer használatával előállított kimenet\nmennyire könnyen korrigálható vagy visszafordítható - figyelembe véve a\nkimenet korrigálása vagy a visszafordítása céljából rendelkezésre álló műszaki\nmegoldásokat -, ahol is az egészségre, a biztonságra vagy az alapvető jogokra\nkedvezőtlen hatást gyakorló kimenetek nem tekinthetők könnyen korrigálhatónak\nvagy visszafordíthatónak; j) az MI-rendszer bevezetéséből származó előnyök\nnagyságrendje és valószínűsége az egyének, csoportok vagy a társadalom egésze\nszámára, beleértve a termékbiztonság lehetséges javulását; k) az, hogy a\nmeglévő uniós jog milyen mértékben rendelkezik a következőkről: i. hatékony\njogorvoslati intézkedések az MI-rendszerek jelentette kockázatokkal\nkapcsolatban, a kártérítési keresetek kizárásával; ii. hatékony intézkedések\naz említett kockázatok megelőzésére vagy jelentős minimalizálására. (3) A\nBizottság felhatalmazást kap arra, hogy a 97. cikknek megfelelően\nfelhatalmazáson alapuló jogi aktusokat fogadjon el abból a célból, hogy a III.\nmellékletben szereplő jegyzéket nagy kockázatú MI-rendszerek törlésével\nmódosítsa, amennyiben mindkét következő feltétel teljesül: a) az érintett nagy\nkockázatú MI-rendszer már nem jelent jelentős kockázatot az alapvető jogokra,\naz egészségre vagy a biztonságra nézve, figyelembe véve a (2) bekezdésben\nfelsorolt kritériumokat; b) a törlés nem csökkenti az egészség, a biztonság és\naz alapvető jogok uniós jog szerinti védelmének általános szintjét. (1) A nagy\nkockázatú MI-rendszereknek meg kell felelniük az e szakaszban meghatározott\nkövetelményeknek, figyelembe véve a rendeltetésüket, valamint az MI-vel és az\nMI-vonatkozású technológiákkal kapcsolatos technika általánosan elfogadott,\nmindenkori állását. Az említett követelményeknek való megfelelés biztosítása\nsorán figyelembe kell venni a 9. cikkben említett kockázatkezelési rendszert.\n(2) Amennyiben egy termék olyan MI-rendszert tartalmaz, amelyre e rendelet\nkövetelményei, valamint az I. melléklet A. szakaszában felsorolt uniós\nharmonizációs jogszabályok követelményei alkalmazandók, a szolgáltatók\nfelelősek annak biztosításáért, hogy termékük teljes mértékben megfeleljen az\nalkalmazandó uniós harmonizációs jogszabályok szerinti valamennyi alkalmazandó\nkövetelménynek. Annak biztosítása érdekében, hogy az (1) bekezdésben említett\nnagy kockázatú MI-rendszerek megfeleljenek az e szakaszban meghatározott\nkövetelményeknek, valamint a következetesség biztosítása, az átfedések\nelkerülése és a további terhek minimalizálása érdekében a szolgáltatók\ndönthetnek úgy, hogy adott esetben a termékükkel kapcsolatban általuk\nrendelkezésre bocsátott szükséges tesztelési és jelentéstételi folyamatokat,\ninformációkat és dokumentációt integrálják a már meglévő, az I. melléklet A.\nszakaszában felsorolt uniós harmonizációs jogszabályok által előírt\ndokumentációba és eljárásokba. (1) A nagy kockázatú MI-rendszerek tekintetében\nkockázatkezelési rendszert kell létrehozni, bevezetni, dokumentálni és\nfenntartani. (2) A kockázatkezelési rendszer alatt olyan megszakítás nélkül\nvégzett iteratív folyamatot kell érteni, amelyet a nagy kockázatú MI-rendszer\negész életciklusára terveztek és működtetnek, és amely rendszeres és\nszisztematikus felülvizsgálatot és aktualizálást igényel. A folyamatnak a\nkövetkező lépéseket kell tartalmaznia: a) azon ismert, valamint észszerűen\nelőre látható kockázatok azonosítása és elemzése, amelyeket a nagy kockázatú\nMI-rendszer rendeltetésszerű használata esetén az egészségre, a biztonságra és\naz alapvető jogokra jelenthet; b) a nagy kockázatú MI-rendszer\nrendeltetésszerű használata, valamint észszerűen előre látható rendellenes\nhasználata esetén felmerülő kockázatok becslése és értékelése; c) egyéb\nesetlegesen felmerülő kockázatok értékelése a 72. cikkben említett forgalomba\nhozatal utáni nyomonkövetési rendszerből gyűjtött adatok elemzése alapján; d)\naz a) pont alapján azonosított kockázatok kezelésére irányuló megfelelő és\ncélzott kockázatkezelési intézkedések elfogadása. (3) Az e cikkben említett\nkockázatok alatt csak azok értendők, amelyek a nagy kockázatú MI-rendszer\nfejlesztése vagy tervezése, vagy a megfelelő műszaki információk biztosítása\nrévén észszerűen enyhíthetők vagy kiküszöbölhetők. (4) A (2) bekezdés d)\npontjában említett kockázatkezelési intézkedések tekintetében kellően\nfigyelembe kell venni az e szakaszban meghatározott követelmények együttes\nalkalmazásából eredő hatásokat és lehetséges kölcsönhatást a kockázatok\nhatékonyabb minimalizálása érdekében, egyúttal megfelelő egyensúlyt elérve az\nemlített követelmények teljesítését célzó intézkedések végrehajtása során. (5)\nA (2) bekezdés d) pontjában említett kockázatkezelési intézkedéseket úgy kell\nkialakítani, hogy az egyes veszélyekhez kapcsolódó releváns fennmaradó\nkockázatot, valamint a nagy kockázatú MI-rendszerek teljes fennmaradó\nkockázatát elfogadhatónak ítéljék. A legmegfelelőbb kockázatkezelési\nintézkedések meghatározásakor a következőket kell biztosítani: a) a (2)\nbekezdés alapján azonosított és értékelt kockázatok megszüntetése vagy\ncsökkentése - amennyiben műszakilag megvalósítható - a nagy kockázatú MI-\nrendszer megfelelő tervezése és fejlesztése révén; b) adott esetben a nem\nmegszüntethető kockázatok kezelésére szolgáló kockázatcsökkentő és ellenőrző\nintézkedések végrehajtása; c) a 13. cikk alapján előírt tájékoztatás, valamint\nadott esetben képzés nyújtása az alkalmazók számára. A nagy kockázatú MI-\nrendszer használatával kapcsolatos kockázatok megszüntetése vagy csökkentése\ncéljából kellő figyelmet kell fordítani az alkalmazó által elvárt műszaki\nismeretekre, tapasztalatokra, oktatásra és képzésre, valamint azon\nkörülményekre, amelyek között a rendszert feltételezhetően használni kívánják.\n(6) A nagy kockázatú MI-rendszereket tesztelni kell a legmegfelelőbb és\ncélzott kockázatkezelési intézkedések azonosítása céljából. A tesztelés\nbiztosítja, hogy a nagy kockázatú MI-rendszerek következetesen működjenek a\nrendeltetésüknek megfelelően, és megfeleljenek az e szakaszban meghatározott\nkövetelményeknek. (7) A tesztelési eljárások a 60. cikkel összhangban valós\nkörülmények közötti tesztelést is magukban foglalhatnak. (8) A nagy kockázatú\nMI-rendszerek tesztelését adott esetben a fejlesztési folyamat során bármikor,\nde mindenképpen a forgalomba hozatalt vagy az üzembe helyezést megelőzően kell\nelvégezni. A tesztelést a nagy kockázatú MI-rendszer rendeltetése\nszempontjából megfelelő, előzetesen meghatározott mérőszámok és valószínűségi\nküszöbértékek alapján kell elvégezni. (9) Az (1)-(7) bekezdésben meghatározott\nkockázatkezelési rendszer végrehajtása során a szolgáltatóknak megfontolás\ntárgyává kell tenniük azt, hogy a nagy kockázatú MI-rendszer - a rendeltetése\nszempontjából - valószínűleg kedvezőtlen hatást gyakorol-e a 18 év alatti\nszemélyekre és adott esetben más kiszolgáltatott csoportokra. (10) A nagy\nkockázatú MI-rendszerek azon szolgáltatói esetében, amelyek az uniós jog egyéb\nvonatkozó rendelkezéseinek értelmében belső kockázatkezelési folyamatokra\nvonatkozó követelmények hatálya alá tartoznak, az (1)-(9) bekezdésben leírt\nszempontok az említett jog alapján létrehozott kockázatkezelési eljárások\nrészét képezhetik vagy azokhoz társulhatnak. (1) A modellek adatokkal való\ntanítását magukban foglaló technikákat használó nagy kockázatú MI-rendszereket\nolyan tanító-, validálási és tesztadatkészletek alapján kell fejleszteni,\namelyek - az ilyen adatkészletek használatakor - megfelelnek a (2)-(5)\nbekezdésben említett minőségi kritériumoknak. (2) A tanító-, a validálási és a\ntesztadatkészleteket a nagy kockázatú MI-rendszer rendeltetésének megfelelő\nadatkormányzási és adatgazdálkodási gyakorlatoknak kell alávetni. Ezek a\ngyakorlatok különösen a következőket érintik: a) a vonatkozó tervezési\ndöntések; b) az adatgyűjtési eljárások és az adatok eredete, valamint\nszemélyes adatok esetében az adatgyűjtés eredeti célja; c) a releváns\nadatelőkészítési műveletek, mint például annotálás, címkézés, tisztítás,\nfrissítés, gazdagítás és összesítés; d) feltételezések megfogalmazása, különös\ntekintettel azon információkra, amelyeket az adatoknak az elvárás szerint\nmérniük kell és meg kell jeleníteniük; e) a szükséges adatkészletek\nrendelkezésre állásának, mennyiségének és alkalmasságának értékelése; f) az\nesetleges olyan torzítások vizsgálata, amelyek valószínűleg hatnak a személyek\negészségére és biztonságára, negatív hatást gyakorolnak az alapvető jogokra,\nvagy az uniós jog által tiltott megkülönböztetéshez vezetnek, különösen akkor,\nha az adatok kimenetei befolyásolják a jövőbeli műveletek bemeneteit; g) az f)\nponttal összhangban azonosított esetleges torzítások felderítését, megelőzését\nés enyhítését célzó megfelelő intézkedések; h) az e rendeletnek való\nmegfelelést akadályozó releváns adathiányok vagy hiányosságok azonosítása,\nvalamint e hiányok és hiányosságok kezelésének módja. (3) A tanító-, a\nvalidálási és a tesztadatkészleteknek relevánsnak, kellően reprezentatívnak,\nvalamint - a rendeltetés szempontjából - a lehető legnagyobb mértékben\nhibáktól mentesnek és teljesnek kell lenniük. Rendelkezniük kell a megfelelő\nstatisztikai tulajdonságokkal is, többek között adott esetben azon személyek\nvagy személyek csoportjai tekintetében, akikkel vagy amelyekkel kapcsolatosan\na nagy kockázatú MI-rendszert használni kívánják. Az említett adatkészletek e\njellemzői teljesíthetők az egyes adatkészletek szintjén vagy azok\nkombinációjának a szintjén. (4) Az adatkészleteknek - a rendeltetéstől függően\nszükséges mértékben - figyelembe kell venniük azon jellemzőket vagy elemeket,\namelyek azon sajátos földrajzi, kontextuális, magatartási vagy funkcionális\nkörnyezethez kapcsolódnak, amelyben a nagy kockázatú MI-rendszert használni\nkívánják. (5) A nagy kockázatú MI-rendszerekkel kapcsolatos torzítás\nészlelésének és korrekciójának biztosításához feltétlenül szükséges mértékben\n- e cikk (2) bekezdésének f) és g) pontjával összhangban - az ilyen rendszerek\nszolgáltatói kivételesen kezelhetik a személyes adatok különleges kategóriáit,\nfigyelemmel a természetes személyek alapvető jogaira és szabadságaira\nvonatkozó megfelelő biztosítékokra. Ahhoz, hogy az ilyen feldolgozás\nmegtörténhessen, az (EU) 2016/679 és az (EU) 2018/1725 rendeletben, valamint\naz (EU) 2016/680 irányelvben meghatározott rendelkezéseken túlmenően, a\nkövetkező feltételek mindegyikének teljesülnie kell: a) a torzítás észlelése\nés korrekciója más adatok - köztük szintetikus vagy anonimizált adatok -\nfeldolgozásával nem valósítható meg hatékonyan; b) a személyes adatok\nkülönleges kategóriái a személyes adatok további felhasználására vonatkozó\ntechnikai korlátozások, valamint a legkorszerűbb biztonsági és\nmagánéletvédelmi intézkedések - köztük az álnevesítés - hatálya alá tartoznak;\nc) a személyes adatok különleges kategóriái olyan intézkedések hatálya alá\ntartoznak, amelyek célja annak biztosítása, hogy a feldolgozott személyes\nadatok biztonságosak és védettek legyenek, megfelelő biztosítékok hatálya alá\ntartozzanak - ideértve a szigorú ellenőrzést és a hozzáférés dokumentálását -,\nvalamint a rendellenes használat elkerülése és annak garantálása, hogy az\nemlített személyes adatokhoz csak felhatalmazott és megfelelő titoktartási\nkötelezettségek alá tartozó személyek férjenek hozzá; d) a különleges\nkategóriájú személyes adatok nem továbbíthatók, nem ruházhatók át, és nem\ntehetők harmadik felek által egyéb módon hozzáférhetővé; e) a különleges\nkategóriájú személyes adatok törlésre kerülnek, amint a torzítást korrigálták,\nvagy a személyes adatok megőrzési időszaka lejárt, attól függően, hogy melyik\nkövetkezik be előbb; f) az adatkezelési tevékenységeknek az (EU) 2016/679 és\naz (EU) 2018/1725 rendelet, valamint az (EU) 2016/680 irányelv szerinti\nnyilvántartásai tartalmazzák annak magyarázatát, hogy a személyes adatok\nkülönleges kategóriáinak kezelése miért volt feltétlenül szükséges a\ntorzítások felderítéséhez és korrekciójához, és hogy ez a cél miért nem volt\nelérhető más adatok kezelésével. (6) Az MI-modellek tanítását magukban foglaló\ntechnikákat nem alkalmazó nagy kockázatú MI-rendszerek fejlesztése esetében a\n(2)-(5) bekezdés csak a tesztadatkészletekre alkalmazandó. (1) A nagy\nkockázatú MI-rendszerek műszaki dokumentációját a rendszer forgalomba hozatala\nvagy üzembe helyezése előtt kell elkészíteni, és naprakészen kell tartani. A\nműszaki dokumentációt úgy kell összeállítani, hogy bizonyítsa, hogy a nagy\nkockázatú MI-rendszer megfelel az e szakaszban meghatározott követelményeknek,\nés hogy belőle az illetékes nemzeti hatóságok és a bejelentett szervezetek\nvilágos és érthető formában hozzájussanak az annak értékeléséhez szükséges\ninformációkhoz, hogy az MI-rendszer megfelel-e az említett követelményeknek. A\nműszaki dokumentációnak tartalmaznia kell legalább a IV. mellékletben\nmeghatározott elemeket. A kkv-k - köztük az induló innovatív vállalkozások -\negyszerűsített formában nyújthatják be a IV. mellékletben meghatározott\ntechnikai dokumentáció elemeit. E célból a Bizottság létrehozza a kis- és\nmikrovállalkozások igényeinek megfelelő, egyszerűsített műszaki dokumentációs\nformanyomtatványt. Amennyiben valamely kkv - például induló innovatív\nvállalkozás - úgy dönt, hogy a IV. mellékletben előírt információkat\negyszerűsített formában nyújtja be, e célra az e bekezdésben említett\nformanyomtatványt kell használnia. A bejelentett szervezeteknek a\nmegfelelőségértékelés céljára el kell fogadniuk a formanyomtatványt. (2) Olyan\ntermékhez kapcsolódó nagy kockázatú MI-rendszer forgalomba hozatala vagy\nüzembe helyezése esetén, amelyre az I. melléklet A. szakaszában felsorolt\nuniós harmonizációs jogszabályok vonatkoznak, egyetlen műszaki dokumentációs\ncsomagot kell készíteni, amely tartalmazza az (1) bekezdésben meghatározott\nvalamennyi információt, valamint az említett jogi aktusokban előírt\ninformációkat. (3) A Bizottság felhatalmazást kap arra, hogy a 97. cikknek\nmegfelelően felhatalmazáson alapuló jogi aktusokat fogadjon el, hogy szükség\nesetén módosítsa a IV. mellékletet annak biztosítása érdekében, hogy a műszaki\ndokumentáció a műszaki fejlődés fényében minden szükséges információt megadjon\nannak értékeléséhez, hogy a rendszer megfelel-e az e szakaszban meghatározott\nkövetelményeknek. (1) A nagy kockázatú MI-rendszereknek a rendszer élettartama\nsorán technikailag lehetővé kell tenniük az események automatikus rögzítését\n(naplózás). (2) Annak érdekében, hogy biztosítsák a nagy kockázatú MI-rendszer\nműködésének olyan szinten történő nyomon követhetőségét, amely megfelelő a\nrendszer rendeltetéséhez, a naplózási képességeknek lehetővé kell tenniük a\nkövetkezők szempontjából releváns események rögzítését: a) azon helyzetek\nazonosítása, amelyek eredményeként a nagy kockázatú MI-rendszer a 79. cikk (1)\nbekezdése értelmében vett kockázatot jelenthet, vagy amelyek eredményeként\njelentős módosítás következhet be; b) a 72. cikkben említett forgalomba\nhozatal utáni nyomon követés megkönnyítése; és c) a nagy kockázatú MI-\nrendszerek működésének a 26. cikk (5) bekezdésében említett nyomon követése.\n(3) A III. melléklet 1. pontjának a) alpontjában említett nagy kockázatú MI-\nrendszerek esetében a naplózási képességnek legalább a következőket kell\nbiztosítania: a) a rendszer minden egyes használati időszakának rögzítése (az\negyes használatok kezdő dátuma és időpontja, valamint záró dátuma és\nidőpontja); b) az a referencia-adatbázis, amelyhez viszonyítva a rendszer\nellenőrizte a bemeneti adatokat; c) azok a bemeneti adatok, amelyek esetében a\nkeresés egyezést eredményezett; d) a 14. cikk (5) bekezdésében említettek\nszerint az eredmények ellenőrzésében részt vevő természetes személyek\nazonosítása. (1) A nagy kockázatú MI-rendszereket úgy kell megtervezni és\nfejleszteni, hogy működésük kellően átlátható legyen ahhoz, hogy az alkalmazók\nértelmezhessék a rendszer kimenetét és megfelelően használhassák azt. A\nszolgáltatónak és az alkalmazónak a 3. szakaszban meghatározott vonatkozó\nkötelezettségeinek való megfelelés érdekében megfelelő típusú és mértékű\nátláthatóságot kell biztosítani. (2) A nagy kockázatú MI-rendszerekhez\nmegfelelő digitális formátumú vagy egyéb használati utasítást kell mellékelni,\namely tömör, teljes körű, pontos és egyértelmű, az alkalmazók számára\nreleváns, hozzáférhető és érthető információkat tartalmaz. (3) A használati\nutasításnak tartalmaznia kell legalább a következő információkat: a) a\nszolgáltatónak és - adott esetben - a meghatalmazott képviselőjének a kiléte\nés elérhetőségei; b) a nagy kockázatú MI-rendszer jellemzői, képességei és\nteljesítményének korlátai, beleértve a következőket: i. a rendszer\nrendeltetése; ii. a 15. cikkben említett pontosság - ideértve a mérőszámait is\n-, stabilitás és kiberbiztonság azon várható szintje, amelyhez viszonyítva a\nnagy kockázatú MI-rendszert tesztelték és validálták, valamint minden olyan\nismert és előre látható körülmény, amely befolyásolhatja a pontosság, a\nstabilitás és a kiberbiztonság említett várható szintjét; iii. bármely ismert\nvagy előre látható, a nagy kockázatú MI-rendszer rendeltetésszerű\nhasználatával vagy az észszerűen előrelátható rendellenes használatával\nösszefüggő körülmény, amely a 9. cikk (2) bekezdésében említett, az egészségre\nés a biztonságra vagy az alapvető jogokra jelentett kockázatokhoz vezethet;\niv. adott esetben a nagy kockázatú MI-rendszer műszaki képességei és\ntulajdonságai a kimenetének magyarázata szempontjából releváns tájékoztatás\ntekintetében; v. adott esetben a rendszer teljesítménye azon meghatározott\nszemélyek vagy személyek csoportjai tekintetében, akikre vagy amelyekre a\nrendszert használni kívánják; vi. adott esetben a bemeneti adatokra vonatkozó\nelőírások vagy az alkalmazott tanító-, validálási és tesztadatkészletekre\nvonatkozó egyéb releváns információk, figyelembe véve a nagy kockázatú MI-\nrendszer rendeltetését; vii. adott esetben a nagy kockázatú MI-rendszer\nkimeneteinek az alkalmazók általi értelmezését és megfelelő használatát\nlehetővé tevő információk; c) a nagy kockázatú MI-rendszert és annak\nteljesítményét érintő, a szolgáltató által az első megfelelőségértékelés\nidőpontjában előre meghatározott változások, ha vannak ilyenek; d) a 14.\ncikkben említett emberi felügyeleti intézkedések, beleértve a nagy kockázatú\nMI-rendszerek kimeneteinek alkalmazók általi értelmezését megkönnyítő\ntechnikai intézkedéseket; e) a szükséges számítási és hardveres erőforrások, a\nnagy kockázatú MI-rendszer várható élettartama, valamint az említett MI-\nrendszer megfelelő működésének biztosításához szükséges karbantartási és\ngondozási intézkedések, beleértve a gyakoriságukat is, többek között a\nszoftverfrissítések tekintetében; f) adott esetben a nagy kockázatú MI-\nrendszerben foglalt mechanizmusok leírása, amelyek lehetővé teszik az\nalkalmazók számára a naplók megfelelő gyűjtését, tárolását és értelmezését a\n12. cikkel összhangban. (1) A nagy kockázatú MI-rendszereket úgy kell\nmegtervezni és fejleszteni - többek között megfelelő ember-gép interfész\neszközökkel -, hogy azokat a használatuk időtartama alatt természetes\nszemélyek hatékonyan felügyelhessék. (2) Az emberi felügyelet célja az\negészséget, a biztonságot vagy az alapvető jogokat érintő azon kockázatok\nmegelőzése vagy minimalizálása, amelyek a nagy kockázatú MI-rendszer\nrendeltetésszerű használata vagy észszerűen előrelátható rendellenes\nhasználata esetén merülhetnek fel, különösen, amennyiben az ilyen kockázatok\naz e szakaszban meghatározott egyéb követelmények alkalmazásának ellenére\ntartósan fennállnak. (3) A felügyeleti intézkedéseknek arányban kell állniuk a\nnagy kockázatú MI-rendszer kockázataival, autonómiaszintjével és felhasználási\nkontextusával, és azokat a következő intézkedéstípusok közül az egyik vagy\nmindkettő révén kell biztosítani: a) a szolgáltató által a nagy kockázatú MI-\nrendszer forgalomba hozatala vagy üzembe helyezése előtt azonosított és -\namennyiben műszakilag megvalósítható - a nagy kockázatú MI-rendszerbe\nbeépített intézkedések; b) a szolgáltató által a nagy kockázatú MI-rendszer\nforgalomba hozatala vagy üzembe helyezése előtt azonosított, és az alkalmazó\náltali alkalmazásra megfelelő intézkedések. (4) Az (1), a (2) és a (3)\nbekezdés végrehajtása céljából a nagy kockázatú MI-rendszert oly módon kell az\nalkalmazó rendelkezésére bocsátani, hogy az emberi felügyelettel megbízott\ntermészetes személyek - adott esetben és arányos módon - képessé váljanak a\nkövetkezőkre: a) megfelelően megérteni a nagy kockázatú MI-rendszer releváns\nképességeit és korlátait, valamint tudni kellően nyomon követni annak\nműködését, többek között a rendellenességek, zavarok és a váratlan\nteljesítmény felderítése és kezelése érdekében; b) tudatában maradni a nagy\nkockázatú MI-rendszerek által előállított kimenetre való automatikus vagy\ntúlzott mértékű támaszkodás tendenciájának („automatizálási torzítás”),\nkülönösen azon nagy kockázatú MI-rendszerek esetében, amelyeket információ\nvagy ajánlások nyújtására használnak a természetes személyek által hozandó\ndöntésekhez; c) helyesen értelmezni a nagy kockázatú MI-rendszer kimenetét,\nfigyelembe véve például a rendelkezésre álló értelmezési eszközöket és\nmódszereket; d) bármely konkrét helyzetben dönteni arról, hogy nem használják\na nagy kockázatú MI-rendszert, vagy más módon figyelmen kívül hagyják,\nfelülírják vagy visszafordítják a nagy kockázatú MI-rendszer kimenetét; e)\nbeavatkozni a nagy kockázatú MI-rendszer működésébe, vagy megszakítani a\nrendszert egy „stop” gomb vagy olyan, hasonló eljárás révén, amely lehetővé\nteszi a rendszer biztonságos állapotban történő leállását. (5) A III.\nmelléklet 1. pontjának a) alpontjában említett nagy kockázatú MI-rendszerek\nesetében az e cikk (3) bekezdésében említett intézkedéseknek olyanoknak kell\nlenniük, amelyek biztosítják, hogy emellett az alkalmazó a rendszerből\nszármazó azonosítás alapján ne hozzon intézkedést vagy döntést, kivéve, ha az\nemlített azonosítást legalább két, a szükséges kompetenciával, képzettséggel\nés hatáskörrel rendelkező természetes személy - egymástól függetlenül -\nellenőrizte és megerősítette. A legalább két természetes személy által\negymástól függetlenül végzett ellenőrzésre vonatkozó követelmény nem\nalkalmazandó a bűnüldözés, a migráció, a határellenőrzés vagy a menekültügy\ncéljaira használt nagy kockázatú MI-rendszerekre, amennyiben az uniós vagy a\nnemzeti jog e követelmény alkalmazását aránytalannak tekinti. (1) A nagy\nkockázatú MI-rendszereket úgy kell megtervezni és fejleszteni, hogy megfelelő\nszintű pontosságot, stabilitást és kiberbiztonságot érjenek el, továbbá, hogy\ne tekintetben a teljes életciklusuk során következetesen teljesítsenek. (2) A\npontosság és a stabilitás (1) bekezdésben meghatározott szintjeinek mérésével\nkapcsolatos technikai szempontok figyelembevétele érdekében a Bizottság - a\nreleváns érdekelt felekkel és szervezetekkel, így például a metrológiai és\nteljesítményértékelési hatóságokkal együttműködve - adott esetben ösztönzi a\nreferenciaértékek és mérési módszertanok kidolgozását. (3) A nagy kockázatú\nMI-rendszerek pontossági szintjeit és vonatkozó pontossági mérőszámait a\nmellékelt használati utasításban kell feltüntetni. (4) A nagy kockázatú MI-\nrendszereknek a lehető leginkább reziliensnek kell lenniük azon hibák,\nmeghibásodások vagy következetlenségek tekintetében, amelyek a rendszeren vagy\na rendszer működési környezetén belül előfordulhatnak, különösen a természetes\nszemélyekkel vagy más rendszerekkel való kölcsönhatásuk miatt. E tekintetben\ntechnikai és szervezeti intézkedéseket kell hozni. A nagy kockázatú MI-\nrendszerek stabilitása elérhető műszaki redundanciamegoldásokkal, amelyek\nmagukban foglalhatnak biztonsági vagy vészüzemi terveket is. Azon nagy\nkockázatú MI-rendszereket, amelyek a forgalomba hozatalt vagy az üzembe\nhelyezést követően is tanulnak, úgy kell fejleszteni, hogy kiküszöböljék vagy\na lehető legnagyobb mértékben csökkentsék annak kockázatát, hogy az\nesetlegesen torzított kimenetek befolyásolják a jövőbeli műveletek bemenetét\n(visszacsatolási hurkok), valamint biztosítva azt, hogy az ilyen\nvisszacsatolási hurkokat megfelelő kockázatcsökkentő intézkedésekkel\nkielégítően kezeljék. (5) A nagy kockázatú MI-rendszereknek reziliensnek kell\nlenniük a jogosulatlan harmadik felek arra irányuló kísérleteivel szemben,\nhogy a rendszer sebezhetőségeinek kiaknázása révén megváltoztassák a rendszer\nhasználatát, kimeneteit vagy teljesítményét. A nagy kockázatú MI-rendszerek\nkiberbiztonságának biztosítását célzó műszaki megoldásoknak megfelelőnek kell\nlenniük a releváns körülmények és a kockázatok szempontjából. Az MI-specifikus\nsebezhetőségek kezelésére szolgáló műszaki megoldásoknak adott esetben\nmagukban kell foglalniuk azon intézkedéseket, amelyek a tanítóadat-készlet\nmanipulálását megkísérlő támadásoknak (adatmérgezés) vagy a tanítás során\nhasznált előtanított összetevők manipulálását megkísérlő támadásoknak\n(„modellmérgezés”), a modell hibájának előidézésére szolgáló bemeneteknek\n(támadó szempontú példák vagy modellkijátszás), a bizalmasság elleni\ntámadásoknak vagy a modellhibáknak a megelőzésére, felderítésére, az azokra\nvaló reagálásra, azok megoldására és ellenőrzésére irányulnak. A nagy\nkockázatú MI-rendszerek szolgáltatóinak: a) biztosítaniuk kell, hogy nagy\nkockázatú MI-rendszereik megfeleljenek a 2. szakaszban meghatározott\nkövetelményeknek; b) fel kell tüntetniük a nagy kockázatú MI-rendszeren - vagy\namennyiben ez nem lehetséges, annak csomagolásán vagy adott esetben a kísérő\ndokumentációján - a nevüket, bejegyzett kereskedelmi nevüket vagy bejegyzett\nvédjegyüket és azt a címüket, amelyen velük kapcsolatba lehet lépni; c) a 17.\ncikknek megfelelő minőségirányítási rendszerrel kell rendelkezniük; d)\nvezetniük kell a 18. cikkben említett dokumentációt; e) a 19. cikkben\nemlítettek szerint meg kell őrizniük a nagy kockázatú MI-rendszereik által\nautomatikusan generált naplókat, ha azok az ellenőrzésük alatt állnak; f)\nbiztosítaniuk kell, hogy a nagy kockázatú MI-rendszert forgalomba hozatala\nvagy üzembe helyezése előtt alávessék a 43. cikkben említett vonatkozó\nmegfelelőségértékelési eljárásnak; g) a 47. cikkel összhangban EU-\nmegfelelőségi nyilatkozatot kell készíteniük; h) a 48. cikkel összhangban fel\nkell tüntetniük a CE-jelölést a nagy kockázatú MI-rendszeren - vagy amennyiben\nez nem lehetséges, annak csomagolásán vagy kísérő dokumentációján -, hogy\njelezzék az e rendeletnek való megfelelést; i) eleget kell tenniük a 49. cikk\n(1) bekezdésében említett regisztrációs kötelezettségeknek; j) a 20. cikkben\nelőírtak szerint meg kell hozniuk a szükséges korrekciós intézkedéseket és\ntájékoztatást kell nyújtaniuk; k) az illetékes nemzeti hatóság indokolással\nellátott kérésére igazolniuk kell, hogy a nagy kockázatú MI-rendszer megfelel\na 2. szakaszban meghatározott követelményeknek; l) az (EU) 2016/2102 és az\n(EU) 2019/882 irányelvvel összhangban biztosítaniuk kell, hogy a nagy\nkockázatú MI-rendszer megfeleljen az akadálymentesítési követelményeknek. (1)\nA nagy kockázatú MI-rendszerek szolgáltatóinak minőségirányítási rendszert\nkell bevezetniük, amely biztosítja az e rendeletnek való megfelelést. Ezt a\nrendszert írásbeli szabályzatok, eljárások és utasítások formájában\nszisztematikus és rendezett módon dokumentálni kell, és annak legalább a\nkövetkező szempontokra kell kiterjednie: a) a jogszabályi rendelkezések\ntiszteletben tartását célzó stratégia, beleértve a megfelelőségértékelési\neljárásoknak, valamint a nagy kockázatú MI-rendszer módosításának kezelését\ncélzó eljárásoknak való megfelelést is; b) a nagy kockázatú MI-rendszer\ntervezéséhez, tervezés-ellenőrzéséhez és tervezés-igazolásához alkalmazandó\ntechnikák, eljárások és módszeres intézkedések; c) a nagy kockázatú MI-\nrendszer fejlesztésére, minőség-ellenőrzésére és minőségbiztosítására\nalkalmazandó technikák, eljárások és módszeres intézkedések; d) a nagy\nkockázatú MI-rendszer fejlesztése előtt, alatt és után végrehajtandó\nvizsgálati, tesztelési és validálási eljárások, valamint azok elvégzésének\nelőírt gyakorisága; e) az alkalmazandó műszaki előírások, beleértve a\nszabványokat, valamint - amennyiben a vonatkozó harmonizált szabványokat nem\nalkalmazzák teljes mértékben, vagy azok nem terjednek ki a 2. szakaszban\nmeghatározott valamennyi releváns követelményre - az annak biztosítására\nszolgáló eszközök, hogy a nagy kockázatú MI-rendszer megfeleljen az említett\nkövetelményeknek; f) adatgazdálkodási rendszerek és eljárások, beleértve az\nadatszerzést, az adatgyűjtést, az adatelemzést, az adatcímkézést, az\nadattárolást, az adatszűrést, az adatbányászatot, az adatösszesítést, az\nadatmegőrzést és a nagy kockázatú MI-rendszerek forgalomba hozatala vagy\nüzembe helyezése előtt és céljából végzett bármely más, az adatokkal\nkapcsolatos műveletet; g) a 9. cikkben említett kockázatkezelési rendszer; h)\na 72. cikkel összhangban a forgalomba hozatal utáni nyomonkövetési rendszer\nkidolgozása, végrehajtása és fenntartása; i) a 73. cikkel összhangban a súlyos\nváratlan események bejelentésével kapcsolatos eljárások; j) az illetékes\nnemzeti hatóságokkal, egyéb releváns - többek között az adatokhoz való\nhozzáférést biztosító vagy támogató - hatóságokkal, a bejelentett\nszervezetekkel, más gazdasági szereplőkkel, ügyfelekkel vagy más érdekelt\nfelekkel folytatott kommunikáció kezelése; k) valamennyi releváns dokumentáció\nés információ nyilvántartására szolgáló rendszerek és eljárások; l) erőforrás-\ngazdálkodás, beleértve az ellátás biztonságával kapcsolatos intézkedéseket; m)\nelszámoltathatósági keret, amely meghatározza a vezetőség és az egyéb\nszemélyzet felelősségi körét az e bekezdésben felsorolt valamennyi szempont\ntekintetében. (2) Az (1) bekezdésben említett szempontok megvalósításának\narányosnak kell lennie a szolgáltató szervezetének méretével. A\nszolgáltatóknak minden esetben tiszteletben kell tartaniuk a nagy kockázatú\nMI-rendszereik e rendeletnek való megfelelésének biztosításához szükséges\nszigorúsági mértéket és védelmi szintet. (3) A nagy kockázatú MI-rendszerek\nazon szolgáltatói, amelyek a minőségirányítási rendszerekre vagy a releváns\nágazati uniós jog szerinti valamely egyenértékű funkcióra vonatkozó\nkötelezettségek hatálya alá tartoznak, az (1) bekezdésben felsorolt\nszempontokat az említett jog alapján létrehozott minőségirányítási rendszerek\nrészévé tehetik. (4) Azon szolgáltatók esetében, amelyek a pénzügyi\nszolgáltatásokra vonatkozó uniós jog értelmében a belső irányításukra,\nrendszerükre vagy eljárásaikra vonatkozó követelmények hatálya alá tartozó\npénzügyi intézmények, az e cikk (1) bekezdésének g), h) és i) pontja\nkivételével a minőségirányítási rendszer létrehozására vonatkozó\nkötelezettséget a pénzügyi szolgáltatásokra vonatkozó uniós jog szerinti,\nbelső irányítási rendszerekre vagy eljárásokra vonatkozó szabályoknak való\nmegfeleléssel teljesítettnek kell tekinteni. E célból figyelembe kell venni a\n40. cikkben említett harmonizált szabványokat. (1) A szolgáltatónak a nagy\nkockázatú MI-rendszer forgalomba hozatala vagy üzembe helyezése után 10 évig\naz illetékes nemzeti hatóságok számára elérhetővé kell tennie a következőket:\na) a 11. cikkben említett műszaki dokumentáció; b) a 17. cikkben említett\nminőségirányítási rendszerre vonatkozó dokumentáció; c) adott esetben a\nbejelentett szervezetek által jóváhagyott változtatások dokumentációja; d)\nadott esetben a bejelentett szervezetek által kiadott határozatok és egyéb\ndokumentumok; e) a 47. cikkben említett EU-megfelelőségi nyilatkozat. (2)\nMinden tagállam meghatározza azon feltételeket, amelyek mellett az (1)\nbekezdésben említett dokumentáció az említett bekezdésben megjelölt ideig\ntovábbra is az illetékes nemzeti hatóságok rendelkezésére áll azokban az\nesetekben, amikor a szolgáltató vagy a területén letelepedett meghatalmazott\nképviselője az említett időszak vége előtt csődbe megy vagy beszünteti\ntevékenységét. (3) Azon szolgáltatóknak, amelyek a pénzügyi szolgáltatásokra\nvonatkozó uniós jog értelmében a belső irányításukra, rendszerükre vagy\neljárásaikra vonatkozó követelmények hatálya alá tartozó pénzügyi intézmények,\na technikai dokumentációt a pénzügyi szolgáltatásokra vonatkozó uniós jog\nalapján vezetett dokumentáció részeként kell megőrizniük. (1) A nagy kockázatú\nMI-rendszerek szolgáltatóinak meg kell őrizniük az adott nagy kockázatú MI-\nrendszereik által automatikusan generált, a 12. cikk (1) bekezdésében említett\nnaplókat, amennyiben az ilyen naplók ellenőrzésük alatt állnak. A naplókat -\naz alkalmazandó uniós vagy nemzeti jog sérelme nélkül - a nagy kockázatú MI-\nrendszer rendeltetésének megfelelő - legalább hat hónapos - időtartamig kell\nmegőrizni, kivéve, ha az alkalmazandó uniós vagy nemzeti jog, különösen a\nszemélyes adatok védelmére vonatkozó uniós jog másként rendelkezik. (2) Azon\nszolgáltatóknak, amelyek a pénzügyi szolgáltatásokra vonatkozó uniós jog\nértelmében a belső irányításukra, rendszerükre vagy eljárásaikra vonatkozó\nkövetelmények hatálya alá tartozó pénzügyi intézmények, a pénzügyi\nszolgáltatásokra vonatkozó releváns jogszabályok alapján vezetett dokumentáció\nrészeként meg kell őrizniük a nagy kockázatú MI-rendszereik által\nautomatikusan generált naplókat. (1) A nagy kockázatú MI-rendszerek azon\nszolgáltatóinak, amelyek úgy ítélik meg, vagy okuk van úgy megítélni, hogy az\náltaluk forgalomba hozott vagy üzembe helyezett nagy kockázatú MI-rendszer nem\nfelel meg e rendeletnek, azonnal meg kell hozniuk a szükséges korrekciós\nintézkedéseket az említett rendszer - adott esetben - megfelelőségének\nbiztosítására, forgalomból való kivonására, üzemen kívül helyezésére vagy\nvisszahívására. Ennek megfelelően tájékoztatniuk kell az érintett nagy\nkockázatú MI-rendszer forgalmazóit, valamint adott esetben az alkalmazókat, a\nmeghatalmazott képviselőt és az importőröket. (2) Amennyiben a nagy kockázatú\nMI-rendszer a 79. cikk (1) bekezdése értelmében kockázatot jelent, és ez a\nkockázat a rendszer szolgáltatójának a tudomására jut, a szolgáltatónak\nhaladéktalanul ki kell vizsgálnia az okokat, adott esetben a bejelentést tevő\nalkalmazóval együttműködve, valamint tájékoztatnia kell - különösen a meg nem\nfelelés és a meghozott releváns korrekciós intézkedések jellegéről - az\nérintett nagy kockázatú MI-rendszerért felelős piacfelügyeleti hatóságokat és\nadott esetben azon bejelentett szervezetet, amely az adott nagy kockázatú MI-\nrendszerre a 44. cikknek megfelelően tanúsítványt adott ki. (1) A nagy\nkockázatú MI-rendszerek szolgáltatóinak valamely illetékes hatóság indokolt\nkérésére, az Unió intézményeinek egyik hivatalos, az érintett tagállam által\nmegjelölt és az adott hatóság által könnyen érthető nyelvén át kell adniuk az\nemlített hatóság részére minden olyan információt és dokumentációt, amely\nszükséges annak igazolásához, hogy a nagy kockázatú MI-rendszer megfelel a 2.\nszakaszban meghatározott követelményeknek. (2) Valamely illetékes hatóság\nindokolt kérésére a szolgáltatóknak adott esetben hozzáférést kell\nbiztosítaniuk a megkereső illetékes hatóság számára a 12. cikk (1)\nbekezdésében említett nagy kockázatú MI-rendszer automatikusan generált\nnaplóihoz is, amennyiben ezek a naplók az ellenőrzésük alatt állnak. (3) Az\nilletékes hatóságok által e cikk alapján megszerzett információkat a 78.\ncikkben meghatározott titoktartási kötelezettségeknek megfelelően kell\nkezelni. (1) A nagy kockázatú MI-rendszereiknek az Unió piacán való\nforgalmazását megelőzően a harmadik országokban letelepedett szolgáltatóknak\nírásbeli megbízással ki kell nevezniük egy, az Unióban letelepedett\nmeghatalmazott képviselőt. (2) A szolgáltatónak lehetővé kell tennie a\nmeghatalmazott képviselője számára, hogy elvégezze a szolgáltatótól kapott\nmegbízásban meghatározott feladatokat. (3) A meghatalmazott képviselőknek el\nkell ellátniuk a szolgáltatótól kapott megbízásban meghatározott feladatokat.\nA megbízás egy példányát kérésre a piacfelügyeleti hatóságok rendelkezésére\nkell bocsátaniuk az Unió intézményeinek egyik hivatalos, az illetékes hatóság\náltal megjelölt nyelvén. E rendelet alkalmazása céljából a megbízásban fel\nkell hatalmazni a meghatalmazott képviselőt a következő feladatok elvégzésére:\na) annak ellenőrzése, hogy elkészült-e a 47. cikkben említett EU-megfelelőségi\nnyilatkozat és a 11. cikkben említett műszaki dokumentáció, valamint hogy a\nszolgáltató elvégzett-e egy megfelelő megfelelőségértékelési eljárást; b) a\nnagy kockázatú MI-rendszer forgalomba hozatalát vagy üzembe helyezését követő\ntízéves időtartamra az illetékes hatóságok és a 74. cikk (10) bekezdésében\nemlített nemzeti hatóságok vagy szervek számára a következők elérhetővé\ntétele: azon szolgáltató elérhetőségei, aki vagy amely kinevezte a\nmeghatalmazott képviselőt, a 47. cikkben említett EU-megfelelőségi nyilatkozat\negy példánya, a műszaki dokumentáció és adott esetben a bejelentett szervezet\náltal kiadott tanúsítvány; c) indokolt kérésre az annak igazolásához szükséges\nminden információnak és dokumentációnak - beleértve az ezen albekezdés b)\npontjában említetteket is - az illetékes hatóság rendelkezésére bocsátása,\nhogy a nagy kockázatú MI-rendszer megfelel a 2. szakaszban foglalt\nkövetelményeknek, ideértve a nagy kockázatú MI-rendszer által automatikusan\ngenerált, a 12. cikk (1) bekezdésében említett naplókhoz való hozzáférést is,\namennyiben az ilyen naplók a szolgáltató ellenőrzése alatt állnak; d) indokolt\nkérésre együttműködés az illetékes hatóságokkal a nagy kockázatú MI-\nrendszerrel kapcsolatban - különösen a nagy kockázatú MI-rendszer jelentette\nkockázatok csökkentését és enyhítését illetően - e hatóságok által tett\nbármely intézkedés tekintetében; e) adott esetben a 49. cikk (1) bekezdésében\nemlített nyilvántartásba vételi kötelezettségek teljesítése, vagy - ha a\nnyilvántartásba vételt maga a szolgáltató végzi - a VIII. melléklet A.\nszakaszának 3. pontjában említett információk helyességének biztosítása. A\nmegbízásban fel kell hatalmazni a meghatalmazott képviselőt arra, hogy az\nilletékes hatóságok hozzá forduljanak - a szolgáltató mellett vagy helyett -\naz e rendeletnek való megfelelés biztosításával kapcsolatos minden kérdést\nilletően. (4) A meghatalmazott képviselőnek meg kell szüntetnie a megbízást,\nha úgy ítéli meg, vagy oka van úgy megítélni, hogy a szolgáltató az e rendelet\nszerinti kötelezettségeivel ellentétesen jár el. Ilyen esetben a megbízás\nmegszüntetéséről és annak okairól haladéktalanul tájékoztatnia kell a releváns\npiacfelügyeleti hatóságot és adott esetben a releváns bejelentett szervezetet\nis. (1) Valamely nagy kockázatú MI-rendszer forgalomba hozatala előtt az\nimportőröknek biztosítaniuk kell, hogy a rendszer megfeleljen e rendeletnek a\nkövetkezők ellenőrzésével: a) a nagy kockázatú MI-rendszer szolgáltatója\nelvégezte a 43. cikkben említett releváns megfelelőségértékelési eljárást; b)\na szolgáltató elkészítette a műszaki dokumentációt a 11. cikknek és a IV.\nmellékletnek megfelelően; c) a rendszeren feltüntették az előírt CE-jelölést,\nvalamint mellékelték ahhoz a 47. cikkben említett EU-megfelelőségi\nnyilatkozatot és a használati utasítást; d) a szolgáltató kinevezett egy\nmeghatalmazott képviselőt a 22. cikk (1) bekezdésének megfelelően. (2)\nAmennyiben az importőrnek elegendő oka van úgy megítélni, hogy valamely nagy\nkockázatú MI-rendszer nem felel meg e rendeletnek, vagy azt hamisították, vagy\nhamisított dokumentációval rendelkezik, addig nem hozhatja forgalomba a\nrendszert, amíg annak megfelelőségét nem biztosították. Amennyiben a nagy\nkockázatú MI-rendszer a 79. cikk (1) bekezdése értelmében kockázatot jelent,\naz importőrnek erről tájékoztatnia kell a rendszer szolgáltatóját, a\nmeghatalmazott képviselőket és a piacfelügyeleti hatóságokat. (3) Az\nimportőröknek fel kell tüntetniük a nagy kockázatú MI-rendszeren és annak\ncsomagolásán vagy adott esetben a kísérő dokumentációján a nevüket, bejegyzett\nkereskedelmi nevüket vagy bejegyzett védjegyüket, valamint azon címet, amelyen\nvelük a nagy kockázatú MI-rendszert illetően kapcsolatba lehet lépni. (4) Az\nimportőröknek biztosítaniuk kell, hogy mindaddig, amíg ők felelnek egy nagy\nkockázatú MI-rendszerért, adott esetben a tárolási vagy szállítási feltételek\nne veszélyeztessék a rendszer 2. szakaszban foglalt követelményeknek való\nmegfelelőségét. (5) Az importőröknek a nagy kockázatú MI-rendszer forgalomba\nhozatalát vagy üzembe helyezését követő tízéves időtartamig meg kell őrizniük\na bejelentett szervezet által kiállított tanúsítvány, adott esetben a\nhasználati utasítás és a 47. cikkben említett EU-megfelelőségi nyilatkozat\negy-egy példányát. (6) Az importőröknek indokolt kérésre a releváns illetékes\nhatóságok rendelkezésére kell bocsátaniuk minden, annak igazolásához szükséges\ninformációt és dokumentációt - ideértve az (5) bekezdésben említetteket is -,\nhogy a nagy kockázatú MI-rendszer megfelel a 2. szakaszban foglalt\nkövetelményeknek, az adott illetékes nemzeti hatóság számára könnyen érthető\nnyelven. E célból az importőröknek biztosítaniuk kell azt is, hogy a műszaki\ndokumentációt az említett hatóságok rendelkezésére lehessen bocsátani. (7) Az\nimportőröknek együtt kell működniük a releváns illetékes nemzeti hatóságokkal\nminden olyan intézkedés tekintetében, amelyet az említett hatóságok hoznak egy\nolyan nagy kockázatú MI-rendszerrel kapcsolatban - különösen az általa\njelentett kockázatok csökkentése és enyhítése érdekében -, amelyet az\nimportőrök hoztak forgalomba. (1) Valamely nagy kockázatú MI-rendszer\nforgalmazását megelőzően a forgalmazóknak ellenőrizniük kell, hogy a nagy\nkockázatú MI-rendszeren fel van-e tüntetve az előírt CE- jelölés,\nmellékelték-e ahhoz a 47. cikkben említett EU-megfelelőségi nyilatkozat egy\npéldányát és a használati utasítást, valamint hogy az említett rendszer\nszolgáltatója, illetve - adott esetben - importőre teljesítette-e a 16. cikk\nb) és c) pontjában, illetve a 23. cikk (3) bekezdésében foglalt\nkötelezettségeit. (2) Amennyiben a forgalmazó a birtokában lévő információk\nalapján úgy ítéli meg, vagy oka van úgy megítélni, hogy egy nagy kockázatú MI-\nrendszer nem felel meg a 2. szakaszban meghatározott követelményeknek, nem\nforgalmazhatja a nagy kockázatú MI-rendszert mindaddig, amíg a rendszert nem\nhozták összhangba az említett követelményekkel. Továbbá, amennyiben a nagy\nkockázatú MI-rendszer a 79. cikk (1) bekezdése értelmében kockázatot jelent, a\nforgalmazónak erről tájékoztatnia kell a rendszer szolgáltatóját vagy adott\nesetben importőrét. (3) A forgalmazóknak biztosítaniuk kell, hogy mindaddig,\namíg ők felelnek a nagy kockázatú MI-rendszerért, adott esetben a tárolási\nvagy szállítási feltételek ne veszélyeztessék a rendszer 2. szakaszban foglalt\nkövetelményeknek való megfelelőségét. (4) Azon forgalmazónak, amely a\nbirtokában lévő információk alapján úgy ítéli meg, vagy oka van úgy megítélni,\nhogy az általa forgalmazott nagy kockázatú MI-rendszer nem felel meg a 2.\nszakaszban foglalt követelményeknek, meg kell tennie a szükséges korrekciós\nintézkedéseket ahhoz, hogy a rendszert összhangba hozza az említett\nkövetelményekkel, kivonja a forgalomból vagy visszahívja, vagy biztosítania\nkell, hogy a szolgáltató, az importőr vagy adott esetben bármely érintett\nüzemeltető megtegye az említett korrekciós intézkedéseket. Amennyiben a nagy\nkockázatú MI-rendszer a 79. cikk (1) bekezdése értelmében kockázatot jelent, a\nforgalmazónak erről haladéktalanul tájékoztatnia kell a rendszer\nszolgáltatóját vagy importőrét, és az érintett nagy kockázatú MI-rendszerért\nfelelős hatóságokat, részletezve különösen a meg nem felelést és a meghozott\nkorrekciós intézkedéseket. (5) Valamely releváns illetékes nemzeti hatóság\nindokolt kérésére a nagy kockázatú MI-rendszerek forgalmazóinak az említett\nhatóság rendelkezésére kell bocsátaniuk az (1)-(4) bekezdés szerinti\ntevékenységeikre vonatkozó valamennyi olyan információt és dokumentációt,\namely szükséges annak igazolásához, hogy az említett rendszer megfelel a 2.\nszakaszban meghatározott követelményeknek. (6) A forgalmazóknak együtt kell\nműködniük a releváns illetékes hatóságokkal minden olyan intézkedés\ntekintetében, amelyet az említett hatóságok hoznak egy olyan nagy kockázatú\nMI-rendszerrel kapcsolatban - különösen az általa jelentett kockázat\ncsökkentése vagy enyhítése érdekében -, amelyet a forgalmazók forgalmaznak.\n(1) E rendelet alkalmazásában minden forgalmazót, importőrt, alkalmazót vagy\negyéb harmadik felet nagy kockázatú MI-rendszer szolgáltatójának kell\ntekinteni, és arra a szolgáltatónak a 16. cikk szerinti kötelezettségei\nvonatkoznak a következő körülmények bármelyikének esetében: a) nevüket vagy\nvédjegyüket egy már forgalomba hozott vagy üzembe helyezett, nagy kockázatú\nMI-rendszeren helyezik el, olyan szerződéses megállapodások sérelme nélkül,\namelyek a kötelezettségek másképp történő megosztását írják elő; b) jelentős\nmódosítást hajtanak végre egy már forgalomba hozott vagy már üzembe helyezett\nnagy kockázatú MI-rendszeren oly módon, hogy az a 6. cikkel összhangban\ntovábbra is nagy kockázatú MI-rendszer marad; c) jelentősen módosítják egy\nolyan MI-rendszer rendeltetését, beleértve az általános célú MI-rendszereket\nis, amelyet nem minősítettek nagy kockázatúnak, és amelyet már forgalomba\nhoztak vagy üzembe helyeztek, oly módon, hogy az érintett MI-rendszer a 6.\ncikkel összhangban nagy kockázatú MI-rendszerré válik; (2) Amennyiben az (1)\nbekezdésben említett körülmények fennállnak, az MI-rendszert eredetileg\nforgalomba hozó vagy üzembe helyező szolgáltató e rendelet alkalmazása\ncéljából többé nem tekinthető az adott konkrét MI-rendszer szolgáltatójának.\nAz említett eredeti szolgáltatónak szorosan együtt kell működnie az új\nszolgáltatókkal, és rendelkezésre kell bocsátania a szükséges információkat,\nvalamint biztosítania kell az e rendeletben meghatározott kötelezettségek\nteljesítéséhez szükséges, észszerűen elvárható technikai hozzáférést és egyéb\nsegítséget, különösen a nagy kockázatú MI-rendszerek megfelelőségértékelésének\nvaló megfelelés tekintetében. E bekezdés nem alkalmazandó azokban az\nesetekben, amikor az eredeti szolgáltató egyértelműen meghatározta, hogy MI-\nrendszerét nem szabad nagy kockázatú MI-rendszerré alakítani, és ezért az\nilyen esetek nem tartoznak a dokumentáció átadására vonatkozó kötelezettség\nhatálya alá. (3) Az olyan nagy kockázatú MI-rendszerek esetében, amelyek az I.\nmelléklet A. szakaszában felsorolt uniós harmonizációs jogszabályok hatálya\nalá tartozó termékek biztonsági alkotórészei, a termék gyártóját kell a nagy\nkockázatú MI-rendszer szolgáltatójának tekinteni, és annak a 16. cikk szerinti\nkötelezettségek hatálya alá kell tartoznia a következő körülmények közül\nbármelyik esetében: a) a nagy kockázatú MI-rendszert a termékkel együtt, a\ntermék gyártójának neve vagy védjegye alatt hozzák forgalomba; b) a nagy\nkockázatú MI-rendszert a termék gyártójának neve vagy védjegye alatt helyezik\nüzembe a termék forgalomba hozatalát követően. (4) A nagy kockázatú MI-\nrendszer szolgáltatójának és a nagy kockázatú MI-rendszerben használt vagy\nabba integrált eszközöket, szolgáltatásokat, alkotóelemeket vagy folyamatokat\nszállító harmadik félnek írásbeli megállapodás révén, a technika általánosan\nelismert, mindenkori állása alapján meg kell határoznia a szükséges\ninformációkat, képességeket, technikai hozzáférést és egyéb segítséget, annak\nérdekében, hogy a nagy kockázatú MI-rendszer szolgáltatója teljes mértékben\neleget tudjon tenni az e rendeletben foglalt kötelezettségeknek. Ez a bekezdés\nnem alkalmazandó azon harmadik felekre, akik az általános célú MI-modellektől\neltérő eszközöket, szolgáltatásokat, folyamatokat vagy alkotóelemeket szabad\nés nyílt forráskódú licenc alapján tesznek nyilvánosan hozzáférhetővé. Az MI-\nhivatal önkéntes mintafeltételeket dolgozhat ki és ajánlhat a nagy kockázatú\nMI-rendszerek szolgáltatói és a nagy kockázatú MI-rendszerekhez használt vagy\nazokba integrált eszközöket, szolgáltatásokat, alkotóelemeket vagy\nfolyamatokat szolgáltató harmadik felek közötti szerződésekre vonatkozóan. Az\nemlített önkéntes mintafeltételek kidolgozása során az MI-hivatalnak\nfigyelembe kell vennie az egyes ágazatokban vagy konkrét üzleti esetekben\nalkalmazandó lehetséges szerződéses követelményeket. Az önkéntes\nmintafeltételeket könnyen használható elektronikus formátumban közzé kell\ntenni és díjmentesen elérhetővé kell tenni. (5) A (2) és a (3) bekezdés nem\nsérti azt, hogy a szellemitulajdon-jogokat, a bizalmas üzleti információkat és\naz üzleti titkokat az uniós és a nemzeti joggal összhangban tiszteletben kell\ntartani és védeni kell. (1) A nagy kockázatú MI-rendszerek alkalmazóinak\nmegfelelő technikai és szervezési intézkedéseket kell tenniük annak\nbiztosítására, hogy ezeket a rendszereket a (3) és (6) bekezdés szerint, a\nrendszerekhez mellékelt használati utasításoknak megfelelően használják. (2)\nAz alkalmazóknak az emberi felügyeletet olyan természetes személyekre kell\nbízniuk, akik rendelkeznek a szükséges szakértelemmel, képzéssel és\nhatáskörrel, valamint a szükséges támogatással. (3) Az (1) és a (2)\nbekezdésben meghatározott kötelezettségek nem sértik az uniós vagy nemzeti jog\nszerinti egyéb alkalmazói kötelezettségeket, valamint az alkalmazó azon\nszabadságát, hogy a szolgáltató által megjelölt emberi felügyeleti\nintézkedések végrehajtása céljából megszervezze saját erőforrásait és\ntevékenységeit. (4) Az (1) és a (2) bekezdés sérelme nélkül, amennyiben az\nalkalmazó ellenőrzést gyakorol a bemeneti adatok felett, ezen alkalmazónak\nbiztosítania kell, hogy a bemeneti adatok relevánsak és kellően\nreprezentatívak legyenek a nagy kockázatú MI-rendszer rendeltetése\nszempontjából. (5) Az alkalmazóknak a használati utasítások alapján nyomon\nkell követniük a nagy kockázatú MI-rendszer működését, és adott esetben a 72.\ncikknek megfelelően tájékoztatniuk kell a szolgáltatót. Amennyiben az\nalkalmazóknak okuk van úgy megítélni, hogy a nagy kockázatú MI-rendszer\nutasításoknak megfelelő használata azt eredményezheti, hogy az említett MI-\nrendszer a 79. cikk (1) bekezdésének értelmében vett kockázatot jelent, erről\nindokolatlan késedelem nélkül tájékoztatniuk kell a szolgáltatót vagy a\nforgalmazót, valamint a releváns piacfelügyeleti hatóságot, és fel kell\nfüggeszteniük az említett rendszer használatát. Amennyiben az alkalmazók\nsúlyos váratlan eseményt azonosítottak, haladéktalanul tájékoztatniuk kell\nelőször a szolgáltatót, majd az importőrt vagy a forgalmazót és a releváns\npiacfelügyeleti hatóságokat is az említett eseményről. Ha az alkalmazó nem\ntudja elérni a szolgáltatót, a 73. cikket kell értelemszerűen alkalmazni. Ez a\nkötelezettség nem terjed ki az MI-rendszerek azon alkalmazóinak érzékeny\noperatív adataira, amelyek bűnüldöző hatóságok. Azon alkalmazók esetében,\namelyek a pénzügyi szolgáltatásokra vonatkozó uniós jog értelmében a belső\nirányításukra, szabályaikra vagy eljárásaikra vonatkozó követelmények hatálya\nalá tartozó pénzügyi intézmények, az első albekezdésben meghatározott\nnyomonkövetési kötelezettséget a pénzügyi szolgáltatásokra vonatkozó releváns\njog szerinti, a belső irányítási rendszerekre, eljárásokra és mechanizmusokra\nvonatkozó szabályoknak való megfeleléssel teljesítettnek kell tekinteni. (6) A\nnagy kockázatú MI-rendszerek alkalmazóinak meg kell őrizniük az adott nagy\nkockázatú MI-rendszer által automatikusan generált naplókat, amennyiben az\nilyen naplók az ellenőrzésük alatt állnak a nagy kockázatú MI-rendszer\nrendeltetésének megfelelő - legalább hat hónapos - időtartamig, kivéve, ha az\nalkalmazandó uniós vagy nemzeti jog, különösen a személyes adatok védelmére\nvonatkozó uniós jog másként rendelkezik. Azon alkalmazóknak, amelyek a\npénzügyi szolgáltatásokra vonatkozó uniós jog értelmében a belső\nirányításukra, szabályaikra vagy eljárásaikra vonatkozó követelmények hatálya\nalá tartozó pénzügyi intézmények, a naplót a pénzügyi szolgáltatásokra\nvonatkozó megfelelő uniós jog alapján vezetett dokumentáció részeként kell\nmegőrizniük. (7) A nagy kockázatú MI-rendszer munkahelyi üzembe helyezése vagy\nhasználata előtt azon alkalmazóknak, akik munkáltatók, tájékoztatniuk kell a\nmunkavállalók képviselőit és az érintett munkavállalókat arról, hogy esetükben\nnagy kockázatú MI-rendszer használatára fog sor kerülni. Ezt a tájékoztatást\nadott esetben a munkavállalók és képviselőik tájékoztatására vonatkozó uniós\nés nemzeti jogban és gyakorlatban megállapított szabályokkal és eljárásokkal\nösszhangban kell megadni. (8) A nagy kockázatú MI-rendszerek alkalmazói,\namennyiben azok hatóságok vagy uniós intézmények, szervek, hivatalok vagy\nügynökségek, eleget tesznek a 49. cikkben említett nyilvántartási\nkötelezettségeknek. Amennyiben az ilyen alkalmazók megállapítják, hogy az\náltaluk használni kívánt nagy kockázatú MI-rendszer nincs nyilvántartva a 71.\ncikkben említett uniós adatbázisban, nem használhatják az adott rendszert, és\nerről tájékoztatják a szolgáltatót vagy a forgalmazót. (9) A nagy kockázatú\nMI-rendszerek alkalmazóinak az e rendelet 13. cikke szerint megadott\ninformációkat - adott esetben - arra kell használniuk, hogy eleget tegyenek az\n(EU) 2016/679 rendelet 35. cikke vagy adott esetben az (EU) 2016/680 irányelv\n27. cikke szerinti, adatvédelmi hatásvizsgálat elvégzésére vonatkozó\nkötelezettségüknek. (10) Az (EU) 2016/680 irányelv sérelme nélkül, a\nbűncselekmény elkövetésével gyanúsított vagy a miatt elítélt személyek célzott\nfelkutatására irányuló nyomozás keretében a nem valós idejű távoli biometrikus\nazonosításra szolgáló, nagy kockázatú MI-rendszert alkalmazó személynek\nelőzetesen vagy indokolatlan késedelem nélkül, de legkésőbb 48 órán belül\nengedélyt kell kérnie az adott rendszer használatára valamely igazságügyi\nhatóságtól vagy közigazgatási hatóságtól, amelynek határozata kötelező erejű\nés bírósági felülvizsgálat tárgyát képezi, kivéve, ha azt egy potenciális\ngyanúsítottnak a bűncselekményhez közvetlenül kapcsolódó objektív és\nellenőrizhető tényeken alapuló kezdeti azonosítására használják. Minden\nfelhasználásnak az adott bűncselekmény nyomozásához feltétlenül szükséges\nmértékre kell korlátozódnia. Ha az első albekezdés szerint kérelmezett\nengedélyt elutasítják, a kért engedélyhez kapcsolódó, nem valós idejű távoli\nbiometrikus azonosító rendszer használatát azonnali hatállyal le kell\nállítani, és törölni kell az azon nagy kockázatú MI-rendszer használatához\nkapcsolódó személyes adatokat, amelyre az engedélyt kérték. Az ilyen, nem\nvalós idejű távoli biometrikus azonosításra szolgáló, nagy kockázatú MI-\nrendszert semmilyen esetben sem szabad nem célzott módon bűnüldözési célokra\nhasználni bűncselekményhez, büntetőeljáráshoz, bűncselekmény tényleges és\nvalós vagy előre látható veszélyéhez vagy egy konkrét eltűnt személy\nfelkutatásához való kapcsolódás nélkül. Biztosítani kell, hogy a bűnüldöző\nhatóságok ne hozhassanak kizárólag a nem valós idejű távoli biometrikus\nazonosító rendszer által adott eredmény alapján olyan döntést, amely egy\nszemélyre nézve kedvezőtlen joghatással jár. Ez a bekezdés nem sérti az (EU)\n2016/679 rendelet 9. cikkét és az (EU) 2016/680 irányelv 10. cikkét a\nbiometrikus adatok feldolgozása tekintetében. Az ilyen, nagy kockázatú MI-\nrendszerek minden egyes használatát a vonatkozó rendőrségi nyilvántartásban -\na célra vagy az alkalmazóra való tekintet nélkül - dokumentálni kell, és\nkérésre az érintett piacfelügyeleti hatóság és a nemzeti adatvédelmi hatóság\nrendelkezésére kell bocsátani, kivéve a bűnüldözéssel kapcsolatos érzékeny\noperatív adatok közzétételét. Ez az albekezdés nem sérti az (EU) 2016/680\nirányelv által a felügyeleti hatóságokra ruházott hatásköröket. Az\nalkalmazóknak éves jelentéseket kell benyújtaniuk az érintett piacfelügyeleti\nés nemzeti adatvédelmi hatóságok számára a nem valós idejű távoli biometrikus\nazonosító rendszerek általuk történő használatáról, kivéve a bűnüldözéssel\nkapcsolatos érzékeny operatív adatok közzétételét. A jelentések összevonhatók\núgy, hogy azok egynél többszöri alkalmazásra is kiterjedjenek. A tagállamok az\nuniós joggal összhangban szigorúbb jogszabályokat is bevezethetnek a nem valós\nidejű távoli biometrikus azonosító rendszerek használatára vonatkozóan. (11) E\nrendelet 50. cikkének sérelme nélkül, a III. mellékletben említett,\ntermészetes személyekkel kapcsolatos döntéseket hozó vagy az ilyen döntések\nmeghozatalában segítséget nyújtó, nagy kockázatú MI-rendszerek alkalmazóinak\ntájékoztatniuk kell a természetes személyeket arról, hogy esetükben nagy\nkockázatú MI-rendszert használnak. A bűnüldözési célokra használt nagy\nkockázatú MI-rendszerek esetében alkalmazni kell az (EU) 2016/680 irányelv 13.\ncikkét. (12) Az alkalmazóknak együtt kell működniük a releváns illetékes\nhatóságokkal a nagy kockázatú MI-rendszerrel kapcsolatos minden olyan\nintézkedés tekintetében, amelyeket a hatóságok e rendelet végrehajtása\nérdekében hoznak. (1) A 6. cikk (2) bekezdésében említett nagy kockázatú MI-\nrendszer bevezetését megelőzően - a III. melléklet 2. pontjában felsorolt\nterületen való használatra szánt nagy kockázatú MI-rendszerek kivételével -\nazon alkalmazóknak, amelyek közjogi szervek vagy közszolgáltatásokat nyújtó\nmagánszervezetek, valamint a III. melléklet 5. pontjának b) és c) alpontjában\nemlített nagy kockázatú MI-rendszerek alkalmazóinak értékelniük kell azon\nhatást, amelyet az ilyen rendszerek használata az alapvető jogokra\ngyakorolhat. E célból az alkalmazóknak értékelést kell végezniük, amely a\nkövetkezőkből áll: a) az alkalmazó azon folyamatainak leírása, amelyekben a\nnagy kockázatú MI-rendszert a rendeltetésének megfelelően fogják használni; b)\nazon időszak és gyakoriság leírása, amelyen belül és amellyel az egyes nagy\nkockázatú MI-rendszereket használni szándékoznak; c) a természetes személyek\nés csoportok azon kategóriái, akiket a rendszer használata az adott\nkontextusban valószínűleg érint; d) az e bekezdés c) pontja alapján\nazonosított természetes személyek vagy személycsoportok kategóriáira\nvalószínűleg hatást gyakorló konkrét kárkockázatok, figyelembe véve a\nszolgáltató által a 13. cikk szerint nyújtott információkat; e) az emberi\nfelügyeleti intézkedések végrehajtásának leírása, a használati utasításnak\nmegfelelően; f) az említett kockázatok bekövetkezése esetén meghozandó\nintézkedések, ideértve a belső irányítási és panasztételi mechanizmusokra\nvonatkozó szabályokat. (2) Az (1) bekezdésben megállapított kötelezettség a\nnagy kockázatú MI-rendszer első használatára vonatkozik. Az alkalmazó hasonló\nesetekben támaszkodhat a korábban elvégzett alapjogi hatásvizsgálatokra vagy a\nszolgáltatók által már elvégzett, meglévő hatásvizsgálatokra. Amennyiben a\nnagy kockázatú MI-rendszer használata során az alkalmazó úgy ítéli meg, hogy\naz (1) bekezdésben felsorolt elemek bármelyike megváltozott vagy már nem\nnaprakész, az alkalmazónak meg kell tennie a szükséges lépéseket az\ninformációk aktualizálására. (3) Az e cikk (1) bekezdésében említett értékelés\nelvégzését követően az alkalmazónak értesítenie kell a piacfelügyeleti\nhatóságot annak eredményeiről, az értesítés részeként benyújtva az e cikk (5)\nbekezdésében említett kitöltött kérdőívmintát is. A 46. cikk (1) bekezdésében\nemlített esetben az alkalmazók mentesíthetők ezen értesítési kötelezettség\nalól. (4) Ha az (EU) 2016/679 rendelet 35. cikke vagy az (EU) 2016/680\nirányelv 27. cikke alapján elvégzett adatvédelmi hatásvizsgálat révén már\nmegfeleltek az e cikkben megállapított kötelezettségek bármelyikének, az e\ncikk (1) bekezdésében említett alapvetőjogi hatásvizsgálatnak ki kell\negészítenie az említett adatvédelmi hatásvizsgálatot. (5) Az MI-hivatal -\ntöbbek között egy automatizált eszköz révén - kérdőívmintát dolgoz ki, hogy\nmegkönnyítse az alkalmazók számára az e cikk szerinti kötelezettségeiknek\negyszerűsített módon való megfelelést. (1) Minden tagállam kijelöl vagy\nlétrehoz legalább egy bejelentő hatóságot, amely a megfelelőségértékelő\nszervezetek értékeléséhez, kijelöléséhez és bejelentéséhez, valamint nyomon\nkövetéséhez szükséges eljárások kialakításáért és végrehajtásáért felel. Az\nemlített eljárásokat valamennyi tagállam bejelentő hatóságainak\negyüttműködésével kell kidolgozni. (2) A tagállamok dönthetnek úgy, hogy az\n(1) bekezdésben említett értékelést és nyomon követést egy, a 765/2008/EK\nrendelet szerinti nemzeti akkreditáló testület végzi el az említett rendelet\nrendelkezéseivel összhangban. (3) A bejelentő hatóságokat úgy kell létrehozni,\nmegszervezni és működtetni, hogy ne merülhessen fel összeférhetetlenség a\nmegfelelőségértékelő szervezetekkel, továbbá hogy tevékenységük objektivitása\nés pártatlansága biztosított legyen. (4) A bejelentő hatóságokat úgy kell\nmegszervezni, hogy a megfelelőségértékelő szervezet bejelentésével kapcsolatos\ndöntéseket az adott szervezet értékelését végzőktől eltérő illetékes személyek\nhozzák meg. (5) A bejelentő hatóságok kereskedelmi vagy piaci alapon nem\nkínálhatnak vagy végezhetnek sem olyan tevékenységet, amelyet\nmegfelelőségértékelő szervezetek végeznek, sem szaktanácsadási szolgáltatást.\n(6) A bejelentő hatóságoknak a 78. cikkel összhangban meg kell őrizniük az\náltaluk kapott információk bizalmas jellegét. (7) A bejelentő hatóságoknak\nmegfelelő létszámú hozzáértő személyzettel kell rendelkezniük ahhoz, hogy\nmegfelelően elláthassák feladataikat. A hozzáértő személyzetnek adott esetben\nrendelkeznie kell a feladatai ellátásához szükséges szakértelemmel olyan\nterületeken, mint az információtechnológiák, a mesterséges intelligencia és a\njog, beleértve az alapvető jogok felügyeletét is. (1) A megfelelőségértékelő\nszervezetnek bejelentés iránti kérelmet kell benyújtania a letelepedési helye\nszerinti tagállam bejelentő hatóságához. (2) A bejelentés iránti kérelemhez\ncsatolnia kell azon megfelelőségértékelési tevékenységek,\nmegfelelőségértékelési modul vagy modulok és MI-rendszertípusok leírását,\namelyek tekintetében a megfelelőségértékelő szervezet szakmailag alkalmasnak\ntekinti magát, továbbá - amennyiben van ilyen - a nemzeti akkreditáló testület\náltal kiállított akkreditálási okiratot, amely tanúsítja, hogy a\nmegfelelőségértékelő szervezet teljesíti a 31. cikkben megállapított\nkövetelményeket. Csatolni kell minden érvényes, a kérelmező bejelentett\nszervezet bármely egyéb uniós harmonizációs jogszabály szerinti, meglévő\nkijelöléseivel kapcsolatos dokumentumot. (3) Amennyiben az érintett\nmegfelelőségértékelő szervezet nem tud akkreditálási okiratot benyújtani, be\nkell nyújtania a bejelentő hatóság számára a 31. cikkben megállapított\nkövetelményeknek való megfelelésének ellenőrzéséhez, elismeréséhez és\nrendszeres nyomon követéséhez szükséges valamennyi igazoló okmányt. (4) A\nbármely egyéb uniós harmonizációs jogszabály alapján kijelölt bejelentett\nszervezetek esetében az említett kijelölésekhez kapcsolódó valamennyi\ndokumentum és tanúsítvány felhasználható adott esetben az e rendelet szerinti\nkijelölésükre irányuló eljárás alátámasztására. A bejelentett szervezet az e\ncikk (2) és (3) bekezdésében említett dokumentációt minden releváns változás\nesetén naprakésszé teszi annak érdekében, hogy lehetővé tegye a bejelentett\nszervezetekért felelős hatóság számára a 31. cikkben megállapított valamennyi\nkövetelménynek való folyamatos megfelelés nyomon követését és ellenőrzését.\n(1) A bejelentő hatóságok csak olyan megfelelőségértékelő szervezeteket\njelenthetnek be, amelyek megfelelnek a 31. cikkben megállapított\nkövetelményeknek. (2) A bejelentő hatóságok a Bizottság által kifejlesztett és\nkezelt elektronikus bejelentési eszköz alkalmazásával értesítik a Bizottságot\nés a többi tagállamot az (1) bekezdésben említett minden egyes\nmegfelelőségértékelő szervezetről. (3) Az e cikk (2) bekezdésében említett\nbejelentésnek tartalmaznia kell részletes információkat a\nmegfelelőségértékelési tevékenységekről, a megfelelőségértékelési modulról\nvagy modulokról, az érintett MI-rendszerek típusairól, valamint a szakmai\nalkalmasság releváns igazolását. Amennyiben a bejelentés nem a 29. cikk (2)\nbekezdésében említett akkreditálási okiraton alapul, a bejelentő hatóságnak\nrendelkezésre kell bocsátania a Bizottság és a többi tagállam számára a\nmegfelelőségértékelő szervezet alkalmasságát és azon meglévő intézkedéseket\nigazoló dokumentumokat, amelyeknek biztosítják, hogy az említett szervezetet\nrendszeresen nyomon fogják követni, és azt, hogy az továbbra is meg fog\nfelelni a 31. cikkben megállapított követelményeknek. (4) Az érintett\nmegfelelőségértékelő szervezet csak akkor végezheti egy bejelentett szervezet\ntevékenységeit, ha a Bizottság és a többi tagállam nem emel kifogást a\nbejelentő hatóság általi bejelentést követő két héten belül, amennyiben a\nbejelentés a 29. cikk (2) bekezdése szerinti akkreditálási okiratot tartalmaz,\nvagy a bejelentő hatóság általi bejelentést követő két hónapon belül,\namennyiben a bejelentés a 29. cikk (3) bekezdése szerinti igazoló dokumentumot\ntartalmaz. (5) Amennyiben kifogást emelnek, a Bizottság haladéktalanul\nkonzultációkat kezdeményez a releváns tagállamokkal és a megfelelőségértékelő\nszervvel. Erre figyelemmel a Bizottság dönt arról, hogy az engedély\nindokolt-e. A Bizottság döntését az érintett tagállamnak és a releváns\nmegfelelőségértékelő szervnek címezi. (1) A bejelentett szervezeteket a\ntagállamok nemzeti joga alapján kell létrehozni, és azoknak jogi\nszemélyiséggel kell rendelkezniük. (2) A bejelentett szervezeteknek eleget\nkell tenniük azoknak a szervezeti, minőségirányítási, erőforrásokra vonatkozó\nés eljárási követelményeknek, amelyek a feladataik ellátásához szükségesek,\nvalamint megfelelő kiberbiztonsági követelményeket kell teljesíteniük. (3) A\nbejelentett szervezetek szervezeti felépítésének, a szervezeten belül a\nfelelősségi körök kijelölésének, a jelentési útvonalaknak és a bejelentett\nszervezetek működésének biztosítania kell a bejelentett szervezet által\nvégzett megfelelőségértékelési tevékenységek elvégzése és az e tevékenységek\neredményei iránti bizalmat. (4) A bejelentett szervezeteknek függetlennek kell\nlenniük azon nagy kockázatú MI-rendszer szolgáltatójától, amellyel\nkapcsolatban megfelelőségértékelési tevékenységeket végeznek. A bejelentett\nszervezeteknek továbbá függetlennek kell lenniük az értékelés tárgyát képező\nnagy kockázatú MI-rendszerben gazdasági érdekeltséggel rendelkező bármely\negyéb üzemeltetőtől, valamint a szolgáltató versenytársaitól is. Ez nem\nzárhatja ki az olyan értékelt nagy kockázatú MI-rendszerek használatát,\namelyek a megfelelőségértékelő szervezet működéséhez szükségesek, illetve az\nilyen nagy kockázatú MI-rendszerek személyes célra történő használatát. (5)\nSem a megfelelőségértékelő szervezet, sem annak felső szintű vezetése, sem a\nmegfelelőségértékelési feladatok elvégzéséért felelős személyzete nem vehet\nrészt közvetlenül a nagy kockázatú MI-rendszerek tervezésében, fejlesztésében,\nforgalmazásában vagy használatában, és nem képviselhetik az ilyen\ntevékenységekben részt vevő feleket sem. Nem folytathatnak olyan\ntevékenységet, amely ellentétes lehet a bejelentett megfelelőségértékelési\ntevékenységekkel kapcsolatos döntéshozói függetlenségükkel vagy\nfeddhetetlenségükkel. Ez különösen érvényes a szaktanácsadási\nszolgáltatásokra. (6) A bejelentett szervezetet úgy kell megszervezni és\nműködtetni, hogy tevékenységeinek függetlensége, objektivitása és\npártatlansága biztosított legyen. A bejelentett szervezeteknek olyan\nstruktúrát és eljárásokat kell dokumentálniuk és alkalmazniuk, amelyek a\nszervezetük, a személyzetük és az értékelési tevékenységeik egészében\nbiztosítják a pártatlanság megőrzését, valamint a pártatlanság elveinek az\nelőmozdítását és alkalmazását. (7) A bejelentett szervezeteknek dokumentált\neljárásokkal kell rendelkezniük, amelyek biztosítják, hogy a személyzetük, a\nbizottságaik, a leányvállalataik, az alvállalkozóik és bármely velük\nkapcsolatban álló szervezet vagy külső szervezetek munkavállalói - a 78.\ncikknek megfelelően - tiszteletben tartsák azon információk bizalmasságát,\namelyek a megfelelőségértékelési tevékenységek végzése során a birtokukba\nkerülnek, kivéve, ha azok közzétételét jogszabály írja elő. A bejelentett\nszervezetek személyzetének be kell tartania a szakmai titoktartás\nkövetelményeit minden olyan információ tekintetében, amely az e rendeletben\nfoglalt feladataik végrehajtása során jutott a birtokába, kivéve annak a\ntagállamnak a bejelentő hatóságaival szemben, ahol a bejelentett szervezetek\ntevékenységüket végzik. (8) A bejelentett szervezeteknek a tevékenységek\nellátásához olyan eljárásokkal kell rendelkezniük, amelyek kellően figyelembe\nveszik a szolgáltató méretét, azon ágazatot, amelyben az működik, annak\nszerkezetét és az érintett MI-rendszer összetettségi fokát. (9) A bejelentett\nszervezeteknek megfelelőségértékelési tevékenységeikre megfelelő\nfelelősségbiztosítást kell kötniük, kivéve, ha a felelősséget a nemzeti jognak\nmegfelelően az a tagállam vállalja, amelyben a bejelentett szervezet\nletelepedett, vagy ha az említett tagállam közvetlenül maga felelős a\nmegfelelőségértékelésért. (10) A bejelentett szervezeteknek képesnek kell\nlenniük az e rendelet szerinti valamennyi feladatukat a legmagasabb fokú\nszakmai feddhetetlenséggel és a konkrét területen megkövetelt alkalmassággal\nvégezni, függetlenül attól, hogy az említett feladatokat a bejelentett\nszervezetek maguk végzik-e, vagy az ő nevükben és felelősségi körükben eljárva\nmások végzik-e. (11) A bejelentett szervezeteknek elegendő belső\nszakértelemmel kell rendelkezniük ahhoz, hogy hatékonyan értékelni tudják a\nkülső felek által a nevükben elvégzett feladatokat. A bejelentett szervezetnek\nállandó jelleggel elegendő olyan adminisztratív, műszaki, jogi és tudományos\nmunkatárssal kell rendelkeznie, akik tapasztalattal és ismeretekkel\nrendelkeznek a vonatkozó MI-rendszertípusokkal, adatokkal és adatszámítással,\nvalamint a 2. szakaszban foglalt követelményekkel kapcsolatban. (12) A\nbejelentett szervezeteknek részt kell venniük a 38. cikkben említett\nkoordinációs tevékenységekben. Emellett közvetlenül részt kell venniük vagy\nképviseltetni kell magukat az európai szabványügyi szervezetekben, vagy\ngondoskodniuk kell arról, hogy tisztában legyenek a vonatkozó szabványokkal,\nés naprakész ismeretekkel rendelkezzenek ezekről. Amennyiben valamely\nmegfelelőségértékelő szervezet igazolja, hogy megfelel az olyan vonatkozó\nharmonizált szabványokban vagy azok részeiben rögzített kritériumoknak,\namelyek hivatkozásait közzétették az Európai Unió Hivatalos Lapjában,\nvélelmezni kell, hogy megfelel a 31. cikkben foglalt követelményeknek,\namennyiben az alkalmazandó harmonizált szabványok kiterjednek az említett\nkövetelményekre. (1) Amennyiben valamely bejelentett szervezet\nmegfelelőségértékeléssel kapcsolatos, konkrét feladatokat alvállalkozásba ad,\nvagy leányvállalatot bíz meg elvégzésükkel, biztosítania kell, hogy az\nalvállalkozó vagy a leányvállalat megfeleljen a 31. cikkben megállapított\nkövetelményeknek, és ennek megfelelően tájékoztatnia kell erről a bejelentő\nhatóságot. (2) A bejelentett szervezeteknek teljes felelősséget kell\nvállalniuk a bármely alvállalkozó vagy leányvállalat által elvégzett\nfeladatokért. (3) A tevékenységeket csak a szolgáltató beleegyezésével lehet\nalvállalkozásba adni vagy leányvállalattal elvégeztetni. A bejelentett\nszervezeteknek nyilvánosan hozzáférhetővé kell tenniük leányvállalataik\njegyzékét. (4) Az alvállalkozó vagy a leányvállalat képesítésének értékelésére\nés az általuk e rendelet alapján elvégzett munkára vonatkozó releváns\ndokumentumokat az alvállalkozói tevékenység megszüntetésének időpontjától\nszámított öt évig a bejelentő hatóság számára elérhetővé kell tenni. (1) A\nbejelentett szervezeteknek a 43. cikkben meghatározott megfelelőségértékelési\neljárásokkal összhangban ellenőrizniük kell a nagy kockázatú MI-rendszerek\nmegfelelőségét. (2) A bejelentett szervezeteknek tevékenységeik végzése során\nel kell kerülniük, hogy szükségtelen terheket rójanak a szolgáltatókra, és\nkellően figyelembe kell venniük a szolgáltató méretét, az ágazatot, amelyben\nműködik, a szolgáltató szerkezetét és az érintett nagy kockázatú MI-rendszer\nösszetettségi fokát, különösen a 2003/361/EK ajánlás értelmében vett mikro- és\nkisvállalkozások adminisztratív terheinek és megfelelési költségeinek\nminimalizálására tekintettel. A bejelentett szervezetnek mindazonáltal\ntiszteletben kell tartania az ahhoz szükséges szigorúság mértékét és védelem\nszintjét, hogy a nagy kockázatú MI-rendszer megfeleljen e rendelet\nkövetelményeinek. (3) A bejelentett szervezetek - kérésre - a 28. cikkben\nemlített bejelentő hatóság számára rendelkezésre bocsátanak és benyújtanak\nminden releváns dokumentációt, ideértve a szolgáltatók dokumentációját is,\nhogy lehetővé tegyék az említett hatóság számára az értékelési, kijelölési,\nbejelentési és nyomonkövetési tevékenységei elvégzését, továbbá, hogy\nelősegítsék az e szakaszban vázolt értékelést. (1) A Bizottság minden egyes\nbejelentett szervezethez egyetlen azonosító számot rendel, még akkor is, ha\negy szervezetet egynél több uniós jogi aktus alapján jelentenek be. (2) A\nBizottság nyilvánosan közzéteszi az e rendelet szerint bejelentett szervezetek\njegyzékét, ideértve az azonosító számukat és azon tevékenységeket, amelyek\ntekintetében azokat bejelentették. A Bizottság biztosítja, hogy a jegyzéket\nnaprakészen tartsák. (1) A bejelentő hatóságok - a 30. cikk (2) bekezdésében\nemlített elektronikus bejelentési eszközön keresztül - értesítik a Bizottságot\nés a többi tagállamot a bejelentett szervezet bejelentésében bekövetkezett\nminden releváns változásról. (2) A bejelentés hatályának kiterjesztésére a 29.\nés a 30. cikkben megállapított eljárásokat kell alkalmazni. A bejelentést\nérintő, a hatályának kiterjesztésétől eltérő változásokra a (3)-(9)\nbekezdésben megállapított eljárásokat kell alkalmazni. (3) Amennyiben egy\nbejelentett szervezet úgy dönt, hogy megszünteti a megfelelőségértékelési\ntevékenységeit, a lehető leghamarabb - és tervezett megszüntetés esetén a\ntevékenységeinek megszüntetését megelőzően legalább egy évvel - tájékoztatja a\nbejelentő hatóságot és az érintett szolgáltatókat. A bejelentett szervezet\ntanúsítványai a bejelentett szervezet tevékenységeinek megszüntetését követő\nkilenc hónapos időszakra érvényesek maradhatnak, feltéve, hogy egy másik\nbejelentett szervezet írásban megerősítette, hogy vállalni fogja a\nfelelősséget az említett tanúsítványok hatálya alá tartozó nagy kockázatú MI-\nrendszerekért. Az utóbbi bejelentett szervezet az említett kilenc hónapos\nidőszak végéig elvégzi az érintett nagy kockázatú MI-rendszerek teljes\nértékelését, mielőtt új tanúsítványokat adna ki az említett rendszerekre\nvonatkozóan. Amennyiben a bejelentett szervezet megszüntette tevékenységét, a\nbejelentő hatóság visszavonja a kijelölést. (4) Amennyiben a bejelentő\nhatóságnak elegendő oka van úgy megítélni, hogy valamely bejelentett szervezet\nmár nem felel meg a 31. cikkben megállapított követelményeknek, vagy\nelmulasztja teljesíteni a kötelezettségeit, a bejelentő hatóság a lehető\nlegnagyobb gondossággal kivizsgálja az ügyet. Ezzel összefüggésben\ntájékoztatja az érintett bejelentett szervezetet a felmerült kifogásokról, és\nlehetőséget biztosít számára álláspontjának ismertetésére. Ha a bejelentő\nhatóság arra a következtetésre jut, hogy a bejelentett szervezet már nem felel\nmeg a 31. cikkben megállapított követelményeknek, vagy elmulasztja teljesíteni\na kötelezettségeit, adott esetben - az említett követelményeknek való\nmegfelelés vagy az említett kötelezettségek teljesítése elmulasztásának\nsúlyosságától függően - korlátozza, felfüggeszti vagy visszavonja a\nkijelölést. A bejelentő hatóság ennek megfelelően haladéktalanul tájékoztatja\na Bizottságot és a többi tagállamot. (5) Amennyiben a kijelölését\nfelfüggesztették, korlátozták, vagy részben vagy egészben visszavonták, a\nbejelentett szervezet 10 napon belül tájékoztatja az érintett szolgáltatókat.\n(6) A kijelölés korlátozása, felfüggesztése vagy visszavonása esetén a\nbejelentő hatóság megfelelő lépéseket tesz annak biztosítására, hogy az\nérintett bejelentett szervezet dokumentumait megőrizzék, valamint más\ntagállamok bejelentő hatóságai és a piacfelügyeleti hatóságok számára - azok\nkérésére - rendelkezésre bocsássák. (7) A kijelölés korlátozása,\nfelfüggesztése vagy visszavonása esetén a bejelentő hatóság: a) értékeli kell,\nhogy ez milyen hatással jár a bejelentett szervezet által kibocsátott\ntanúsítványokra nézve; b) a kijelölést érintő változások bejelentésétől\nszámított három hónapon belül jelentést nyújt be megállapításairól a Bizottság\nés a többi tagállam számára; c) a piacon forgalmazott nagy kockázatú MI-\nrendszerek folyamatos megfelelőségének biztosítása érdekében előírja a\nbejelentett szervezet számára, hogy - a hatóság által meghatározott észszerű\nhatáridőn belül - függesszen fel vagy vonjon vissza minden jogtalanul kiadott\ntanúsítványt; d) tájékoztatja a Bizottságot és a tagállamokat azon\ntanúsítványokról, amelyek felfüggesztését vagy visszavonását előírta; e) megad\na szolgáltató bejegyzett székhelye szerinti tagállam illetékes nemzeti\nhatóságainak minden releváns információt azon tanúsítványokról, amelyek\nfelfüggesztését vagy visszavonását előírta; az említett hatóság szükség esetén\nmeghozza a megfelelő intézkedéseket az egészséget, a biztonságot vagy az\nalapvető jogokat fenyegető potenciális kockázat elkerülése érdekében. (8) A\nkijelölés felfüggesztése vagy korlátozása esetén a tanúsítványok - a\njogtalanul kiállított tanúsítványok kivételével - érvényesek maradnak a\nkövetkező körülmények egyikének esetén: a) a bejelentő hatóság - a\nfelfüggesztést vagy korlátozást követő egy hónapon belül - megerősítette, hogy\na felfüggesztés vagy a korlátozás által érintett tanúsítványokkal kapcsolatban\nnem áll fenn az egészséget, a biztonságot vagy az alapvető jogokat fenyegető\nkockázat, és a bejelentő hatóság felvázolta a felfüggesztés vagy a korlátozás\nfeloldását célzó intézkedések ütemezését; vagy b) a bejelentő hatóság\nmegerősítette, hogy a felfüggesztés vagy korlátozás folyamán nem fognak\nkiadni, módosítani vagy újra kiadni a felfüggesztés szempontjából releváns\ntanúsítványt, és kijelenti, hogy a bejelentett szervezet képes-e folytatni a\nfelfüggesztés vagy a korlátozás időtartamára kiadott, meglévő tanúsítványok\nnyomon követését, és azokért továbbra is felelősséget vállalni; abban az\nesetben, ha a bejelentő hatóság megállapítja, hogy a bejelentett szervezet nem\nképes a kiadott, meglévő tanúsítványokat támogatni, a tanúsítvány hatálya alá\ntartozó rendszer szolgáltatójának a felfüggesztéstől vagy korlátozástól\nszámított három hónapon belül írásban meg kell erősítenie a bejegyzett\nszékhelye szerinti tagállam illetékes nemzeti hatóságai felé, hogy a\nfelfüggesztés vagy a korlátozás időtartama alatt ideiglenesen egy másik\nminősített bejelentett szervezet vállalja a bejelentett szervezetnek a\ntanúsítványok nyomon követésére és az azokért való további\nfelelősségvállalásra vonatkozó feladatait. (9) A kijelölés visszavonása esetén\na tanúsítványok - a jogtalanul kiállított tanúsítványok kivételével - a\nkövetkező körülmények esetén kilenc hónapig érvényben maradnak: a) a\ntanúsítvány hatálya alá tartozó nagy kockázatú MI-rendszer szolgáltatójának\nbejegyzett székhelye szerinti tagállam illetékes nemzeti hatósága\nmegerősítette, hogy nem áll fenn az egészséget, a biztonságot vagy az alapvető\njogokat fenyegető, az érintett nagy kockázatú MI-rendszerekkel kapcsolatos\nkockázat; és b) egy másik bejelentett szervezet írásban megerősítette, hogy\nközvetlen felelősséget fog vállalni az említett MI-rendszerekért, és a\nkijelölés visszavonásától számított 12 hónapon belül elvégzi annak\nértékelését. Az első albekezdésben említett körülmények esetén a tanúsítvány\nhatálya alá tartozó rendszer szolgáltatójának székhelye szerinti tagállam\nilletékes nemzeti hatósága további három hónapos időszakokkal - amelyek\nösszességében nem haladhatják meg a 12 hónapot - meghosszabbíthatja a\ntanúsítványok ideiglenes érvényességét. Az illetékes nemzeti hatóság vagy a\nkijelölés megváltozása által érintett bejelentett szervezet feladatait ellátó\nbejelentett szervezet erről haladéktalanul tájékoztatja a Bizottságot, a többi\ntagállamot és a többi bejelentett szervezetet. (1) A Bizottság szükség esetén\nkivizsgál minden olyan esetet, amikor okkal vonható kétségbe a bejelentett\nszervezet alkalmassága, vagy az, hogy a bejelentett szervezet folyamatosan\nteljesíti-e a 31. cikkben megállapított követelményeket és az alkalmazandó\nfelelősségi köreit. (2) A bejelentő hatóság - kérésre - megad a Bizottságnak\nminden, az érintett bejelentett szervezet bejelentésével vagy alkalmasságának\nfenntartásával kapcsolatos információt. (3) A Bizottság biztosítja, hogy az e\ncikk alapján lefolytatott vizsgálatai során a birtokába jutott valamennyi\nérzékeny információt a 78. cikkel összhangban bizalmasan kezeljék. (4)\nAmennyiben a Bizottság megbizonyosodik arról, hogy egy bejelentett szervezet\nnem vagy már nem tesz eleget a rá vonatkozó bejelentés követelményeinek, ennek\nmegfelelően tájékoztatja a bejelentő tagállamot, és felkéri a szükséges\nkorrekciós intézkedések megtételére, ideértve szükség esetén a bejelentés\nfelfüggesztését vagy visszavonását is. Amennyiben a tagállam elmulasztja\nmeghozni a szükséges korrekciós intézkedéseket, a Bizottság végrehajtási jogi\naktus útján felfüggesztheti, korlátozhatja vagy visszavonhatja a kijelölést.\nAz említett végrehajtási jogi aktust a 98. cikk (2) bekezdésében említett\nvizsgálóbizottsági eljárás keretében kell elfogadni. (1) A Bizottság\nbiztosítja, hogy - a nagy kockázatú MI-rendszerek tekintetében - az e rendelet\nszerinti megfelelőségértékelési eljárásokban részt vevő bejelentett\nszervezetek között megfelelő koordinációt és együttműködést vezessenek be és\nmegfelelően működtessenek a bejelentett szervezetek ágazati csoportja\nformájában. (2) Minden egyes bejelentő hatóságnak biztosítania kell, hogy az\náltala bejelentett szervezetek közvetlenül vagy kijelölt képviselőkön\nkeresztül részt vegyenek az (1) bekezdésben említett csoport munkájában. (3) A\nBizottság gondoskodik az ismereteknek és a legjobb gyakorlatoknak a bejelentő\nhatóságok közötti cseréjéről. Az olyan harmadik ország joga szerint\nlétrehozott megfelelőségértékelő szervezetek, amellyel az Unió megállapodást\nkötött, felhatalmazhatók a bejelentett szervezetek e rendelet szerinti\ntevékenységeinek elvégzésére, feltéve, hogy megfelelnek a 31. cikkben\nmegállapított követelményeknek, vagy biztosítják az egyenértékű szintű\nmegfelelőséget. (1) Azon nagy kockázatú vagy általános célú MI-rendszerekről,\namelyek megfelelnek az olyan harmonizált szabványoknak vagy azok részeinek,\namelyek hivatkozásait az 1025/2012/EU rendeletnek megfelelően közzétették az\nEurópai Unió Hivatalos Lapjában, vélelmezni kell, hogy megfelelnek az e\nfejezet 2. szakaszában meghatározott követelményeknek, vagy adott esetben az e\nrendelet V. fejezetének 2. és 3. szakaszában meghatározott kötelezettségeknek,\namennyiben az említett szabványok e követelményekre vagy kötelezettségekre\nkiterjednek. (2) A Bizottság - az 1025/2012/EU rendelet 10. cikkével\nösszhangban - indokolatlan késedelem nélkül bocsátja ki az e fejezet 2.\nszakaszában meghatározott valamennyi követelményre kiterjedő szabványosítási\nkérelmeket és adott esetben az e rendelet V. fejezetének 2. és 3. szakaszában\nmeghatározott kötelezettségekre kiterjedő szabványosítási kérelmeket. A\nszabványosítási kérelemben kérni kell az MI-rendszerek erőforrás-\nteljesítményének javítását célzó jelentéstételi és dokumentációs folyamatokra\n- így például életciklusa során a nagy kockázatú MI-rendszer energia- és egyéb\nerőforrás-fogyasztásának csökkentésére -, valamint az általános célú MI-\nmodellek energiahatékony fejlesztésére vonatkozó szabvány jellegű\ndokumentumokat is. A szabványosítási kérelem elkészítésekor a Bizottság\nkonzultál a Testülettel és a releváns érdekelt felekkel, ideértve a tanácsadó\nfórumot is. Az európai szabványügyi szervezeteknek címzett szabványosítási\nkérelem kiadásakor a Bizottság meghatározza, hogy a szabványoknak világosnak\nés konzisztensnek kell lenniük - többek között az I. mellékletben felsorolt\nmeglévő uniós harmonizációs jogszabályok hatálya alá tartozó termékekre\nvonatkozóan a különböző ágazatokban kidolgozott szabványokkal -, és annak\nbiztosítására kell irányulniuk, hogy az Unióban forgalomba hozott vagy üzembe\nhelyezett nagy kockázatú MI-rendszerek vagy általános célú MI-modellek\nmegfeleljenek az e rendeletben megállapított releváns követelményeknek vagy\nkötelezettségeknek. A Bizottság az 1025/2012/EU rendelet 24. cikkének\nmegfelelően felkéri az európai szabványügyi szervezeteket, hogy igazolják az e\nbekezdés első és második albekezdésében említett célkitűzések elérésére tett\nerőfeszítéseiket. (3) A szabványosítási folyamat résztvevőinek törekedniük\nkell arra, hogy előmozdítsák az MI-vel kapcsolatos beruházásokat és innovációt\n- többek között a jogbiztonság, valamint az uniós piac versenyképességének és\nnövekedésének fokozása révén -, hozzájáruljanak a szabványosítás terén\nfolytatott globális együttműködés megerősítéséhez, valamint az MI területén\nmeglévő, az uniós értékekkel, alapvető jogokkal és érdekekkel összhangban álló\nnemzetközi szabványok figyelembevételéhez, továbbá hogy javítsák a\ntöbbszereplős irányítást, biztosítva az érdekek kiegyensúlyozott képviseletét\nés valamennyi érdekelt fél tényleges részvételét az 1025/2012/EU rendelet 5.,\n6. és 7. cikkével összhangban. (1) A Bizottság elfogadhat az e fejezet 2.\nszakaszában foglalt követelményekre vagy adott esetben az V. fejezetben 2. és\n3. szakaszában meghatározott kötelezettségekre vonatkozó közös előírásokat\nmegállapító végrehajtási jogi aktusokat, amennyiben teljesültek a következő\nfeltételek: a) a Bizottság az 1025/2012/EU rendelet 10. cikkének (1) bekezdése\nalapján felkért egy vagy több európai szabványügyi szervezetet az e fejezet 2.\nszakaszában foglalt követelményekre vagy - adott esetben - az V. fejezet 2. és\n3. szakaszában foglalt kötelezettségekre vonatkozó harmonizált szabvány\nkidolgozására, és: i. a felkérést egyik európai szabványügyi szervezet sem\nfogadta be; vagy ii. a felkérés szerinti harmonizált szabványokat nem\nnyújtották be az 1025/2012/EU rendelet 10. cikkének (1) bekezdésének\nmegfelelően meghatározott határidőn belül; vagy iii. a vonatkozó harmonizált\nszabványok nem kezelnek kielégítő mértékben alapjogi aggályokat; vagy iv. az\nemlített szabványok nem felelnek meg a felkérésnek; és b) az Európai Unió\nHivatalos Lapjában nem tettek közzé - az 1025/2012/EU rendeletnek megfelelően\n- hivatkozást az e fejezet 2. szakaszában említett követelményekre vagy adott\nesetben az V. fejezet 2. és 3. szakaszában említett kötelezettségekre\nkiterjedő harmonizált szabványokra, és észszerű időn belül várhatóan nem is\ntesznek közzé ilyen hivatkozást. A közös előírások kidolgozása során a\nBizottság konzultál a 67. cikkben említett tanácsadó fórummal. Az e bekezdés\nelső albekezdésében említett végrehajtási jogi aktusokat a 98. cikk (2)\nbekezdésében említett vizsgálóbizottsági eljárás keretében kell elfogadni. (2)\nA végrehajtási jogi aktus tervezetének kidolgozása előtt a Bizottság\ntájékoztatja az 1025/2012/EU rendelet 22. cikkében említett bizottságot arról,\nhogy megítélése szerint teljesülnek az e cikk (1) bekezdésében megállapított\nfeltételek. (3) Azon nagy kockázatú MI-rendszerekről vagy általános célú MI-\nmodellekről, amelyek megfelelnek az (1) bekezdésben említett közös\nelőírásoknak vagy ezen előírások egyes részeinek, azt kell vélelmezni, hogy\nmegfelelnek az e fejezet 2. szakaszában meghatározott követelményeknek, vagy\nadott esetben megfelelnek az V. fejezet 2. és 3. szakaszában említett\nkötelezettségeknek, amennyiben az említett közös előírások az említett\nkövetelményekre vagy az említett kötelezettségekre is kiterjednek. (4)\nAmennyiben valamely európai szabványügyi szervezet harmonizált szabványt fogad\nel, és javasolja a Bizottságnak, hogy arra vonatkozóan tegyen közzé\nhivatkozást az Európai Unió Hivatalos Lapjában, a Bizottság az 1025/2012/EU\nrendelettel összhangban értékeli a harmonizált szabványt. Amikor egy\nharmonizált szabvány hivatkozását közzéteszik az Európai Unió Hivatalos\nLapjában, a Bizottság hatályon kívül helyezi az (1) bekezdésben említett\nvégrehajtási jogi aktusokat vagy azok azon részeit, amelyek az e fejezet 2.\nszakaszában meghatározott ugyanazon követelményekre, vagy adott esetben az V.\nfejezet 2. és 3. szakaszában meghatározott ugyanazon kötelezettségekre\nvonatkoznak. (5) Amennyiben a nagy kockázatú MI-rendszerek vagy az általános\ncélú MI-modellek szolgáltatói nem felelnek meg az (1) bekezdésben említett\nközös előírásoknak, megfelelően igazolniuk kell, hogy olyan műszaki\nmegoldásokat fogadtak el, amelyek - azokkal legalább egyenértékű szinten -\nmegfelelnek az e fejezet 2. szakaszában említett követelményeknek, vagy adott\nesetben megfelelnek az V. fejezet 2. és 3. szakaszában meghatározott\nkötelezettségeknek. (6) Amennyiben egy tagállam úgy ítéli meg, hogy valamely\nközös előírás nem felel meg teljes mértékben a 2. szakaszban meghatározott\nkövetelményeknek, vagy adott esetben nem felel meg teljes mértékben az V.\nfejezet 2. és 3. szakaszában meghatározott kötelezettségeknek, erről részletes\nmagyarázatot mellékelve tájékoztatja a Bizottságot. A Bizottság értékeli az\nemlített információkat, és adott esetben módosítja az érintett közös előírást\nmegállapító végrehajtási jogi aktust. (1) Vélelmezni kell, hogy azok a nagy\nkockázatú MI-rendszerek, amelyeket azon konkrét földrajzi, viselkedési,\nkontextuális vagy funkcionális környezetet tükröző adatok alapján tanítottak\nbe és teszteltek, amely környezeten belül használni kívánják őket, megfelelnek\na 10. cikk (4) bekezdésében megállapított vonatkozó követelménynek. (2)\nAzokról a nagy kockázatú MI-rendszerekről, amelyek tanúsítvánnyal\nrendelkeznek, vagy amelyekre az (EU) 2019/881 rendelet alapján valamely\nkiberbiztonsági rendszer keretében megfelelőségi nyilatkozatot adtak ki, és\namelyek hivatkozásait közzétették az Európai Unió Hivatalos Lapjában, azt kell\nvélelmezni, hogy megfelelnek az e rendelet 15. cikkében foglalt\nkiberbiztonsági követelményeknek, amennyiben a kiberbiztonsági tanúsítvány\nvagy megfelelőségi nyilatkozat vagy annak részei e követelményekre is\nkiterjednek. (1) A III. melléklet 1. pontjában felsorolt nagy kockázatú MI-\nrendszerek esetében, amennyiben valamely nagy kockázatú MI-rendszer a 2.\nszakaszban meghatározott követelményeknek való megfelelése igazolása során a\nszolgáltató a 40. cikkben említett harmonizált szabványokat, vagy adott\nesetben a 41. cikkben említett közös előírásokat alkalmazta, a szolgáltatónak\na következőkön alapuló megfelelőségértékelési eljárások egyikét kell\nválasztania: a) a VI. mellékletben említett belső ellenőrzés; vagy b) a\nminőségirányítási rendszer és a műszaki dokumentáció valamely bejelentett\nszervezet bevonásával történő értékelése, a VII. mellékletben említettek\nszerint. Annak igazolása során, hogy valamely nagy kockázatú MI-rendszer\nmegfelel a 2. szakaszban foglalt követelményeknek, a szolgáltatónak a VII.\nmellékletben meghatározott megfelelőségértékelési eljárást kell követnie a\nkövetkező esetekben: a) a 40. cikkben említett harmonizált szabványok nem\nléteznek, és a 41. cikkben említett közös előírások nem állnak rendelkezésre;\nb) a szolgáltató nem alkalmazta a harmonizált szabványt, vagy annak csak egy\nrészét alkalmazta; c) az a) pontban említett közös előírások léteznek, de a\nszolgáltató nem alkalmazta őket; d) az a) pontban említett egy vagy több\nharmonizált szabványt korlátozással és csak a szabvány korlátozott részére\ntettek közzé. A VII. mellékletben említett megfelelőségértékelési eljárás\ncéljából a szolgáltató a bejelentett szervezetek bármelyikét választhatja.\nAzonban amennyiben a nagy kockázatú MI-rendszert bűnüldöző, bevándorlási vagy\nmenekültügyi hatóságok, valamint uniós intézmények, szervek, hivatalok vagy\nügynökségek szándékoznak üzembe helyezni, a 74. cikk (8) vagy - adott esetben\n- (9) bekezdésében említett piacfelügyeleti hatóságnak kell eljárnia\nbejelentett szervezetként. (2) A III. melléklet 2-8. pontjában említett nagy\nkockázatú MI-rendszerek esetében a szolgáltatóknak a VI. mellékletben\nemlített, belső ellenőrzésen alapuló megfelelőségértékelési eljárást kell\nkövetniük, amely nem rendelkezik bejelentett szervezet bevonásáról. (3) Az I.\nmelléklet A. szakaszában felsorolt uniós harmonizációs jogszabályok hatálya\nalá tartozó nagy kockázatú MI-rendszerek esetében a szolgáltatónak az említett\njogi aktusokban előírt megfelelőségértékelést kell követnie. Az e fejezet 2.\nszakaszában foglalt követelményeket alkalmazni kell az említett nagy kockázatú\nMI-rendszerekre, és azoknak az említett értékelés részét kell képezniük. A\nVII. melléklet 4.3., 4.4., 4.5. pontja és 4.6. pontjának ötödik bekezdése\nszintén alkalmazandó. Az értékelés céljából az említett jogi aktusok alapján\nbejelentett szervezeteket fel kell jogosítani annak ellenőrzésére, hogy a nagy\nkockázatú MI-rendszerek megfelelnek-e a 2. szakaszban foglalt\nkövetelményeknek, feltéve, hogy az említett bejelentett szervezeteknek a 31.\ncikk (4), (5), (10) és (11) bekezdésében megállapított követelményeknek való\nmegfelelését az említett jogi aktusok szerinti bejelentési eljárás keretében\nértékelték. Amennyiben az I. melléklet A. szakaszában felsorolt valamely jogi\naktus lehetővé teszik a termék gyártója számára, hogy kimaradjon egy harmadik\nfél által végzett megfelelőségértékelésből, feltéve, hogy a gyártó a\nvalamennyi releváns követelményre kiterjedő valamennyi harmonizált szabványt\nalkalmazta, az említett gyártó csak akkor élhet e lehetőséggel, ha harmonizált\nszabványokat vagy adott esetben a 41. cikkben említett, az e fejezet 2.\nszakaszában foglalt valamennyi követelményre kiterjedő közös előírásokat is\nalkalmazott. (4) A megfelelőségértékelési eljárásnak korábban már alávetett\nnagy kockázatú MI-rendszereket új megfelelőségértékelési eljárásnak kell\nalávetni akkor, amikor lényeges módosításon mennek keresztül, függetlenül\nattól, hogy a módosított rendszert további forgalmazásra szánják-e, vagy azt a\njelenlegi alkalmazó használja-e továbbra is; Azon nagy kockázatú MI-rendszerek\nesetében, amelyek tanulása a forgalomba hozatalt vagy üzembe helyezést\nkövetően is folytatódik, a nagy kockázatú MI-rendszernek és teljesítményének -\namelyeket a szolgáltató az első megfelelőségértékelés időpontjában előre\nmeghatározott, és amelyek a IV. melléklet 2. pontjának f) alpontjában említett\nműszaki dokumentációban szereplő információk részét képezik - a\nmegváltoztatása nem minősülhet jelentős módosításnak. (5) A Bizottság\nfelhatalmazást kap arra, hogy a 97. cikknek megfelelően felhatalmazáson\nalapuló jogi aktusokat fogad el abból a célból, hogy módosítsa a VI. és a VII.\nmellékletet, a műszaki fejlődés fényében naprakésszé. (6) A Bizottság\nfelhatalmazást kap arra, hogy a 97. cikknek megfelelően felhatalmazáson\nalapuló jogi aktusokat fogadjon el e cikk (1) és a (2) bekezdésének annak\nérdekében történő módosítása céljából, hogy a III. melléklet 2-8. pontjában\nemlített nagy kockázatú MI-rendszereket a VII. mellékletben említett\nmegfelelőségértékelési eljárás vagy az eljárás egyes részeinek hatálya alá\nvonja. A Bizottság ilyen, felhatalmazáson alapuló jogi aktusokat oly módon\nfogad el, hogy figyelembe veszi a VI. mellékletben említett belső ellenőrzésen\nalapuló megfelelőségértékelési eljárás hatékonyságát az ilyen rendszerek által\naz egészséget és a biztonságot érintő kockázatok megelőzése vagy minimálisra\ncsökkentése, valamint az alapvető jogok védelme tekintetében, továbbá a\nmegfelelő kapacitások és erőforrások rendelkezésre állását bejelentett\nszervezetek körében (1) A bejelentett szervezetek által a VII. mellékletnek\nmegfelelően kibocsátott tanúsítványokat azon a nyelven kell kiadni, amelyet a\nbejelentett szervezet letelepedési helye szerinti tagállam érintett hatóságai\nkönnyen megértenek. (2) A tanúsítványok érvényessége a bennük feltüntetett\nidőtartamra szól, amely nem haladhatja meg az öt évet az I. melléklet hatálya\nalá tartozó MI-rendszerek esetében, és a négy évet a III. melléklet hatálya\nalá tartozó MI-rendszerek esetében. A szolgáltató kérelmére a tanúsítvány\nérvényessége - az alkalmazandó megfelelőségértékelési eljárásokkal összhangban\nelvégzett felülvizsgálat alapján - további, egyenként öt évet meg nem haladó\nidőszakokra meghosszabbítható az I. melléklet hatálya alá tartozó MI-\nrendszerek esetében, és egyenként négy évet meg nem haladó időszakokra a III.\nmelléklet hatálya alá tartozó MI-rendszerek esetében. A tanúsítvány bármely\nkiegészítése érvényben marad feltéve, hogy az általa kiegészített tanúsítvány\nis érvényes. (3) Amennyiben egy bejelentett szervezet megállapítja, hogy az\nMI-rendszer már nem tesz eleget a 2. szakaszban foglalt követelményeknek, az\narányosság elvét figyelembe véve köteles felfüggeszteni vagy visszavonni a\nkiadott tanúsítványt, vagy korlátozásokat bevezetni a tanúsítványra\nvonatkozóan, kivéve, ha a rendszer szolgáltatója a bejelentett szervezet által\nmeghatározott megfelelő határidőn belül megfelelő korrekciós intézkedéssel\nbiztosítja az említett követelményeknek való megfelelést. A bejelentett\nszervezetnek meg kell indokolnia a döntését. Biztosítani kell, hogy a\nbejelentett szervezetek határozatai ellen - ideértve a kiadott megfelelőségi\ntanúsítványokra vonatkozó határozatokat is - fellebbezési eljárás álljon\nrendelkezésre. (1) A bejelentett szervezeteknek tájékoztatniuk kell a\nbejelentő hatóságot a következőkről: a) a VII. melléklet követelményeivel\nösszhangban kiállított, a műszaki dokumentáció értékelésére vonatkozó uniós\ntanúsítványok, azok kiegészítései, és a minőségirányítási rendszerre vonatkozó\nminden jóváhagyás; b) a VII. melléklet követelményeivel összhangban\nkiállított, a műszaki dokumentáció értékelésére vonatkozó uniós tanúsítvány\nvagy a minőségirányítási rendszerre vonatkozó jóváhagyás elutasítása,\nkorlátozása, felfüggesztése vagy visszavonása; c) azok a körülmények, amelyek\nérinthetik a bejelentés hatályát vagy feltételeit; d) a piacfelügyeleti\nhatóságoktól a megfelelőségértékelési tevékenységek kapcsán hozzájuk\nbeérkezett valamennyi tájékoztatási kérelem; e) kérésre a bejelentésük hatálya\nalá tartozó megfelelőségértékelési tevékenységek, valamint minden más\nelvégzett tevékenység, többek között a határon átnyúló tevékenységek és a\ntevékenységek alvállalkozásba adása. (2) Minden bejelentett szervezetnek\ntájékoztatnia kell a többi bejelentett szervezetet a következőkről: a)\nminőségirányítási rendszereknek a bejelentett szervezet által elutasított,\nfelfüggesztett vagy visszavont jóváhagyásai, valamint kérésre a\nminőségbiztosítási rendszerek bejelentett szervezet által kiadott\njóváhagyásai; b) a bejelentett szervezet által elutasított, visszavont,\nfelfüggesztett vagy más módon korlátozott, a műszaki dokumentáció értékelésére\nvonatkozó uniós tanúsítványok vagy azok kiegészítései, valamint - kérésre - az\náltala kiadott tanúsítványok és/vagy kiegészítések. (3) Minden egyes\nbejelentett szervezetnek megfelelően tájékoztatnia kell az ugyanazokra az MI-\nrendszertípusokra vonatkozó, hasonló megfelelőségértékelési tevékenységeket\nvégző más bejelentett szervezeteket a negatív és - kérésre - a pozitív\nmegfelelőségértékelési eredményekről. (4) A bejelentett szervezeteknek a 78.\ncikkel összhangban meg kell őrizniük az álaluk kapott információk bizalmas\njellegét. (1) A 43. cikktől eltérve és kellően indokolt kérésre bármely\npiacfelügyeleti hatóság engedélyezheti adott nagy kockázatú MI-rendszerek\nforgalomba hozatalát vagy üzembe helyezését az érintett tagállam területén, a\nközbiztonság vagy a személyek életének és egészségének védelmét, a\nkörnyezetvédelmet, valamint a kulcsfontosságú ipari és infrastrukturális\neszközök védelmét szolgáló rendkívüli okokból. Az engedély arra a korlátozott\nidőtartamra szól, amíg elvégzik a szükséges megfelelőségértékelési\neljárásokat, figyelembe véve az eltérést indokoló rendkívüli okokat. Ezen\neljárások lefolytatását indokolatlan késedelem nélkül meg kell kezdeni. (2)\nRendkívüli közbiztonsági okokból felmerülő, kellően indokolt sürgős helyzetben\nvagy természetes személyek életét vagy fizikai biztonságát fenyegető konkrét,\njelentős és közvetlen veszély esetén a bűnüldöző hatóságok vagy a polgári\nvédelmi hatóságok az (1) bekezdésben említett engedély nélkül is üzembe\nhelyezhetnek egy adott nagy kockázatú MI-rendszert, feltéve, hogy a használat\nsorán vagy azt követően - indokolatlan késedelem nélkül - kérnek ilyen\nengedélyt. Az (1) bekezdésben említett engedély elutasítása esetén a nagy\nkockázatú MI-rendszer használatát azonnali hatállyal le kell állítani,\nvalamint e használat valamennyi eredményét és kimenetét azonnal meg kell\nsemmisíteni. (3) Az (1) bekezdésben említett engedély csak akkor adható ki, ha\na piacfelügyeleti hatóság arra a következtetésre jut, hogy a nagy kockázatú\nMI-rendszer megfelel a 2. szakaszban foglalt követelményeknek. A\npiacfelügyeleti hatóságnak tájékoztatnia kell a Bizottságot és a többi\ntagállamot az (1) és a (2) bekezdés alapján kiadott bármely engedélyről. Ez a\nkötelezettség nem terjedhet ki a bűnüldöző hatóságok tevékenységeivel\nkapcsolatos érzékeny operatív adatokra. (4) Amennyiben a (3) bekezdésben\nemlített tájékoztatás kézhezvételétől számított 15 naptári napon belül egyik\ntagállam és a Bizottság sem emel kifogást a valamely tagállam piacfelügyeleti\nhatósága által az (1) bekezdéssel összhangban kiadott engedéllyel szemben, az\nengedély indokoltnak tekintendő. (5) Amennyiben a (3) bekezdésben említett\nértesítés kézhezvételétől számított 15 naptári napon belül valamely tagállam\nkifogást emel egy másik tagállam piacfelügyeleti hatósága által kiadott\nengedéllyel szemben, vagy ha a Bizottság úgy ítéli meg, hogy az engedély\nellentétes az uniós joggal, vagy hogy a tagállamoknak a (3) bekezdésben\nemlített, a rendszer megfelelőségére vonatkozó következtetése megalapozatlan,\na Bizottság haladéktalanul egyeztetést kezdeményez az érintett tagállammal. Az\nérintett üzemeltetőkkel egyeztetni kell, és lehetőséget kell biztosítani\nszámukra, hogy kifejtsék álláspontjukat. Minderre tekintettel, a Bizottság\ndönt arról, hogy az engedély indokolt-e. A Bizottság közli határozatát az\nérintett tagállammal és a releváns üzemeltetőkkel. (6) Amennyiben a Bizottság\naz engedélyt indokolatlannak ítéli, az engedélyt az érintett tagállam\npiacfelügyeleti hatóságának vissza kell vonnia. (7) Az I. melléklet A.\nszakaszában felsorolt uniós harmonizációs jogszabályok hatálya alá tartozó\ntermékekhez kapcsolódó, nagy kockázatú MI-rendszerek esetében kizárólag az\nemlített uniós harmonizációs jogszabályokban megállapított\nmegfelelőségértékelési eljárástól való eltéréseket kell alkalmazni. (1) A\nszolgáltatónak minden egyes nagy kockázatú MI-rendszerre vonatkozóan írásos,\ngéppel olvasható, fizikai vagy elektronikus aláírással ellátott EU-\nmegfelelőségi nyilatkozatot kell készítenie, és azt a nagy kockázatú MI-\nrendszer forgalomba hozatala vagy üzembe helyezése után 10 évig az illetékes\nnemzeti hatóság számára elérhetővé kell tennie. Az EU-megfelelőségi\nnyilatkozatban azonosítani kell azon nagy kockázatú MI-rendszert, amelyre\nvonatkozóan a nyilatkozatot kiállították. Az EU-megfelelőségi nyilatkozat egy\npéldányát kérésre be kell nyújtani a megfelelő illetékes nemzeti hatóságok\nrészére. (2) Az EU-megfelelőségi nyilatkozatban fel kell tüntetni, hogy az\nérintett nagy kockázatú MI-rendszer megfelel a 2. szakaszban foglalt\nkövetelményeknek. Az EU-megfelelőségi nyilatkozatnak tartalmaznia kell az V.\nmellékletben szereplő információkat, és a nyilatkozatot le kell fordítani az\nazon tagállamok illetékes nemzeti hatóságai által könnyen érthető nyelvre,\namelyekben a nagy kockázatú MI-rendszert forgalomba hozták vagy forgalmazzák.\n(3) Amennyiben a nagy kockázatú MI-rendszerek más olyan uniós harmonizációs\njogszabályok hatálya alá tartoznak, amelyek szintén EU-megfelelőségi\nnyilatkozatot írnak elő, a nagy kockázatú MI-rendszerre alkalmazandó\nvalamennyi uniós jogszabály tekintetében egyetlen EU-megfelelőségi\nnyilatkozatot kell kiállítani. A nyilatkozatnak tartalmaznia kell minden olyan\ninformációt, amelyre szükség van annak az uniós harmonizációs jogszabálynak az\nazonosításához, amelynek tekintetében a nyilatkozatot tették. (4) Az EU-\nmegfelelőségi nyilatkozat kiállítását követően a szolgáltatónak felelősséget\nkell vállalnia a 2. szakaszban foglalt követelmények teljesítéséért. A\nszolgáltatónak szükség szerint naprakészen kell tartania az EU-megfelelőségi\nnyilatkozatot. (5) A Bizottság felhatalmazást kap arra, hogy a 97. cikknek\nmegfelelően felhatalmazáson alapuló jogi aktusokat fogadjon el az V.\nmellékletnek az említett mellékletben meghatározott EU-megfelelőségi\nnyilatkozat tartalmának naprakésszé tételével történő módosítása céljából,\nannak érdekében hogy a műszaki fejlődés fényében szükségessé váló elemeket\nbeillessze. (1) A CE-jelölésre a 765/2008/EK rendelet 30. cikkében\nmeghatározott általános elvek vonatkoznak. (2) A kizárólag digitálisan\nszolgáltatott nagy kockázatú MI-rendszerek esetében digitális CE-jelölés csak\nakkor használható, ha az könnyen hozzáférhető azon interfészen keresztül,\nahonnan az adott rendszer elérhető, vagy könnyen hozzáférhető, géppel\nolvasható kód vagy más elektronikus eszköz révén. (3) A CE-jelölést a nagy\nkockázatú MI-rendszerek esetében jól láthatóan, olvashatóan és\neltávolíthatatlan módon kell elhelyezni. Amennyiben a nagy kockázatú MI-\nrendszer jellege miatt ez nem lehetséges vagy nem indokolt, a jelölést a\ncsomagoláson vagy adott esetben a kísérő dokumentáción kell feltüntetni. (4) A\nCE-jelölés mellett adott esetben fel kell tüntetni a 43. cikkben foglalt\nmegfelelőségértékelési eljárásokért felelős bejelentett szervezet azonosító\nszámát. A bejelentett szervezet azonosító számát magának a szervezetnek vagy -\nannak utasításai alapján - a szolgáltatónak vagy a szolgáltató meghatalmazott\nképviselőjének kell feltüntetnie. Az azonosító számot fel kell tüntetni minden\nolyan promóciós anyagon is, amelyben megemlítésre kerül, hogy a nagy kockázatú\nMI-rendszer eleget tesz a CE-jelölésre vonatkozó követelményeknek. (5) Ha a\nnagy kockázatú MI-rendszerek olyan más uniós jogszabály hatálya alá tartoznak,\namely szintén előírja a CE-jelölés feltüntetését, a CE-jelölésben jelezni\nkell, hogy a nagy kockázatú MI-rendszer ezen más jogszabály követelményeinek\nis megfelel. (1) A III. mellékletben felsorolt valamely, nagy kockázatú MI-\nrendszer - a III. melléklet 2. pontjában említett nagy kockázatú MI-rendszerek\nkivételével - forgalomba hozatala vagy üzembe helyezése előtt a szolgáltatónak\nvagy adott esetben a meghatalmazott képviselőnek saját magát és a rendszerét\nregisztrálnia kell a 71. cikkben említett uniós adatbázisban. (2) Az olyan MI-\nrendszer forgalomba hozatala vagy üzembe helyezése előtt, amelyről a\nszolgáltató megállapította, hogy a 6. cikk (3) bekezdése értelmében nem nagy\nkockázatú, az említett szolgáltatónak vagy adott esetben a meghatalmazott\nképviselőnek saját magát és az említett rendszert regisztrálnia kell a 71.\ncikkben említett uniós adatbázisban. (3) Valamely, a III. mellékletben\nfelsorolt nagy kockázatú MI-rendszer - a III. melléklet 2. pontjában felsorolt\nnagy kockázatú MI-rendszerek kivételével - üzembe helyezése vagy használata\nelőtt azon alkalmazók, amelyek hatóságok, uniós intézmények, szervek,\nhivatalok vagy ügynökségek, vagy a nevükben eljáró személyek, regisztrálják\nmagukat, kiválasztják a rendszert, és regisztrálják annak használatát a 71.\ncikkben említett uniós adatbázisban. (4) A III. melléklet 1., 6. és 7.\npontjában említett nagy kockázatú MI-rendszerek esetében a bűnüldözés, a\nmigráció, a menekültügy és a határigazgatás területén az e cikk (1), (2) és\n(3) bekezdésében említett regisztrációt a 71. cikkben említett uniós adatbázis\nbiztonságos, nem nyilvános részében kell megtenni, és annak adott esetben csak\na következő, az alábbi helyeken említett információkra kell kiterjednie: a) a\nVIII. melléklet A. szakaszának 1-10. pontja, kivéve a 6., a 8. és a 9. pontot;\nb) a VIII. melléklet B. szakaszának 1-5. pontja, valamint 8. és 9. pontja; c)\na VIII. melléklet C. szakaszának 1-3. pontja; d) a IX. melléklet 1., 2., 3. és\n5. pontja. Csak a Bizottság és a 74. cikk (8) bekezdésében említett nemzeti\nhatóságok férhetnek hozzá az uniós adatbázisnak az e bekezdés első\nalbekezdésében felsorolt, vonatkozó korlátozott részeihez. (5) A III.\nmelléklet 2. pontjában említett nagy kockázatú MI-rendszereket nemzeti szinten\nkell nyilvántartásba venni. (1) A szolgáltatóknak biztosítaniuk kell, hogy a\ntermészetes személyekkel való közvetlen interakcióra szánt MI-rendszereket úgy\ntervezzék meg és fejlesszék ki, hogy az érintett természetes személyek\ntájékoztatást kapjanak arról, hogy egy MI-rendszerrel állnak interakcióban,\nkivéve, ha ez a körülményekre és a felhasználási kontextusra figyelemmel, egy\nészszerűen jól tájékozott, figyelmes és körültekintő természetes személy\nszempontjából nyilvánvaló tény. Ez a kötelezettség nem alkalmazandó\nbűncselekmények felderítése, megelőzése, nyomozása vagy büntetőeljárás alá\nvonása céljára - a harmadik felek jogaira és szabadságaira vonatkozó megfelelő\nbiztosítékok mellett - a törvény által engedélyezett MI-rendszerekre, kivéve,\nha az említett rendszerek bűncselekmények bejelentése céljából a nyilvánosság\nrendelkezésére állnak. (2) A szintetikus hang-, kép-, video- vagy szöveges\ntartalmat létrehozó MI-rendszerek - köztük az általános célú MI-rendszerek -\nszolgáltatóinak biztosítaniuk kell, hogy az MI-rendszer kimeneteit géppel\nolvasható formátumban jelöljék meg, és azok mesterségesen létrehozottként vagy\nmanipuláltként észlelhetők legyenek. A szolgáltatóknak biztosítaniuk kell,\nhogy műszaki megoldásaik hatékonyak, interoperábilisak, robusztusak és\nmegbízhatóak legyenek, amennyiben ez műszakilag megvalósítható, figyelembe\nvéve a különböző tartalomtípusok sajátosságait és korlátait, a megvalósítás\nköltségeit és a technika általánosan elismert állását, amint azt a vonatkozó\nműszaki szabványok tükrözhetik. Ez a kötelezettség nem alkalmazandó,\namennyiben az MI-rendszerek támogató funkciót töltenek be hagyományos\nszerkesztés céljára, vagy nem változtatják meg lényegesen az alkalmazó által\nszolgáltatott bemeneti adatokat vagy azok szemantikáját, vagy amennyiben azt\ntörvény engedélyezi bűncselekmények felderítése, megelőzése, nyomozása vagy\nbüntetőeljárás alá vonása céljából. (3) Az érzelemfelismerő rendszer vagy a\nbiometrikus kategorizálási rendszer alkalmazóinak tájékoztatniuk kell a\nrendszer működéséről azon természetes személyeket, akik a rendszer működésének\nki vannak téve, és a személyes adatokat az (EU) 2016/679 és az (EU) 2018/1725\nrendeletnek, valamint - adott esetben - az (EU) 2016/680 irányelvnek\nmegfelelően kell kezelniük. Ez a kötelezettség nem alkalmazandó a biometrikus\nkategorizálásra és érzelemfelismerésre használt olyan MI-rendszerekre,\namelyeket a törvény megenged bűncselekmények felderítése, megelőzése és\nnyomozása céljából, a harmadik felek jogaira és szabadságaira vonatkozó\nmegfelelő biztosítékok mellett, és az uniós jognak megfelelően. (4) Az olyan\nMI-rendszerek alkalmazóinak, amelyek eredetinek vagy valóságosnak tűnő\n(„deepfake”) kép-, hang- vagy videotartalmat hoznak létre vagy manipulálnak,\nközölniük kell, hogy a tartalmat mesterségesen hozták létre vagy manipulálták.\nEz a kötelezettség nem alkalmazandó, amennyiben a használatot törvény\nengedélyezi bűncselekmények felderítése, megelőzése, nyomozása vagy\nbüntetőeljárás alá vonása céljából. Amennyiben a tartalom nyilvánvalóan\nművészeti, kreatív, szatirikus, fiktív vagy hasonló mű vagy program részét\nképezi, az e bekezdésben meghatározott átláthatósági kötelezettségek az ilyen\nlétrehozott vagy manipulált tartalom meglétének megfelelő, a mű megjelenítését\nvagy élvezetét nem akadályozó közlésére korlátozódnak. A nyilvánosság\nközérdekű ügyekről való tájékoztatása céljából közzétett szöveget generáló\nvagy manipuláló MI-rendszer alkalmazóinak közölniük kell, hogy a szöveget\nmesterségesen hozták létre vagy manipulálták. Ez a kötelezettség nem\nalkalmazandó abban az esetben, ha a felhasználást törvény engedélyezi\nbűncselekmények felderítése, megelőzése, nyomozása vagy büntetőeljárás alá\nvonása céljából, vagy ha a mesterséges intelligencia által létrehozott\ntartalmon emberi felülvizsgálatra vagy szerkesztési ellenőrzésre került sor,\nés amennyiben a tartalom közzétételéért természetes vagy jogi személy\nszerkesztői felelősséget visel. (5) Az (1)-(4) bekezdésben említett\ntájékoztatást legkésőbb az első interakció vagy kitettség alkalmával,\negyértelmű és jól megkülönböztethető módon kell az érintett természetes\nszemélyek számára nyújtani. A tájékoztatásnak meg kell felelnie az\nalkalmazandó akadálymentesítési követelményeknek. (6) Az (1)-(4) bekezdés nem\nérintheti a III. fejezetben meghatározott követelményeket és\nkötelezettségeket, és nem sérthet az MI-rendszerek alkalmazóira vonatkozóan az\nuniós vagy a nemzeti jogban megállapított egyéb átláthatósági\nkötelezettségeket. (7) Az MI-hivatalnak ösztönöznie és segítenie kell uniós\nszintű gyakorlati kódexek kidolgozását a mesterségesen előállított vagy\nmanipulált tartalom észlelésére és címkézésére vonatkozó kötelezettségek\nhatékony végrehajtásának elősegítése érdekében. A Bizottság az 56. cikk (6)\nbekezdésében megállapított eljárásnak megfelelően végrehajtási jogi aktusokat\nfogadhat el az említett gyakorlati kódexek jóváhagyása céljából. A Bizottság -\nha úgy ítéli meg, hogy a kódex nem megfelelő - a 98. cikk (2) bekezdésében\nmegállapított vizsgálóbizottsági eljárásnak megfelelően végrehajtási jogi\naktust fogadhat el, amelyben közös szabályokat határoz meg az említett\nkötelezettségek végrehajtására vonatkozóan. (1) Valamely általános célú MI-\nmodellt rendszerszintű kockázatot jelentő általános célú MI-modellként kell\nbesorolni, ha megfelel a következő feltételek bármelyikének: a) megfelelő\ntechnikai eszközök és módszertanok - többek között mutatók és\nreferenciaértékek - alapján értékelt, nagy hatású képességekkel rendelkezik;\nb) a Bizottság - hivatalból vagy a tudományos testület által tett minősített\nriasztást követően hozott - határozata alapján az a) pontban\nmeghatározottakkal egyenértékű képességekkel vagy hatással rendelkezik,\ntekintettel a XIII. mellékletben meghatározott kritériumokra. (2) Valamely\náltalános célú MI-modellről vélelmezni kell, hogy rendelkezik az (1) bekezdés\na) pontja szerinti nagy hatású képességekkel, amikor a tanításához használt,\nlebegőpontos műveletekben mért, összesített számítási összege nagyobb, mint\n1025. (3) A Bizottság a 97. cikknek megfelelően felhatalmazáson alapuló jogi\naktusokat fogad el annak érdekében, hogy a folyamatosan változó technológiai\nfejlemények - például az algoritmusok javulása vagy a hardverhatékonyság\nfokozódása - fényében módosítsa az e cikk (1) és (2) bekezdésében felsorolt\nküszöbértékeket, valamint kiegészítse a referenciamutatókat és a\nreferenciaértékeket abból a célból, hogy ezen küszöbértékek a technika\nmindenkori állását tükrözzék. (1) Amennyiben egy általános célú MI-modell\nmegfelel az 51. cikk (1) bekezdésének a) pontjában említett feltételnek, a\nreleváns szolgáltató haladéktalanul, de legkésőbb két héttel azt követően\nértesíti a Bizottságot, hogy az említett követelmény teljesül, vagy ismertté\nválik, hogy a követelmény teljesülni fog. Az említett értesítésnek\ntartalmaznia kell az annak bizonyításához szükséges információkat, hogy a\nreleváns követelmény teljesült. Ha a Bizottság tudomást szerez egy\nrendszerszintű kockázatot jelentő általános célú MI-modellről, amelyről nem\nértesítették, dönthet úgy, hogy azt rendszerszintű kockázatot jelentő\nmodellként jelöli meg. (2) Az 51. cikk (1) bekezdésének a) pontjában említett\nfeltételnek megfelelő, általános célú MI-modell szolgáltatója az értesítésével\negyütt kellően megalapozott érveket terjeszthet elő annak bizonyítására, hogy\naz általános célú MI-modell - bár megfelel az említett követelménynek - a\nsajátos jellemzői miatt, kivételesen nem jelent rendszerszintű kockázatokat,\nés ezért nem kell rendszerszintű kockázatot jelentő általános célú MI-\nmodellként besorolni. (3) Amennyiben a Bizottság arra a következtetésre jut,\nhogy a (2) bekezdés alapján benyújtott érvek nem kellően megalapozottak, és az\nérintett szolgáltató nem tudta bizonyítani, hogy az általános célú MI-modell -\na sajátos jellemzői miatt - nem jelent rendszerszintű kockázatot, elutasítja\naz említett érveket, és az általános célú MI-modellt rendszerszintű kockázatot\njelentő általános célú MI-modellnek kell tekinteni. (4) A Bizottság -\nhivatalból vagy a tudományos testület által a 90. cikk (1) bekezdésének a)\npontja alapján tett minősített riasztást követően - a XIII. mellékletben\nmeghatározott kritériumok alapján rendszerszintű kockázatot jelentő modellként\njelölhet meg egy általános célú MI-modellt. A Bizottság felhatalmazást kap\narra, hogy a 97. cikknek megfelelően felhatalmazáson alapuló jogi aktusokat\nfogadjon el a XIII. mellékletnek az említett mellékletben meghatározott\nkritériumok pontosítása és naprakésszé tétele révén történő módosítása\ncéljából. (5) Azon szolgáltató indokolással ellátott kérésére, amelynek\nmodelljét a (4) bekezdés alapján rendszerszintű kockázatot jelentő általános\nMI-modellként jelölték meg, a Bizottság figyelembe veszi a kérelmet, és\nhatározhat úgy, hogy újraértékeli, vajon az általános célú MI-modell a XIII.\nmellékletben meghatározott kritériumok alapján továbbra is rendszerszintű\nkockázatot jelentőnek tekinthető-e. Az ilyen kérelemnek tartalmaznia kell a\nmegjelölésről szóló határozat óta felmerült objektív, részletes és új\nindokokat. A szolgáltatók legkorábban hat hónappal a megjelölésről szóló\nhatározatot követően újraértékelést kérhetnek. Amennyiben a Bizottság az\nújraértékelését követően úgy határoz, hogy fenntartja a rendszerszintű\nkockázatot jelentő általános célú MI-modellként való megjelölést, a\nszolgáltatók legkorábban hat hónappal az említett határozatot követően\nkérhetnek újraértékelést. (6) A Bizottság biztosítja a rendszerszintű\nkockázatot jelentő általános célú MI-modellek jegyzékének közzétételét, és\nnaprakészen tartja az említett jegyzéket, a szellemitulajdon-jogok és a\nbizalmas üzleti információk vagy üzleti titkok uniós és nemzeti joggal\nösszhangban történő tiszteletben tartása és védelme szükségességének sérelme\nnélkül. (1) Az általános célú MI-modellek szolgáltatóinak: a) el kell\nkészíteniük és naprakészen kell tartaniuk a modell műszaki dokumentációját,\nbeleértve annak tanítási és tesztelési folyamatát, valamint értékelésének\neredményeit, amelynek tartalmaznia kell legalább a XI. mellékletben\nmeghatározott információkat abból a célból, hogy azt kérésre az MI-hivatal és\naz illetékes nemzeti hatóságok rendelkezésére bocsássák; b) információkat és\ndokumentációt kell kidolgozniuk, naprakészen tartaniuk és rendelkezésre\nbocsátaniuk az MI-rendszerek azon szolgáltatói részére, amelyek az általános\ncélú MI-modellt be kívánják építeni MI-rendszereikbe. A szellemitulajdon-jogok\nés a bizalmas üzleti információk vagy üzleti titkok uniós és nemzeti joggal\nösszhangban történő tiszteletben tartásának és védelmének sérelme nélkül, az\ninformációknak és a dokumentációnak: i. lehetővé kell tenniük az MI-rendszerek\nszolgáltatói számára, hogy jól megértsék az általános célú MI-modell\nképességeit és korlátait, és eleget tegyenek az e rendelet szerinti\nkötelezettségeiknek; és ii. tartalmazniuk kell legalább a XII. mellékletben\nmeghatározott elemeket; c) a szerzői és kapcsolódó jogokra vonatkozó uniós\njognak való megfelelésre irányuló politikát kell bevezetniük, és különösen\nazért, hogy azonosítsák és betartsák az (EU) 2019/790 irányelv 4. cikkének (3)\nbekezdése szerint kifejezett jogfenntartást, többek között a legkorszerűbb\ntechnológiák révén; d) kellően részletes összefoglalót kell készíteniük - az\nMI-hivatal által rendelkezésre bocsátott sablonnak megfelelően - és\nközzétenniük az általános célú MI-modell tanításához használt tartalomról. (2)\nAz (1) bekezdés a) és b) pontjában meghatározott kötelezettségek nem\nalkalmazandók az olyan MI-modellek szolgáltatóira, amelyeket olyan szabad és\nnyílt forráskódú licenc alapján bocsátanak ki, amely lehetővé teszi a\nmodellhez való hozzáférést, annak használatát, módosítását és terjesztését, és\namelyek paramétereit - beleértve a súlyokat, a modell-architektúrára vonatkozó\ninformációkat és a modellhasználatra vonatkozó információkat - nyilvánosan\nhozzáférhetővé teszik. Ez a kivétel nem alkalmazandó a rendszerszintű\nkockázatot jelentő általános célú MI-modellekre. (3) Az általános célú MI-\nmodellek szolgáltatóinak szükség szerint együtt kell működniük a Bizottsággal\nés az illetékes nemzeti hatóságokkal az e rendelet szerinti hatásköreik és\njogköreik gyakorlása során. (4) Az általános célú MI-modellek szolgáltatói egy\nharmonizált szabvány közzétételéig támaszkodhatnak az 56. cikk szerinti\ngyakorlati kódexekre az e cikk (1) bekezdésében meghatározott\nkötelezettségeknek való megfelelés bizonyítása céljából. Az európai\nharmonizált szabványoknak való megfelelés a szolgáltatók számára a megfelelés\nvélelmét biztosítja annyiban, amennyiben az említett szabványok kiterjednek az\nemlített kötelezettségekre. Az általános célú MI-modellek azon\nszolgáltatóinak, amelyek nem tartanak be valamely jóváhagyott gyakorlati\nkódexet, vagy nem felelnek meg valamely európai harmonizált szabványnak, a\nBizottság általi értékelés céljából megfelelő alternatív megfelelőségi\neszközöket kell bemutatniuk. (5) A XI. mellékletnek és különösen annak 2.\npontja d) és e) alpontjának való megfelelés elősegítése érdekében a Bizottság\nfelhatalmazást kap arra, hogy a 97. cikknek megfelelően felhatalmazáson\nalapuló jogi aktusokat fogadjon el a mérési és számítási módszerek\nrészletezése céljából, hogy lehetővé tegye összehasonlítható és ellenőrizhető\ndokumentáció készítését. (6) A Bizottság felhatalmazást kap arra, hogy a 97.\ncikk (2) bekezdésének megfelelően felhatalmazáson alapuló jogi aktusokat\nfogadjon el abból a célból, hogy a technológiai fejlemények fényében módosítsa\na XI. és a XII. mellékletet. (7) Az e cikk alapján megszerzett információkat,\nilletve dokumentációt - az üzleti titkokat is beleértve - a 78. cikkben\nfoglalt titoktartási kötelezettségeknek megfelelően kell kezelni. (1) Valamely\náltalános célú MI-rendszernek az Unió piacán való forgalomba hozatalát\nmegelőzően a harmadik országokban letelepedett szolgáltatóknak írásbeli\nmeghatalmazással ki kell nevezniük egy, az Unióban letelepedett meghatalmazott\nképviselőt. (2) A szolgáltatónak lehetővé kell tennie a meghatalmazott\nképviselője számára, hogy elvégezze a szolgáltatótól kapott megbízásban\nmeghatározott feladatokat. (3) A meghatalmazott képviselőknek a szolgáltatótól\nkapott megbízásban meghatározott feladatokat kell ellátniuk. A megbízás egy\npéldányát kérésre az MI-hivatal rendelkezésére kell bocsátaniuk az Unió\nintézményeinek egyik hivatalos nyelvén. E rendelet alkalmazása céljából a\nmegbízásban fel kell hatalmazni a meghatalmazott képviselőt a következő\nfeladatok elvégzésére: a) annak ellenőrzése, hogy a XI. mellékletben\nmeghatározott műszaki dokumentációt a szolgáltató elkészítette-e, és\nteljesítette-e az 53. cikkben és - adott esetben - az 55. cikkben említett\nvalamennyi kötelezettséget; b) az általános célú MI-modell forgalomba\nhozatalát követően 10 évig a XI. mellékletben meghatározott műszaki\ndokumentáció egy példányának megőrzése az MI-hivatal és az illetékes nemzeti\nhatóságok számára, valamint a meghatalmazott képviselőt kinevező szolgáltató\nelérhetőségének megőrzése; c) indokolt kérésre az e fejezetben foglalt\nkötelezettségeknek való megfelelés igazolásához szükséges valamennyi\ninformációnak és dokumentációnak - ideértve a b) pontban említetteket is - az\nMI-hivatal rendelkezésére bocsátása; d) indokolt kérésre együttműködés az MI-\nhivatallal és az illetékes hatóságokkal az általuk a rendszerszintű kockázatot\njelentő általános célú MI-modellel kapcsolatban hozott minden intézkedés\ntekintetében, ideértve azt is, amikor a modellt az Unióban forgalomba hozott\nvagy üzembe helyezett MI-rendszerekbe integrálják. (4) A megbízásban fel kell\nhatalmazni a meghatalmazott képviselőt arra, hogy az MI-hivatal vagy az\nilletékes hatóságok hozzá fordulhassanak - a szolgáltató mellett vagy helyett\n- az e rendeletnek való megfelelés biztosításával kapcsolatos minden kérdést\nilletően. (5) A meghatalmazott képviselőnek meg kell szüntetnie a megbízást,\nha úgy ítéli meg, vagy oka van úgy megítélni, hogy a szolgáltató az e rendelet\nszerinti kötelezettségeivel ellentétesen jár el. Ilyen esetben a megbízás\nmegszüntetéséről és annak okairól haladéktalanul tájékoztatnia kell az MI-\nhivatalt is. (6) Az e cikkben meghatározott kötelezettségek nem alkalmazandók\naz olyan, általános célú MI-modellek szolgáltatóira, amelyeket olyan szabad és\nnyílt forráskódú licenc alapján bocsátanak ki, amely lehetővé teszi a\nmodellhez való hozzáférést, annak használatát, módosítását és terjesztését, és\namelyek paramétereit - beleértve a súlyokat, a modell-architektúrára vonatkozó\ninformációkat és a modellhasználatra vonatkozó információkat - nyilvánosan\nhozzáférhetővé teszik, kivéve, ha az általános célú MI-modell rendszerszintű\nkockázatot jelent. (1) Az 53. és az 54. cikkben felsorolt kötelezettségeken\ntúlmenően, a rendszerszintű kockázatot jelentő általános célú MI-modellek\nszolgáltatóinak: a) modellértékelést kell végezniük a technika állásának\nmegfelelő, szabványosított protokollokkal és eszközökkel összhangban, ideértve\na modell támadó szempontú tesztelésének elvégzését és dokumentálását a\nrendszerszintű kockázatok azonosítása és enyhítése céljából; b) értékelniük és\nenyhíteniük kell az esetlegesen a rendszerszintű kockázatot jelentő általános\ncélú MI-modellek fejlesztéséből, forgalomba hozatalából vagy használatából\neredő lehetséges, uniós szintű rendszerszintű kockázatokat, beleértve azok\nforrásait is; c) nyomon kell követniük, dokumentálniuk kell és indokolatlan\nkésedelem nélkül jelenteniük kell az MI-hivatal és adott esetben az illetékes\nnemzeti hatóságok részére a súlyos váratlan eseményekre és az azok kezelésére\nszolgáló lehetséges korrekciós intézkedésekre vonatkozó releváns\ninformációkat; d) megfelelő szintű kiberbiztonsági védelmet kell biztosítaniuk\na rendszerszintű kockázatot jelentő általános célú MI-modell és a modell\nfizikai infrastruktúrája számára. (2) A rendszerszintű kockázatot jelentő\náltalános célú MI-modellek szolgáltatói egy harmonizált szabvány közzétételéig\ntámaszkodhatnak az 56. cikk szerinti gyakorlati kódexekre az e cikk (1)\nbekezdésében meghatározott kötelezettségeknek való megfelelés bizonyítása\ncéljából. A európai harmonizált szabványoknak való megfelelés a szolgáltatók\nszámára a megfelelés vélelmét biztosítja annyiban, amennyiben az említett\nszabványok kiterjednek az említett kötelezettségekre. A rendszerszintű\nkockázatot jelentő általános célú MI-modellek azon szolgáltatóinak, amelyek\nnem tartanak be valamely jóváhagyott gyakorlati kódexet, vagy nem felelnek meg\negy európai harmonizált szabványnak, a Bizottság általi értékelés céljából\nmegfelelő alternatív megfelelőségi eszközöket kell bemutatniuk. (3) Az e cikk\nalapján megszerzett információkat, illetve dokumentációt - az üzletit titkokat\nis beleértve - a 78. cikkben foglalt titoktartási kötelezettségeknek\nmegfelelően kell kezelni. (1) Az MI-hivatalnak ösztönöznie kell és elő kell\nsegítenie uniós szintű gyakorlati kódexek kidolgozását annak érdekében, hogy\nhozzájáruljon e rendelet megfelelő alkalmazásához, figyelembe véve a\nnemzetközi megközelítéseket. (2) Az MI-hivatalnak és a Testületnek törekednie\nkell annak biztosítására, hogy a gyakorlati kódexek kiterjedjenek legalább az\n53. és az 55. cikkben meghatározott kötelezettségekre, beleértve a következő\nkérdéseket: a) az annak biztosítására szolgáló eszközök, hogy az 53. cikk (1)\nbekezdésének a) és b) pontjában említett információkat a piaci és technológiai\nfejlemények fényében naprakészen tartsák; b) a tanításhoz használt tartalomról\nszóló összefoglaló megfelelő szintű részletessége; c) az uniós szintű\nrendszerszintű kockázatok típusának és jellegének azonosítása, beleértve adott\nesetben azok forrásait is; d) az uniós szintű rendszerszintű kockázatok\nértékelésére és kezelésére vonatkozó olyan intézkedések, eljárások és\nmodalitások, ideértve azok dokumentációját is, amelyeknek arányosnak kell\nlenniük a kockázatokkal, figyelembe kell venniük azok súlyosságát és\nvalószínűségét, és figyelembe kell venniük az e kockázatok kezelésével\nkapcsolatos sajátos kihívásokat, tekintetbe véve az ilyen kockázatok\nfelmerülésének és megvalósulásának lehetséges módjait az MI-értéklánc mentén.\n(3) Az MI-hivatal felkérheti az általános célú MI-modellek valamennyi\nszolgáltatóját, valamint az érintett illetékes nemzeti hatóságokat, hogy\nvegyenek részt gyakorlati kódexek kidolgozásában. A civil társadalmi\nszervezetek, az ipar, a tudományos élet és más érintett érdekelt felek,\npéldául a downstream szolgáltatók és a független szakértők támogathatják a\nfolyamatot. (4) Az MI-hivatalnak és a Testületnek törekednie kell annak\nbiztosítására, hogy a gyakorlati kódexek egyértelműen meghatározzák egyedi\ncélkitűzéseiket, és az e célkitűzések elérésének biztosítására irányuló\nkötelezettségvállalásokat vagy intézkedéseket tartalmazzanak, beleértve adott\nesetben fő teljesítménymutatókat is, valamint hogy uniós szinten kellően\nfigyelembe vegyék valamennyi érdekelt fél - köztük az érintett személyek -\nszükségleteit és érdekeit. (5) Az MI-hivatalnak törekednie kell annak\nbiztosítására, hogy a gyakorlati kódexek résztvevői rendszeresen beszámoljanak\naz MI-hivatalnak a kötelezettségvállalások végrehajtásáról, valamint a\nmeghozott intézkedésekről és azok eredményeiről, adott esetben a fő\nteljesítménymutatókkal összevetve is. A fő teljesítménymutatóknak és a\njelentéstételi kötelezettségvállalásoknak tükrözniük kell a különböző\nrésztvevők mérete és kapacitása közötti különbségeket. (6) Az MI-hivatalnak és\na Testületnek rendszeresen nyomon kell követnie és értékelnie kell a\ngyakorlati kódexek célkitűzéseinek a résztvevők általi teljesítését, valamint\naz e rendelet megfelelő alkalmazásához való hozzájárulásukat. Az MI-hivatalnak\nés a Testületnek értékelnie kell, hogy a gyakorlati kódexek kiterjednek-e az\n53. és az 55. cikkben meghatározott kötelezettségekre, és rendszeresen nyomon\nkell követnie és értékelnie kell a kódexekben foglalt célkitűzések elérését. A\ngyakorlati kódexek megfelelőségéről szóló értékelésüket közzé kell tenniük. A\nBizottság végrehajtási jogi aktus útján jóváhagyhatja a gyakorlati kódexet, és\nazt az Unión belül általánosan érvényessé nyilváníthatja. Ezt a végrehajtási\njogi aktust a 98. cikk (2) bekezdésében említett vizsgálóbizottsági eljárás\nkeretében kell elfogadni. (7) Az MI-hivatal felkérheti az általános célú MI-\nmodellek valamennyi szolgáltatóját, hogy tartsák be a gyakorlati kódexekben\nfoglaltakat. A rendszerszintű kockázatot nem jelentő általános célú MI-\nmodellek szolgáltatói esetében a kódexek ezen betartása az 53. cikkben\nmeghatározott kötelezettségekre korlátozódhat, kivéve, ha kifejezetten\nkinyilvánítják a teljes kódexhez való csatlakozás iránti szándékukat. (8) Az\nMI-hivatalnak adott esetben ösztönöznie kell és elő kell segítenie a\ngyakorlati kódexek felülvizsgálatát és kiigazítását, különösen az újonnan\nmegjelenő szabványokra figyelemmel. Az MI-hivatalnak segítséget kell nyújtania\na rendelkezésre álló szabványok értékeléséhez. (9) A gyakorlati kódexeknek\nlegkésőbb 2025. május 2-ig el kell készülniük. Az MI-hivatalnak meg kell\ntennie a szükséges lépéseket, beleértve a szolgáltatók (7) bekezdés szerinti\nfelkérését is. Ha 2025. augusztus 2-ig nem véglegesíthető valamely gyakorlati\nkódex, vagy ha az MI-hivatal annak e cikk (6) bekezdése szerinti értékelését\nkövetően úgy ítéli meg, hogy az nem megfelelő, a Bizottság végrehajtási jogi\naktusok útján közös szabályokat állapíthat meg az 53. és az 55. cikkben\nmeghatározott kötelezettségek végrehajtására vonatkozóan, beleértve az e cikk\n(2) bekezdésében meghatározott kérdéseket is. Ezeket a végrehajtási jogi\naktusokat a 98. cikk (2) bekezdésében említett vizsgálóbizottsági eljárás\nkeretében kell elfogadni. (1) A tagállamok biztosítják, hogy illetékes\nhatóságaik nemzeti szinten legalább egy MI szabályozói tesztkörnyezetet\nhozzanak létre, amelynek 2026. augusztus 2-re működőképesnek kell lennie. Az\nemlített tesztkörnyezetet egy vagy több másik tagállam illetékes hatóságaival\nközösen is létre lehet hozni. A Bizottság technikai támogatást, tanácsadást és\neszközöket biztosíthat az MI szabályozói tesztkörnyezetek létrehozásához és\nműködtetéséhez. Az első albekezdés szerinti kötelezettség egy meglévő\ntesztkörnyezetben való részvétellel is teljesíthető, amennyiben ez a részvétel\nazonos szintű nemzeti lefedettséget biztosít a részt vevő tagállamok számára.\n(2) További MI szabályozói tesztkörnyezeteket is létre lehet hozni regionális\nvagy helyi szinten, vagy más tagállamok illetékes hatóságaival közösen. (3) Az\neurópai adatvédelmi biztos szintén létrehozhat MI szabályozói tesztkörnyezetet\naz uniós intézmények, szervek, hivatalok és ügynökségek számára, és e\nfejezettel összhangban gyakorolhatja az illetékes nemzeti hatóságok szerepét\nés feladatait. (4) A tagállamok biztosítják, hogy az (1) és a (2) bekezdésben\nemlített illetékes hatóságok elegendő forrást különítsenek el az e cikknek\nvaló tényleges és kellő időben történő megfelelés érdekében. Az illetékes\nnemzeti hatóságoknak adott esetben együtt kell működniük más érintett\nhatóságokkal, és lehetővé tehetik az MI-ökoszisztémán belüli más szereplők\nbevonását. Ez a cikk nem érinthet a nemzeti vagy uniós jog alapján létrehozott\negyéb szabályozói tesztkörnyezeteket. A tagállamok megfelelő szintű\negyüttműködést biztosítanak az említett egyéb szabályozói tesztkörnyezeteket\nfelügyelő hatóságok és az illetékes nemzeti hatóságok között. (5) Az (1)\nbekezdés értelmében létrehozott MI szabályozói tesztkörnyezeteknek olyan\nellenőrzött környezetet kell biztosítaniuk, amely előmozdítja az innovációt,\nés korlátozott ideig elősegíti az innovatív MI-rendszerek fejlesztését,\ntesztelését és validálását azok forgalomba hozatala vagy üzembe helyezése\nelőtt, a szolgáltatók vagy a leendő szolgáltatók és az illetékes hatóság\nközötti megállapodás szerinti, a tesztkörnyezetre vonatkozó egyedi terv\nalapján. Az ilyen tesztkörnyezetek kiterjedhetnek az azokban felügyelt, valós\nkörülmények közötti tesztelésre. (6) Az illetékes hatóságoknak adott esetben\niránymutatást, felügyeletet és támogatást kell biztosítaniuk az MI szabályozói\ntesztkörnyezeten belül a kockázatok azonosítása céljából, különösen az\nalapvető jogok, az egészség és a biztonság, a tesztelési és kockázatcsökkentő\nintézkedések, valamint azok hatékonysága tekintetében az e rendeletben és\nadott esetben a tesztkörnyezetben felügyelt egyéb uniós és nemzeti\njogszabályokban foglalt kötelezettségekkel és követelményekkel kapcsolatban.\n(7) Az illetékes hatóságoknak iránymutatást kell nyújtaniuk az MI szabályozói\ntesztkörnyezetben részt vevő szolgáltatók és leendő szolgáltatók számára a\nszabályozási elvárásokról és az e rendeletben meghatározott követelmények és\nkötelezettségek teljesítésének módjáról. Az MI-rendszer szolgáltatójának vagy\nleendő szolgáltatójának kérésére az illetékes hatóságnak írásbeli bizonyítékot\nkell szolgáltatnia a tesztkörnyezetben sikeresen elvégzett tevékenységekről.\nAz illetékes hatóságnak kilépési jelentést is kell készítenie, amelyben\nrészletezi a tesztkörnyezetben elvégzett tevékenységeket, valamint a\nkapcsolódó eredményeket és tanulási eredményeket. A szolgáltatók az ilyen\ndokumentációt felhasználhatják arra, hogy a megfelelőségértékelési eljárás\nvagy a vonatkozó piacfelügyeleti tevékenységek során igazolják az e\nrendeletnek való megfelelésüket. E tekintetben a piacfelügyeleti hatóságoknak\nés a bejelentett szervezeteknek pozitívan figyelembe kell venniük az illetékes\nnemzeti hatóság által benyújtott kilépési jelentéseket és írásbeli\nbizonyítékokat a megfelelőségértékelési eljárások észszerű mértékű\nfelgyorsítása érdekében. (8) A Bizottság és a Testület - a 78. cikkben foglalt\ntitoktartási rendelkezésekre is figyelemmel, és a szolgáltató vagy a leendő\nszolgáltató egyetértésével - jogosult hozzáférni a kilépési jelentésekhez, és\nazokat adott esetben figyelembe veszi az e rendelet szerinti feladatai\nellátása során. Ha mind a szolgáltató vagy a leendő szolgáltató, mind az\nilletékes nemzeti hatóság ehhez kifejezetten hozzájárul, a kilépési jelentés\nnyilvánosan hozzáférhetővé tehető az e cikkben említett egységes információs\nplatformon keresztül. (9) Az MI szabályozói tesztkörnyezetek létrehozásának\nazt kell céloznia, hogy hozzájáruljon a következő célkitűzésekhez: a) a\njogbiztonság javítása az e rendeletnek vagy adott esetben más alkalmazandó\nuniós és nemzeti jognak való megfelelés elérése érdekében; b) az MI\nszabályozói tesztkörnyezetben részt vevő hatóságokkal való együttműködés révén\nhozzájárulás a legjobb gyakorlatok megosztásához; c) az innováció és a\nversenyképesség ösztönzése, valamint egy MI-ökoszisztéma kialakításának\nmegkönnyítése; d) hozzájárulás a szabályozó hatóságok általi, tényeken alapuló\ntanuláshoz; e) az MI-rendszerek uniós piacra jutásának megkönnyítése és\nfelgyorsítása, különösen akkor, ha azokat kkv-k, köztük induló innovatív\nvállalkozások biztosítják. (10) Az illetékes nemzeti hatóságok biztosítják,\nhogy amennyiben az innovatív MI-rendszerek személyes adatok kezelésével\njárnak, vagy egyébként az adatokhoz való hozzáférést biztosító vagy támogató\nmás nemzeti hatóságok vagy illetékes hatóságok felügyeleti hatáskörébe\ntartoznak, a nemzeti adatvédelmi hatóságok és az említett más nemzeti vagy\nilletékes hatóságok részt vegyenek az MI szabályozói tesztkörnyezet\nműködtetésében, továbbá feladataiknak és hatásköreiknek megfelelően részt\nvegyenek e szempontok felügyeletében. (11) Az MI szabályozói tesztkörnyezetek\nnem érinthetik a tesztkörnyezeteket - többek között regionális vagy helyi\nszinten - felügyelő illetékes hatóságok felügyeleti és korrekciós hatásköreit.\nAmennyiben az ilyen MI-rendszerek fejlesztése és tesztelése során az\negészséget és a biztonságot, valamint az alapvető jogokat érintő jelentős\nkockázatok merülnek fel, azokat megfelelően csökkenteni kell. Az illetékes\nnemzeti hatóságoknak hatáskörrel kell rendelkezniük arra, hogy ideiglenesen\nvagy véglegesen felfüggesszék a tesztelési folyamatot vagy a tesztkörnyezetben\nvaló részvételt, ha nincs lehetőség hatékony kockázatcsökkentésre, és erről a\ndöntésről tájékoztatniuk kell az MI-hivatalt. Az illetékes nemzeti\nhatóságoknak a vonatkozó jogszabályok keretein belül, mérlegelési jogkörükkel\nélve kell gyakorolniuk felügyeleti hatásköreiket, amikor jogi rendelkezéseket\nhajtanak végre egy konkrét MI szabályozóitesztkörnyezet-projekt vonatkozásában\nazzal a céllal, hogy támogassák az MI-vel kapcsolatos innovációt az Unióban.\n(12) Az MI szabályozói tesztkörnyezetben részt vevő szolgáltatóknak és leendő\nszolgáltatóknak a felelősségvállalásra alkalmazandó uniós és nemzeti\njogszabályok értelmében továbbra is felelősséggel kell tartozniuk a\ntesztkörnyezetben való kísérletezés következtében harmadik feleknek okozott\nminden kárért. Azonban feltéve, hogy a leendő szolgáltatók tiszteletben\ntartják az egyedi tervet és részvételük feltételeit, és jóhiszeműen követik az\nilletékes nemzeti hatóság által adott iránymutatást, a hatóságok nem\nszabhatnak ki közigazgatási bírságot e rendelet megsértése miatt. Amennyiben\naz egyéb uniós és nemzeti jogszabályokért felelős más illetékes hatóságok\naktívan részt vettek az MI-rendszernek a tesztkörnyezetben történő\nfelügyeletében, és iránymutatást nyújtottak a megfelelésre vonatkozóan, az\nemlített jogszabály tekintetében nem szabható ki közigazgatási bírság. (13) Az\nMI szabályozói tesztkörnyezeteket úgy kell megtervezni és kialakítani, hogy\nazok adott esetben megkönnyítsék az illetékes nemzeti hatóságok közötti,\nhatárokon átnyúló együttműködést. (14) Az illetékes nemzeti hatóságoknak össze\nkell hangolniuk tevékenységeiket és együtt kell működniük a Testület\nkeretében. (15) Az illetékes nemzeti hatóságoknak tájékoztatniuk kell az MI-\nhivatalt és a Testületet a tesztkörnyezet létrehozásáról, és támogatást és\niránymutatást kérhetnek azoktól. Az MI-hivatalnak nyilvánosan hozzáférhetővé\nkell tennie és naprakészen kell tartania a tervezett és meglévő\ntesztkörnyezetek jegyzékét annak érdekében, hogy ösztönözze az MI szabályozói\ntesztkörnyezetekben való nagyobb számú interakciót és a határokon átnyúló\negyüttműködést. (16) Az illetékes nemzeti hatóságoknak éves jelentéseket kell\nbenyújtaniuk az MI-hivatal és a Testület részére az MI szabályozói\ntesztkörnyezet létrehozását követő egy év elteltétől kezdődően, majd azt\nkövetően annak megszüntetéséig évente, valamint zárójelentést kell\nbenyújtaniuk. Az említett jelentésekben tájékoztatást kell nyújtani az\nemlített tesztkörnyezetek megvalósításának előrehaladásáról és eredményeiről,\nbeleértve a legjobb gyakorlatokat, a súlyos váratlan eseményeket, a levont\ntanulságokat és a kialakításukra vonatkozó ajánlásokat, valamint adott esetben\ne rendelet - ideértve a kapcsolódó felhatalmazáson alapuló és végrehajtási\njogi aktusokat - alkalmazásáról és esetleges módosításáról, továbbá a\ntesztkörnyezetben az illetékes hatóságok által felügyelt egyéb uniós\njogszabályok alkalmazásáról. Az illetékes nemzeti hatóságoknak ezeket az éves\njelentéseket vagy azok kivonatait online elérhetővé kell tenniük a\nnyilvánosság számára. A Bizottság az e rendelet szerinti feladatai ellátása\nsorán adott esetben figyelembe veszi az éves jelentéseket. (17) A Bizottság\negységes és célzott interfészt dolgoz ki, amely tartalmazza az MI szabályozói\ntesztkörnyezetekkel kapcsolatos valamennyi releváns információt, hogy lehetővé\ntegye az érdekelt felek számára, hogy interakciót folytassanak az MI\nszabályozói tesztkörnyezetekkel, és kérdéseket intézzenek az illetékes\nhatóságokhoz, valamint hogy a 62. cikk (1) bekezdésének c) pontjával\nösszhangban nem kötelező erejű iránymutatást kérjenek az MI-technológiákon\nalapuló innovatív termékek, szolgáltatások és üzleti modellek\nmegfelelőségéről. A Bizottság adott esetben proaktív koordinációt folytat az\nilletékes nemzeti hatóságokkal is. (1) Az Unión belüli széttagoltság\nelkerülése érdekében a Bizottság végrehajtási jogi aktusokat fogad el,\namelyekben meghatározza az MI szabályozói tesztkörnyezetek létrehozására,\nfejlesztésére, megvalósítására, működtetésére és felügyeletére vonatkozó\nrészletes szabályokat. E végrehajtási jogi aktusoknak közös elveket kell\ntartalmazniuk a következő kérdésekre vonatkozóan: a) az MI szabályozói\ntesztkörnyezetben való részvételre való jogosultság és kiválasztás\nkritériumai; b) az MI szabályozói tesztkörnyezet alkalmazására, az abban való\nrészvételre, annak nyomon követésére, az abból való kilépésre és a\nmegszüntetésére vonatkozó eljárások, beleértve a tesztkörnyezetre vonatkozó\ntervet és a kilépési jelentést is; c) a résztvevőkre alkalmazandó feltételek.\nE végrehajtási jogi aktusokat a 98. cikk (2) bekezdésében említett\nvizsgálóbizottsági eljárás keretében kell elfogadni. (2) Az (1) bekezdésben\nemlített végrehajtási jogi aktusoknak biztosítaniuk kell, hogy: a) az MI\nszabályozói tesztkörnyezetek nyitva álljanak bármely olyan MI-rendszer-\nszolgáltató vagy leendő MI-rendszer-szolgáltató előtt, amely megfelel a\ntámogathatósági és kiválasztási kritériumoknak, amelyeknek átláthatónak és\nméltányosnak kell lenniük, valamint hogy az illetékes nemzeti hatóságok a\nkérelem benyújtásától számított három hónapon belül tájékoztassák a\nkérelmezőket döntésükről; b) a szabályozói tesztkörnyezetek széles körű és\negyenlő hozzáférést tegyenek lehetővé, és lépést tartsanak a részvételre\nirányuló kereslettel; a szolgáltatók és a leendő szolgáltatók az alkalmazókkal\nés más releváns harmadik felekkel partnerségben is benyújthatnak kérelmeket;\nc) az MI szabályozói tesztkörnyezetekre vonatkozó részletes szabályok és\nfeltételek a lehető legnagyobb mértékben támogassák az illetékes nemzeti\nhatóságok számára az MI szabályozói tesztkörnyezeteik létrehozásához és\nműködtetéséhez szükséges rugalmasságot; d) az MI szabályozói\ntesztkörnyezetekhez való hozzáférés ingyenes legyen a kkv-k - köztük az induló\ninnovatív vállalkozások - számára, azon rendkívüli költségek sérelme nélkül,\namelyeket az illetékes nemzeti hatóságok méltányos és arányos módon\nbehajthatnak; e) az MI szabályozói tesztkörnyezetek tanulási eredményei révén\nkönnyítsék meg a szolgáltatók és a leendő szolgáltatók számára az e rendelet\nszerinti megfelelőségértékelési kötelezettségeknek való megfelelést és a 95.\ncikkben említett magatartási kódexek önkéntes alkalmazását; f) az MI\nszabályozói tesztkörnyezetek megkönnyítsék más érintett szereplők - például a\nbejelentett szervezetek és a szabványügyi szervezetek, a kkv-k, ideértve az\ninduló innovatív vállalkozásokat is, a vállalkozások, az innovátorok, a\ntesztelési és kísérleti létesítmények, a kutatási és kísérleti laboratóriumok\nés a digitális innovációs központok, a kiválósági központok, az egyéni kutatók\n- bevonását az MI-ökoszisztémán belül a köz- és a magánszektorral való\negyüttműködés lehetővé tétele és megkönnyítése érdekében; g) a kérelmezésre,\nkiválasztásra, részvételre és az MI szabályozói tesztkörnyezetből való\nkilépésre vonatkozó eljárások, folyamatok és adminisztratív követelmények\negyszerűek, könnyen érthetők és egyértelműen kommunikáltak legyenek a\nkorlátozott jogi és adminisztratív kapacitásokkal rendelkező kkv-k - köztük az\ninduló innovatív vállalkozások - részvételének megkönnyítése érdekében, és az\negész Unióban észszerűsítettek legyenek, hogy elkerülhető legyen a\nszéttagoltság, és hogy a valamely tagállam vagy az európai adatvédelmi biztos\náltal létrehozott MI szabályozói tesztkörnyezetben való részvétel kölcsönösen\nés egységesen elismert legyen, és Unió-szerte azonos joghatással járjon; h) az\nMI szabályozói tesztkörnyezetben való részvétel olyan időtartamra\nkorlátozódjon, amely megfelel a projekt összetettségének és nagyságrendjének,\nés amelyet az illetékes nemzeti hatóság meghosszabbíthat; i) az MI szabályozói\ntesztkörnyezetek megkönnyítsék az MI-rendszerek azon dimenziói - így például a\npontosság, a megbízhatóság és a kiberbiztonság - tesztelésére, összehasonlító\nteljesítményértékelésére, értékelésére és magyarázatára szolgáló eszközök és\ninfrastruktúra fejlesztését, amelyek a szabályozó hatóságok általi tanulás\nszempontjából relevánsak, valamint az alapvető jogokat és a társadalom egészét\nérintő kockázatok enyhítését célzó intézkedéseket. (3) Az MI szabályozói\ntesztkörnyezetekben a leendő szolgáltatókat, különösen a kkv-kat és az induló\ninnovatív vállalkozásokat, adott esetben a telepítést megelőző\nszolgáltatásokhoz - mint például az e rendelet végrehajtásával kapcsolatos\niránymutatás -, más értéknövelő szolgáltatásokhoz - mint például a\nszabványosítási dokumentumokkal és a tanúsítással kapcsolatos segítségnyújtás\n-, tesztelési és kísérleti létesítményekhez, az európai digitális innovációs\nközpontokhoz és a kiválósági központokhoz kell irányítani. (4) Amennyiben az\nilletékes nemzeti hatóságok az e cikk alapján létrehozandó MI szabályozói\ntesztkörnyezet keretrendszerében felügyelt, valós körülmények közötti\ntesztelés engedélyezését mérlegelik, kifejezetten meg kell állapodniuk a\nrésztvevőkkel az ilyen tesztelés feltételeiről és különösen a megfelelő\nbiztosítékokról, az alapvető jogok, az egészség és a biztonság védelme\ncéljából. Adott esetben együtt kell működniük más illetékes nemzeti\nhatóságokkal annak érdekében, hogy Unió-szerte biztosítsák a következetes\ngyakorlatokat. (1) Az MI szabályozói tesztkörnyezetben a más célból jogszerűen\ngyűjtött személyes adatokat kizárólag bizonyos MI-rendszereknek a\ntesztkörnyezetben való kifejlesztése, betanítása és tesztelése céljából, a\nkövetkező feltételek mindegyikének teljesülése esetén lehet kezelni: a) az MI-\nrendszereket valamely hatóságnak vagy más természetes vagy jogi személynek a\njelentős közérdek védelme érdekében és a következők közül egy vagy több\nterületen kell kifejlesztenie: i. közbiztonság és népegészségügy, beleértve a\nbetegségek kimutatását, diagnózisát, megelőzését, felügyeletét és kezelését,\nvalamint az egészségügyi rendszerek javítását; ii. a környezet minőségének\nmagas szintű védelme és javítása, a biológiai sokféleség védelme, a szennyezés\nelleni védelem, a zöld átállásra irányuló intézkedések, valamint az\néghajlatváltozás mérséklése és az ahhoz való alkalmazkodás; iii. fenntartható\nenergia; iv. a közlekedési rendszerek és a mobilitás, a kritikus\ninfrastruktúrák és a hálózatok biztonsága és rezilienciája; v. a közigazgatás\nés a közszolgáltatások hatékonysága és minősége; b) a kezelt adatok a III.\nfejezet 2. szakaszában említett egy vagy több követelménynek való\nmegfeleléshez szükségesek, amennyiben e követelmények ténylegesen nem\nteljesíthetők anonimizált, szintetikus vagy egyéb nem személyes adatok\nkezelésével; c) hatékony nyomonkövetési mechanizmusok állnak rendelkezésre\nannak megállapítására, hogy a tesztkörnyezettel kapcsolatos kísérletek során\nfelmerülhetnek-e az érintettek jogait és szabadságát fenyegető jelentős\nkockázatok, az (EU) 2016/679 rendelet 35. cikkében és az (EU) 2018/1725\nrendelet 39. cikkében említettek szerint, valamint hogy rendelkezésre állnak-e\nolyan reagálási mechanizmusok, amelyek e kockázatok azonnali enyhítésére és\nszükség esetén az adatkezelés leállítására szolgálnak; d) a tesztkörnyezettel\nösszefüggésben kezelendő személyes adatok funkcionálisan különálló,\nelszigetelt és védett, a leendő szolgáltató ellenőrzése alatt álló\nadatkezelési környezetben vannak, és csak az arra jogosult személyek férnek\nhozzá ezekhez az adatokhoz; e) a szolgáltatók kizárólag az uniós adatvédelmi\njoggal összhangban jogosultak az eredetileg gyűjtött adatok további\nmegosztására; a tesztkörnyezetben létrehozott személyes adatok nem oszthatók\nmeg a tesztkörnyezeten kívül; f) a személyes adatoknak a tesztkörnyezettel\nösszefüggésben végzett kezelése nem vezet az érintettekre vonatkozó\nintézkedésekhez vagy határozatokhoz, és nem érinti a személyes adatok\nvédelméről szóló uniós jogban meghatározott jogaik alkalmazását sem; g) a\ntesztkörnyezettel összefüggésben kezelt személyes adatok megfelelő technikai\nés szervezeti intézkedések útján védelem alatt állnak, illetve törlésre\nkerülnek, miután a tesztkörnyezetben való részvétel véget ért, vagy a\nszemélyes adatok megőrzési időszaka lejárt; h) a tesztkörnyezettel\nösszefüggésben végzett személyesadat-kezelés naplóit a tesztkörnyezetben való\nrészvétel időtartama alatt megőrzik, kivéve, ha az uniós vagy nemzeti jog\nmásképp rendelkezik; i) a folyamat teljes körű és részletes leírását, valamint\naz MI-rendszer betanításának, tesztelésének és validálásának indokolását a IV.\nmellékletben említett műszaki dokumentáció részeként, a tesztelés\neredményeivel együtt megőrzik; j) a tesztkörnyezetben fejlesztett MI-projekt\nrövid összefoglalását, célkitűzéseit és várt eredményeit közzéteszik az\nilletékes hatóságok honlapján; ez a kötelezettség nem terjedhet ki a\nbűnüldöző, a határellenőrzési, a bevándorlási vagy a menekültügyi hatóságok\ntevékenységeivel kapcsolatos érzékeny operatív adatokra. (2) Bűncselekmények\nmegelőzése, nyomozása, felderítése, büntetőeljárás alá vonása vagy büntetőjogi\nszankciók végrehajtása - többek között a közbiztonságot fenyegető veszélyekkel\nszembeni védelem és azok megelőzése - céljából az MI szabályozói\ntesztkörnyezetekben a személyes adatok kezelését az adott uniós vagy nemzeti\njog alapján és az (1) bekezdésben említettekkel azonos feltételek együttes\nteljesülése függvényében kell végezni, a bűnüldöző hatóságok ellenőrzése és\nfelelőssége mellett. (3) Az (1) bekezdés nem érinti azt az uniós vagy nemzeti\njogot, amely kizárja a személyes adatoknak az adott jogban kifejezetten\nemlített céloktól eltérő célokból történő kezelését, valamint az innovatív MI-\nrendszerek fejlesztéséhez, teszteléséhez vagy betanításához szükséges\nszemélyesadat-kezelés alapját meghatározó uniós vagy nemzeti jogot vagy\nbármely más jogalapot, megfelelve a személyes adatok védelmére vonatkozó uniós\njognak. (1) A nagy kockázatú MI-rendszerek valós körülmények közötti, az MI\nszabályozói tesztkörnyezeteken kívül történő tesztelését a III. mellékletben\nfelsorolt nagy kockázatú MI-rendszerek szolgáltatói vagy leendő szolgáltatói\nvégezhetik e cikkel és az e cikkben említett, valós körülmények közötti\ntesztelésre vonatkozó tervvel összhangban, az 5. cikk szerinti tilalmak\nsérelme nélkül. A Bizottság végrehajtási jogi aktusok révén határozza meg a\nvalós körülmények közötti tesztelésre vonatkozó terv részletes elemeit. E\nvégrehajtási jogi aktusokat a 98. cikk (2) bekezdésében említett\nvizsgálóbizottsági eljárás keretében kell elfogadni. E bekezdés nem érinti az\nI. mellékletben felsorolt uniós harmonizációs jogszabályok hatálya alá tartozó\ntermékekhez kapcsolódó nagy kockázatú MI-rendszerek valós körülmények közötti\ntesztelésére vonatkozó uniós vagy nemzeti jogot. (2) A szolgáltatók vagy a\nleendő szolgáltatók a III. mellékletben említett nagy kockázatú MI-rendszerek\nforgalomba hozatala vagy üzembe helyezése előtt saját maguk, vagy egy vagy\ntöbb alkalmazóval vagy leendő alkalmazóval partnerségben bármikor elvégezhetik\naz MI-rendszer valós körülmények közötti tesztelését. (3) A nagy kockázatú MI-\nrendszerek e cikk szerinti, valós körülmények közötti tesztelése nem sértheti\naz uniós vagy nemzeti jog által előírt etikai felülvizsgálatot. (4) A\nszolgáltatók vagy a leendő szolgáltatók csak akkor végezhetnek valós\nkörülmények közötti tesztelést, ha a következő feltételek mindegyike teljesül:\na) a szolgáltató vagy a leendő szolgáltató elkészítette a valós körülmények\nközötti tesztelésre vonatkozó tervet, és azt benyújtotta azon tagállam\npiacfelügyeleti hatóságához, amelyben a valós körülmények közötti tesztelésre\nsor kell, hogy kerüljön; b) azon tagállam piacfelügyeleti hatósága, amelyben a\nvalós körülmények közötti tesztelésre sor kell, hogy kerüljön, jóváhagyta a\nvalós körülmények közötti tesztelést és a valós körülmények közötti\ntesztelésre vonatkozó tervet; amennyiben a piacfelügyeleti hatóság 30 napon\nbelül nem ad választ, a valós körülmények közötti tesztelést és a valós\nkörülmények közötti tesztelésre vonatkozó tervet jóváhagyottnak kell\ntekinteni; amennyiben a nemzeti jog nem rendelkezik a hallgatólagos\njóváhagyásról, a valós körülmények közötti tesztelést továbbra is engedélyhez\nkell kötni; c) a szolgáltató vagy a leendő szolgáltató - a bűnüldözés, a\nmigráció, a menekültügy és a határellenőrzés területén használt, a III.\nmelléklet 1., 6. és 7. pontjában említett nagy kockázatú MI-rendszerek,\nvalamint a III. melléklet 2. pontjában említett nagy kockázatú MI-rendszerek\nszolgáltatói vagy leendő szolgáltatói kivételével - a valós körülmények\nközötti tesztelést a 71. cikk (4) bekezdésével összhangban - egy Unió-szerte\negységes, egyedi azonosító számmal és a IX. mellékletben meghatározott\ninformációkkal együtt - rögzítette; a bűnüldözés, a migráció, a menekültügy és\na határellenőrzés területén használt, a III. melléklet 1., 6. és 7. pontjában\nemlített nagy kockázatú MI-rendszerek szolgáltatója vagy leendő szolgáltatója\na valós körülmények közötti tesztelést - a 49. cikk (4) bekezdésének d)\npontjával összhangban - az uniós adatbázis biztonságos nem nyilvános részében\nrögzítette egy Unió-szerte egységes, egyedi azonosító számmal és az ott\nmeghatározott információkkal együtt; a III. melléket 2. pontjában említett\nnagy kockázatú MI-rendszerek szolgáltatója vagy leendő szolgáltatója a valós\nkörülmények közötti tesztelést - a 49. cikk (5) bekezdésével összhangban -\nrögzítette; d) a tesztelést valós körülmények között végző szolgáltató vagy\nleendő szolgáltató letelepedett az Unióban, vagy az Unióban letelepedett jogi\nképviselőt nevezett ki; e) a valós körülmények közötti tesztelés céljából\ngyűjtött és kezelt adatok csak akkor továbbíthatók harmadik országokba, ha az\nuniós jog szerinti megfelelő és alkalmazandó biztosítékok végrehajtásra\nkerülnek; f) a valós körülmények közötti tesztelés nem tart annál tovább, mint\nami szükséges a céljai eléréséhez, de semmi esetre sem hosszabb hat hónapnál;\nez az időszak további hat hónappal meghosszabbítható, feltéve, hogy a\nszolgáltató vagy a leendő szolgáltató előzetesen értesíti a piacfelügyeleti\nhatóságot, mellékelve annak magyarázatát, hogy miért van szükség a\nhosszabbításra; g) a valós körülmények közötti tesztelés azon alanyai, akik\néletkoruk vagy fogyatékosságuk miatt kiszolgáltatott csoportokhoz tartozó\nszemélyek, megfelelő védelemben részesülnek; h) amennyiben egy szolgáltató\nvagy a leendő szolgáltató a valós körülmények közötti tesztelést egy vagy több\nalkalmazóval vagy leendő alkalmazóval együttműködve szervezi meg, ez\nutóbbiakat tájékoztatták a tesztelés minden olyan vonatkozásáról, amely\nreleváns a részvételükre vonatkozó döntésük szempontjából, és megkapták az MI-\nrendszer használatára vonatkozó, a 13. cikkben említett releváns utasításokat;\na szolgáltatónak vagy a leendő szolgáltatónak és az alkalmazónak vagy a leendő\nalkalmazónak megállapodást kell kötniük, amelyben meghatározzák szerepüket és\nfelelősségüket annak érdekében, hogy biztosítsák az e rendeletben, valamint\nmás alkalmazandó uniós és nemzeti jogban a valós körülmények közötti\ntesztelésre vonatkozóan előírt rendelkezéseknek való megfelelést; i) a valós\nkörülmények közötti tesztelés vizsgálati alanyai a 61. cikkel összhangban\ntájékoztatáson alapuló hozzájárulásukat adták, vagy bűnüldözés esetében,\namennyiben a tájékoztatáson alapuló hozzájárulás megkérése megakadályozná az\nMI-rendszer tesztelését, maga a tesztelés és a valós körülmények közötti\ntesztelés eredménye nem gyakorolhat negatív hatást a tesztelés vizsgálati\nalanyaira, és a személyes adataikat a teszt elvégzése után törölni kell; j) a\nvalós körülmények közötti tesztelést a szolgáltató vagy a leendő szolgáltató,\nvalamint az alkalmazók és a leendő alkalmazók hatékonyan felügyelik olyan\nszemélyek révén, akik az adott területen megfelelően képzettek, és\nrendelkeznek a feladataik ellátásához szükséges kapacitással, képzettséggel és\nfelhatalmazással; k) az MI-rendszer előrejelzéseit, ajánlásait és döntéseit\nténylegesen vissza lehet fordítani és figyelmen kívül lehet hagyni. (5) A\nvalós körülmények közötti tesztelés alanyai vagy adott esetben azok jogszerűen\nkijelölt képviselői a tájékoztatáson alapuló hozzájárulásuk visszavonásával -\nminden hátrányos következmény nélkül és indokolási kötelezettség nélkül -\nbármikor elállhatnak a teszteléstől, és kérhetik személyes adataik azonnali és\nvégleges törlését. A tájékoztatáson alapuló hozzájárulás visszavonása nem\nérinti a már elvégzett tevékenységeket. (6) A 75. cikkel összhangban a\ntagállamok felruházzák piacfelügyeleti hatóságaikat azzal a hatáskörrel, hogy\na szolgáltatókat és a leendő szolgáltatókat információszolgáltatásra\nkötelezzék, előre be nem jelentett távoli vagy helyszíni ellenőrzéseket\nvégezzenek, valamint hogy ellenőrzéseket végezzenek a valós körülmények\nközötti tesztelés lebonyolítására és a kapcsolódó nagy kockázatú MI-\nrendszerekre vonatkozóan. A piacfelügyeleti hatóságoknak az említett\nhatásköröket abból a célból kell gyakorolniuk, hogy biztosítsák a valós\nkörülmények közötti tesztelés biztonságos fejlesztését. (7) A valós\nkörülmények közötti tesztelés során azonosított súlyos váratlan eseményeket a\n73. cikkel összhangban jelenteni kell a nemzeti piacfelügyeleti hatóságnak. A\nszolgáltatónak vagy leendő szolgáltatónak azonnali kockázatcsökkentő\nintézkedéseket kell elfogadnia, vagy ennek hiányában fel kell függesztenie a\nvalós körülmények közötti tesztelést mindaddig, amíg a kockázatcsökkentésre\nsor nem kerül, vagy egyébként meg kell szüntetnie azt. A valós körülmények\nközötti tesztelés említett megszüntetésének esetére a szolgáltatónak vagy a\nleendő szolgáltatónak ki kell alakítania egy eljárást az MI-rendszer azonnali\nvisszahívására. (8) A szolgáltatóknak vagy a leendő szolgáltatóknak\nértesíteniük kell a valós körülmények közötti tesztelés felfüggesztéséről vagy\nmegszüntetéséről, továbbá a végeredményekről azon tagállam nemzeti\npiacfelügyeleti hatóságát, amelyben a valós körülmények közötti tesztelésre\nsor kerül. (9) A szolgáltató vagy a leendő szolgáltató - a\nfelelősségvállalásra alkalmazandó uniós és nemzeti jog alapján - felelősséggel\ntartozik a valós körülmények közötti tesztelés során okozott károkért. (1) A\n60. cikk szerinti, valós körülmények közötti tesztelés céljából - a\ntesztelésben való részvételüket megelőzően - be kell szerezni a vizsgálat\nalanyainak tájékoztatáson alapuló, önkéntes hozzájárulását azt követően, hogy\ntömör, egyértelmű, releváns és érthető tájékoztatást kaptak a következőket\nilletően: a) a valós körülmények közötti tesztelés jellege és célkitűzései,\nvalamint a részvételükkel összefüggő esetleges kellemetlenségek; b) azon\nfeltételek, amelyek mellett a valós körülmények közötti tesztelést el kell\nvégezni, ideértve a vizsgálati alany vagy alanyok részvételének várható\nidőtartamát; c) a jogaik és a garanciák a részvételüket illetően, különös\ntekintettel a részvétel megtagadására való jogukra, valamint a valós\nkörülmények közötti teszteléstől való, indokolás nélkül bármikor bejelenthető,\nhátrányos következménnyel nem járó elálláshoz való jogra; d) az MI-rendszer\nelőrejelzéseinek, ajánlásainak vagy döntéseinek visszafordítására vagy\nfigyelmen kívül hagyására irányuló kérésre vonatkozó szabályok; e) a 60. cikk\n(4) bekezdésének c) pontjával összhangban a valós körülmények közötti\ntesztelés Unió-szerte egységes, egyedi azonosító száma, valamint azon\nszolgáltatónak vagy jogi képviselőjének az elérhetősége, akitől további\ninformációk szerezhetők be. (2) A tájékoztatáson alapuló hozzájárulást\ndátummal kell ellátni és dokumentálni kell, és annak másolatát át kell adni a\nvizsgálati alanyoknak vagy jogi képviselőiknek. (1) A tagállamok a következő\nintézkedéseket hajtják végre: a) az Unióban bejegyzett székhellyel vagy\nfiókteleppel rendelkező kkv-k, köztük az induló innovatív vállalkozások\nszámára elsőbbségi hozzáférést biztosítanak az MI szabályozói\ntesztkörnyezetekhez, amennyiben e vállalkozások teljesítik a jogosultsági\nfeltételeket és a kiválasztási kritériumokat; az elsőbbségi hozzáférés nem\nzárhatja ki, hogy az e bekezdésben említettektől eltérő egyéb kkv-k - ideértve\naz induló innovatív vállalkozásokat is - hozzáféréssel rendelkezzenek az MI\nszabályozói tesztkörnyezethez, feltéve, hogy teljesítik a jogosultsági\nfeltételeket és a kiválasztási szempontokat is; b) az e rendelet\nalkalmazásával kapcsolatos, a kkv-k, köztük az induló innovatív vállalkozások,\naz alkalmazók, valamint adott esetben a helyi közigazgatási szervek igényeihez\nigazított külön figyelemfelhívó és képzési tevékenységeket szerveznek; c)\nkihasználják a meglévő célzott csatornákat és adott esetben újakat hoznak\nlétre a kkv-kkal, köztük az induló innovatív vállalkozásokkal, az\nalkalmazókkal, egyéb innovátorokkal, valamint adott esetben a helyi\nközigazgatási szervekkel folytatott kommunikáció céljára, hogy tanácsot és\nválaszt adjanak az e rendelet végrehajtásával kapcsolatos kérdéseket illetően,\ntöbbek között az MI szabályozói tesztkörnyezetekben való részvétel\ntekintetében; d) elősegítik a kkv-k és egyéb érintett érdekelt felek\nrészvételét a szabványalkotási folyamatban. (2) A 43. cikk szerinti\nmegfelelőségértékelési díjak megállapításakor figyelembe kell venni a kkv-\nszolgáltatók, köztük az induló innovatív vállalkozások sajátos érdekeit és\nigényeit, arányosan csökkentve e díjakat a vállalkozások méretének, a piac\nméretének és egyéb releváns tényezőknek megfelelően. (3) Az MI-hivatalnak a\nkövetkező intézkedéseket kell végrehajtania: a) a Testület által a kérelmében\nmeghatározottak szerint szabványosított mintákat bocsát rendelkezésre az e\nrendelet hatálya alá tartozó területekre vonatkozóan; b) egységes információs\nplatformot fejleszt ki és tart fenn, amely könnyen használható információkat\nnyújt e rendelettel kapcsolatban valamennyi uniós gazdasági szereplő számára;\nc) megfelelő kommunikációs kampányokat szervez annak érdekében, hogy felhívja\na figyelmet az e rendeletből eredő kötelezettségekre; d) értékeli és\nelőmozdítja az MI-rendszerekre vonatkozó közbeszerzési eljárások legjobb\ngyakorlatainak közelítését. (1) A 2003/361/EK ajánlás értelmében vett\nmikrovállalkozások az e rendelet 17. cikke által előírt minőségirányítási\nrendszer bizonyos elemeinek egyszerűsített módon is megfelelhetnek, feltéve,\nhogy nem rendelkeznek az említett ajánlás értelmében vett\npartnervállalkozásokkal vagy kapcsolt vállalkozásokkal. E célból a Bizottság\niránymutatásokat dolgoz ki a minőségirányítási rendszer azon elemeire\nvonatkozóan, amelyeknek - a mikrovállalkozások igényeit figyelembe véve -\negyszerűsített módon is meg lehet felelni, méghozzá anélkül, hogy ez érintené\na védelem szintjét vagy a nagy kockázatú MI-rendszerekre vonatkozó\nkövetelményeknek való megfelelés szükségességét. (2) E cikk (1) bekezdése nem\nértelmezhető úgy, hogy mentesíti az említett gazdasági szereplőket az e\nrendeletben meghatározott egyéb követelmények vagy kötelezettségek teljesítése\nalól, ideértve a 9., a 10., a 11., a 12., a 13., a 14., a 15., a 72. és a 73.\ncikkben meghatározott követelményeket és kötelezettségeket is. (1) A Bizottság\naz MI-hivatalon keresztül fejleszti az uniós szakértelmet és képességeket a\nmesterséges intelligencia területén. (2) A tagállamok elősegítik az e rendelet\nalapján az MI-hivatalra ruházott feladatok ellátását. (1) Létrejön a\nMesterséges Intelligenciával Foglalkozó Európai Testület (a továbbiakban: a\nTestület). (2) A Testületnek a tagállamok egy-egy képviselőjéből kell állnia.\nAz európai adatvédelmi biztosnak megfigyelőként kell részt vennie a\nTestületben. A Testület ülésein az MI-hivatalnak is részt kell vennie, a\nszavazásokon való részvétel nélkül. A Testület eseti alapon más nemzeti és\nuniós hatóságokat, szerveket vagy szakértőket is meghívhat az ülésekre,\namennyiben a megvitatott kérdések számukra relevánsak. (3) Az egyes\nképviselőket a tagállamaik jelölik ki hároméves, egyszer megújítható\nidőtartamra. (4) A tagállamok biztosítják, hogy a Testületben részt vevő\nképviselőik: a) a tagállamukban rendelkeznek a releváns kompetenciákkal és\nhatáskörökkel ahhoz, hogy aktívan hozzájáruljanak a Testületnek a 66. cikkben\nemlített feladatai teljesítéséhez; b) a Testület felé egyedüli kapcsolattartó\npontként vannak kijelölve, és adott esetben - figyelembe véve a tagállamok\nigényeit - egyedüli kapcsolattartó pontként az érdekelt felek számára; c)\nfelhatalmazással rendelkeznek arra, hogy elősegítsék a tagállamuk illetékes\nnemzeti hatóságai közötti összhangot és koordinációt e rendelet végrehajtása\ntekintetében, többek között a Testületen belüli feladataik ellátása céljából\nreleváns adatok és információk gyűjtése révén. (5) A tagállamok kijelölt\nképviselői kétharmados többséggel fogadják el a Testület eljárási\nszabályzatát. Az eljárási szabályzatban meg kell állapítani különösen a\nkiválasztási folyamat eljárásait, az elnök megbízatásának időtartamát és\nfeladatainak leírását, a szavazásra vonatkozó részletes szabályokat, valamint\na Testület és alcsoportjai tevékenységeinek megszervezését. (6) A Testületnek\nlétre kell hoznia két állandó alcsoportot, hogy platformot biztosítsanak a\npiacfelügyeleti hatóságok, illetve a bejelentő hatóságok közötti\negyüttműködéshez és véleménycseréhez a piacfelügyelettel, illetve a\nbejelentett szervezetekkel kapcsolatos ügyekről. A piacfelügyelettel\nfoglalkozó állandó alcsoportnak e rendelet tekintetében az (EU) 2019/1020\nrendelet 30. cikke értelmében vett igazgatási együttműködési csoportként kell\neljárnia. A Testület adott esetben, konkrét kérdések megvizsgálása céljából\nújabb állandó vagy ideiglenes alcsoportokat hozhat létre. Adott esetben a 67.\ncikkben említett tanácsadó fórum képviselőit megfigyelői minőségben meg lehet\nhívni ilyen alcsoportokba vagy ezen alcsoportok egyes üléseire. (7) A Testület\nfelépítésének és működésének biztosítania kell a Testület tevékenységeinek\nobjektivitását és pártatlanságát. (8) A Testület elnöki tisztét az egyik\ntagállam képviselőjének kell betöltenie. Az MI-hivatal látja el a Testület\ntitkári feladatait, az elnök kérésére összehívja az üléseket, valamint\nelkészíti a napirendet a Testület e rendelet és eljárási szabályzata szerinti\nfeladatainak megfelelően. A Testületnek tanácsadással és segítségnyújtással\nkell támogatnia Bizottságot és a tagállamokat e rendelet következetes és\nhatékony alkalmazásának elősegítése érdekében. E célból a Testület különösen:\na) hozzájárulhat az e rendelet alkalmazásáért felelős illetékes nemzeti\nhatóságok közötti koordinációhoz, és az érintett piacfelügyeleti hatóságokkal\negyüttműködve és azok beleegyezésével támogathatja a piacfelügyeleti\nhatóságoknak a 74. cikk (11) bekezdésében említett közös tevékenységeit; b)\nösszegyűjtheti és megoszthatja a tagállamok között a műszaki és szabályozási\nszaktudást és a legjobb gyakorlatokat; c) tanácsadást nyújthat e rendelet\nvégrehajtásával kapcsolatban, különösen az általános célú MI-modellekre\nvonatkozó szabályok végrehajtása tekintetében; d) hozzájárulhat a tagállamok\nközigazgatási gyakorlatainak harmonizálásához, többek között a 46. cikkben\nemlített, a megfelelőségértékelési eljárásoktól való eltéréssel, az MI\nszabályozói tesztkörnyezetek működésével, valamint az 57., az 59. és a 60.\ncikkben említett, valós körülmények közötti teszteléssel kapcsolatban; e) a\nBizottság kérésére vagy saját kezdeményezésére ajánlásokat és írásbeli\nvéleményeket adhat ki az e rendelet végrehajtásával, valamint következetes és\nhatékony alkalmazásával kapcsolatos bármely releváns kérdésben, beleértve a\nkövetkezőket is: i. az e rendelet szerinti magatartási kódexek és gyakorlati\nkódexek, valamint a Bizottság iránymutatásainak kidolgozása és alkalmazása;\nii. e rendeletnek a 112. cikk szerinti értékelése és felülvizsgálata, többek\nközött a 73. cikkben említett súlyos váratlan eseményekről szóló jelentések,\nvalamint a 71. cikkben említett uniós adatbázis működése és a felhatalmazáson\nalapuló jogi aktusok vagy végrehajtási jogi aktusok előkészítése tekintetében,\ntovábbá e rendeletnek az I. mellékletben felsorolt uniós harmonizációs\njogszabályokkal való esetleges összehangolása tekintetében; iii. a III.\nfejezet 2. szakaszában meghatározott követelményekre vonatkozó műszaki\nelőírások vagy meglévő szabványok; iv. a 40. és a 41. cikkben említett\nharmonizált szabványok vagy közös előírások használata; v. olyan tendenciák,\nmint például az európai globális versenyképesség a mesterséges intelligencia\nterén, a mesterséges intelligencia elterjedése az Unióban, valamint a\ndigitális készségek fejlesztése; vi. az MI-értékláncok folyamatosan változó\ntipológiájával, különösen az ebből eredően az elszámoltathatóság tekintetében\njelentkező következményekkel kapcsolatos tendenciák; vii. a III. melléklet\nesetlegesen szükséges módosítása a 7. cikkel összhangban, valamint az 5. cikk\n112. cikk szerinti esetlegesen szükséges átdolgozása, figyelembe véve a\nrendelkezésre álló releváns tudományos eredményeket és a legújabb technológiai\nfejleményeket; f) támogathatja a Bizottságot az MI-jártasságnak, valamint az\nMI-rendszerek használatával kapcsolatos, a nyilvánosságot célzó\nfigyelemfelkeltő tevékenységeknek és az MI-rendszerek használatával\nkapcsolatos előnyök, kockázatok, biztosítékok, jogok és kötelezettségek\nmegértésének az előmozdításában; g) elősegítheti a közös kritériumok\nkidolgozását, valamint az e rendeletben meghatározott releváns fogalmaknak a\npiaci szereplők és az illetékes hatóságok általi közös értelmezését, többek\nközött a referenciaértékek kidolgozásához való hozzájárulás által; h) adott\nesetben együttműködhet egyéb uniós intézményekkel, szervekkel és hivatalokkal,\nvalamint érintett uniós szakértői csoportokkal és hálózatokkal, különösen a\ntermékbiztonság, a kiberbiztonság, a verseny, a digitális és\nmédiaszolgáltatások, a pénzügyi szolgáltatások, a fogyasztóvédelem, az\nadatvédelem és az alapvető jogok védelme területén; i) hozzájárulhat a\nharmadik országok illetékes hatóságaival és a nemzetközi szervezetekkel való\nhatékony együttműködéshez; j) segítheti az illetékes nemzeti hatóságokat és a\nBizottságot az e rendelet végrehajtásához szükséges szervezeti és műszaki\nszakértelem fejlesztésében, többek között azáltal, hogy hozzájárul az e\nrendelet végrehajtásában részt vevő tagállami személyzet képzési igényeinek\nfelméréséhez; k) segítheti az MI-hivatalt abban, hogy támogassa az illetékes\nnemzeti hatóságokat az MI szabályozói tesztkörnyezetek kialakításában és\nfejlesztésében, valamint elősegítheti az MI szabályozói tesztkörnyezetek\nközötti együttműködést és információmegosztást; l) hozzájárulhat és megfelelő\ntanácsadással szolgálhat iránymutatások kidolgozásához; m) tanácsot adhat a\nBizottságnak az MI-vel kapcsolatos nemzetközi kérdésekkel kapcsolatban; n)\nállásfoglalásokat nyújthat be a Bizottság számára az általános célú MI-\nmodellekre vonatkozó minősített riasztásokról; o) állásfoglalásokat kaphat a\ntagállamoktól az általános célú MI-modellekre vonatkozó minősített\nriasztásokról, valamint az MI-rendszerek, különösen az általános célú MI-\nmodelleket integráló rendszerek nyomon követésével és végrehajtásával\nkapcsolatos nemzeti tapasztalatokról és gyakorlatokról. (1) Létre kell hozni\negy tanácsadó fórumot, amelynek feladata, hogy műszaki szakértelmet\nbiztosítson és tanácsadást nyújtson a Testület és a Bizottság számára,\nvalamint hozzájáruljon az e rendelet szerinti feladataik ellátásához. (2) A\ntanácsadó fórum tagságában az érdekelt felek kiegyensúlyozottan képviseltetik\nmagukat, beleértve az ipart, az induló vállalkozásokat, a kkv-kat, a civil\ntársadalmat és a tudományos köröket. A tanácsadó fórum tagságának\nkiegyensúlyozottnak kell lennie a kereskedelmi és nem kereskedelmi érdekek,\nvalamint - a kereskedelmi érdekek kategóriáján belül - a kkv-k és más\nvállalkozások tekintetében. (3) A Bizottság a tanácsadó fórum tagjait - a (2)\nbekezdésben meghatározott szempontokkal összhangban - a mesterséges\nintelligencia területén elismert szakértelemmel rendelkező érdekelt felek\nköréből nevezi ki. (4) A tanácsadó fórum tagjainak megbízatása két évre szól,\nés legfeljebb négy évvel meghosszabbítható. (5) Az Alapjogi Ügynökség, az\nENISA, az Európai Szabványügyi Bizottság (CEN), az Európai Elektrotechnikai\nSzabványügyi Bizottság (CENELEC) és az Európai Távközlési Szabványügyi Intézet\n(ETSI) a tanácsadó fórum állandó tagjai. (6) A tanácsadó bizottság\nmegállapítja eljárási szabályzatát. Tagjai közül - a (2) bekezdésben\nmeghatározott szempontokkal összhangban - két társelnököt kell választania. A\ntárselnökök megbízatása két évre szól, és egyszer megújítható. (7) A tanácsadó\nfórumnak évente legalább két ülést kell tartania. A tanácsadó fórum\nszakértőket és más érdekelt feleket hívhat meg üléseire. (8) A tanácsadó fórum\na Testület vagy a Bizottság kérésére véleményeket, ajánlásokat és írásbeli\nészrevételeket dolgozhat ki. (9) A tanácsadói fórum adott esetben állandó vagy\nideiglenes alcsoportokat hozhat létre az e rendelet célkitűzéseivel\nkapcsolatos konkrét kérdések vizsgálatára. (10) A tanácsadó fórumnak\ntevékenységeiről éves jelentést kell készítenie. Ezt a jelentést nyilvánosan\nhozzáférhetővé kell tenni. (1) A Bizottság végrehajtási jogi aktus útján\nrendelkezik egy független szakértőkből álló tudományos testület (a\ntovábbiakban: a tudományos testület) létrehozásáról, amely az e rendelet\nszerinti végrehajtási tevékenységek támogatására hivatott. Ezt a végrehajtási\njogi aktust a 98. cikk (2) bekezdésében említett vizsgálóbizottsági eljárás\nkeretében kell elfogadni. (2) A tudományos testület olyan szakértőkből áll,\nakiket a Bizottság választ ki az MI területén meglévő, a (3) bekezdésben\nmeghatározott feladatok ellátásához szükséges naprakész tudományos vagy\nműszaki szakértelem alapján, és a testület képes bizonyítani, hogy a következő\nfeltételek mindegyikének megfelel: a) különleges szakértelemmel és\nalkalmassággal, valamint tudományos vagy műszaki szakértelemmel rendelkezik az\nMI területén; b) független az MI-rendszerek vagy az általános célú MI-modellek\nbármely szolgáltatójától; c) képes gondosan, pontosan és objektíven végezni\ntevékenységeit. A Bizottság - a Testülettel konzultálva - az igényeknek\nmegfelelően állapítja meg a testületben részt vevő szakértők számát, és\nbiztosítja a méltányos nemek szerinti és földrajzi képviseletet. (3) A\ntudományos testület tanácsadást és támogatást kell nyújt az MI-hivatal\nszámára, különösen a következő feladatok tekintetében: a) e rendelet\nvégrehajtásának és érvényesítésének támogatása az általános célú MI-modellek\nés -rendszerek tekintetében, különösen a következők révén: i. az MI-hivatal\nfigyelmeztetése az általános célú MI-modellek Uniós szinten lehetséges\nrendszerszintű kockázataira a 90. cikkel összhangban; ii. hozzájárulás az\náltalános célú MI-modellek és -rendszerek képességeinek - többek között\nreferenciaértékek révén történő - értékelésére szolgáló eszközök és módszerek\nkifejlesztéséhez; iii. tanácsadás nyújtása a rendszerszintű kockázatot jelentő\náltalános célú MI-modellek besorolásával kapcsolatban; iv. tanácsadás nyújtása\nkülönböző általános célú MI-modellek és -rendszerek besorolásával\nkapcsolatban; v. hozzájárulás eszközök és minták kidolgozásához; b) a\npiacfelügyeleti hatóságok kérésére a munkájuk támogatása; c) a piacfelügyeleti\nhatóságok hatásköreinek sérelme nélkül a 74. cikk (11) bekezdésében említett,\nhatárokon átnyúló piacfelügyeleti tevékenységek támogatása; d) az MI-hivatal\ntámogatása feladatainak ellátásában a 81. cikk szerinti uniós védintézkedési\neljárással összefüggésben. (4) A tudományos testületben részt vevő\nszakértőknek feladataikat pártatlanul és objektíven kell ellátniuk, továbbá\nbiztosítaniuk kell a feladataik és tevékenységeik végzése során szerzett\ninformációk és adatok bizalmas jellegét. A (3) bekezdés szerinti feladataik\nellátása során senkitől sem kérhetnek vagy fogadhatnak el utasításokat. Minden\nszakértőnek érdekeltségi nyilatkozatot kell tennie, amelyet nyilvánosan\nhozzáférhetővé kell tenni. Az MI-hivatal rendszereket és eljárásokat hoz létre\na potenciális összeférhetetlenségek aktív kezelésére és megelőzésére. (5) Az\n(1) bekezdésben említett végrehajtási jogi aktusnak rendelkezéseket kell\ntartalmaznia azon feltételekre, eljárásokra és részletes szabályokra\nvonatkozóan, amelyek alapján a tudományos testület és tagjai riasztásokat\nbocsáthatnak ki, és kérhetik az MI-hivatal segítségét a tudományos testület\nfeladatainak ellátásához. (1) A tagállamok felkérhetik a tudományos testület\nszakértőit, hogy nyújtsanak támogatást az e rendelet szerinti végrehajtási\ntevékenységeikhez. (2) A tagállamok kötelezhetők arra, hogy a szakértők által\nnyújtott tanácsadásért és támogatásért díjat fizessenek. A díjak szerkezetére\nés összegére, valamint a megtérítendő költségek mértékére és szerkezetére\nvonatkozó rendelkezéseket a 68. cikk (1) bekezdésben említett végrehajtási\njogi aktusban kell meghatározni, szem előtt tartva e rendelet megfelelő\nvégrehajtásának célkitűzéseit, a költséghatékonyságot és annak szükségességét,\nhogy valamennyi tagállam ténylegesen igénybe vehesse a szakértők segítségét.\n(3) A Bizottság szükség esetén elősegíti, hogy a tagállamok megfelelő időben\nigénybe vehessék a szakértők segítségét, és biztosítja az uniós vizsgálóhelyek\náltal a 84. cikk szerint, illetve a szakértők által e cikk szerint végzett\ntámogató tevékenységek kombinációjának hatékony megszervezését, illetve hogy e\nkombináció a lehető legtöbb hozzáadott értéket nyújtsa. (1) Minden tagállam\nlegalább egy bejelentő hatóságot és legalább egy piacfelügyeleti hatóságot hoz\nlétre vagy jelöl ki illetékes nemzeti hatóságként e rendelet végrehajtásának\ncéljából. Az említett illetékes nemzeti hatóságoknak hatásköreiket\nfüggetlenül, pártatlanul és elfogulatlanul kell gyakorolniuk, hogy megőrizzék\ntevékenységeik és feladataik objektivitását, és biztosítsák e rendelet\nalkalmazását és végrehajtását. Az említett hatóságok tagjainak tartózkodniuk\nkell minden, a feladataikkal összeférhetetlen intézkedéstől. Feltéve, hogy az\nemlített elveket tiszteletben tartják, az ilyen tevékenységeket és feladatokat\n- a tagállam szervezeti igényeinek megfelelően - egy vagy több kijelölt\nhatóság is elláthatja. (2) A tagállamok közlik a Bizottsággal a bejelentő\nhatóságok és a piacfelügyeleti hatóságok nevét és e hatóságok feladatait,\nvalamint az ezekkel kapcsolatos minden későbbi változást. A tagállamok 2025.\naugusztus 2-ig nyilvánosan hozzáférhetővé teszik az illetékes hatóságokkal és\naz egyedüli kapcsolattartó pontokkal való, elektronikus kommunikációs eszközök\nútján történő kapcsolatfelvétel módjára vonatkozó információkat. A tagállamok\nkijelölik a piacfelügyeleti hatóságot, hogy e rendelet tekintetében egyedüli\nkapcsolattartó pontként járjon el, és bejelentik a Bizottságnál az egyedüli\nkapcsolattartó pont nevét. A Bizottság létrehozza az egyedüli kapcsolattartó\npontok nyilvánosan elérhető jegyzékét. (3) A tagállamok biztosítják, hogy\nilletékes nemzeti hatóságaik megfelelő technikai, pénzügyi és emberi\nerőforrásokkal, valamint infrastruktúrával rendelkezzenek az e rendelet\nszerinti feladataik hatékony ellátásához. Így különösen, az illetékes nemzeti\nhatóságoknak elegendő számú, tartósan rendelkezésre álló munkatárssal kell\nrendelkezniük, akiknek a kompetenciái és szakértelme kitejed az MI-\ntechnológiák, az adatok és az adatszámítás, a személyes adatok védelme, a\nkiberbiztonság, az alapvető jogok, az egészségügyi és biztonsági kockázatok\nalapos megértésére, valamint a meglévő szabványok és jogi követelmények\nismeretére. A tagállamok évente értékelik, és szükség esetén frissítik az e\nbekezdésben említett kompetencia- és erőforrás-követelményeket. (4) Az\nilletékes nemzeti hatóságok megfelelő intézkedéseket hoznak, hogy megfelelő\nszintű kiberbiztonságot biztosítsanak. (5) Feladataik ellátása során az\nilletékes nemzeti hatóságoknak a 78. cikkben meghatározott titoktartási\nkötelezettségeknek megfelelően kell eljárniuk. (6) A tagállamok 2025.\naugusztus 2-ig, majd azt követően kétévente egyszer jelentést tesznek a\nBizottságnak az illetékes nemzeti hatóságok pénzügyi erőforrásainak, műszaki\nfelszereléseinek és emberi erőforrásainak helyzetéről, és értékelik azok\nmegfelelőségét. A Bizottság ezeket az információkat megvitatás és esetleges\najánlások céljából továbbítja a Testületnek. (7) A Bizottság elősegíti az\nilletékes nemzeti hatóságok közötti tapasztalatcserét. (8) Az illetékes\nnemzeti hatóságok iránymutatást és tanácsot adhatnak e rendelet\nvégrehajtásával kapcsolatban, különösen a kkv-knak, köztük az induló innovatív\nvállalkozásoknak, adott esetben figyelembe véve a Testület és a Bizottság\niránymutatását és tanácsait. Amennyiben az illetékes nemzeti hatóságok egyéb\nuniós jog hatálya alá tartozó területeken kívánnak iránymutatást és tanácsot\nadni valamely MI-rendszerrel kapcsolatban, adott esetben konzultálniuk kell az\nemlített uniós jogszabályok szerinti illetékes nemzeti hatóságokkal. (9)\nAmennyiben az uniós intézmények, szervek, hivatalok vagy ügynökségek e\nrendelet hatálya alá tartoznak, a felügyeletük tekintetében az európai\nadatvédelmi biztos jár el illetékes hatóságként. (1) A Bizottság a\ntagállamokkal együttműködve uniós adatbázist hoz létre és tart fenn, amely az\ne cikk (2) és (3) bekezdésben említett információkat tartalmazza a 49. és a\n60. cikknek megfelelően regisztrált, a 6. cikk (2) bekezdésében említett nagy\nkockázatú MI-rendszerekre, valamint a 6. cikk (3) bekezdése alapján nagy\nkockázatúnak nem tekintett és a 6. cikk (4) bekezdésének és a 49. cikknek\nmegfelelően regisztrált MI-rendszerekre vonatkozóan. Egy ilyen adatbázis\nfunkcionális jellemzőinek meghatározásakor a Bizottság konzultál a releváns\nszakértőkkel, és az ilyen adatbázis funkcionális jellemzőinek frissítésekor a\nBizottság a Testülettel konzultál. (2) A VIII. melléklet A. és B. szakaszában\nfelsorolt adatokat a szolgáltatóknak vagy adott esetben a meghatalmazott\nképviselőnek kell bevinnie az uniós adatbázisba. (3) A VIII. melléklet C.\nszakaszában felsorolt adatokat azon alkalmazónak kell bevinnie az uniós\nadatbázisba a 49. cikk (3) és (4) bekezdésével összhangban, aki hatóság,\nügynökség vagy szerv, illetve hatóság, ügynökség vagy szerv nevében jár el.\n(4) A 49. cikk (4) bekezdésében és a 60. cikk (4) bekezdésének c) pontjában\nemlített szakasz kivételével az uniós adatbázisban szereplő, a 49. cikkel\nösszhangban rögzített információknak felhasználóbarát módon hozzáférhetőnek és\nnyilvánosan elérhetőnek kell lenniük. Az információknak könnyen navigálhatónak\nés géppel olvashatónak kell lenniük. A 60. cikkel összhangban rögzített\ninformációkhoz csak a piacfelügyeleti hatóságok és a Bizottság férhetnek\nhozzá, kivéve, ha a leendő szolgáltató vagy a szolgáltató hozzájárulását adta\nahhoz, hogy az információkat a nyilvánosság számára is hozzáférhetővé tegyék.\n(5) Az uniós adatbázis csak annyiban tartalmazhat személyes adatokat,\namennyiben arra az e rendelettel összhangban történő információgyűjtéshez és\n-kezeléshez szükség van. Az említett információknak tartalmazniuk kell azon\ntermészetes személyek nevét és elérhetőségét, akik a rendszer regisztrálásáért\nfelelnek, valamint jogosultak a szolgáltató vagy - adott esetben - az\nalkalmazó képviseletére. (6) Az uniós adatbázist a Bizottság felügyeli.\nMegfelelő műszaki és adminisztratív támogatást biztosít a szolgáltatók, a\nleendő szolgáltatók és az alkalmazók számára. Az uniós adatbázisnak meg kell\nfelelnie az alkalmazandó akadálymentesítési követelményeknek. (1) A\nszolgáltatóknak az MI-technológiák jellegével és a nagy kockázatú MI-rendszer\nkockázataival arányos módon forgalomba hozatal utáni nyomonkövetési rendszert\nkell létrehozniuk, és azt dokumentálniuk kell. (2) A forgalomba hozatal utáni\nnyomonkövetési rendszernek aktívan és szisztematikusan gyűjtenie,\ndokumentálnia és elemeznie kell az adott esetben az alkalmazók által\nszolgáltatott, vagy más forrásokból származó, a nagy kockázatú MI-rendszerek\nteljes élettartamuk során mutatott teljesítményére vonatkozó releváns\nadatokat, amelyek lehetővé teszik a szolgáltató számára annak értékelését,\nhogy az MI-rendszerek folyamatosan megfelelnek-e a III. fejezet 2. szakaszában\nmeghatározott követelményeknek. A forgalomba hozatal utáni nyomon követésnek\nadott esetben magában kell foglalnia az egyéb MI-rendszerekkel való\nkölcsönhatás elemzését. Ez a kötelezettség nem terjedhet ki azon alkalmazók\nérzékeny operatív adataira, amelyek bűnüldöző hatóságok. (3) A forgalomba\nhozatal utáni nyomonkövetési rendszernek egy forgalomba hozatal utáni\nnyomonkövetési terven kell alapulnia. A forgalomba hozatal utáni\nnyomonkövetési tervnek a IV. mellékletben említett műszaki dokumentáció részét\nkell képeznie. A Bizottság 2026. február 2-ig végrehajtási jogi aktust fogad\nel, amelyben megállapítja a forgalomba hozatal utáni nyomonkövetési terv\nmintáját meghatározó részletes rendelkezéseket és a tervben feltüntetendő\nelemek jegyzékét. Ezt a végrehajtási jogi aktust a 98. cikk (2) bekezdésében\nemlített vizsgálóbizottsági eljárás keretében kell elfogadni. (4) Az I.\nmelléklet A. szakaszában felsorolt uniós harmonizációs jogszabályok hatálya\nalá tartozó nagy kockázatú MI-rendszerek esetében, amennyiben az említett\njogszabályok alapján már létrehoztak egy forgalomba hozatal utáni\nnyomonkövetési rendszert és tervet, a következetesség biztosítása, az\nátfedések elkerülése és a további terhek minimalizálása érdekében a\nszolgáltatók dönthetnek úgy, hogy adott esetben a (3) bekezdésben említett\nminta felhasználásával integrálják az (1), a (2) és a (3) bekezdésben\nismertetett szükséges elemeket az említett jogszabályok alapján már meglévő\nrendszerekbe és tervekbe, feltéve, hogy az egyenértékű szintű védelmet ér el.\nAz e bekezdés első albekezdése a III. melléklet 5. pontjában említett azon,\nnagy kockázatú MI-rendszerekre is alkalmazandó, amelyeket olyan pénzügyi\nintézmények hoznak forgalomba vagy helyeznek üzembe, amelyek a pénzügyi\nszolgáltatásokra vonatkozó uniós jog értelmében a belső irányításukra,\nszabályaikra vagy eljárásaikra vonatkozó követelmények hatálya alá tartoznak.\n(1) Az uniós piacon forgalomba hozott nagy kockázatú MI-rendszerek\nszolgáltatóinak minden súlyos váratlan eseményt be kell jelenteniük azon\ntagállamok piacfelügyeleti hatóságainak, ahol az esemény történt. (2) Az (1)\nbekezdésben említett bejelentést haladéktalanul meg kell tenni azt követően,\nhogy a szolgáltató megállapította az MI-rendszer és a súlyos váratlan esemény\nközötti ok-okozati összefüggést vagy az ilyen összefüggés észszerű\nvalószínűségét, de legkésőbb 15 nappal azt követően, hogy a szolgáltató, vagy\nadott esetben az alkalmazó tudomást szerzett a súlyos váratlan eseményről. Az\nelső albekezdésben említett bejelentésre nyitva álló időszak meghatározása\nsorán figyelembe kell venni a súlyos váratlan esemény súlyosságát. (3) E cikk\n(2) bekezdésétől eltérve, a kiterjedt jogsértés vagy a 3. cikk 49. pontjának\nb) alpontjában meghatározott súlyos váratlan esemény esetén az e cikk (1)\nbekezdésében említett bejelentést haladéktalanul, de legkésőbb két nappal azt\nkövetően meg kell tenni, hogy a szolgáltató vagy adott esetben az alkalmazó\ntudomást szerzett az eseményről. (4) A (2) bekezdéstől eltérve, valamely\nszemély halála esetén a bejelentést haladéktalanul meg kell tenni azt\nkövetően, hogy a szolgáltató vagy az alkalmazó megállapította a nagy kockázatú\nMI-rendszer és a súlyos váratlan esemény közötti ok-okozati összefüggést, vagy\namint feltételezi azt, de legkésőbb 10 nappal azt követően, hogy a szolgáltató\nvagy adott esetben az alkalmazó tudomást szerzett a súlyos váratlan\neseményről. (5) Amennyiben az időben történő bejelentés biztosításához\nszükséges, a szolgáltató vagy adott esetben az alkalmazó nem teljes körű,\nelőzetes bejelentést, majd ezt követően teljes körű bejelentést tehet. (6) A\nsúlyos váratlan esemény (1) bekezdés szerinti bejelentését követően a\nszolgáltatónak haladéktalanul el kell végeznie a súlyos váratlan eseménnyel és\naz érintett MI-rendszerrel kapcsolatos szükséges vizsgálatokat. Ennek magában\nkell foglalnia az esemény kockázatértékelését és a korrekciós intézkedéseket.\nA szolgáltatónak az első albekezdésben említett vizsgálatok során együtt kell\nműködnie az illetékes hatóságokkal és adott esetben az érintett bejelentett\nszervezettel, továbbá a szolgáltató - az illetékes hatóságok ilyen\nintézkedésről való tájékoztatását megelőzően - nem végezhet olyan vizsgálatot,\namely magában foglalja az érintett MI-rendszer oly módon történő\nmegváltoztatását, amely hatással lehet az esemény okainak későbbi\nértékelésére. (7) A 3. cikk 49. pontjának c) alpontjában említett súlyos\nváratlan eseménnyel kapcsolatos értesítés kézhezvételét követően a releváns\npiacfelügyeleti hatóságnak tájékoztatnia kell a 77. cikk (1) bekezdésében\nemlített nemzeti hatóságokat vagy szerveket. A Bizottság célzott iránymutatást\ndolgoz ki az e cikk (1) bekezdésben meghatározott kötelezettségeknek való\nmegfelelés elősegítése érdekében. Az említett iránymutatást 2025. augusztus\n2-ig kell kiadni, és rendszeresen értékelni kell. (8) A piacfelügyeleti\nhatóságnak az e cikk (1) bekezdésében említett értesítés kézhezvételétől\nszámított hét napon belül meg kell hoznia az (EU) 2019/1020 rendelet 19.\ncikkében előírt megfelelő intézkedéseket, továbbá követnie kell az említett\nrendeletben előírt értesítési eljárásokat. (9) A III. mellékletben említett\nazon nagy kockázatú MI-rendszerek esetében, amelyeket olyan szolgáltatók\nhoznak forgalomba vagy helyeznek üzembe, amelyek az e rendeletben\nmeghatározottakkal egyenértékű jelentéstételi követelményeket megállapító\nuniós jogalkotási eszközök hatálya alá tartoznak, a súlyos váratlan esemény\nbejelentésére vonatkozó kötelezettségnek a 3. cikk 49. pontjának c)\nalpontjában említett eseményekre kell korlátozódnia. (10) Az olyan nagy\nkockázatú MI-rendszerek esetében, amelyek az (EU) 2017/745 rendelet és az (EU)\n2017/746 rendelet hatálya alá tartozó eszközök biztonsági alkotórészei vagy\nmaguk is eszközök, a súlyos váratlan események bejelentésére vonatkozó\nkötelezettségnek az e rendelet 3. cikke 49. pontjának c) alpontjában említett\neseményekre kell korlátozódnia, és az értesítést a váratlan esemény\nbekövetkeztének helye szerinti tagállam által az adott célra kiválasztott\nilletékes nemzeti hatóságnak kell megküldeni. (11) Az illetékes nemzeti\nhatóságoknak az (EU) 2019/1020 rendelet 20. cikkével összhangban\nhaladéktalanul értesíteniük kell a Bizottságot minden súlyos váratlan\neseményről, függetlenül attól, hogy hoztak-e intézkedéseket az eseménnyel\nkapcsolatban. (1) Az (EU) 2019/1020 rendelet az e rendelet hatálya alá tartozó\nMI-rendszerekre alkalmazandó. E rendelet hatékony végrehajtása érdekében: a)\naz (EU) 2019/1020 rendelet szerinti gazdasági szereplőre történő bármely\nhivatkozást úgy kell értelmezni, hogy az magában foglalja az e rendelet 2.\ncikkének (1) bekezdésében meghatározott valamennyi gazdasági szereplőt; b) az\n(EU) 2019/1020 rendelet szerinti termékre történő bármely hivatkozást úgy kell\nértelmezni, hogy az magában foglalja az e rendelet hatálya alá tartozó\nvalamennyi MI-rendszert. (2) A piacfelügyeleti hatóságoknak az (EU) 2019/1020\nrendelet 34. cikkének (4) bekezdése szerinti jelentéstételi kötelezettségeik\nrészeként évente jelentést kell tenniük a Bizottságnak és az érintett nemzeti\nversenyhatóságoknak a piacfelügyeleti tevékenységek során azonosított minden\nolyan információról, amely a versenyszabályokra vonatkozó uniós jog\nalkalmazása szempontjából potenciálisan érdekes lehet. Ezenfelül évente\njelentést kell tenniük a Bizottságnak arról, hogy az adott évben alkalmaztak-e\ntiltott gyakorlatokat, valamint a meghozott intézkedésekről. (3) Az I.\nmelléklet A. szakaszában felsorolt uniós harmonizációs jogszabályok hatálya\nalá tartozó termékekhez kapcsolódó nagy kockázatú MI-rendszerek esetében a\npiacfelügyeleti hatóság e rendelet alkalmazásában az említett jogi aktusok\nalapján kijelölt, a piacfelügyeleti tevékenységekért felelős hatóság. Az első\nalbekezdéstől eltérve, és megfelelő körülmények között a tagállamok egy másik\nreleváns hatóságot is kijelölhetnek arra, hogy piacfelügyeleti hatóságként\njárjon el, feltéve, hogy biztosítják az I. mellékletben felsorolt uniós\nharmonizációs jogszabályok végrehajtásáért felelős, releváns ágazati\npiacfelügyeleti hatóságokkal való koordinációt. (4) Az e rendelet 79-83.\ncikkében említett eljárások nem alkalmazandók az I. melléklet A. szakaszában\nfelsorolt uniós harmonizációs jogszabályok hatálya alá tartozó termékekhez\nkapcsolódó MI-rendszerekre, amennyiben az ilyen jogi aktusok már rendelkeznek\negyenértékű szintű védelmet biztosító, azonos célú eljárásokról. Ilyen\nesetekben helyettük a releváns ágazati eljárások alkalmazandók. (5) A\npiacfelügyeleti hatóságok (EU) 2019/1020 rendelet 14. cikke szerinti\nhatásköreinek sérelme nélkül, a piacfelügyeleti hatóságok e rendelet hatékony\nvégrehajtásának biztosítása céljából adott esetben távolról is gyakorolhatják\naz említett rendelet 14. cikke (4) bekezdésének d) és j) pontjában említett\nhatásköröket. (6) A pénzügyi szolgáltatásokra vonatkozó uniós jog által\nszabályozott pénzügyi intézmények által forgalomba hozott, üzembe helyezett\nvagy használt nagy kockázatú MI-rendszerek esetében e rendelet alkalmazásában\na piacfelügyeleti hatóság az említett intézmények e jogszabályok szerinti\npénzügyi felügyeletéért felelős releváns nemzeti hatóság, amennyiben az MI-\nrendszer forgalomba hozatala, üzembe helyezése vagy használata közvetlenül az\nemlített pénzügyi szolgáltatások nyújtásához kapcsolódik. (7) A (6)\nbekezdéstől eltérve, megfelelő körülmények között és feltéve, hogy a\nkoordináció biztosított, a tagállam e rendelet alkalmazásában egy másik\nmegfelelő hatóságot is kijelölhet piacfelügyeleti hatóságként. Az 1024/2013/EU\nrendelettel létrehozott egységes felügyeleti mechanizmusban részt vevő, a\n2013/36/EU irányelv alapján szabályozott hitelintézeteket felügyelő nemzeti\npiacfelügyeleti hatóságoknak haladéktalanul be kell jelenteniük az Európai\nKözponti Banknak a piacfelügyeleti tevékenységeik során azonosított minden\nolyan információt, amely az Európai Központi Banknak az említett rendeletben\nmeghatározott prudenciális felügyeleti feladatai szempontjából esetlegesen\njelentőséggel bírhat. (8) Az e rendelet III. mellékletének 1. pontjában\nfelsorolt nagy kockázatú MI-rendszerek esetében, amennyiben a rendszereket\nbűnüldözési célokra, határellenőrzésre, valamint az igazságosság és a\ndemokrácia területén használják, továbbá az e rendelet III. mellékletének 6.,\n7. és 8. pontjában felsorolt nagy kockázatú MI-rendszerek esetében, a\ntagállamok e rendelet alkalmazásában vagy az (EU) 2016/679 rendelet vagy az\n(EU) 2016/680 irányelv szerinti illetékes adatvédelmi felügyeleti hatóságokat,\nvagy az (EU) 2016/680 irányelv 41-44. cikkében megállapítottakkal azonos\nfeltételek alapján kijelölt bármely egyéb hatóságot jelölnek ki\npiacfelügyeleti hatóságokként. A piacfelügyeleti tevékenységek semmilyen módon\nnem érinthetik az igazságügyi hatóságok függetlenségét, vagy nem\nbefolyásolhatják egyébként a tevékenységeiket, amikor igazságügyi minőségükben\njárnak el. (9) Amennyiben az Unió intézményei, szervei, hivatalai vagy\nügynökségei e rendelet hatálya alá tartoznak, az európai adatvédelmi biztos\njár el piacfelügyeleti hatóságukként, kivéve az igazságszolgáltatási\nhatáskörében eljáró Európai Unió Bíróságával kapcsolatban. (10) A tagállamok\nelősegítik az e rendelet alapján kijelölt piacfelügyeleti hatóságok és az I.\nmellékletben vagy más uniós jogszabályban felsorolt olyan uniós harmonizációs\njogszabályok alkalmazását felügyelő egyéb releváns nemzeti hatóságok vagy\nszervek közötti koordinációt, amelyek a nagy kockázatú MI-rendszerek\nszempontjából relevánsak lehetnek. (11) A piacfelügyeleti hatóságok és a\nBizottság számára lehetővé kell tenni, hogy javaslatot tegyenek olyan, a\npiacfelügyeleti hatóságok által önállóan vagy a Bizottsággal közösen végzendő\nközös tevékenységekre, például közös vizsgálatokra, amelyek célja - e rendelet\nvonatkozásában - a megfelelés előmozdítása, a meg nem felelés feltárása, a\nfigyelemfelhívás vagy az iránymutatás a nagy kockázatú MI-rendszerek azon\nkonkrét kategóriáira tekintettel, amelyekről bebizonyosodik, hogy két vagy\ntöbb tagállamban jelentenek súlyos kockázatot az (EU) 2019/1020 rendelet 9.\ncikkével összhangban. Az MI-hivatalnak a közös vizsgálatokhoz koordinációs\ntámogatást kell nyújtania. (12) Az (EU) 2019/1020 rendelet alapján biztosított\nhatáskörök sérelme nélkül, adott esetben és a piacfelügyeleti hatóság\nfeladatainak ellátásához szükséges mértékre korlátozva, a szolgáltatónak\nteljes hozzáférést kell adnia a piacfelügyeleti hatóságok számára a\ndokumentációhoz, valamint a nagy kockázatú MI-rendszer kifejlesztéséhez\nalkalmazott tanító-, validálási és tesztadatkészletekhez, többek között -\nadott esetben és biztonsági garanciák mellett - alkalmazásprogramozási\nfelületeken (API) vagy távoli hozzáférést lehetővé tevő egyéb releváns műszaki\nmegoldásokon és eszközökön keresztül. (13) Indokolással ellátott kérésre és\nkizárólag a következő két feltétel együttes teljesülése esetén a\npiacfelügyeleti hatóságok számára hozzáférést kell biztosítani a nagy\nkockázatú MI-rendszer forráskódjához: a) a forráskódhoz való hozzáférés annak\nértékeléséhez szükséges, hogy a nagy kockázatú MI-rendszer megfelel-e a III.\nfejezet 2. szakaszában meghatározott követelményeknek; és b) a szolgáltató\náltal rendelkezésre bocsátott adatokon és dokumentáción alapuló tesztelési\nvagy auditeljárásokat és ellenőrzéseket kimerítették, illetve azok\nelégtelennek bizonyultak. (14) A piacfelügyeleti hatóságok által megszerzett\ninformációkat, illetve dokumentációt a 78. cikkben meghatározott titoktartási\nkötelezettségeknek megfelelően kell kezelni. (1) Amennyiben valamely MI-\nrendszer általános célú MI-modellre épül, és a modell és a rendszer\nkifejlesztését ugyanazon szolgáltató végezte, az MI-hivatalnak hatáskörrel\nkell rendelkeznie annak nyomon követésére és felügyeletére, hogy az adott MI-\nrendszer megfelel-e az e rendelet szerinti követelményeknek. A nyomonkövetési\nés felügyeleti feladatainak ellátása érdekében az MI-hivatal rendelkezik egy\npiacfelügyeleti hatóság számára e szakaszban és az (EU) 2019/1020 rendeletben\nbiztosított valamennyi hatáskörrel. (2) Amennyiben a releváns piacfelügyeleti\nhatóságoknak elegendő okuk van úgy megítélni, hogy az olyan általános célú MI-\nrendszerek, amelyeket az alkalmazók közvetlenül használhatnak legalább egy, e\nrendelet értelmében nagy kockázatúnak minősített célra, nem felelnek meg az e\nrendeletben meghatározott követelményeknek, az említett hatóságoknak együtt\nkell működniük az MI-hivatallal a megfelelőségi értékelések elvégzése\nérdekében, és ennek megfelelően tájékoztatniuk kell a Testületet és a többi\npiacfelügyeleti hatóságot. (3) Amennyiben a piacfelügyeleti hatóság azért nem\ntudja lezárni valamely nagy kockázatú MI-rendszer vizsgálatát, mert annak\nellenére sem tud hozzáférni az általános célú MI-modellhez kapcsolódó bizonyos\ninformációkhoz, hogy minden megfelelő erőfeszítést megtett ezek megszerzése\nérdekében, indokolással ellátott kérelmet nyújthat be az MI-hivatalhoz,\namelyen keresztül érvényre juttatható az említett információkhoz való\nhozzáférés. Ebben az esetben az MI-hivatalnak haladéktalanul, de legkésőbb 30\nnapon belül meg kell adnia a megkereső hatóságnak minden olyan információt,\namelyet az MI-hivatal szükségesnek ítél valamely nagy kockázatú MI-rendszer\nmeg nem felelésének megállapításához. A piacfelügyeleti hatóságoknak e\nrendelet 78. cikkével összhangban meg kell őrizniük az általuk kapott\ninformációk bizalmas jellegét. Az (EU) 2019/1020 rendelet VI. fejezetében\nelőírt eljárás értelemszerűen alkalmazandó. (1) A piacfelügyeleti hatóságoknak\nilletékességgel és hatáskörrel kell rendelkezniük annak biztosítására, hogy a\nvalós körülmények közötti tesztelés összhangban legyen e rendelettel. (2)\nAmennyiben az 58. cikknek megfelelően MI szabályozói tesztkörnyezetben\nfelügyelt MI-rendszerek esetében valós körülmények között végeznek tesztelést,\na piacfelügyeleti hatóságoknak az MI szabályozói tesztkörnyezetet illetően\nbetöltött felügyeleti szerepük részeként ellenőrizniük kell a 60. cikknek való\nmegfelelést. Az említett hatóságok adott esetben engedélyezhetik, hogy a valós\nkörülmények közötti tesztelést a 60. cikk (4) bekezdésének f) és g) pontjában\nmeghatározott feltételektől eltérve, a szolgáltató vagy a leendő szolgáltató\nvégezze el. (3) Amennyiben a szolgáltató, a leendő szolgáltató vagy valamely\nharmadik fél tájékoztatta a piacfelügyeleti hatóságot egy súlyos váratlan\neseményről, vagy ha a piacfelügyeleti hatóság más indokok alapján úgy véli,\nhogy a 60. és a 61. cikkben foglalt feltételek nem teljesültek, szükség\nszerint meghozhatja a következő határozatok valamelyikét a saját területén: a)\nfelfüggesztheti vagy megszüntetheti a valós körülmények közötti tesztelést; b)\nkötelezheti a szolgáltatót vagy leendő szolgáltatót, valamint az alkalmazót és\na leendő alkalmazót a valós körülmények közötti tesztelés bármely aspektusának\nmódosítására. (4) Amennyiben a piacfelügyeleti hatóság az e cikk (3)\nbekezdésében említett határozatot hozott, vagy a 60. cikk (4) bekezdésének b)\npontja értelmében vett kifogást emelt, a határozatban vagy a kifogásban fel\nkell tüntetni annak indokait, és azt, hogy a szolgáltató vagy leendő\nszolgáltató miként támadhatja meg a határozatot vagy a kifogást. (5) Adott\nesetben, amennyiben a piacfelügyeleti hatóság a (3) bekezdésben említett\nhatározatot hozott, közölnie kell ennek indokait azon egyéb tagállamok\npiacfelügyeleti hatóságaival, amelyekben az MI-rendszert a tesztelési tervnek\nmegfelelően tesztelték. (1) Azon nemzeti hatóságoknak vagy szerveknek, amelyek\nfelügyelik vagy érvényesítik a III. mellékletben említett nagy kockázatú MI-\nrendszerek használatával kapcsolatos, az alapvető jogok - köztük a\nmegkülönböztetésmentességhez való jog - védelmét célzó uniós jogi\nkötelezettségek betartását, hatáskörrel kell rendelkezniük arra, hogy\nkérelmezzék az e rendelet alapján létrehozott vagy vezetett dokumentációt, és\nközérthető nyelven, valamint hozzáférhető formátumban hozzáférjenek ahhoz,\namennyiben az adott dokumentációhoz való hozzáférés a megbízatásuk\njoghatóságuk keretein belüli hatékony teljesítéséhez szükséges. Az érintett\nhatóságnak vagy szervnek minden ilyen kérelemről tájékoztatnia kell az\nérintett tagállam piacfelügyeleti hatóságát. (2) 2024. november 2-ig minden\ntagállam kijelöli az (1) bekezdésben említett hatóságokat vagy szerveket, és\nnyilvánosan hozzáférhetővé teszi az ezekről összeállított jegyzéket . A\ntagállamok megküldik a Bizottságnak és a többi tagállamnak a jegyzéket, és azt\nnaprakészen tartják. (3) Amennyiben az (1) bekezdésben említett dokumentáció\nnem elegendő annak megállapításához, hogy sor került-e az alapvető jogok\nvédelmét célzó uniós jog szerinti kötelezettségek megsértésére, az (1)\nbekezdésben említett hatóság vagy szerv indokolással ellátott kérelmet\nintézhet a piacfelügyeleti hatósághoz a nagy kockázatú MI-rendszer műszaki\nmegoldások útján történő tesztelésének megszervezésére. A piacfelügyeleti\nhatóságnak a kérelem beérkezését követően észszerű időn belül meg kell\nszerveznie a tesztelést a kérelmező hatóság vagy szerv szoros bevonásával. (4)\nAz e cikk (1) bekezdésében említett nemzeti hatóságok vagy szervek által e\ncikk alapján megszerzett információkat és dokumentációt a 78. cikkben foglalt\ntitoktartási kötelezettségeknek megfelelően kell kezelni. (1) A Bizottság, a\npiacfelügyeleti hatóságok és a bejelentett szervezetek, valamint az e rendelet\nalkalmazásában részt vevő egyéb természetes vagy jogi személyek az uniós vagy\na nemzeti joggal összhangban tiszteletben tartják a feladataik ellátása során\nmegszerzett információk és adatok titkosságát oly módon, hogy védjék különösen\na következőket: a) az (EU) 2016/943 európai parlamenti és tanácsi irányelv *\n5. cikkében említett esetek kivételével a szellemitulajdon-jogok, valamint\nvalamely természetes vagy jogi személy bizalmas üzleti információi vagy üzleti\ntitkai, így például forráskódja; b) e rendelet hatékony végrehajtása,\nkülönösen az ellenőrzések, a vizsgálatok és az auditok céljából; c) köz- és\nnemzetbiztonsági érdekek; d) a büntetőjogi vagy közigazgatási eljárások\nlefolytatása; e) az uniós vagy a nemzeti jog szerinti minősített adatok. (2)\nAz e rendelet alkalmazásában részt vevő, (1) bekezdés szerinti hatóságok\nkizárólag olyan adatokat kérhetnek, amelyek az MI-rendszerek által jelentett\nkockázat értékeléséhez, valamint hatásköreik e rendeletnek és az (EU)\n2019/1020 rendeletnek megfelelő gyakorlásához kifejezetten szükségesek.\nMegfelelő és hatékony kiberbiztonsági intézkedéseket kell bevezetniük a\nmegszerzett információk és adatok biztonságának és titkosságának védelme\nérdekében, valamint az alkalmazandó uniós vagy nemzeti joggal összhangban\ntörölniük kell az összegyűjtött adatokat, amint azokra már nincs szükség a\nmegszerzésüket indokoló célból. (3) Az (1) és a (2) bekezdés sérelme nélkül az\nilletékes nemzeti hatóságok között, illetve az illetékes nemzeti hatóságok és\na Bizottság között bizalmas alapon megosztott információk nem hozhatók\nnyilvánosságra a kibocsátó illetékes nemzeti hatósággal és az alkalmazóval\nvaló előzetes egyeztetés nélkül, amennyiben a III. melléklet 1., 6. vagy 7.\npontjában említett nagy kockázatú MI-rendszereket a bűnüldöző,\nhatárellenőrzési, bevándorlási vagy menekültügyi hatóságok használják, ha az\nilyen nyilvánosságra hozatal közbiztonsági és nemzetbiztonsági érdekeket\nveszélyeztetne. Ez az információcsere nem terjedhet ki a bűnüldöző, a\nhatárellenőrzési, a bevándorlási vagy a menekültügyi hatóságok\ntevékenységeivel kapcsolatos érzékeny operatív adatokra. Amennyiben a\nbűnüldöző, a bevándorlási vagy a menekültügyi hatóságok a III. melléklet 1.,\n6. vagy 7. pontjában említett nagy kockázatú MI-rendszerek szolgáltatói, a IV.\nmellékletben említett műszaki dokumentációnak e hatóságok telephelyén kell\nmaradnia. E hatóságoknak biztosítaniuk kell, hogy a 74. cikk (8) és - adott\nesetben - (9) bekezdésében említett piacfelügyeleti hatóságok kérésre azonnal\nhozzá tudjanak férni a dokumentációhoz, vagy megkaphassák annak egy példányát.\nCsak a piacfelügyeleti hatóság megfelelő szintű biztonsági tanúsítvánnyal\nrendelkező munkatársai férhetnek hozzá az említett dokumentációhoz vagy annak\nbármely példányához. (4) Az (1), a (2) és a (3) bekezdés nem érintheti a\nBizottságnak, a tagállamoknak, a releváns hatóságaiknak és a bejelentett\nszervezeteknek az információcsere és a figyelmeztetések terjesztése\ntekintetében, többek között a határon átnyúló együttműködés kontextusában\nfennálló jogait és kötelezettségeit, és nem érintheti az érintett feleknek a\ntagállamok büntetőjoga alapján fennálló tájékoztatásnyújtási kötelezettségeit.\n(5) A Bizottság és a tagállamok - amennyiben szükséges, valamint a nemzetközi\nés a kereskedelmi megállapodások releváns rendelkezéseivel összhangban\nmegoszthatnak bizalmas információkat azon harmadik országok szabályozó\nhatóságaival, amelyekkel a bizalmas kezelésre vonatkozó, megfelelő szintű\ntitoktartást biztosító, kétoldalú vagy többoldalú megállapodásokat kötöttek.\n(1) Kockázatot jelentő MI-rendszerek alatt az (EU) 2019/1020 rendelet 3.\ncikkének 19. pontjában meghatározott, „kockázatot jelentő termék” értendő,\namennyiben e rendszerek kockázatot jelentenek személyek egészségére és\nbiztonságára, illetve alapvető jogaira nézve. (2) Amennyiben egy tagállam\npiacfelügyeleti hatóságának elegendő oka van úgy megítélni, hogy egy MI-\nrendszer az e cikk (1) bekezdésben említettek alapján kockázatot jelent, el\nkell végeznie az érintett MI-rendszer értékelését a tekintetben, hogy az\nmegfelel-e az e rendeletben meghatározott valamennyi követelménynek és\nkötelezettségnek. Különös figyelmet kell fordítani azon MI-rendszerekre,\namelyek kockázatot jelentenek a kiszolgáltatott csoportokra. Amennyiben az\nalapvető jogokat veszélyeztető kockázatokat azonosítanak, a piacfelügyeleti\nhatóságnak tájékoztatnia kell a 77. cikk (1) bekezdésében említett érintett\nnemzeti hatóságokat vagy szerveket is, és azokkal teljes mértékben együtt kell\nműködnie. A releváns gazdasági szereplőknek szükség szerint együtt kell\nműködniük a piacfelügyeleti hatósággal és a 77. cikk (1) bekezdésében említett\negyéb nemzeti hatóságokkal vagy szervekkel. Amennyiben az említett értékelés\nsorán a nemzeti felügyeleti hatóság vagy adott esetben a nemzeti felügyeleti\nhatóság a 77. cikk (1) bekezdésében említett nemzeti hatósággal\negyüttműködésben megállapítja, hogy az MI-rendszer nem felel meg az e\nrendeletben megállapított követelményeknek és kötelezettségeknek,\nhaladéktalanul elő kell írnia a releváns gazdasági szereplő számára, hogy - az\nadott esetben a piacfelügyeleti hatóság által előírt időszakon, de legkésőbb\ntizenöt munkanapon belül, vagy adott esetben a releváns uniós harmonizációs\njogszabályokban előírtak szerint, attól függően, hogy melyik következik be\nhamarabb - tegyen meg minden ahhoz szükséges megfelelő korrekciós intézkedést,\nhogy az MI-rendszer megfeleljen az említett követelményeknek, vonja ki az MI-\nrendszert a forgalomból vagy hívja vissza azt. A piacfelügyeleti hatóságnak\nennek megfelelően tájékoztatnia kell az érintett bejelentett szervezetet. Az e\nbekezdés második albekezdésében említett intézkedésekre az (EU) 2019/1020\nrendelet 18. cikke alkalmazandó. (3) Amennyiben a piacfelügyeleti hatóság úgy\nítéli meg, hogy a meg nem felelés nem korlátozódik az adott ország területére,\nindokolatlan késedelem nélkül tájékoztatnia kell a Bizottságot és a többi\ntagállamot az értékelés eredményeiről és azokról az intézkedésekről, amelyek\nmeghozatalára a gazdasági szereplőt felszólította. (4) A gazdasági szereplőnek\nbiztosítania kell, hogy az uniós piacon általa forgalmazott valamennyi\nérintett MI-rendszer tekintetében minden megfelelő korrekciós intézkedést\nmeghozzon. (5) Amennyiben az MI-rendszer üzemeltetője nem teszi meg a\nmegfelelő korrekciós intézkedéseket a (2) bekezdésben említett időszakon\nbelül, a piacfelügyeleti hatóságnak meg kell hoznia minden megfelelő átmeneti\nintézkedést az MI-rendszer nemzeti piacon történő forgalmazásának vagy üzembe\nhelyezésének megtiltása vagy korlátozása, illetve a termék vagy a különálló\nMI-rendszer forgalomból való kivonása vagy visszahívása érdekében. Ezekről az\nintézkedésekről a hatóságnak indokolatlan késedelem nélkül értesítenie kell a\nBizottságot és a többi tagállamot. (6) Az (5) bekezdésben említett\nértesítésnek tartalmaznia kell minden rendelkezésre álló információt,\nkülönösen az előírásoknak nem megfelelő MI-rendszer azonosításához szükséges\ninformációkat, az MI-rendszer származási helyét, és az ellátási láncot, a\nfeltételezett meg nem felelésnek és a fennálló kockázatnak a jellegét, a\nmeghozott nemzeti intézkedések jellegét és időtartamát, valamint a releváns\ngazdasági szereplő által felhozott érveket. Így különösen, a piacfelügyeleti\nhatóságoknak jelezniük kell, hogy a meg nem felelés a következő okok közül egy\nvagy több miatt következett-e be: a) az 5. cikkben említett MI-gyakorlatok\ntilalmának be nem tartása; b) valamely nagy kockázatú MI-rendszer nem felel\nmeg a III. fejezet 2. szakaszában foglalt követelményeknek; c) a megfelelés\nvélelmét megalapozó, a 40. és a 41. cikkben említett harmonizált szabványok\nvagy közös előírások hiányosságai; d) az 50. cikknek való meg nem felelés. (7)\nA piacfelügyeleti hatóságoknak - az eljárást kezdeményező tagállam\npiacfelügyeleti hatóságának kivételével - indokolatlan késedelem nélkül\ntájékoztatniuk kell a Bizottságot és a többi tagállamot az elfogadott\nintézkedésekről és azokról a birtokukban lévő további információkról, amelyek\naz érintett MI-rendszer meg nem feleléséről tanúskodnak, valamint - amennyiben\nnem értenek egyet a bejelentett tagállami intézkedéssel - a kifogásaikról. (8)\nAmennyiben az e cikk (5) bekezdésében említett értesítés kézhezvételétől\nszámított három hónapon belül sem valamely tagállam piacfelügyeleti hatósága,\nsem a Bizottság nem emel kifogást egy másik tagállam piacfelügyeleti hatósága\náltal hozott ideiglenes intézkedéssel szemben, az intézkedést indokoltnak kell\ntekinteni. Ez nem érinti az érintett gazdasági szereplőnek az (EU) 2019/1020\nrendelet 18. cikke szerinti eljárási jogait. Az e bekezdésben említett három\nhónapos határidőt 30 napra kell csökkenteni az e rendelet 5. cikkében említett\nMI-gyakorlatok tilalmának be nem tartása esetén. (9) A piacfelügyeleti\nhatóságoknak biztosítaniuk kell, hogy az érintett termékkel vagy MI-\nrendszerrel kapcsolatban indokolatlan késedelem nélkül megfelelő korlátozó\nintézkedések meghozatalára kerüljön sor, ideértve a termék vagy az MI-rendszer\nforgalomból való kivonását is az adott tagállam piacáról. (1) Amennyiben a\npiacfelügyeleti hatóságnak elegendő oka van úgy megítélni, hogy a szolgáltató\náltal a 6. cikk (3) bekezdését alapul véve nem nagy kockázatúnak minősített\nMI-rendszer valójában nagy kockázatú, a piacfelügyeleti hatóságnak el kell\nvégeznie az érintett MI-rendszer értékelését a tekintetben, hogy a 6. cikk (3)\nbekezdésében és a bizottsági iránymutatásokban meghatározott feltételek\nalapján nagy kockázatúnak minősül-e. (2) Amennyiben az értékelés során a\npiacfelügyeleti hatóság megállapítja, hogy az érintett MI-rendszer nagy\nkockázatot rejt, indokolatlan késedelem nélkül fel kell szólítania az érintett\nszolgáltatót, hogy tegye meg az ahhoz szükséges valamennyi intézkedést, hogy\naz MI-rendszer megfeleljen az e rendeletben meghatározott követelményeknek és\nkötelezettségeknek, valamint hogy - adott esetben a piacfelügyeleti hatóság\náltal előírt időszakon belül - tegyen megfelelő korrekciós intézkedéseket. (3)\nAmennyiben a piacfelügyeleti hatóság úgy ítéli meg, hogy az MI-rendszer\nhasználata nem korlátozódik az adott ország területére, indokolatlan késedelem\nnélkül tájékoztatnia kell a Bizottságot és a többi tagállamot az értékelés\neredményeiről és azokról az intézkedésekről, amelyek megtételére a\nszolgáltatót felszólította. (4) A szolgáltatónak biztosítania kell, hogy\nminden szükséges intézkedést meghozzanak az MI-rendszer e rendeletben\nmeghatározott követelményeknek és kötelezettségeknek való megfelelése\nérdekében. Amennyiben az érintett MI-rendszer szolgáltatója az e cikk (2)\nbekezdésében említett időszakon belül nem biztosítja az MI-rendszernek az\nemlített követelményeknek és kötelezettségeknek való megfelelését, a\nszolgáltatóra a 99. cikknek megfelelő pénzbírságot kell kiszabni. (5) A\nszolgáltató biztosítja, hogy az uniós piacon általa forgalmazott valamennyi\nérintett MI-rendszer tekintetében minden megfelelő korrekciós intézkedést\nmeghozzanak. (6) Amennyiben az érintett MI-rendszer szolgáltatója nem teszi\nmeg a megfelelő korrekciós intézkedéseket az e cikk (2) bekezdésében említett\nidőszakon belül, a 79. cikk (5)-(9) bekezdése alkalmazandó. (7) Amennyiben az\ne cikk (1) bekezdése szerinti értékelés során a piacfelügyeleti hatóság\nmegállapítja, hogy a szolgáltató annak érdekében minősítette tévesen nem nagy\nkockázatúnak az MI-rendszert, hogy megkerülje a III. fejezet 2. szakaszában\nfoglalt követelmények alkalmazását, a szolgáltatóra a 99. cikknek megfelelő\npénzbírságot kell kiszabni. (8) A piacfelügyeleti hatóságok az e cikk\nalkalmazásának nyomon követésére vonatkozó hatáskörük gyakorlása során, az\n(EU) 2019/1020 rendelet 11. cikkével összhangban megfelelő ellenőrzéseket\nvégezhetnek, figyelembe véve különösen az e rendelet 71. cikkében említett\nuniós adatbázisban tárolt információkat. (1) Amennyiben valamely tagállam\npiacfelügyeleti hatósága a 79. cikk (5) bekezdésében említett értesítés\nkézhezvételét követő három hónapon - illetve az 5. cikkben említett MI-\ngyakorlatok tilalmának be nem tartása esetén 30 napon - belül kifogást emel\nvalamely más piacfelügyeleti hatóság által elfogadott intézkedéssel szemben,\nilletve ha a Bizottság úgy ítéli meg, hogy az intézkedés ellentétes az uniós\njoggal, a Bizottság indokolatlan késedelem nélkül egyeztetést kezdeményez a\nreleváns tagállam piacfelügyeleti hatóságával és a gazdasági szereplővel vagy\ngazdasági szereplőkkel, és értékeli a nemzeti intézkedést. Az említett\nértékelés eredményei alapján a Bizottság a 79. cikk (5) bekezdésében említett\nértesítéstől számított hat hónapon belül - vagy az 5. cikkben említett MI-\ngyakorlatok tilalmának be nem tartása esetén 60 napon belül - határoz arról,\nhogy a nemzeti intézkedés indokolt-e, és határozatáról értesíti az érintett\ntagállam piacfelügyeleti hatóságát. A Bizottság a határozatáról valamennyi más\npiacfelügyeleti hatóságot is tájékoztat. (2) Amennyiben az érintett tagállam\náltal tett intézkedést a Bizottság indokoltnak ítéli, minden tagállam\nbiztosítja, hogy megfelelő korlátozó intézkedéseket hozzon az érintett MI-\nrendszer tekintetében - így például előírja, hogy az MI-rendszert indokolatlan\nkésedelem nélkül vonják ki a forgalomból -, és erről tájékoztatja a\nBizottságot. Amennyiben a nemzeti intézkedést a Bizottság indokolatlannak\nítéli, az érintett tagállam visszavonja az intézkedést, és erről tájékoztatja\na Bizottságot. (3) Amennyiben a nemzeti intézkedést indokoltnak ítélik, és az\nMI-rendszer meg nem felelése az e rendelet 40. és 41. cikkében említett\nharmonizált szabványok vagy közös előírások hiányosságainak a következménye, a\nBizottság az 1025/2012/EU rendelet 11. cikkében előírt eljárást alkalmazza.\n(1) Amennyiben egy tagállam piacfelügyeleti hatósága a 79. cikk szerinti\nértékelés elvégzését, és a 77. cikk (1) bekezdésében említett érintett nemzeti\nhatósággal való konzultációt követően megállapítja, hogy bár a nagy kockázatú\nMI-rendszer megfelel e rendeletnek, mindazonáltal kockázatot jelent személyek\negészségére vagy biztonságára, az alapvető jogokra, vagy a közérdek védelmének\negyéb szempontjaira nézve, akkor - a kockázat jellegétől függően - fel kell\nszólítania az érintett gazdasági szereplőt, hogy - indokolatlan késedelem\nnélkül, adott esetben a piacfelügyeleti hatóság által előírt időszakon belül -\ntegyen meg minden megfelelő intézkedést annak biztosítására, hogy az érintett\nMI-rendszer a forgalomba hozatalkor vagy az üzembe helyezéskor már ne\njelentsen kockázatot. (2) A szolgáltatónak vagy valamely egyéb releváns\ngazdasági szereplőnek biztosítania kell, hogy az uniós piacon általa\nforgalmazott valamennyi MI-rendszer tekintetében korrekciós intézkedéseket\nhozzon az (1) bekezdésben említett tagállam piacfelügyeleti hatósága által\nelőírt határidőn belül. (3) A tagállamok haladéktalanul tájékoztatják a\nBizottságot és a többi tagállamot az (1) bekezdés szerinti megállapításokról.\nA tájékoztatásnak tartalmaznia kell valamennyi rendelkezésre álló adatot,\nkülönösen az érintett MI-rendszer azonosításához szükséges adatokat, az MI-\nrendszer származását és ellátási láncát, a felmerülő kockázat jellegét,\nvalamint a meghozott nemzeti intézkedések jellegét és időtartamát. (4) A\nBizottság indokolatlan késedelem nélkül konzultációt kezd az érintett\ntagálamokkal és a releváns gazdasági szereplőkkel, valamint értékeli a\nmeghozott nemzeti intézkedéseket. Az értékelés eredményei alapján a Bizottság\nhatározatot hoz arról, hogy az intézkedés indokolt-e, és szükség esetén\njavaslatot tesz más megfelelő intézkedésekre. (5) A Bizottság haladéktalanul\nközli határozatát az érintett tagállamokkal és a releváns gazdasági\nszereplőkkel. Tájékoztatja a többi tagállamot is. (1) Amennyiben egy tagállam\npiacfelügyeleti hatósága megteszi a következő megállapítások egyikét, meg kell\nkövetelnie a releváns szolgáltatótól, hogy - az esetlegesen előírt időszakon\nbelül - szüntesse meg az érintett meg nem felelést: a) a CE-jelölést a 48.\ncikket megsértő módon helyezték el; b) nem helyeztek el CE-jelölést; c) nem\nkészült a 47. cikkben említett EU-megfelelőségi nyilatkozat; d) a 47. cikkben\nemlített EU-megfelelőségi nyilatkozatot nem megfelelően készítették el; e) nem\nvégezték el a 71. cikkben említett uniós adatbázisba történő regisztrációt; f)\nnem neveztek ki adott esetben meghatalmazott képviselőt; g) nem áll\nrendelkezésre műszaki dokumentáció. (2) Amennyiben az (1) bekezdésben említett\nmeg nem felelés továbbra is fennáll, az érintett tagállam piacfelügyeleti\nhatóságának megfelelő és arányos intézkedéseket kell hoznia a nagy kockázatú\nMI-rendszer forgalmazásának korlátozása vagy betiltása céljából, vagy\ngondoskodnia kell annak haladéktalan visszahívásáról vagy piaci forgalomból\ntörténő kivonásáról. (1) A Bizottság kijelöl egy vagy több uniós MI-tesztelési\ntámogató struktúrát az (EU) 2019/1020 rendelet 21. cikkének (6) bekezdésében\nfelsorolt feladatoknak az MI területén való elvégzésére. (2) Az (1)\nbekezdésben említett feladatok sérelme nélkül, az uniós MI-tesztelési támogató\nstruktúrák - a Testület, a Bizottság vagy a piacfelügyeleti hatóságok kérésére\n- független műszaki vagy tudományos tanácsadást is nyújtanak. Az egyéb\nközigazgatási vagy bírósági jogorvoslatok sérelme nélkül, bármely olyan\ntermészetes vagy jogi személy, aki vagy amely okkal feltételezi, hogy e\nrendelet rendelkezéseit megsértették, panaszokat nyújthat be a releváns\npiacfelügyeleti hatósághoz. Az ilyen panaszokat - az (EU) 2019/1020\nrendelettel összhangban - figyelembe kell venni a piacfelügyeleti\ntevékenységek végzése céljából, és azokat a piacfelügyeleti hatóságok által\nerre meghatározott, célzott eljárásokkal összhangban kell kezelni. (1) Minden\nolyan érintett személy számára, aki egy olyan döntés hatálya alá tartozik,\namelyet az alkalmazó a III. mellékletben - az annak 2. pontjában felsorolt\nrendszerek kivételével - felsorolt valamely nagy kockázatú MI-rendszer\nkimenete alapján hozott, és amely joghatásokat vált ki, vagy az említett\nszemélyt hasonlóan jelentősen érinti oly módon, hogy annak megítélése szerint\na döntés kedvezőtlen hatást gyakorol az egészségére, biztonságára vagy\nalapvető jogaira, biztosítani kell az ahhoz való jogot, hogy az alkalmazótól\negyértelmű és érdemi magyarázatot kapjon az MI-rendszernek a döntéshozatali\neljárásban betöltött szerepéről és a hozott döntés fő elemeiről. (2) Az (1)\nbekezdés nem alkalmazandó az olyan MI-rendszerek használatára, amelyek\nesetében az említett bekezdés szerinti kötelezettség alóli kivételek vagy az\narra vonatkozó korlátozások az uniós jogból vagy az uniós jognak megfelelő\nnemzeti jogból következnek. (3) Ez a cikk csak annyiban alkalmazandó,\namennyiben az (1) bekezdésben említett jogról az uniós jog másként nem\nrendelkezik. Az e rendelet megsértéseinek bejelentésére és az ilyen\njogsértéseket bejelentő személyek védelmére az (EU) 2019/1937 irányelv\nalkalmazandó. (1) A Bizottság - figyelembe véve a 94. cikk szerinti eljárási\ngaranciákat - kizárólagos hatáskörrel rendelkezik az V. fejezetben foglaltak\nfelügyeletére és végrehajtására. A Bizottság e feladatok végrehajtásával az\nMI-hivatalt bízza meg, ami nem érinti a Bizottság szervezési hatásköreit,\nvalamint a hatásköröknek az Unió és a tagállamok közötti, a Szerződéseken\nalapuló megosztását. (2) Anélkül, hogy ez sértené a 75. cikk (3) bekezdését, a\npiacfelügyeleti hatóságok, amennyiben ez szükséges az e rendelet szerinti\nfeladataik ellátásához, és arányos azzal, felkérhetik a Bizottságot az e\nszakaszban megállapított hatáskörök gyakorlására. (1) Az MI-hivatal - az e\nszakasz alapján ráruházott feladatok ellátása céljából - meghozhatja azon\nintézkedéseket, amelyek a hatékony végrehajtásnak, valamint annak nyomon\nkövetéséhez szükségesek, hogy az általános célú MI-modellek szolgáltatói\nmegfelelnek-e ezen rendeletnek, ideértve a jóváhagyott gyakorlati kódexek\nbetartását is. (2) A downstream szolgáltatók számára jogot kell biztosítani\nahhoz, hogy panaszt nyújtsanak be e rendelet feltételezett megsértése miatt. A\npanaszt megfelelően meg kell indokolni, és abban legalább a következőket fel\nkell tüntetni: a) az érintett általános célú MI-modell szolgáltatójának\nkapcsolattartó pontja; b) a releváns tények, e rendelet érintett\nrendelkezései, valamint annak megindokolása, hogy a downstream szolgáltató\nmiért véli úgy, hogy az érintett általános célú MI-modell szolgáltatója\nmegsértette e rendeletet; c) bármely egyéb olyan információ, amelyet a\nkérelmet benyújtó downstream szolgáltató relevánsnak tekint, beleértve adott\nesetben a saját kezdeményezésére gyűjtött információkat is. (1) A tudományos\ntestület minősített riasztást küldhet az MI-hivatal számára, ha oka van úgy\nmegítélni, hogy: a) egy általános célú MI-modell konkrét és azonosítható\nkockázatot hordoz uniós szinten; vagy b) az általános célú MI-modell megfelel\naz 51. cikkben említett feltételeknek. (2) Az említett minősített riasztás\nalapján a Bizottság az MI-hivatalon keresztül és a Testület tájékoztatását\nkövetően gyakorolhatja az e szakaszban az ügy értékelése céljából\nmeghatározott hatásköröket. Az MI-hivatalnak tájékoztatnia kell a Testületet a\n91-94. cikk szerinti intézkedésekről. (3) A minősített riasztást megfelelően\nmeg kell indokolni, és abban legalább a következőket fel kell tüntetni: a) az\nérintett, rendszerszintű kockázatot jelentő általános célú MI-modell\nszolgáltatójának kapcsolattartó pontja; b) a releváns tények leírása és a\ntudományos testület általi riasztás indokolása; c) bármely egyéb olyan\ninformáció, amelyet a tudományos testület relevánsnak tekint, ideértve adott\nesetben a saját kezdeményezésére gyűjtött információkat is. (1) A Bizottság\nfelkérheti az érintett általános célú MI-modell szolgáltatóját, hogy nyújtsa\nbe a szolgáltató által az 53. és 55. cikknek megfelelően elkészített\ndokumentációt, illetve bármely olyan további információt, amely szükséges\nannak értékeléséhez, hogy a szolgáltató megfelel-e ezen rendeletnek. (2) Az\ninformációkérés elküldése előtt az MI-hivatal strukturált párbeszédet\nkezdeményezhet az általános célú MI-modell szolgáltatójával. (3) A tudományos\ntestület kellően indokolt kérésére a Bizottság információkérést intézhet az\náltalános célú MI-modell szolgáltatójához, amennyiben az információkhoz való\nhozzáférés szükséges a tudományos testület 68. cikk (2) bekezdése szerinti\nfeladatainak ellátásához, és arányos azzal. (4) Az információkérésben fel kell\ntüntetni a kérés jogalapját és célját, meg kell jelölni, hogy mely\ninformációkra van szükség, meg kell határozni az információk rendelkezésre\nbocsátására vonatkozó határidőt, továbbá meg kell jelölni a 101. cikkben\nfoglalt, a helytelen, hiányos vagy félrevezető információk szolgáltatása\nesetén kiszabandó bírságokat. (5) Az érintett általános célú MI-modell\nszolgáltatójának vagy annak képviselőjének rendelkezésre kell bocsátania a\nkért információkat. Jogi személyek, társaságok vagy cégek esetében, illetve ha\na szolgáltató nem rendelkezik jogi személyiséggel, a kért információkat az\nemlítettek képviseletére a jogszabály vagy az alapszabályuk által\nfelhatalmazott személyek bocsátják rendelkezésre az érintett általános célú\nMI-modell szolgáltatója nevében. A megfelelő meghatalmazással rendelkező\nügyvédek jogosultak arra, hogy ügyfeleik nevében információkat\nszolgáltassanak. Mindazonáltal továbbra is teljes mértékben az ügyfelek\nfelelnek azért, ha a szolgáltatott információk hiányosak, helytelenek vagy\nfélrevezetők. (1) Az MI-hivatal a Testülettel folytatott konzultációt követően\naz érintett általános célú MI-modellre vonatkozó értékeléseket végezhet annak\nérdekében, hogy: a) értékelje, hogy a szolgáltató megfelel-e az e rendelet\nszerinti kötelezettségeknek, amennyiben a 91. cikk alapján gyűjtött\ninformációk nem elégségesek; vagy b) különösen a tudományos testület által a\n90. cikk (1) bekezdésének a) pontjával összhangban adott minősített riasztást\nkövetően megvizsgálja a rendszerszintű kockázatot jelentő általános célú MI-\nmodellek rendszerszintű kockázatait uniós szinten. (2) A Bizottság dönthet\núgy, hogy - többek között a 68. cikk alapján létrehozott tudományos testület\nsoraiból - független szakértőket jelöl ki az értékeléseknek a Bizottság\nnevében történő elvégzésére. Az e feladatra kijelölt független szakértőknek\nmeg kell felelniük a 68. cikk (2) bekezdésében meghatározott kritériumoknak.\n(3) Az (1) bekezdés alkalmazásában a Bizottság API-kon vagy további megfelelő\nműszaki megoldásokon és eszközökön - többek között forráskódon - keresztül\nhozzáférést kérhet az érintett általános célú MI-modellhez. (4) A hozzáférés\niránti kérelemben fel kell tüntetni a kérelem jogalapját, célját és indokait,\nvalamint meg kell határozni azon időszakot, amelyen belül a hozzáférés\nbiztosítandó, és a 101. cikkben a hozzáférés biztosításának elmulasztása\nesetére előírt bírságokat. (5) Az érintett általános célú MI-modell\nszolgáltatóinak vagy képviselőinek meg kell adniuk a kért információkat. Jogi\nszemélyek, társaságok vagy cégek esetében, vagy ha a szolgáltató nem\nrendelkezik jogi személyiséggel, az érintett általános célú MI-modell\nszolgáltatója nevében az említettek képviseletére jogszabály vagy a létesítő\nokiratuk által felhatalmazott személyek biztosítják a kért hozzáférést. (6) A\nBizottság végrehajtási jogi aktusokat fogad el, amelyekben meghatározza az\nértékelések részletes szabályait és feltételeit, ideértve a független\nszakértők bevonására vonatkozó részletes szabályokat és a kiválasztásukra\nirányuló eljárást. Ezeket a végrehajtási jogi aktusokat a 98. cikk (2)\nbekezdésében említett vizsgálóbizottsági eljárás keretében kell elfogadni. (7)\nAz érintett általános célú MI-modellhez való hozzáférés kérelmezése előtt az\nMI-hivatal strukturált párbeszédet kezdeményezhet az általános célú MI-modell\nszolgáltatójával annak érdekében, hogy több információt gyűjtsön a modell\nbelső teszteléséről, a rendszerszintű kockázatok megelőzésére szolgáló belső\nbiztosítékokról, valamint a szolgáltató által az ilyen kockázatok enyhítése\nérdekében hozott egyéb belső eljárásokról és intézkedésekről. (1) Amennyiben\nszükséges és helyénvaló, a Bizottság előírhatja a szolgáltatók számára, hogy:\na) hozzanak megfelelő intézkedéseket az 53. és az 54. cikkben meghatározott\nkötelezettségeknek való megfelelés érdekében; b) kockázatenyhítő\nintézkedéseket hajtanak végre, amennyiben a 92. cikkel összhangban elvégzett\nértékelés komoly és megalapozott aggályokat vetett fel valamely uniós szinten\nfennálló rendszerszintű kockázattal kapcsolatban; c) korlátozzák a modell\nforgalmazását, vonják ki a modellt a forgalomból vagy hívják vissza azt. (2)\nAzt megelőzően, hogy sor kerül valamely intézkedés előírására, az MI-hivatal\nstrukturált párbeszédet kezdeményezhet az általános célú MI-modell\nszolgáltatójával. (3) Ha a (2) bekezdésben említett strukturált párbeszéd\nsorán a rendszerszintű kockázatot jelentő általános célú MI-modell\nszolgáltatója kötelezettséget vállal arra, hogy kockázatcsökkentő\nintézkedéseket hajt végre egy uniós szinten fennálló rendszerszintű kockázat\nkezelése érdekében, a Bizottság - határozat útján - kötelező erejűvé\nnyilváníthatja ezeket a kötelezettségvállalásokat, és megállapíthatja, hogy\ntovábbi intézkedések nem indokoltak. Az (EU) 2019/1020 rendelet 18. cikke - az\ne rendelet által előírt konkrétabb eljárási jogok sérelme nélkül -\nértelemszerűen alkalmazandó az általános célú MI-modell szolgáltatóira. (1) Az\nMI-hivatal és a tagállamok ösztönzik és elősegítik olyan - a vonatkozó\nirányítási mechanizmusokat is magukban foglaló - magatartási kódexek\nkidolgozását, amelyek célja előmozdítani az e rendelet III. fejezetének 2.\nszakaszában meghatározott követelmények közül néhánynak vagy valamennyinek a\nnagy kockázatú MI-rendszerektől eltérő MI-rendszerekre történő önkéntes\nalkalmazását, figyelembe véve az ilyen követelmények alkalmazását lehetővé\ntevő, rendelkezésre álló műszaki megoldásokat és iparági legjobb\ngyakorlatokat. (2) Az MI-hivatal és a tagállamok elősegítik olyan magatartási\nkódexek kidolgozását, amelyek a konkrét követelmények valamennyi MI-rendszerre\nvaló - többek között az alkalmazók általi - önkéntes alkalmazására\nvonatkoznak, egyértelmű célkitűzések és e célkitűzések elérésének mérésére\nszolgáló fő teljesítménymutatók alapján, beleértve például, de nem\nkizárólagosan a következő elemeket: a) a megbízható mesterséges\nintelligenciára alkalmazandó uniós etikai iránymutatásokban előírt,\nalkalmazandó elemek; b) az MI-rendszerek környezeti fenntarthatóságra\ngyakorolt hatásának értékelése és minimalizálása, többek között az\nenergiahatékony programozás és a mesterséges intelligencia hatékony\ntervezését, betanítását és használatát szolgáló technikák tekintetében; c) az\nMI-jártasság előmozdítása, különösen a mesterséges intelligencia\nfejlesztésével, üzemeltetésével és használatával foglalkozó személyek körében;\nd) az MI-rendszerek kialakítása során az inkluzivitás és a sokszínűség\nelősegítése, többek között inkluzív és sokszínű fejlesztői csapatok\nlétrehozása és az érdekelt felek e folyamatban való részvételének előmozdítása\nrévén; e) azon negatív hatások értékelése és megelőzése, amelyeket az MI-\nrendszerek a kiszolgáltatott személyekre vagy a kiszolgáltatott személyek\ncsoportjaira - ideértve a fogyatékossággal élő személyeknek biztosítandó\nakadálymentességet is -, valamint a nemek közötti egyenlőségre gyakorolnak.\n(3) Az MI-rendszerek egyes szolgáltatói vagy alkalmazói, vagy az azokat\nképviselő szervezetek vagy mindkettő magatartási kódexeket készíthetnek,\ntöbbek között bármely érdekelt fél és képviseleti szervezetei - ideértve a\ncivil szféra szervezeteit és a tudományos köröket is - bevonásával. A\nmagatartási kódexek vonatkozhatnak egy vagy több MI-rendszerre, figyelembe\nvéve az adott rendszerek rendeltetésének hasonlóságát. (4) A magatartási\nkódexek kidolgozásának ösztönzése és elősegítése során az MI-hivatal és a\ntagállamok figyelembe veszik a kkv-k - köztük az induló innovatív\nvállalkozások - sajátos érdekeit és igényeit. (1) A Bizottság iránymutatásokat\ndolgoz ki e rendelet gyakorlati végrehajtására vonatkozóan, különös\ntekintettel a következőkre: a) a 8-15. cikkben és a 25. cikkben említett\nkövetelmények és kötelezettségek alkalmazása; b) az 5. cikkben említett\ntiltott gyakorlatok; c) a jelentős módosításra vonatkozó rendelkezések\ngyakorlati végrehajtása; d) az 50. cikkben meghatározott átláthatósági\nkötelezettségek gyakorlati végrehajtása; e) részletes információk az e\nrendelet és az I. mellékletben felsorolt uniós harmonizációs jogszabályok,\nvalamint más releváns uniós jog közötti kapcsolatról, többek között a\nvégrehajtásuk következetessége tekintetében; f) az MI-rendszer 3. cikk 1.\npontjában foglalt fogalommeghatározásának alkalmazása. Az iránymutatások\nkiadásakor a Bizottság különös figyelmet fordít a kkv-k, köztük az induló\ninnovatív vállalkozások, valamint a helyi közigazgatási szervek és az e\nrendelet által legvalószínűbben érintett ágazatok igényeire. Az e bekezdés\nelső albekezdésében említett iránymutatásokban kellően figyelembe kell venni\naz MI-vel kapcsolatos technika általánosan elfogadott, mindenkori állását,\nvalamint a 40. és a 41. cikkben említett vonatkozó harmonizált szabványokat és\nközös előírásokat, vagy az uniós harmonizációs jog alapján meghatározott\nharmonizált szabványokat vagy műszaki előírásokat. (2) A tagállamok vagy az\nMI-hivatal kérésére vagy saját kezdeményezésére a Bizottság szükség esetén\naktualizálja a korábban elfogadott iránymutatásokat. (1) A felhatalmazáson\nalapuló jogi aktusok elfogadására vonatkozóan a Bizottság részére adott\nfelhatalmazás feltételeit ez a cikk határozza meg. (2) A Bizottságnak a 6.\ncikk (6) és (7) bekezdésében, a 7. cikk (1) és (3) bekezdésében, a 11. cikk\n(3) bekezdésében, a 43. cikk (5) és (6) bekezdésében, a 47. cikk (5)\nbekezdésében, az 51. cikk (3) bekezdésében, az 52. cikk (4) bekezdésében,\nvalamint az 53. cikk (5) és (6) bekezdésében említett, felhatalmazáson alapuló\njogi aktusok elfogadására vonatkozó felhatalmazása ötéves időtartamra szól\n2024. augusztus 1-től kezdődő hatállyal. A Bizottság legkésőbb kilenc hónappal\naz ötéves időtartam letelte előtt jelentést készít a felhatalmazásról. A\nfelhatalmazás hallgatólagosan meghosszabbodik a korábbival megegyező\nidőtartamra, amennyiben az Európai Parlament vagy a Tanács nem ellenzi a\nmeghosszabbítást legkésőbb három hónappal minden egyes időtartam letelte\nelőtt. (3) Az Európai Parlament vagy a Tanács bármikor visszavonhatja a 6.\ncikk (6) és (7) bekezdésében, a 7. cikk (1) és (3) bekezdésében, a 11. cikk\n(3) bekezdésében, a 43. cikk (5) és (6) bekezdésében, a 47. cikk (5)\nbekezdésében, az 51. cikk (3) bekezdésében, az 52. cikk (4) bekezdésében,\nvalamint az 53. cikk (5) és (6) bekezdésében említett felhatalmazást. A\nvisszavonásról szóló határozat megszünteti az abban meghatározott\nfelhatalmazást. A határozat az Európai Unió Hivatalos Lapjában való\nkihirdetését követő napon vagy a benne megjelölt későbbi időpontban lép\nhatályba. A határozat nem érinti a már hatályban lévő, felhatalmazáson alapuló\njogi aktusok érvényességét. (4) A felhatalmazáson alapuló jogi aktus\nelfogadása előtt a Bizottság a jogalkotás minőségének javításáról szóló, 2016.\náprilis 13-i intézményközi megállapodásban megállapított elvekkel összhangban\nkonzultál az egyes tagállamok által kijelölt szakértőkkel. (5) A Bizottság a\nfelhatalmazáson alapuló jogi aktus elfogadását követően haladéktalanul és\negyidejűleg értesíti arról az Európai Parlamentet és a Tanácsot. (6) A 6. cikk\n(6) vagy (7) bekezdése, a 7. cikk (1) vagy (3) bekezdése, a 11. cikk (3)\nbekezdése, a 43. cikk (5) vagy (6) bekezdése, a 47. cikk (5) bekezdése, az 51.\ncikk (3) bekezdése, az 52. cikk (4) bekezdése vagy az 53. cikk (5) vagy (6)\nbekezdése értelmében elfogadott, felhatalmazáson alapuló jogi aktus csak akkor\nlép hatályba, ha az Európai Parlamentnek és a Tanácsnak a jogi aktusokról való\nértesítését követő három hónapon belül sem az Európai Parlament, sem a Tanács\nnem emelt ellene kifogást, illetve ha az említett időtartam lejártát\nmegelőzően mind az Európai Parlament, mind a Tanács arról tájékoztatta a\nBizottságot, hogy nem fog kifogást emelni. Az Európai Parlament vagy a Tanács\nkezdeményezésére ez az időtartam három hónappal meghosszabbodik. (1) A\nBizottságot egy bizottság segíti. Ez a bizottság a 182/2011/EU rendelet\nértelmében vett bizottságnak minősül. (2) Az e bekezdésre történő\nhivatkozáskor a 182/2011/EU rendelet 5. cikkét kell alkalmazni. (1) Az e\nrendeletben meghatározott feltételekkel összhangban a tagállamok megállapítják\naz e rendelet gazdasági szereplők általi megsértése esetén alkalmazandó -\nadott esetben figyelmeztetéseket és nem pénzbeli intézkedéseket is magukban\nfoglaló - szankciókra és egyéb végrehajtási intézkedésekre vonatkozó\nszabályokat, és meghoznak minden szükséges intézkedést ezek megfelelő és\nhatékony végrehajtásának biztosítására, figyelembe véve ennek során a\nBizottság által a 96. cikk szerint kiadott iránymutatásokat. Az előírt\nszankcióknak hatékonyaknak, arányosaknak és visszatartó erejűeknek kell\nlenniük. Figyelmet kell fordítaniuk a kkv-k - köztük az induló innovatív\nvállalkozások - érdekeire, valamint gazdasági életképességükre. (2) A\ntagállamok az (1) bekezdésben említett szankciókra és egyéb végrehajtási\nintézkedésekre vonatkozó szabályokról haladéktalanul, de legkésőbb az\nalkalmazás kezdőnapjáig értesítik a Bizottságot, és haladéktalanul\ntájékoztatják a Bizottságot az e szabályokat érintő minden későbbi\nmódosításról. (3) Az 5. cikkben említett MI-gyakorlatok tilalmának be nem\ntartása legfeljebb 35 000 000 EUR összegű, vagy ha az elkövető vállalkozás, az\nelőző pénzügyi év teljes globális éves árbevételének legfeljebb 7%-át kitevő\nösszegű közigazgatási bírsággal sújtandó, a kettő közül a magasabb összegűt\nfigyelembe véve. (4) Ha az MI-rendszer nem felel meg a gazdasági szereplőkkel\nvagy a bejelentett szervezetekkel kapcsolatos - az 5. cikkben\nmeghatározottaktól eltérő -, következő rendelkezések bármelyikének, az\nlegfeljebb 15 000 000 EUR összegű, vagy ha az elkövető vállalkozás, az előző\npénzügyi év teljes globális éves árbevételének legfeljebb 3%-át kitevő összegű\nközigazgatási bírsággal sújtandó, a kettő közül a magasabb összegűt figyelembe\nvéve: a) a szolgáltatók 16. cikk szerinti kötelezettségei; b) a meghatalmazott\nképviselők 22. cikk szerinti kötelezettségei; c) az importőrök 23. cikk\nszerinti kötelezettségei; d) a forgalmazók 24. cikk szerinti kötelezettségei;\ne) az alkalmazók 26. cikk szerinti kötelezettségei; f) a bejelentett\nszervezeteknek a 31. cikk, a 33. cikk (1), (3) és (4) bekezdése vagy a 34.\ncikk szerinti követelményei és kötelezettségei; g) a szolgáltatókra és az\nalkalmazókra vonatkozó, 50. cikk szerinti átláthatósági kötelezettségek. (5)\nHa a bejelentett szervezetek vagy az illetékes nemzeti hatóságok kérésére\nválaszul helytelen, hiányos vagy félrevezető információ szolgáltatása\ntörténik, az legfeljebb 7 500 000 EUR összegű, vagy ha az elkövető\nvállalkozás, az előző pénzügyi év teljes globális éves árbevételének\nlegfeljebb 1%-át kitevő összegű közigazgatási bírsággal sújtandó, a kettő\nközül a magasabb összegűt figyelembe véve. (6) A kkv-k, köztük az induló\ninnovatív vállalkozások esetében az e cikkben említett egyes pénzbírságok nem\nhaladhatják meg a (3), a (4) és az (5) bekezdésben említett százalékos\narányokat, illetve összegeket, és a kettő közül mindig az alacsonyabbat kell\nfigyelembe venni. (7) A közigazgatási bírság kiszabására vonatkozó döntés\nmeghozatalakor és a közigazgatási bírság összegéről hozott döntés során minden\negyes esetben figyelembe kell venni az adott helyzetre vonatkozó valamennyi\nreleváns körülményt, és - adott esetben - figyelmet kell fordítani a\nkövetkezőkre: a) a jogsértés és következményeinek jellege, súlyossága és\nidőtartama, figyelembe véve az MI-rendszer célját, valamint adott esteben az\nérintett személyek számát és az általuk elszenvedett kár mértékét; b)\nugyanazon jogsértés miatt más piacfelügyeleti hatóságok szabtak-e már ki\nközigazgatási bírságot ugyanazon gazdasági szereplővel szemben; c) más uniós\nvagy nemzeti jog megsértése miatt más hatóságok szabtak-e már ki közigazgatási\nbírságot ugyanazon gazdasági szereplővel szemben, amennyiben az említett\njogsértések e rendelet tényleges megsértését jelentő ugyanazon tevékenységből\nvagy mulasztásból fakadnak; d) a jogsértést elkövető gazdasági szereplő\nmérete, éves árbevétele és piaci részesedése; e) az eset körülményei szerint\nalkalmazandó, bármely egyéb súlyosbító vagy enyhítő tényező, így például a\njogsértésből fakadó, közvetlen vagy közvetett pénzügyi haszon szerzése vagy\nveszteség elkerülése; f) a nemzeti illetékes hatósággal a jogsértés orvoslása\nés a jogsértés esetleges kedvezőtlen hatásainak enyhítése érdekében folytatott\negyüttműködés mértéke; g) a gazdasági szereplő felelősségének mértéke,\nfigyelembe véve az általa végrehajtott technikai és szervezeti intézkedéseket;\nh) az, ahogyan az illetékes nemzeti hatóságok tudomást szereztek a\njogsértésről, különös tekintettel arra, hogy a gazdasági szereplő jelentette-e\nbe a jogsértést, és ha igen, milyen részletességgel; i) a jogsértés szándékos\nvagy gondatlan jellege; j) intézkedések, amelyeket a gazdasági szereplő az\nérintett személyek által elszenvedett károk enyhítése érdekében tett. (8)\nMinden tagállam szabályokat állapít meg arra vonatkozóan, hogy milyen\nmértékben szabhatók ki közigazgatási bírságok az adott tagállamban létrehozott\nhatóságokra és szervekre. (9) A tagállamok jogrendszerétől függően a\nközigazgatási bírságokra vonatkozó szabályok alkalmazhatók olyan módon, hogy a\nbírságokat - az adott tagállamban alkalmazandó szabályoknak megfelelően - az\nilletékes nemzeti bíróságok vagy adott esetben más szervek szabják ki. Az\nilyen szabályok alkalmazásának ezekben a tagállamokban azonos hatással kell\njárniuk. (10) Az e cikk szerinti hatásköröket az uniós és a nemzeti joggal\nösszhangban lévő megfelelő eljárási garanciák - többek között a hatékony\njogorvoslatok és a jogszerű eljárás - mellett kell gyakorolni. (11) A\ntagállamok évente jelentést tesznek a Bizottságnak az adott évben e cikkel\nösszhangban kiszabott közigazgatási bírságokról, valamint a kapcsolódó\njogvitákról vagy bírósági eljárásokról. (1) Az európai adatvédelmi biztos\nközigazgatási bírságot szabhat ki az e rendelet hatálya alá tartozó uniós\nintézményekre, szervekre és hivatalokra. A közigazgatási bírság kiszabására\nvonatkozó döntés meghozatalakor és a bírság összegének meghatározásakor minden\negyes esetben figyelembe kell venni az adott helyzetre vonatkozó valamennyi\nreleváns körülményt, és kellő figyelmet kell fordítani a következőkre: a) a\njogsértés és következményeinek jellege, súlyossága és időtartama, figyelembe\nvéve az érintett MI-rendszer célját, valamint adott esetben az érintett\nszemélyek számát és az általuk elszenvedett kár mértékét; b) az uniós\nintézmény, szerv vagy hivatal felelősségének mértéke, figyelembe véve a\njogsértés megelőzése érdekében végrehajtott technikai és szervezeti\nintézkedéseket; c) az uniós intézmény, szerv vagy hivatal intézkedései az\nérintettek által elszenvedett kár enyhítésére; d) az európai adatvédelmi\nbiztossal a jogsértés orvoslása és a jogsértés esetleges kedvezőtlen\nhatásainak enyhítése érdekében folytatott együttműködés mértéke, így például\naz európai adatvédelmi biztos által az érintett uniós intézménnyel, szervvel\nvagy hivatallal szemben ugyanazon tárgyban korábban elrendelt bármely\nintézkedésnek való megfelelés; e) az uniós intézmény, szerv vagy hivatal által\nkorábban elkövetett hasonló jogsértések; f) annak módja, ahogyan az európai\nadatvédelmi biztos tudomást szerzett a jogsértésről, különös tekintettel arra,\nhogy az uniós intézmény, szerv vagy hivatal jelentette-e be a jogsértést, és\nha igen, milyen részletességgel; g) az uniós intézmény, szerv vagy hivatal\néves költségvetése. (2) Az 5. cikkben említett MI-gyakorlatok tilalmának be\nnem tartása legfeljebb 1 500 000 EUR összegű közigazgatási bírsággal sújtandó.\n(3) Ha az MI-rendszer nem felel meg az e rendelet szerinti - az 5. cikkben\nmeghatározottaktól eltérő - követelményeknek vagy kötelezettségeknek, az\nlegfeljebb 750 000 EUR összegű közigazgatási bírsággal sújtandó. (4) Az e cikk\nszerinti határozatok meghozatala előtt az európai adatvédelmi biztos\nbiztosítja az európai adatvédelmi biztos által lefolytatott eljárás tárgyát\nképező uniós intézmény, szerv vagy hivatal számára annak lehetőségét, hogy\nkifejtse álláspontját az esetleges jogsértéssel összefüggésben. Az európai\nadatvédelmi biztos a döntéseit csak olyan elemekre és körülményekre\nalapozhatja, amelyekkel kapcsolatban az érintett felek megtehették\nészrevételeiket. Az esetleges panaszosokat szorosan be kell vonni az\neljárásba. (5) Az érintett felek védelemhez való jogát az eljárás során teljes\nmértékben tiszteletben kell tartani. Az érintett felek jogosultak arra, hogy\nhozzáférjenek az európai adatvédelmi biztos aktájához, figyelemmel az\negyéneknek vagy vállalkozásoknak a személyes adataik vagy üzleti titkaik\nvédeleméhez fűződő jogos érdekére. (6) Az e cikk szerint kiszabott bírságok\nrévén beszedett összegek hozzájárulnak az Unió általános költségvetéséhez. A\npénzbírságok nem befolyásolhatják a megbírságolt uniós intézmény, szerv vagy\nhivatal hatékony működését. (7) Az európai adatvédelmi biztos évente\ntájékoztatja az MI-hivatalt az e cikk alapján kiszabott közigazgatási\nbírságokról, valamint az általa kezdeményezett jogvitákról vagy bírósági\neljárásokról. (1) A Bizottság az általános célú MI-modellek szolgáltatóira az\nelőző pénzügyi évben az éves teljes globális árbevételük legfeljebb 3%-át\nkitevő összegű vagy legfeljebb 15 000 000 EUR összegű pénzbírságot szabhat ki,\na kettő közül a magasabb összegűt figyelembe véve, amennyiben a Bizottság\nmegállapítja, hogy a szolgáltató szándékosan vagy gondatlanságból: a)\nmegsértette e rendelet releváns rendelkezéseit; b) nem tett eleget a 91. cikk\nszerinti, dokumentum iránti kérelemnek vagy információkérésnek, illetve\nhelytelen, hiányos vagy félrevezető információt szolgáltatott; c) nem tett\neleget a 93. cikk alapján előírt intézkedésnek; d) nem biztosított hozzáférést\na Bizottság számára az általános célú MI-modellhez vagy a rendszerszintű\nkockázatot jelentő általános célú MI-modellhez a 92. cikk szerinti értékelés\nelvégzése céljából. A Bizottság a pénzbírság vagy a kényszerítő bírság\nösszegét - az arányosság és a megfelelőség elvét kellően figyelembe véve - a\njogsértés jellegére, súlyosságára és időtartamára tekintettel állapítja meg. A\nBizottság figyelembe veszi a 93. cikk (3) bekezdésével összhangban tett vagy\naz 56. cikkel összhangban a vonatkozó gyakorlati kódexekben vállalt\nkötelezettségeket is. (2) Az (1) bekezdés szerinti határozat elfogadása előtt\na Bizottság közli előzetes megállapításait az általános célú MI-modell\nszolgáltatójával, és lehetőséget biztosít számára, hogy kifejtse álláspontját.\n(3) Az e cikkel összhangban kiszabott pénzbírságoknak hatékonyaknak,\narányosaknak és visszatartó erejűeknek kell lenniük. (4) Az e cikk alapján\nkiszabott pénzbírságokra vonatkozó információkat adott esetben a Testülettel\nis közölni kell. (5) Az Európai Unió Bírósága korlátlan felülvizsgálati\njogkörrel rendelkezik a Bizottságnak a pénzbírság összegét e cikk alapján\nmegállapító határozatai tekintetében. A Bíróság a kiszabott pénzbírságot\ntörölheti, csökkentheti vagy növelheti. (6) A Bizottság végrehajtási jogi\naktusokat fogad el, amelyek részletes szabályokat és eljárási biztosítékokat\ntartalmaznak az e cikk (1) bekezdése szerinti határozatok esetleges\nelfogadására irányuló eljárásokra vonatkozóan. Ezeket a végrehajtási jogi\naktusokat a 98. cikk (2) bekezdésében említett vizsgálóbizottsági eljárás\nkeretében kell elfogadni. A 300/2008/EK rendelet 4. cikkének (3) bekezdése a\nkövetkező albekezdéssel egészül ki: „Az (EU) 2024/1689 európai parlamenti és\ntanácsi rendelet * értelmében vett mesterségesintelligencia-rendszerekkel\nkapcsolatos védelmi berendezések jóváhagyására és használatára vonatkozó\nműszaki előírásokkal és eljárásokkal kapcsolatos részletes intézkedések\nelfogadásakor figyelembe kell venni az említett rendelet III. fejezetének 2.\nszakaszában foglalt követelményeket.” A 167/2013/EU rendelet 17. cikkének (5)\nbekezdése a következő albekezdéssel egészül ki: „Az (EU) 2024/1689 európai\nparlamenti és tanácsi rendelet * értelmében biztonsági alkotórészeknek\nminősülő mesterségesintelligencia-rendszerekre vonatkozó, az első albekezdés\nszerinti, felhatalmazáson alapuló jogi aktusok elfogadásakor figyelembe kell\nvenni az említett rendelet III. fejezetének 2. szakaszában foglalt\nkövetelményeket.” A 168/2013/EU rendelet 22. cikkének (5) bekezdése a\nkövetkező albekezdéssel egészül ki: „Az (EU) 2024/1689 európai parlamenti és\ntanácsi rendelet * értelmében biztonsági alkotórészeknek minősülő\nmesterségesintelligencia-rendszerekre vonatkozó, az első albekezdés szerinti,\nfelhatalmazáson alapuló jogi aktusok elfogadásakor figyelembe kell venni az\nemlített rendelet III. fejezetének 2. szakaszában foglalt követelményeket.” A\n2014/90/EU irányelv 8. cikke a következő bekezdéssel egészül ki: „(5) Azon\nmesterségesintelligencia-rendszerek esetében, amelyek az (EU) 2024/1689\neurópai parlamenti és tanácsi rendelet * értelmében biztonsági alkotórészeknek\nminősülnek, a Bizottság az (1) bekezdés szerinti tevékenysége végzésekor,\nvalamint a (2) és a (3) bekezdés szerinti műszaki és vizsgálati előírások\nelfogadásakor figyelembe veszi az említett rendelet III. fejezetének 2.\nszakaszában foglalt követelményeket.” Az (EU) 2016/797 irányelv 5. cikke a\nkövetkező bekezdéssel egészül ki: „(12) Az (EU) 2024/1689 európai parlamenti\nés tanácsi rendelet * értelmében biztonsági alkotórészeknek minősülő\nmesterségesintelligencia-rendszerekre vonatkozó, az (1) bekezdés szerinti,\nfelhatalmazáson alapuló jogi aktusok és a (11) bekezdés szerinti végrehajtási\njogi aktusok elfogadásakor figyelembe kell venni az említett rendelet III.\nfejezetének 2. szakaszában foglalt követelményeket.” Az (EU) 2018/858 rendelet\n5. cikke a következő bekezdéssel egészül ki: „(4) Az (EU) 2024/1689 európai\nparlamenti és tanácsi rendelet * értelmében biztonsági alkotórészeknek\nminősülő mesterségesintelligencia-rendszerekre vonatkozó, a (3) bekezdés\nszerinti, felhatalmazáson alapuló jogi aktusok elfogadásakor figyelembe kell\nvenni az említett rendelet III. fejezetének 2. szakaszában foglalt\nkövetelményeket.” Az (EU) 2018/1139 rendelet a következőképpen módosul: 1. A\n17. cikk a következő bekezdéssel egészül ki: „(3) A (2) bekezdés sérelme\nnélkül, az (EU) 2024/1689 európai parlamenti és tanácsi rendelet * értelmében\nbiztonsági alkotórészeknek minősülő mesterségesintelligencia-rendszerekre\nvonatkozó, az (1) bekezdés szerinti végrehajtási jogi aktusok elfogadásakor\nfigyelembe kell venni az említett rendelet III. fejezetének 2. szakaszában\nfoglalt követelményeket.” 2. A 19. cikk a következő bekezdéssel egészül ki:\n„(4) Az (EU) 2024/1689 rendelet értelmében biztonsági alkotórészeknek minősülő\nmesterségesintelligencia-rendszerekre vonatkozó, az (1) és a (2) bekezdés\nszerinti, felhatalmazáson alapuló jogi aktusok elfogadásakor figyelembe kell\nvenni az említett rendelet III. fejezetének 2. szakaszában foglalt\nkövetelményeket.” 3. A 43. cikk a következő bekezdéssel egészül ki: „(4) Az\n(EU) 2024/1689 rendelet értelmében biztonsági alkotórészeknek minősülő\nmesterségesintelligencia-rendszerekre vonatkozó, az (1) bekezdés szerinti\nvégrehajtási jogi aktusok elfogadásakor figyelembe kell venni az említett\nrendelet III. fejezetének 2. szakaszában foglalt követelményeket.” 4. A 47.\ncikk a következő bekezdéssel egészül ki: „(3) Az (EU) 2024/1689 rendelet\nértelmében biztonsági alkotórészeknek minősülő mesterségesintelligencia-\nrendszerekre vonatkozó, az (1) és a (2) bekezdés szerinti, felhatalmazáson\nalapuló jogi aktusok elfogadásakor figyelembe kell venni az említett rendelet\nIII. fejezetének 2. szakaszában foglalt követelményeket.” 5. Az 57. cikk a\nkövetkező albekezdéssel egészül ki: „Az (EU) 2024/1689 rendelet értelmében\nbiztonsági alkotórészeknek minősülő mesterségesintelligencia-rendszerekre\nvonatkozó, említett végrehajtási jogi aktusok elfogadásakor figyelembe kell\nvenni az említett rendelet III. fejezetének 2. szakaszában foglalt\nkövetelményeket.” 6. Az 58. cikk a következő bekezdéssel egészül ki: „(3) Az\n(EU) 2024/1689 rendelet értelmében biztonsági alkotórészeknek minősülő\nmesterségesintelligencia-rendszerekre vonatkozó, az (1) és a (2) bekezdés\nszerinti, felhatalmazáson alapuló jogi aktusok elfogadásakor figyelembe kell\nvenni az említett rendelet III fejezetének 2. szakaszában foglalt\nkövetelményeket.” Az (EU) 2019/2144 rendelet 11. cikke a következő bekezdéssel\negészül ki: „(3) Az (EU) 2024/1689 európai parlamenti és tanácsi rendelet *\nértelmében biztonsági alkotórészeknek minősülő mesterségesintelligencia-\nrendszerekre vonatkozó, a (2) bekezdés szerinti végrehajtási jogi aktusok\nelfogadásakor figyelembe kell venni az említett rendelet III. fejezetének 2.\nszakaszában foglalt követelményeket.” Az (EU) 2020/1828 európai parlamenti és\ntanácsi irányelv * I. melléklete a következő ponttal egészül ki: „68. Az\nEurópai Parlament és a Tanács (EU) 2024/1689 rendelete (2024. június 13.) a\nmesterséges intelligenciára vonatkozó harmonizált szabályok megállapításáról,\nvalamint a 300/2008/EK, a 167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az\n(EU) 2018/1139 és az (EU) 2019/2144 rendelet, továbbá a 2014/90/EU, az (EU)\n2016/797 és az (EU) 2020/1828 irányelv módosításáról (a mesterséges\nintelligenciáról szóló rendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj)”. (1) Anélkül, hogy ez sértené az\n5. cikknek a 113. cikk harmadik bekezdésének a) pontjában említett\nalkalmazását, a X. mellékletben felsorolt jogi aktusokkal létrehozott nagy\nméretű informatikai rendszerek alkotóelemeit képező azon MI-rendszereknek,\namelyeket 2027. augusztus 2. előtt hoztak forgalomba vagy helyeztek üzembe,\n2030. december 31-ig meg kell felelniük e rendeletnek. Az e rendeletben\nmeghatározott követelményeket figyelembe kell venni minden egyes, a X.\nmellékletben felsorolt jogi aktusokkal létrehozott nagy méretű informatikai\nrendszer értékelése során, amelyet az említett jogi aktusokban előírtak\nszerint kell elvégezni, továbbá abban az esetben, ha az említett jogi\naktusokat más jogi aktussal váltják fel vagy módosítják. (2) E rendelet 5.\ncikkének a 113. cikke harmadik bekezdésének a) pontjában említett\nalkalmazásának sérelme nélkül, e rendelet csak akkor alkalmazandó az e cikk\n(1) bekezdésében említettektől eltérő, nagy kockázatú azon MI-rendszerek\nüzemeltetőire, amelyeket 2026. augusztus 2. előtt hoztak forgalomba vagy\nhelyeztek üzembe, ha az említett időponttól kezdve az említett rendszerek\ntervezésében jelentős változások történnek. Mindenesetre a hatóságok általi\nhasználatra szánt, nagy kockázatú MI-rendszerek szolgáltatóinak és\nalkalmazóinak 2030. augusztus 2-ig meg kell tenniük az e rendelet\nkövetelményeinek és kötelezettségeinek való megfeleléshez szükséges lépéseket.\n(3) Azon általános célú MI-modellek szolgáltatóinak, amelyeket 2025. augusztus\n2. előtt hoztak forgalomba, 2027. augusztus 2-ig meg kell tenniük az e\nrendeletben meghatározott kötelezettségeknek való megfeleléshez szükséges\nlépéseket. (1) A Bizottság e rendelet hatálybalépését követően, a 97. cikkben\nmeghatározott felhatalmazási időszak végéig évente egyszer értékeli a III.\nmellékletben szereplő jegyzék és a tiltott MI-gyakorlatok 5. cikkben\nmeghatározott jegyzéke módosításának szükségességét. A Bizottság az említett\nértékelés megállapításait továbbítja az Európai Parlamentnek és a Tanácsnak.\n(2) A Bizottság 2028. augusztus 2-ig, és azt követően négyévente értékeli a\nkövetkezőket, és azokról jelentést nyújt be az Európai Parlamentnek és a\nTanácsnak: a) a III. mellékletben szereplő meglévő területkategóriák\nbővítésére vagy új területkategóriák felvételére irányuló módosítások\nszükségessége; b) a további átláthatósági intézkedéseket igénylő MI-rendszerek\n50. cikkben szereplő jegyzékének módosításai; c) a felügyeleti és irányítási\nrendszer hatékonyságának megerősítésére irányuló módosítások. (3) A Bizottság\n2029. augusztus 2-ig, majd azt követően négyévente jelentést nyújt be az\nEurópai Parlamentnek és a Tanácsnak e rendelet értékeléséről és\nfelülvizsgálatáról. A jelentésnek értékelést kell magában foglalnia a\nvégrehajtás struktúrájára és arra vonatkozóan, hogy esetlegesen szükség van-e\nvalamely uniós ügynökségre a feltárt hiányosságok orvoslásához. A\nmegállapítások alapján az említett jelentést adott esetben az e rendelet\nmódosítására irányuló javaslatnak kell kísérnie. A jelentéseket közzé kell\ntenni. (4) A (2) bekezdésben említett jelentésekben különös figyelmet kell\nfordítani a következőkre: a) az illetékes nemzeti hatóságok pénzügyi, műszaki\nés emberi erőforrásainak helyzete az e rendelet alapján számukra kijelölt\nfeladatok hatékony elvégzése érdekében; b) a tagállamok által az e rendelet\nmegsértése esetén alkalmazott szankciók és különösen a 99. cikk (1)\nbekezdésében említett közigazgatási bírságok helyzete; c) az e rendelet\ntámogatására kidolgozott, elfogadott harmonizált szabványok és közös\nelőírások; d) az e rendelet alkalmazásának megkezdése után piacra lépő\nvállalkozások száma, és ezek közül mennyi a kkv. (5) A Bizottság 2028.\naugusztus 2-ig értékeli az MI-hivatal működését, azt, hogy az MI-hivatal\nelegendő hatáskörrel és illetékességgel rendelkezik-e feladatainak\nellátásához, valamint azt, hogy e rendelet megfelelő végrehajtása és\nérvényesítése szempontjából releváns és szükséges lenne-e továbbfejleszteni az\nMI-hivatalt és annak végrehajtási hatásköreit, és növelni annak erőforrásait.\nA Bizottság értékeléséről jelentést nyújt be az Európai Parlamentnek és a\nTanácsnak. (6) A Bizottság 2028. augusztus 2-ig, majd azt követően négyévente\njelentést nyújt be az általános célú MI-modellek energiahatékony\nfejlesztésével kapcsolatos szabvány jellegű dokumentumok kidolgozása terén\nelért előrehaladás áttekintéséről, és értékeli, hogy szükség van-e további\nintézkedésekre vagy fellépésekre, beleértve a kötelező erejű intézkedéseket\nvagy fellépéseket is. A jelentést be kell nyújtani az Európai Parlamentnek és\na Tanácsnak, és azt nyilvánosságra kell hozni. (7) A Bizottság 2028. augusztus\n2-ig, majd azt követően háromévente értékeli az önkéntes magatartási kódexek\nhatását és hatékonyságát a III. fejezet 2. szakaszában foglalt, a nagy\nkockázatú MI-rendszerektől eltérő MI-rendszerekre vonatkozó követelmények és\nesetleg a nagy kockázatú MI-rendszerektől eltérő MI-rendszerekre vonatkozó\negyéb további, így például a környezeti fenntarthatóságra vonatkozó\nkövetelmények alkalmazásának előmozdítása érdekében. (8) Az (1)-(7) bekezdés\nalkalmazásában a Testület, a tagállamok és az illetékes nemzeti hatóságok\nkérésre és indokolatlan késedelem nélkül tájékoztatást nyújtanak a\nBizottságnak. (9) A Bizottság az (1)-(7) bekezdésben említett értékelések és\nfelülvizsgálatok során figyelembe veszi a Testület, az Európai Parlament, a\nTanács és az egyéb megfelelő szervek vagy források álláspontját és\nmegállapításait. (10) A Bizottság szükség esetén megfelelő javaslatokat nyújt\nbe e rendelet módosítására, figyelembe véve különösen a technológiai\nfejlődést, az MI-rendszereknek az egészségre és a biztonságra, valamint az\nalapvető jogokra gyakorolt hatását, továbbá tekintettel az információs\ntársadalom fejlődési szintjére. (11) Annak érdekében, hogy iránymutatást\nnyújtson az e cikk (1)-(7) bekezdésében említett értékelésekhez és\nfelülvizsgálatokhoz, az MI-hivatalnak objektív és részvételen alapuló\nmódszertant kell kidolgoznia a kockázati szinteknek a releváns cikkekben\nmeghatározott kritériumok alapján való értékelésére és az új rendszereknek a\nkövetkező jegyzékekbe való felvételére vonatkozóan: a) a III. mellékletben\nmeghatározott jegyzék, beleértve a meglévő területkategóriák bővítését vagy új\nterületkategóriák felvételét az említett mellékletbe; b) az 5. cikkben\nmeghatározott tiltott gyakorlatok jegyzéke; és c) az 50. cikk szerinti,\ntovábbi átláthatósági intézkedéseket igénylő MI-rendszerek jegyzéke. (12) E\nrendelet (10) bekezdés szerinti bármely módosításának, illetve az I. melléklet\nB. szakaszában felsorolt uniós ágazati harmonizációs jogszabályokat érintő,\nfelhatalmazáson alapuló jogi aktusoknak vagy végrehajtási aktusoknak\nfigyelembe kell venniük az egyes ágazatok szabályozási sajátosságait, valamint\na meglévő irányítási, megfelelőségértékelési és végrehajtási mechanizmusokat,\nés az azok keretében létrehozott hatóságokat. (13) A Bizottság 2031. augusztus\n2-ig értékeli e rendelet végrehajtását, és erről jelentést készít az Európai\nParlamentnek, a Tanácsnak, valamint az Európai Gazdasági és Szociális\nBizottságnak, figyelembe véve e rendelet alkalmazásának első éveit. A\nmegállapítások alapján a jelentést adott esetben az e rendelet módosítására\nirányuló javaslatnak kell kísérnie a végrehajtás struktúrájára és arra\nvonatkozóan, hogy szükség van-e valamely uniós ügynökségre a feltárt\nhiányosságok orvoslásához. Ez a rendelet az Európai Unió Hivatalos Lapjában\nvaló kihirdetését követő huszadik napon lép hatályba. Ezt a rendeletet 2026.\naugusztus 2-től kell alkalmazni. Azonban: a) az I. és a II. fejezetet 2025.\nfebruár 2-től kell alkalmazni; b) a III. fejezet 4. szakaszát, az V.\nfejezetet, a VII. fejezetet, és a XII. fejezetet - a 101. cikk kivételével -,\nvalamint a 78. cikket 2025. augusztus 2-től kell alkalmazni; c) A 6. cikk (1)\nbekezdését és az e rendeletben foglalt vonatkozó kötelezettségeket 2027.\naugusztus 2-től kell alkalmazni. Ez a rendelet teljes egészében kötelező és\nközvetlenül alkalmazandó valamennyi tagállamban. Kelt Brüsszelben, 2024.\njúnius 13-án. 1. Az Európai Parlament és a Tanács 2006/42/EK irányelve (2006.\nmájus 17.) a gépekről és a 95/16/EK irányelv módosításáról (HL L 157.,\n2006.6.9., 24. o.); 2. Az Európai Parlament és a Tanács 2009/48/EK irányelve\n(2009. június 18.) a játékok biztonságáról (HL L 170., 2009.6.30., 1. o.); 3.\nAz Európai Parlament és a Tanács 2013/53/EU irányelve (2013. november 20.) a\nkedvtelési célú vízi járművekről és a motoros vízi sporteszközökről, valamint\na 94/25/EK irányelv hatályon kívül helyezéséről (HL L 354., 2013.12.28., 90.\no.); 4. Az Európai Parlament és a Tanács 2014/33/EU irányelve (2014. február\n26.) a felvonókra és a felvonókhoz készült biztonsági berendezésekre vonatkozó\ntagállami jogszabályok harmonizációjáról (HL L 96., 2014.3.29., 251. o.); 5.\nAz Európai Parlament és a Tanács 2014/34/EU irányelve (2014. február 26.) a\nrobbanásveszélyes légkörben való használatra szánt felszerelésekre és védelmi\nrendszerekre vonatkozó tagállami jogszabályok harmonizációjáról (HL L 96.,\n2014.3.29., 309. o.); 6. Az Európai Parlament és a Tanács 2014/53/EU irányelve\n(2014. április 16.) a rádióberendezések forgalmazására vonatkozó tagállami\njogszabályok harmonizációjáról és az 1999/5/EK irányelv hatályon kívül\nhelyezéséről (HL L 153., 2014.5.22., 62. o.); 7. Az Európai Parlament és a\nTanács 2014/68/EU irányelve (2014. május 15.) a nyomástartó berendezések\nforgalmazására vonatkozó tagállami jogszabályok harmonizációjáról (HL L 189.,\n2014.6.27., 164. o.); 8. Az Európai Parlament és a Tanács (EU) 2016/424\nrendelete (2016. március 9.) a kötélpálya-létesítményekről és a 2000/9/EK\nirányelv hatályon kívül helyezéséről (HL L 81., 2016.3.31., 1. o.); 9. Az\nEurópai Parlament és a Tanács (EU) 2016/425 rendelete (2016. március 9.) az\negyéni védőeszközökről és a 89/686/EGK tanácsi irányelv hatályon kívül\nhelyezéséről (HL L 81., 2016.3.31., 51. o.); 10. Az Európai Parlament és a\nTanács (EU) 2016/426 rendelete (2016. március 9.) a gáz halmazállapotú\ntüzelőanyag égetésével üzemelő berendezésekről és a 2009/142/EK irányelv\nhatályon kívül helyezéséről (HL L 81., 2016.3.31., 99. o.); 11. Az Európai\nParlament és a Tanács (EU) 2017/745 rendelete (2017. április 5.) az\norvostechnikai eszközökről, a 2001/83/EK irányelv, a 178/2002/EK rendelet és\naz 1223/2009/EK rendelet módosításáról, valamint a 90/385/EGK és a 93/42/EGK\ntanácsi irányelv hatályon kívül helyezéséről (HL L 117., 2017.5.5., 1. o.);\n12. Az Európai Parlament és a Tanács (EU) 2017/746 rendelete (2017. április\n5.) az in vitro diagnosztikai orvostechnikai eszközökről, valamint a 98/79/EK\nirányelv és a 2010/227/EU bizottsági határozat hatályon kívül helyezéséről (HL\nL 117., 2017.5.5., 176. o.). 13. Az Európai Parlament és a Tanács 300/2008/EK\nrendelete (2008. március 11.) a polgári légi közlekedés védelmének közös\nszabályairól és a 2320/2002/EK rendelet hatályon kívül helyezéséről (HL L 97.,\n2008.4.9., 72. o.); 14. Az Európai Parlament és a Tanács 168/2013/EU rendelete\n(2013. január 15.) a két- vagy háromkerekű járművek, valamint a négykerekű\nmotorkerékpárok jóváhagyásáról és piacfelügyeletéről (HL L 60., 2013.3.2., 52.\no.); 15. Az Európai Parlament és a Tanács 167/2013/EU rendelete (2013. február\n5.) a mezőgazdasági és erdészeti járművek jóváhagyásáról és piacfelügyeletéről\n(HL L 60., 2013.3.2., 1. o.); 16. Az Európai Parlament és a Tanács 2014/90/EU\nirányelve (2014. július 23.) a tengerészeti felszerelésekről és a 96/98/EK\ntanácsi irányelv hatályon kívül helyezéséről (HL L 257., 2014.8.28., 146. o.);\n17. Az Európai Parlament és a Tanács (EU) 2016/797 irányelve (2016. május 11.)\na vasúti rendszer Európai Unión belüli kölcsönös átjárhatóságáról (HL L 138.,\n2016.5.26., 44. o.); 18. Az Európai Parlament és a Tanács (EU) 2018/858\nrendelete (2018. május 30.) a gépjárművek és pótkocsijaik, valamint az ilyen\njárművek rendszereinek, alkotóelemeinek és önálló műszaki egységeinek\njóváhagyásáról és piacfelügyeletéről, a 715/2007/EK és az 595/2009/EK rendelet\nmódosításáról, valamint a 2007/46/EK irányelv hatályon kívül helyezéséről (HL\nL 151., 2018.6.14., 1. o.); 19. Az Európai Parlament és a Tanács (EU)\n2019/2144 rendelete (2019. november 27.) a gépjárműveknek és pótkocsijaiknak,\nvalamint az ilyen járművek rendszereinek, alkotóelemeinek és önálló műszaki\negységeinek az általános biztonság, továbbá az utasok és a veszélyeztetett\núthasználók védelme tekintetében történő típusjóváhagyásáról, az (EU) 2018/858\neurópai parlamenti és tanácsi rendelet módosításáról, valamint a 78/2009/EK, a\n79/2009/EK és a 661/2009/EK európai parlamenti és tanácsi rendelet és a\n631/2009/EK, a 406/2010/EU, a 672/2010/EU, az 1003/2010/EU, az 1005/2010/EU,\naz 1008/2010/EU, az 1009/2010/EU, a 19/2011/EU, a 109/2011/EU, a 458/2011/EU,\na 65/2012/EU, a 130/2012/EU, a 347/2012/EU, a 351/2012/EU, az 1230/2012/EU és\naz (EU) 2015/166 bizottsági rendelet hatályon kívül helyezéséről (HL L 325.,\n2019.12.16., 1. o.); 20. Az Európai Parlament és a Tanács (EU) 2018/1139\nrendelete (2018. július 4.) a polgári légi közlekedés területén alkalmazandó\nközös szabályokról és az Európai Unió Repülésbiztonsági Ügynökségének\nlétrehozásáról, valamint a 2111/2005/EK, az 1008/2008/EK, a 996/2010/EU, a\n376/2014/EU európai parlamenti és tanácsi rendelet és a 2014/30/EU és a\n2014/53/EU európai parlamenti és tanácsi irányelv módosításáról, valamint az\n552/2004/EK és a 216/2008/EK európai parlamenti és tanácsi rendelet és a\n3922/91/EGK tanácsi rendelet hatályon kívül helyezéséről (HL L 212.,\n2018.8.22., 1. o.), a pilóta nélküli légi járművek, valamint motorjaik,\npropellereik, alkatrészeik és a távirányításukra szolgáló berendezések\nesetében a légi járművek 2. cikk (1) bekezdésének a) és b) pontjában említett\ntervezése, gyártása és forgalomba hozatala tekintetében. Az 5. cikk (1)\nbekezdése első albekezdése h) pontjának iii. alpontjában említett\nbűncselekmények: - terrorizmus, - emberkereskedelem, - gyermekek szexuális\nkizsákmányolása és gyermekpornográfia, - kábítószerek vagy pszichotrop anyagok\ntiltott kereskedelme, - fegyverek, lőszerek és robbanóanyagok tiltott\nkereskedelme, - szándékos emberölés, súlyos testi sértés, - emberi szervek\nvagy szövetek tiltott kereskedelme, - nukleáris és radioaktív anyagok tiltott\nkereskedelme, - emberrablás, személyi szabadságtól való jogellenes megfosztás\nés túszejtés, - a Nemzetközi Büntetőbíróság joghatósága alá tartozó\nbűncselekmények, - repülőgép vagy hajó hatalomba kerítése, - szexuális\nkényszerítés, - környezettel kapcsolatos bűncselekmények, - szervezett vagy\nfegyveres rablás, - szabotázs, - a fent felsoroltak közül egy vagy több\nbűncselekményben érintett bűnszervezetben való részvétel. A 6. cikk (2)\nbekezdése szerinti nagy kockázatú MI-rendszerek a következő területek\nbármelyikén felsorolt MI-rendszerek: 1. biometria, amennyiben annak\nhasználatát a releváns uniós vagy nemzeti jog megengedi: a) távoli biometrikus\nazonosító rendszerek. Ez nem terjed ki a biometrikus ellenőrzéshez való\nfelhasználásra szánt azon MI-rendszerekre, amelyek kizárólagos célja annak\nmegerősítése, hogy egy adott természetes személy azonos azzal a személlyel,\nakinek állítja magát; b) érzékeny vagy védett tulajdonságok vagy jellemzők\nszerint, ilyen tulajdonságokból vagy jellemzőkből levont következtetések\nalapján való biometrikus kategorizáláshoz való használatra szánt MI-\nrendszerek; c) érzelemfelismeréshez való használatra szánt MI-rendszerek; 2.\nkritikus infrastruktúra: a kritikus digitális infrastruktúrák, a közúti\nforgalom, vagy a víz-, gáz-, fűtési vagy villamosenergia-szolgáltatás\nirányításában és működtetésében biztonsági alkotórészekként való használatra\nszánt MI-rendszerek; 3. oktatás és szakképzés: a) minden szintre kiterjedő\noktatási és szakképzési intézményekbe való bejutás vagy felvétel\nmeghatározásához, illetve természetes személyek ilyen intézményekhez történő\nhozzárendeléséhez való használatra szánt MI-rendszerek; b) tanulási eredmények\nértékeléséhez való használatra szánt MI-rendszerek, beleértve azon eseteket\nis, amikor ezeket az eredményeket a minden szintre kiterjedő oktatási és\nszakképzési intézményekben tanuló természetes személyek tanulási folyamatának\nirányítására használják; c) valamennyi szinten az oktatási és szakképzési\nintézményekkel összefüggésben vagy azokon belül azon oktatás megfelelő\nszintjének felmérése céljából való használatra szánt MI-rendszerek, amelyet az\negyén kapni fog, vagy amelyhez hozzá fog tudni férni; d) valamennyi szinten az\noktatási és szakképzési intézményekkel összefüggésben vagy azokon belül a\nvizsgák során a tiltott tanulói magatartás figyelemmel követéséhez és\nészleléséhez való használatra szánt MI-rendszerek; 4. foglalkoztatás, a\nmunkavállalók irányítása és az önfoglalkoztatáshoz való hozzáférés: a)\ntermészetes személyek felvételéhez vagy kiválasztásához való használatra szánt\nMI-rendszerek, különösen célzott álláshirdetések elhelyezése, a jelentkezések\nelemzése és szűrése, valamint a jelöltek értékelése céljából; b) a munkával\nkapcsolatos jogviszonyok feltételeit, az előléptetést vagy a munkával\nkapcsolatos szerződéses jogviszonyok megszüntetését érintő döntések\nmeghozatalához, egyéni magatartáson vagy személyes vonásokon vagy jellemzőkön\nalapuló feladatkiosztáshoz, vagy az ilyen jogviszonyokban álló személyek\nteljesítményének és magatartásának nyomon követéséhez és értékeléséhez való\nhasználatra szánt MI-rendszerek; 5. alapvető magán- és közszolgáltatásokhoz és\nellátásokhoz való hozzáférés és ezek igénybevétele: a) hatóságok általi vagy\nhatóságok nevében való használatra szánt MI-rendszerek, természetes személyek\nállami segítségnyújtási ellátásokra és szolgáltatásokra, köztük egészségügyi\nszolgáltatásokra való jogosultságának értékelése, valamint az ilyen ellátások\nés szolgáltatások biztosítása, csökkentése, visszavonása vagy visszaigénylése\ncéljából; b) a természetes személyek hitelképességének értékeléséhez vagy\nhitelpontszámuk megállapításához való használatra szánt MI-rendszerek, kivéve\na pénzügyi csalás észlelésére használt MI-rendszereket; c) a természetes\nszemélyek vonatkozásában egészség- és életbiztosítás esetén a\nkockázatértékeléshez és az árképzéshez való használatra szánt MI-rendszerek;\nd) természetes személyek segélyhívásainak értékeléséhez és osztályozásához,\nvagy a sürgősségi segélyszolgálatok - többek között a rendőrség és a tűzoltók\náltal biztosított ilyen szolgáltatások és orvosi segítségnyújtás -\nkirendeléséhez vagy a kirendelési prioritás megállapításához, valamint a\nsürgősségi egészségügyi ellátásban alkalmazott betegosztályozási rendszerekhez\nvaló használatra szánt MI-rendszerek. 6. bűnüldözés, amennyiben azok\nhasználatát a releváns uniós vagy nemzeti jog megengedi: a) a bűnüldöző\nhatóságok által vagy nevében, vagy a bűnüldöző hatóságok támogatása érdekében\nuniós intézmények, szervek, hivatalok vagy ügynökségek által vagy nevében való\nhasználatra szánt, annak értékelésére szolgáló MI-rendszerek, hogy egy\ntermészetes személy esetében fennáll-e annak kockázata, hogy bűncselekmény\náldozatává válik; b) a bűnüldöző hatóságok által vagy nevében, vagy a\nbűnüldöző hatóságok támogatása érdekében uniós intézmények, szervek, hivatalok\nvagy ügynökségek által például poligráfként vagy hasonló eszközként való\nhasználatra szánt MI-rendszerek; c) bűncselekményekkel kapcsolatos nyomozás\nvagy büntetőeljárás alá vonás során a bizonyítékok megbízhatóságának\nértékelése céljából a bűnüldöző hatóságok által vagy nevében, vagy a bűnüldöző\nhatóságok támogatása érdekében uniós intézmények, szervek, hivatalok vagy\nügynökségek általvaló használatra szánt MI-rendszerek; d) a bűnüldöző\nhatóságok által vagy nevében, vagy a bűnüldöző hatóságok támogatása érdekében\nuniós intézmények, szervek, hivatalok vagy ügynökségek által való használatra\nszánt MI-rendszerek annak értékeléséhez, hogy egy természetes személy esetében\nfennáll-e bűncselekmény elkövetésének vagy ismételt elkövetésének kockázata,\nnem kizárólag az (EU) 2016/680 irányelv 3. cikkének 4. pontjában említett,\ntermészetes személyekre vonatkozó profilalkotás alapján, vagy természetes\nszemélyek vagy csoportok személyiségjegyeinek és személyes jellemzőinek, vagy\nmúltbeli bűnözői magatartásának értékeléséhez; e) bűncselekmények felderítése,\nbűncselekményekkel kapcsolatos nyomozás vagy büntetőeljárás alá vonás során az\n(EU) 2016/680 irányelv 3. cikkének 4. pontjában említett, természetes\nszemélyekre vonatkozó profilalkotás céljából a bűnüldöző hatóságok által vagy\nnevében, vagy a bűnüldöző hatóságok támogatása érdekében uniós intézmények,\nszervek, hivatalok vagy ügynökségek által való használatra szánt MI-\nrendszerek; 7. migráció, menekültügy és határigazgatás, amennyiben azok\nhasználatát a releváns uniós vagy nemzeti jog megengedi: a) az illetékes\nhatóságok vagy az uniós intézmények, szervek, hivatalok vagy ügynökségek által\nvagy nevében poligráfként vagy hasonló eszközként való használatra szánt MI-\nrendszerek; b) a valamely tagállam területére belépni szándékozó vagy oda\nbelépett természetes személy által jelentett kockázat - többek között\nbiztonsági kockázat, irreguláris migrációs kockázat vagy egészségügyi kockázat\n- értékelését célzó, illetékes hatóságok által vagy nevében, vagy uniós\nintézmények, szervek, hivatalok vagy ügynökségek által való használatra szánt\nMI-rendszerek; c) menedékjog iránti kérelmek, vízumkérelmek vagy tartózkodási\nengedély iránti kérelmek, valamint jogállást kérelmező természetes személyek\njogosultsága tekintetében az ezekkel összefüggő panaszok kivizsgálásához -\nbeleértve a bizonyítékok megbízhatóságának kapcsolódó értékeléseihez - az\nilletékes hatóságok által vagy nevében, vagy az illetékes hatóságok támogatása\nérekében uniós intézmények, szervek, hivatalok vagy ügynökségek által való\nhasználatra szánt MI-rendszerek; d) a migrációval, a menekültüggyel vagy a\nhatárigazgatással összefüggésben - az úti okmányok ellenőrzése kivételével - a\ntermészetes személyek felderítése, felismerése vagy azonosítása céljából az\nilletékes hatóságok vagy az uniós intézmények, szervek, hivatalok vagy\nügynökségek által vagy nevében való használatra szánt MI-rendszerek; 8.\nigazságszolgáltatás és demokratikus folyamatok: a) igazságügyi hatóság által\nvagy nevében való használatra szánt MI-rendszerek, amelyek célja, hogy\nsegítsék az igazságügyi hatóságokat a ténybeli és a jogi elemek kutatásában és\nértelmezésében, valamint a jog konkrét tényekre történő alkalmazásában,\nilletve hogy alternatív vitarendezés keretében hasonló módon használják őket;\nb) választások vagy népszavazások eredményének vagy a természetes személyek\nválasztásokon vagy népszavazásokon tanúsított szavazási magatartásának\nbefolyásolásához való használatra szánt MI-rendszerek. Nem tartoznak ide azok\naz MI-rendszerek, amelyek kimenete nem érint közvetlenül természetes\nszemélyeket, mint például a politikai kampányok adminisztratív vagy\nlogisztikai szempontból való megszervezéséhez, optimalizálásához vagy\nstrukturálásához használt eszközök. A 11. cikk (1) bekezdésében említett\nműszaki dokumentációnak a releváns MI-rendszerre alkalmazandó, legalább a\nkövetkező információkat kell tartalmaznia: 1. az MI-rendszer általános\nleírása, ideértve a következőket: a) a rendszer rendeltetése, a szolgáltató\nneve és a rendszer verziója, feltüntetve a korábbi verziókhoz való viszonyát;\nb) adott esetben annak ismertetése, hogy az MI-rendszer hogyan működik együtt\nolyan hardverrel vagy szoftverrel, köztük más MI-rendszerekkel, amelyek nem\nrészei magának az MI-rendszernek, illetve hogyan használható fel az ezekkel\nvaló interakcióra; c) a releváns szoftver vagy förmver verziója és a verzió\nfrissítéseivel kapcsolatos követelmények; d) az MI-rendszer valamennyi\nforgalomba hozatali vagy üzembe helyezési formájának ismertetése, például a\nhardverbe beágyazott szoftvercsomagok, letölthető alkalmazások vagy API-k; e)\nannak a hardvernek a leírása, amelyen az MI-rendszert működtetni kívánják; f)\namennyiben az MI-rendszer termékek alkotóeleme, e termékek külső jellemzőit,\njelölését és belső elrendezését bemutató fényképek vagy illusztrációk; g) az\nalkalmazó rendelkezésére bocsátott felhasználói felület alapleírása; h)\nhasználati utasítás az alkalmazó számára és adott esetben az alkalmazó\nrendelkezésére bocsátott felhasználói felület alapleírása; 2. az MI-rendszer\nelemeinek és fejlesztési folyamatának részletes leírása, beleértve a\nkövetkezőket: a) az MI-rendszer fejlesztése érdekében alkalmazott módszerek és\naz ennek érdekében tett lépések, beleértve adott esetben a harmadik felek\náltal biztosított, előre betanított rendszerek vagy eszközök igénybevételét,\nvalamint azt, hogy a szolgáltató hogyan használta, integrálta vagy módosította\nazokat; b) a rendszer tervezési előírásai, nevezetesen az MI-rendszer és az\nalgoritmusok általános logikája; a legfontosabb tervezési döntések, beleértve\naz indokokat és a feltételezéseket, többek között azon személyek vagy\nszemélyek csoportjai tekintetében is, akik vagy amelyek vonatkozásában a\nrendszert használni kívánják; a fő osztályozási döntések; tervezésének\nmegfelelően mit optimalizál a rendszer és a különböző paraméterek\nrelevanciája; a rendszer várt kimenetének és kimeneti minőségének leírása; a\nIII. fejezet 2. szakaszában foglalt követelményeknek való megfelelés érdekében\nelfogadott műszaki megoldásokkal kapcsolatos, az esetleges kompromisszumokra\nvonatkozó döntések; c) a rendszer architektúrájának leírása, ismertetve, hogy\na szoftverösszetevők hogyan épülnek egymásra vagy egymásba, illetve hogyan\nintegrálódnak a teljes folyamatba; az MI-rendszer fejlesztéséhez, tanításához,\nteszteléséhez és validálásához használt számítási erőforrások; d) adott\nesetben a tanítómódszereket és -technikákat, valamint az alkalmazott\ntanítóadat-készleteket leíró adatlapokra vonatkozó adatszolgáltatási\nkövetelmények, ideértve ezen adatkészletek általános leírását, az eredetükre,\na hatályukra és a fő jellemzőikre vonatkozó információkat is; az adatok\nmegszerzésének és kiválasztásának módja; címkézési eljárások (például\nfelügyelt tanulás esetén), adattisztítási módszerek (például a kiugró értékek\nészlelése); e) a 14. cikkel összhangban szükséges emberi felügyeleti\nintézkedések értékelése, beleértve az MI-rendszerekhez kapcsolódó kimenetek\nalkalmazók általi értelmezésének megkönnyítéséhez szükséges technikai\nintézkedések értékelését, a 13. cikk (3) bekezdésének d) pontjával\nösszhangban; f) adott esetben az MI-rendszer és teljesítménye előre\nmeghatározott változtatásainak részletes leírása, az MI-rendszernek a III.\nfejezet 2. szakaszában foglalt releváns követelményeknek való folyamatos\nmegfelelését biztosító műszaki megoldásokkal kapcsolatos valamennyi releváns\ninformációval együtt; g) az alkalmazott validálási és tesztelési eljárások,\nbeleértve a felhasznált validálási és tesztelési adatokra és azok fő\njellemzőire vonatkozó információkat; a pontosság, a megbízhatóság és a III.\nfejezet 2. szakaszában foglalt egyéb vonatkozó követelményeknek való\nmegfelelés mérésére használt mérőszámok, valamint a potenciálisan\ndiszkriminatív hatások; a felelős személyek által dátummal és aláírással\nellátott tesztelési naplók és tesztelési jelentések, többek között az f)\npontban említett, előre meghatározott változtatásokra vonatkozóan; h) az\néletbe léptetett kiberbiztonsági intézkedések; 3. az MI-rendszer nyomon\nkövetésére, működésére és ellenőrzésére vonatkozó részletes információk,\nkülönös tekintettel a következőkre: a rendszer teljesítménybeli képességei és\nkorlátai, beleértve a pontosság fokát azon személyek vagy személyek csoportjai\nesetében, akik vagy amelyek tekintetében a rendszert használni kívánják,\nvalamint a pontosság általános elvárt szintje a rendeltetéséhez viszonyítva;\naz előre látható nem kívánt eredmények, valamint az egészséggel és a\nbiztonsággal, az alapvető jogokkal és a megkülönböztetéssel kapcsolatos\nkockázatok forrásai az MI-rendszer rendeltetése tekintetében; a 14. cikkel\nösszhangban szükséges emberi felügyeleti intézkedések, beleértve az MI-\nrendszerek kimeneteinek alkalmazók általi értelmezését megkönnyítő technikai\nintézkedéseket; adott esetben a bemeneti adatokra vonatkozó előírások; 4. a\nteljesítménymutatók megfelelőségének leírása az adott MI-rendszer\ntekintetében; 5. a 9. cikk szerinti kockázatkezelési rendszer részletes\nismertetése; 6. a szolgáltató által a rendszeren, annak életciklusa során\nvégrehajtott releváns változtatások leírása; 7. az olyan, részben vagy\negészben alkalmazott harmonizált szabványok jegyzéke, amelyek hivatkozása\nmegjelent az Európai Unió Hivatalos Lapjában; amennyiben nem került sor ilyen\nharmonizált szabványok alkalmazására, a III. fejezet 2. szakaszában foglalt\nkövetelményeknek való megfelelés érdekében alkalmazott megoldások részletes\nleírása, beleértve az egyéb releváns szabványok és műszaki előírások\njegyzékét; 8. a 47. cikkben említett EU-megfelelőségi nyilatkozat másolata; 9.\na 72. cikkel összhangban az MI-rendszer teljesítményének a forgalomba hozatalt\nkövető értékelésére szolgáló rendszer részletes leírása, beleértve a 72. cikk\n(3) bekezdésében említett forgalomba hozatal utáni nyomonkövetési tervet. A\n47. cikkben említett EU-megfelelőségi nyilatkozatnak tartalmaznia kell a\nkövetkező információk mindegyikét: 1. az MI-rendszer neve és típusa, valamint\nminden olyan további egyértelmű hivatkozás, amely lehetővé teszi az MI-\nrendszer azonosítását és nyomonkövethetőségét; 2. a szolgáltatónak vagy adott\nesetben a szolgáltató meghatalmazott képviselőjének neve és címe; 3. arra\nvonatkozó nyilatkozat, hogy a 47. cikkben említett EU-megfelelőségi\nnyilatkozat kiadására a szolgáltató kizárólagos felelőssége mellett kerül sor;\n4. arra vonatkozó nyilatkozat, hogy az MI-rendszer megfelel e rendeletnek, és\nadott esetben bármely egyéb releváns uniós jogszabálynak, amely a 47. cikkben\nemlített EU-megfelelőségi nyilatkozat kiállítását írják elő; 5. amennyiben\nvalamely MI-rendszer személyes adatok kezelését teszi szükségessé, nyilatkozat\narról, hogy az adott MI-rendszer megfelel az (EU) 2016/679 és az (EU)\n2018/1725 rendeletnek, valamint az (EU) 2016/680 irányelvnek; 6. hivatkozás\nbármely releváns, alkalmazott harmonizált szabványra vagy bármely más olyan\nközös előírásra, amellyel kapcsolatban megfelelőségi nyilatkozatra került sor;\n7. adott esetben a bejelentett szervezet neve és azonosító száma, az elvégzett\nmegfelelőségértékelési eljárás leírása és a kiadott tanúsítvány azonosítása;\n8. a megfelelőségi nyilatkozat kiállításának helye és dátuma, az aláíró\nszemély neve és beosztása, valamint annak a személynek a megjelölése, aki\nhelyett vagy akinek a nevében aláír, továbbá aláírás. 1. A belső ellenőrzésen\nalapuló megfelelőségértékelési eljárás a 2., a 3. és a 4. ponton alapuló\nmegfelelőségértékelési eljárás. 2. A szolgáltató ellenőrzi, hogy a létrehozott\nminőségirányítási rendszer megfelel-e a 17. cikkben foglalt követelményeknek.\n3. A szolgáltató megvizsgálja a műszaki dokumentációban szereplő információkat\nannak értékelése érdekében, hogy az MI-rendszer megfelel-e a releváns, a III.\nfejezet 2. szakaszában foglalt alapvető követelményeknek. 4. A szolgáltató azt\nis ellenőrzi, hogy az MI-rendszer tervezésének és fejlesztésének folyamata,\nvalamint a 72. cikkben említett, forgalomba hozatal utáni nyomon követése\nösszhangban van-e a műszaki dokumentációval. 1. Bevezetés A minőségirányítási\nrendszer értékelésén és a műszaki dokumentáció értékelésén alapuló\nmegfelelőség a 2-5. ponton alapuló megfelelőségértékelési eljárás. 2.\nÁttekintés Az MI-rendszerek megtervezésére, fejlesztésére és tesztelésére\nszolgáló, a 17. cikk szerinti jóváhagyott minőségirányítási rendszert a 3.\nponttal összhangban meg kell vizsgálni, és annak az 5. pontban meghatározott\nfelügyelet tárgyát kell képeznie. Az MI-rendszer műszaki dokumentációját a 4.\nponttal összhangban meg kell vizsgálni. 3. Minőségirányítási rendszer 3.1. A\nszolgáltató kérelmének a következőket kell tartalmaznia: a) a szolgáltató neve\nés címe, és amennyiben a kérelmet a meghatalmazott képviselő nyújtja be, a\nmeghatalmazott képviselő neve és címe; b) az ugyanazon minőségirányítási\nrendszer hatálya alá tartozó MI-rendszerek jegyzéke; c) az ugyanazon\nminőségirányítási rendszer hatálya alá tartozó minden egyes MI-rendszer\nműszaki dokumentációja; d) a minőségirányítási rendszerre vonatkozó\ndokumentáció, amelynek a 17. cikkben felsorolt valamennyi szempontra ki kell\nterjednie; e) az olyan eljárások leírása, amelyek biztosítják, hogy a\nminőségirányítási rendszer megfelelő és hatékony maradjon; f) írásos\nnyilatkozat arról, hogy a szolgáltató ugyanazt a kérelmet más bejelentett\nszervezethez nem nyújtotta be. 3.2. A bejelentett szervezetnek értékelnie kell\na minőségirányítási rendszert, és meg kell állapítania, hogy az megfelel-e a\n17. cikkben meghatározott követelményeknek. A határozatról értesíteni kell a\nszolgáltatót vagy annak meghatalmazott képviselőjét. Az értesítésnek\ntartalmaznia kell a minőségirányítási rendszer értékelése alapján levont\nkövetkeztetéseket és az indokolással ellátott értékelési határozatot. 3.3. A\njóváhagyott minőségirányítási rendszert a szolgáltatónak továbbra is\nalkalmaznia kell és karban kell tartania annak érdekében, hogy az megfelelő és\nhatékony maradjon. 3.4. A szolgáltatónak fel kell hívnia a bejelentett\nszervezet figyelmét a jóváhagyott minőségirányítási rendszer vagy az ilyen\nrendszer hatálya alá tartozó MI-rendszerek jegyzékének bármely tervezett\nmódosítására. A bejelentett szervezetnek meg kell vizsgálnia a javasolt\nmódosításokat, majd el kell döntenie, hogy a módosított minőségirányítási\nrendszer a továbbiakban is megfelel-e a 3.2. pontban említett követelményeknek\nvagy újabb értékelésre van szükség. A bejelentett szervezetnek értesítenie\nkell a szolgáltatót a határozatáról. Az értesítésnek tartalmaznia kell a\nváltoztatások értékelése alapján levont következtetéseket és az indokolással\nellátott értékelési határozatot. 4. A műszaki dokumentáció ellenőrzése. 4.1. A\n3. pontban említett kérelem mellett a szolgáltatónak kérelmet kell benyújtania\naz általa választott bejelentett szervezethez a szolgáltató által forgalomba\nhozni vagy üzembe helyezni kívánt, a 3. pontban említett minőségirányítási\nrendszer hatálya alá tartozó MI-rendszerrel kapcsolatos műszaki dokumentáció\nértékelése céljából. 4.2. A kérelemnek a következőket kell tartalmaznia: a) a\nszolgáltató neve és címe; b) írásos nyilatkozat arról, hogy a szolgáltató\nugyanazt a kérelmet más bejelentett szervezethez nem nyújtotta be; c) a IV.\nmellékletben említett műszaki dokumentáció. 4.3. A bejelentett szervezetnek\nmeg kell vizsgálnia a műszaki dokumentációt. Adott esetben és a feladatainak\nellátásához szükséges mértékre korlátozva, a bejelentett szervezet számára\ntöbbek között - adott esetben és biztonsági garanciák mellett - API-kon vagy\ntávoli hozzáférést lehetővé tevő egyéb releváns műszaki megoldásokon és\neszközökön keresztül teljes körű hozzáférést kell biztosítani az alkalmazott\ntanító-, validálási és tesztelő adatkészletekhez. 4.4. A műszaki dokumentáció\nvizsgálata során a bejelentett szervezet előírhatja, hogy a szolgáltató\nnyújtson be további bizonyítékokat, vagy végezzen további vizsgálatokat annak\nérdekében, hogy lehetővé tegye annak megfelelő értékelését, hogy az MI-\nrendszer megfelel-e a III. fejezet 2. szakaszában meghatározott\nkövetelményeknek. Amennyiben a bejelentett szervezet nem elégedett a\nszolgáltató által elvégzett vizsgálatokkal, a bejelentett szervezetnek adott\nesetben közvetlenül saját magának kell elvégeznie a megfelelő vizsgálatokat.\n4.5. Amennyiben ez szükséges annak értékeléséhez, hogy a nagy kockázatú MI-\nrendszer megfelel-e a III. fejezet 2. szakaszában meghatározott\nkövetelményeknek, miután a megfelelőség ellenőrzésére szolgáló minden egyéb\nészszerű megoldást kimerítettek, és azok elégtelennek bizonyultak, továbbá\nindokolással ellátott kérésre a bejelentett szervezet számára hozzáférést kell\nbiztosítani az MI-rendszer tanító- és tanított modelljeihez, ideértve annak\nreleváns paramétereit is. Az ilyen hozzáférésre a szellemi tulajdon és az\nüzleti titkok védelmére vonatkozó meglévő uniós jog alkalmazandó. 4.6. A\nbejelentett szervezet határozatáról értesíteni kell a szolgáltatót vagy annak\nmeghatalmazott képviselőjét. Az értesítésnek tartalmaznia kell a műszaki\ndokumentáció értékelése alapján levont következtetéseket és az indokolással\nellátott értékelési határozatot. Amennyiben az MI-rendszer megfelel a III.\nfejezet 2. szakaszában foglalt követelményeknek, a bejelentett szervezetnek ki\nkell állítania a műszaki dokumentáció értékelésére vonatkozó uniós\ntanúsítványt. A tanúsítványnak tartalmaznia kell a szolgáltató nevét és címét,\na vizsgálat következtetéseit, a tanúsítvány érvényességének (esetleges)\nfeltételeit és az MI-rendszer azonosításához szükséges adatokat. A\ntanúsítványnak és mellékleteinek tartalmazniuk kell minden olyan lényeges\ninformációt, amely lehetővé teszi az MI-rendszer megfelelőségének értékelését,\nés adott esetben lehetővé teszi az MI-rendszer használat közbeni ellenőrzését.\nAmennyiben az MI-rendszer nem felel meg a III. fejezet 2. szakaszában foglalt\nkövetelményeknek, a bejelentett szervezetnek meg kell tagadnia a műszaki\ndokumentáció értékelésére vonatkozó uniós tanúsítvány kiállítását, és az\nelutasítás részletes indokolásával együtt tájékoztatnia kell erről a\nkérelmezőt. Amennyiben az MI-rendszer nem felel meg a tanításhoz használt\nadatokra vonatkozó követelménynek, az új megfelelőségértékelés iránti kérelem\nbenyújtása előtt újra kell tanítani az MI-rendszert. Ebben az esetben a\nbejelentett szervezet által hozott, a műszaki dokumentáció értékelésére\nvonatkozó uniós tanúsítvány kiállítását elutasító, indokolással ellátott\nértékelési határozatnak konkrét megfontolásokat kell tartalmaznia az MI-\nrendszer tanításához használt minőségi adatokra, különösen a meg nem felelés\nokaira vonatkozóan. 4.7. A műszaki dokumentáció értékelésére vonatkozó uniós\ntanúsítványt kiállító bejelentett szervezet értékelése szükséges az MI-\nrendszer minden olyan módosításához, amely érintheti az MI-rendszer\nkövetelményeknek való megfelelését vagy rendeltetését. A szolgáltatónak\ntájékoztatnia kell a bejelentett szervezetet azon szándékáról, hogy be kívánja\nvezetni a fent említett változtatások bármelyikét, vagy arról, ha egyébként\ntudomást szerez ilyen változtatások bekövetkezéséről. A bejelentett\nszervezetnek értékelnie kell a tervezett változtatásokat, és döntenie kell\narról, hogy a 43. cikk (4) bekezdésének megfelelően szükség van-e új\nmegfelelőségértékelésre, vagy elegendő a jóváhagyást a műszaki dokumentáció\nértékelésére vonatkozó uniós tanúsítvány kiegészítésével megadni. Utóbbi\nesetben a bejelentett szervezetnek értékelnie kell a változtatásokat,\nhatározatáról értesítenie kell a szolgáltatót, és amennyiben a változtatásokat\njóváhagyja, ki kell állítania a szolgáltató számára a műszaki dokumentáció\nértékelésére vonatkozó uniós tanúsítvány kiegészítését. 5. A jóváhagyott\nminőségirányítási rendszer felügyelete. 5.1. A 3. pontban említett bejelentett\nszervezet által gyakorolt felügyelet célja annak biztosítása, hogy a\nszolgáltató megfelelően megfeleljen a jóváhagyott minőségirányítási rendszer\nfeltételeinek. 5.2. Értékelés céljából a szolgáltatónak hozzáférést kell\nbiztosítania a bejelentett szervezet számára az MI-rendszerek tervezésének,\nfejlesztésének és tesztelésének helyszínéhez. A szolgáltatónak továbbá minden\nszükséges információt meg kell osztania a bejelentett szervezettel. 5.3. A\nbejelentett szervezetnek időszakos ellenőrzéseket kell végeznie, hogy\nmegbizonyosodjon arról, hogy a szolgáltató fenntartja és alkalmazza-e a\nminőségirányítási rendszert, továbbá erről ellenőrzési jelentést kell\nkészítenie a szolgáltatónak. Az ilyen ellenőrzések keretében a bejelentett\nszervezet további vizsgálatokat végezhet azokkal az MI-rendszerekkel\nkapcsolatban, amelyek tekintetében a műszaki dokumentáció értékelésére\nvonatkozó uniós tanúsítvány kiállítására került sor. A 49. cikk (1)\nbekezdésével összhangban nyilvántartásba veendő, nagy kockázatú MI-rendszerek\ntekintetében a következő információkat kell megadni, és ezt követően\nnaprakészen tartani: 1. a szolgáltató neve, címe és elérhetőségei; 2.\namennyiben az információkat a szolgáltató nevében más személy nyújtja be, e\nszemély neve, címe és elérhetősége; 3. adott esetben a meghatalmazott\nképviselő neve, címe és elérhetőségei; 4. az MI-rendszer kereskedelmi neve,\nvalamint minden olyan további egyértelmű hivatkozás, amely lehetővé teszi az\nMI-rendszer azonosítását és nyomonkövethetőségét; 5. az MI-rendszer\nrendeltetésének, valamint az MI-rendszer révén támogatott alkotóelemeknek és\nfunkcióknak az ismertetése; 6. a rendszer által használt információknak\n(adatok, bemenetek) és a rendszer működési logikájának alapvető és tömör\nleírása; 7. az MI-rendszer állapota (forgalomba hozott, üzembe helyezett, már\nnincs forgalomban/nem üzemel, visszahívták); 8. a bejelentett szervezet által\nkiadott tanúsítvány típusa, száma és lejárati ideje, valamint adott esetben a\nbejelentett szervezet neve vagy azonosító száma; 9. adott esetben a 8. pontban\nemlített tanúsítvány beszkennelt másolata; 10. azon tagállamok megnevezése,\namelyekben az MI-rendszert az Unióban forgalomba hozták, üzembe helyezték vagy\nelérhetővé tették; 11. a 47. cikkben említett EU-megfelelőségi nyilatkozat\nmásolata; 12. elektronikus használati utasítás; ezt az információt nem kell\nmegadni a bűnüldözés, illetve a migráció, a menekültügy és a határigazgatás\nterületén a III. melléklet 1., 6. és 7. pontjában említett nagy kockázatú MI-\nrendszerek esetében; 13. további információkhoz vezető webcím (nem kötelező).\nA 49. cikk (2) bekezdésével összhangban nyilvántartásba veendő MI-rendszerek\ntekintetében a következő információkat kell megadni, és ezt követően\nnaprakészen tartani: 1. a szolgáltató neve, címe és elérhetőségei; 2.\namennyiben az információkat a szolgáltató nevében más személy nyújtja be, e\nszemély neve, címe és elérhetősége; 3. adott esetben a meghatalmazott\nképviselő neve, címe és elérhetőségei; 4. az MI-rendszer kereskedelmi neve,\nvalamint minden olyan további egyértelmű hivatkozás, amely lehetővé teszi az\nMI-rendszer azonosítását és nyomonkövethetőségét; 5. az MI-rendszer\nrendeltetésének ismertetése; 6. a 6. cikk (3) bekezdése szerinti azon feltétel\nvagy feltételek, amely(ek) alapján az MI-rendszer nem minősül nagy\nkockázatúnak; 7. azon indokok rövid összefoglalása, amelyek alapján az MI-\nrendszer a 6. cikk (3) bekezdése szerinti eljárást alkalmazva nem minősül nagy\nkockázatúnak; 8. az MI-rendszer állapota (forgalomba hozott, üzembe helyezett,\nmár nincs forgalomban/nem üzemel, visszahívták); 9. azon tagállamok\nmegnevezése, amelyekben az MI-rendszert az Unióban forgalomba hozták, üzembe\nhelyezték vagy elérhetővé tették. A 49. cikk (3) bekezdésével összhangban\nnyilvántartásba veendő, nagy kockázatú MI-rendszerek tekintetében a következő\ninformációkat kell megadni, és ezt követően naprakészen tartani: 1. Az\nalkalmazó neve, címe és elérhetőségei; 2. Az alkalmazó nevében információt\nbenyújtó személy neve, címe és elérhetősége; 3. A szolgáltató által az MI-\nrendszernek az uniós adatbázisba történő bejegyzésének URL-címe; 4. A 27.\ncikkel összhangban elvégzett alapvetőjogi hatásvizsgálat megállapításainak\nösszefoglalója; 5. Adott esetben az (EU) 2016/679 rendelet 35. cikkével vagy\naz (EU) 2016/680 irányelv 27. cikkével összhangban elvégzett adatvédelmi\nhatásvizsgálat összefoglalója, az e rendelet 26. cikkének (8) bekezdésében\nmeghatározottak szerint. A 60. cikkel összhangban nyilvántartásba veendő,\nvalós körülmények közötti tesztelés tekintetében a következő információkat\nkell megadni, és ezt követően naprakészen tartani: 1. A valós körülmények\nközötti tesztelés Unió-szerte egységes, egyedi azonosító száma; 2. A valós\nkörülmények közötti tesztelésben részt vevő szolgáltató vagy leendő\nszolgáltató és alkalmazók neve és elérhetőségei; 3. Az MI-rendszer rövid\nleírása, rendeltetése és a rendszer azonosításához szükséges egyéb\ninformációk; 4. A valós körülmények közötti tesztelésre vonatkozó terv főbb\njellemzőinek összefoglalása; 5. A valós körülmények közötti tesztelés\nfelfüggesztésére vagy megszüntetésére vonatkozó információk. 1. Schengeni\nInformációs Rendszer a) Az Európai Parlament és a Tanács (EU) 2018/1860\nrendelete (2018. november 28.) a Schengeni Információs Rendszernek a\njogellenesen tartózkodó harmadik országbeli állampolgárok visszaküldése\ncéljából történő használatáról (HL L 312., 2018.12.7., 1. o.). b) Az Európai\nParlament és a Tanács (EU) 2018/1861 rendelete (2018. november 28.) a\nhatárforgalom-ellenőrzés terén a Schengeni Információs Rendszer (SIS)\nlétrehozásáról, működéséről és használatáról, a Schengeni Megállapodás\nvégrehajtásáról szóló egyezmény módosításáról, valamint az 1987/2006/EK\nrendelet módosításáról és hatályon kívül helyezéséről (HL L 312., 2018.12.7.,\n14. o.). c) Az Európai Parlament és a Tanács (EU) 2018/1862 rendelete (2018.\nnovember 28.) a rendőrségi együttműködés és a büntetőügyekben folytatott\nigazságügyi együttműködés terén a Schengeni Információs Rendszer (SIS)\nlétrehozásáról, működéséről és használatáról, a 2007/533/IB tanácsi határozat\nmódosításáról és hatályon kívül helyezéséről, valamint az 1986/2006/EK európai\nparlamenti és tanácsi rendelet és a 2010/261/EU bizottsági határozat hatályon\nkívül helyezéséről (HL L 312., 2018.12.7., 56. o.). 2. Vízuminformációs\nRendszer a) Az Európai Parlament és a Tanács (EU) 2021/1133 rendelete (2021.\njúlius 7.) a 603/2013/EU, az (EU) 2016/794, az (EU) 2018/1862, az (EU)\n2019/816 és az (EU) 2019/818 rendeletnek az egyéb uniós információs\nrendszerekhez a Vízuminformációs Rendszer céljából való hozzáférésre vonatkozó\nfeltételek megállapítása tekintetében történő módosításáról (HL L 248.,\n2021.7.13., 1. o.). b) Az Európai Parlament és a Tanács (EU) 2021/1134\nrendelete (2021. július 7.) a Vízuminformációs Rendszer megreformálásának\ncéljából a 767/2008/EK, a 810/2009/EK, az (EU) 2016/399, az (EU) 2017/2226, az\n(EU) 2018/1240, az (EU) 2018/1860, az (EU) 2018/1861, az (EU) 2019/817 és az\n(EU) 2019/1896 európai parlamenti és tanácsi rendelet módosításáról, valamint\na 2004/512/EK és a 2008/633/IB tanácsi határozat hatályon kívül helyezéséről\n(HL L 248., 2021.7.13., 11. o.). 3. Eurodac Az Európai Parlament és a Tanács\n2024. május 14-i (EU) 2024/1358 rendelete az (EU) 2024/1315 és az (EU)\n2024/1350 európai parlamenti és tanácsi rendelet, valamint a 2001/55/EK\ntanácsi irányelv hatékony alkalmazása érdekében a biometrikus adatok\nösszehasonlítását, és valamely jogellenesen tartózkodó harmadik országbeli\nállampolgár vagy hontalan személy azonosítását szolgáló Eurodac\nlétrehozásáról, valamint a tagállamok bűnüldöző hatóságai és az Europol által\naz Eurodac-adatokkal való, bűnüldözési célú összehasonlítások kérelmezéséről,\naz (EU) 2018/1240 és az (EU) 2019/818 európai parlamenti és tanácsi rendelet\nmódosításáról és az (EU) 603/2013 európai parlamenti és tanácsi rendelet\nhatályon kívül helyezéséről (HL L, 2024/1358, 2024.5.22., ELI:\nhttp://data.europa.eu/eli/reg/2024/1358/oj). 4. Határregisztrációs rendszer Az\nEurópai Parlament és a Tanács (EU) 2017/2226 rendelete (2017. november 30.) a\ntagállamok külső határait átlépő harmadik országbeli állampolgárok belépésére\nés kilépésére, valamint beléptetésének megtagadására vonatkozó adatok\nrögzítésére szolgáló határregisztrációs rendszer (EES) létrehozásáról és az\nEES-hez való bűnüldözési célú hozzáférés feltételeinek meghatározásáról,\nvalamint a Schengeni Megállapodás végrehajtásáról szóló egyezmény, a\n767/2008/EK rendelet és az 1077/2011/EU rendelet módosításáról (HL L 327.,\n2017.12.9., 20. o.). 5. Európai Utasinformációs és Engedélyezési Rendszer a)\nAz Európai Parlament és a Tanács (EU) 2018/1240 rendelete (2018. szeptember\n12.) az Európai Utasinformációs és Engedélyezési Rendszer (ETIAS)\nlétrehozásáról, valamint az 1077/2011/EU rendelet, az 515/2014/EU rendelet, az\n(EU) 2016/399 rendelet, az (EU) 2016/1624 rendelet és az (EU) 2017/2226\nrendelet módosításáról (HL L 236., 2018.9.19., 1. o.). b) Az Európai Parlament\nés a Tanács (EU) 2018/1241 rendelete (2018. szeptember 12.) az (EU) 2016/794\nrendeletnek az Európai Utasinformációs és Engedélyezési Rendszer (ETIAS)\nlétrehozása céljából történő módosításáról (HL L 236., 2018.9.19., 72. o.). 6.\nA harmadik országbeli állampolgárokra és hontalan személyekre vonatkozó\nEurópai Bűnügyi Nyilvántartási Információs Rendszer Az Európai Parlament és a\nTanács (EU) 2019/816 rendelete (2019. április 17.) az Európai Bűnügyi\nNyilvántartási Információs Rendszer kiegészítése érdekében a harmadik\nországbeli állampolgárokkal és a hontalan személyekkel szemben hozott\nítéletekre vonatkozó információval rendelkező tagállamok azonosítására\nszolgáló központosított rendszer (ECRIS-TCN) létrehozásáról, valamint az (EU)\n2018/1726 rendelet módosításáról (HL L 135., 2019.5.22., 1. o.). 7.\nInteroperabilitás a) Az Európai Parlament és a Tanács (EU) 2019/817 rendelete\n(2019. május 20.) az uniós információs rendszerek közötti interoperabilitás\nkereteinek megállapításáról a határok és a vízumügy területén, továbbá a\n767/2008/EK, az (EU) 2016/399, az (EU) 2017/2226, az (EU) 2018/1240, az (EU)\n2018/1726 és az (EU) 2018/1861 európai parlamenti és tanácsi rendelet,\nvalamint a 2004/512/EK és a 2008/633/IB tanácsi határozat módosításáról (HL L\n135., 2019.5.22., 27. o.). b) Az Európai Parlament és a Tanács (EU) 2019/818\nrendelete (2019. május 20.) az uniós információs rendszerek közötti\ninteroperabilitás kereteinek megállapításáról a rendőrségi és igazságügyi\negyüttműködés, a menekültügy és a migráció területén, valamint az (EU)\n2018/1726, az (EU) 2018/1862 és az (EU) 2019/816 rendelet módosításáról (HL L\n135., 2019.5.22., 85. o.). Az 53. cikk (1) bekezdésének a) pontjában említett\nműszaki dokumentáció a modell méretétől és kockázati profiljától függően\nlegalább a következő információkat tartalmazza: 1. Az általános célú MI-modell\náltalános leírása, beleértve a következőket: a) a modell rendeltetése szerint\nellátandó feladatok, valamint azon MI-rendszerek típusa és jellege, amelyekbe\nintegrálható; b) az elfogadható felhasználásra vonatkozóan alkalmazandó\nirányelvek; c) a forgalomba hozatal időpontja és forgalmazási módszerek; d) az\narchitektúra és a paraméterek száma; e) a bemenetek és a kimenetek modalitása\n(pl. szöveg, kép) és formátuma; f) a licenc. 2. A modellnek az 1. pontban\nemlített elemeinek részletes leírása és a fejlesztési folyamatra vonatkozó\nreleváns információk, ideértve a következő elemeket: a) az általános célú MI-\nmodell MI-rendszerekbe történő integrálásához szükséges műszaki megoldások\n(pl. használati utasítás, infrastruktúra, eszközök); b) a modell és a tanítási\nfolyamat - beleértve a tanítómódszereket és -technikákat is - tervezési\nelőírásai, a legfontosabb tervezési döntések, beleértve az indokokat és a\nfeltételezéseket; adott esetben tervezésének megfelelően mit optimalizál a\nmodell és a különböző paraméterek relevanciája; c) adott esetben a tanításhoz,\na teszteléshez és a validáláshoz használt adatokra vonatkozó információk,\nbeleértve az adatok típusát és eredetét, valamint az adatgondozási módszereket\n(pl. tisztítás, szűrés stb.), az adatpontok száma, azok köre és fő jellemzői;\naz adatok megszerzésének és kiválasztásának módja, valamint adott esetben\nminden egyéb, az adatforrások alkalmatlanságának észlelésére irányuló\nintézkedés és az azonosítható torzítások feltárására irányuló módszerek; d) a\nmodell tanításához használt számítási erőforrások (pl. lebegőpontos műveletek\nszáma), tanítási idő és a tanítással kapcsolatos egyéb releváns részletek; e)\na modell ismert vagy becsült energiafogyasztása. Az e) pontot illetően,\namennyiben a modell energiafogyasztása ismeretlen, az energiafogyasztás\nalapulhat a felhasznált számítási erőforrásokra vonatkozó információkon. 1. Az\nértékelési stratégiák részletes leírása, ideértve az értékelési eredményeket\nis, a rendelkezésre álló nyilvános értékelési protokollok és eszközök vagy\negyéb értékelési módszerek alapján. Az értékelési stratégiáknak magukban kell\nfoglalniuk az értékelési kritériumokat, a mérőszámokat és a korlátok\nazonosítására szolgáló módszertant. 2. Adott esetben a belső és/vagy külső\ntámadó szempontú tesztelés (pl. red teaming) céljából bevezetett intézkedések,\na modelladaptációk - ideértve az összehangolást és a finomhangolást is -\nrészletes leírása. 3. Adott esetben a rendszer architektúrájának részletes\nleírása, megmagyarázva, hogy a szoftverösszetevők hogyan épülnek egymásra vagy\negymásba, és hogyan integrálódnak a teljes folyamatba. Az 53. cikk (1)\nbekezdésének b) pontjában említett információk legalább a következőket\ntartalmazzák: 1. Az általános célú MI-modell általános leírása, ideértve a\nkövetkezőket: a) azon feladatok, amelyeket a modell ellátni hivatott, valamint\nazon MI-rendszerek típusa és jellege, amelyekbe integrálható; b) az\nelfogadható felhasználásra vonatkozóan alkalmazandó irányelvek; c) a\nforgalomba hozatal időpontja és forgalmazási módszerek; d) adott esetben az,\nhogy a modell miként működik együtt olyan hardverrel vagy szoftverrel, amely\nnem része magának a modellnek, vagy miként használható fel az együttműködésre;\ne) adott esetben az általános célú MI-modell használatához kapcsolódó releváns\nszoftver verziói; f) az architektúra és a paraméterek száma; g) a bemenetek és\na kimenetek modalitása (pl. szöveg, kép) és formátuma; h) a modell licence. 2.\nA modell elemeinek és fejlesztési folyamatának leírása, ideértve a\nkövetkezőket: a) az általános célú MI-modell MI-rendszerekbe történő\nintegrálásához szükséges műszaki megoldások (pl. használati utasítás,\ninfrastruktúra, eszközök); b) a bemenetek és a kimenetek modalitásai (pl.\nszöveg, kép stb.) és formátuma, valamint ezek maximális mérete (pl. a\nkontextusablak hossza stb.); c) adott esetben a tanításhoz, a teszteléshez és\na validáláshoz használt adatokra vonatkozó információk, beleértve az adatok\ntípusát és eredetét, valamint az adatgondozási módszereket. Annak\nmegállapítása céljából, hogy egy általános célú MI-modell az 51. cikk (1)\nbekezdésének a) pontjában meghatározottakkal egyenértékű képességekkel vagy\nhatással rendelkezik-e, a Bizottságnak a következő kritériumokat kell\nfigyelembe vennie: a) a modell paramétereinek száma; b) az adatkészlet\nminősége vagy mérete, például tokenekben mérve; c) a modell tanításához\nhasznált számítások mennyisége lebegőpontos műveletekben mérve, vagy olyan\negyéb változók kombinációja révén megadva, mint például a tanítás becsült\nköltsége, a tanításhoz szükséges becsült idő vagy a tanításhoz szükséges\nenergiafogyasztás; d) a modell bemeneti és kimeneti modalitása, így például\nszövegből szöveg (nagy nyelvi modellek), szövegből kép, multimodalitás, és az\negyes modalitások tekintetében a nagy hatású képességek meghatározására\nvonatkozó, a technika állásának megfelelő küszöbértékek, valamint a bemenetek\nés kimenetek konkrét típusa (pl. biológiai szekvenciák); e) a modell\nképességeire vonatkozó referenciaértékek és értékelések, ideértve a további\ntanítás nélkül végzett feladatok számának mérlegelését, az új, eltérő\nfeladatok tanulásához való alkalmazkodóképességet, a modell autonómiaszintjét\nés méretezhetőségét, a rendelkezésére álló eszközöket; f) a modell az\nelterjedtsége miatt jelentős hatást gyakorol-e a belső piacra, ami akkor\nvélelmezhető, ha legalább 10 000, az Unióban letelepedett regisztrált üzleti\nfelhasználó rendelkezésére bocsátották; g) a regisztrált végfelhasználók\nszáma. Megjelent az Európai Unió Hivatalos Lapja L sorozatának 2024. július\n12-i kiadásában, hatályos 2024. augusztus 1-től. HL C 517., 2021.12.22., 56.\no. HL C 115., 2022.3.11., 5. o. HL C 97., 2022.2.28., 60. o. Az Európai\nParlament 2024. március 13-i álláspontja (a Hivatalos Lapban még nem tették\nközzé) és a Tanács 2024. május 21-i határozata. Európai Tanács, Az Európai\nTanács rendkívüli ülése (2020. október 1-2.) - Következtetések, EUCO 13/20,\n2020, 6. o. Az Európai Parlament 2020. október 20-i állásfoglalása a\nBizottsághoz intézett ajánlásokkal a mesterséges intelligencia, a robotika és\na kapcsolódó technológiák etikai szempontjainak keretéről, 2020/2012(INL). Az\nEurópai Parlament és a Tanács 765/2008/EK rendelete (2008. július 9.) az\nakkreditálás előírásainak megállapításáról és a 339/93/EGK rendelet hatályon\nkívül helyezéséről (HL L 218., 2008.8.13., 30. o.). Az Európai Parlament és a\nTanács 768/2008/EK határozata (2008. július 9.) a termékek forgalomba\nhozatalának közös keretrendszeréről, valamint a 93/465/EGK tanácsi határozat\nhatályon kívül helyezéséről (HL L 218., 2008.8.13., 82. o.). Az Európai\nParlament és a Tanács (EU) 2019/1020 rendelete (2019. június 20.) a\npiacfelügyeletről és a termékek megfelelőségéről, valamint a 2004/42/EK\nirányelv, továbbá a 765/2008/EK és a 305/2011/EU rendelet módosításáról (HL L\n169., 2019.6.25., 1. o.). A Tanács 85/374/EGK irányelve (1985. július 25.) a\nhibás termékekért való felelősségre vonatkozó tagállami törvényi, rendeleti és\nközigazgatási rendelkezések közelítéséről (HL L 210., 1985.8.7., 29. o.). Az\nEurópai Parlament és a Tanács (EU) 2016/679 rendelete (2016. április 27.) a\ntermészetes személyeknek a személyes adatok kezelése tekintetében történő\nvédelméről és az ilyen adatok szabad áramlásáról, valamint a 95/46/EK irányelv\nhatályon kívül helyezéséről (általános adatvédelmi rendelet) (HL L 119.,\n2016.5.4., 1. o.). Az Európai Parlament és a Tanács (EU) 2018/1725 rendelete\n(2018. október 23.) a természetes személyeknek a személyes adatok uniós\nintézmények, szervek, hivatalok és ügynökségek általi kezelése tekintetében\nvaló védelméről és az ilyen adatok szabad áramlásáról, valamint a 45/2001/EK\nrendelet és az 1247/2002/EK határozat hatályon kívül helyezéséről (HL L 295.,\n2018.11.21., 39. o.). Az Európai Parlament és a Tanács (EU) 2016/680 irányelve\n(2016. április 27.) a személyes adatoknak az illetékes hatóságok által a\nbűncselekmények megelőzése, nyomozása, felderítése, a vádeljárás lefolytatása\nvagy büntetőjogi szankciók végrehajtása céljából végzett kezelése tekintetében\na természetes személyek védelméről és az ilyen adatok szabad áramlásáról,\nvalamint a 2008/977/IB tanácsi kerethatározat hatályon kívül helyezéséről (HL\nL 119., 2016.5.4., 89. o.). Az Európai Parlament és a Tanács 2002/58/EK\nirányelve (2002. július 12.) az elektronikus hírközlési ágazatban a személyes\nadatok kezeléséről, feldolgozásáról és a magánélet védelméről (Elektronikus\nhírközlési adatvédelmi irányelv) (HL L 201., 2002.7.31., 37. o.). Az Európai\nParlament és a Tanács (EU) 2022/2065 rendelete (2022. október 19.) a digitális\nszolgáltatások egységes piacáról és a 2000/31/EK irányelv módosításáról\n(digitális szolgáltatásokról szóló rendelet) (HL L 277., 2022.10.27., 1. o.).\nAz Európai Parlament és a Tanács (EU) 2019/882 irányelve (2019. április 17.) a\ntermékekre és a szolgáltatásokra vonatkozó akadálymentességi követelményekről\n(HL L 151., 2019.6.7., 70. o.). Az Európai Parlament és a Tanács 2005/29/EK\nirányelve (2005. május 11.) a belső piacon az üzleti vállalkozások\nfogyasztókkal szemben folytatott tisztességtelen kereskedelmi gyakorlatairól,\nvalamint a 84/450/EGK tanácsi irányelv, a 97/7/EK, a 98/27/EK és a 2002/65/EK\neurópai parlamenti és tanácsi irányelvek, valamint a 2006/2004/EK európai\nparlamenti és tanácsi rendelet módosításáról („Irányelv a tisztességtelen\nkereskedelmi gyakorlatokról”) (HL L 149., 2005.6.11., 22. o.). A Tanács\n2002/584/IB kerethatározata (2002. június 13.) az európai elfogatóparancsról\nés a tagállamok közötti átadási eljárásokról (HL L 190., 2002.7.18., 1. o.).\nAz Európai Parlament és a Tanács (EU) 2022/2557 irányelve (2022. december 14.)\na kritikus szervezetek rezilienciájáról és a 2008/114/EK tanácsi irányelv\nhatályon kívül helyezéséről (HL L 333., 2022.12.27., 164. o.). HL C 247.,\n2022.6.29., 1. o. Az Európai Parlament és a Tanács (EU) 2017/745 rendelete\n(2017. április 5.) az orvostechnikai eszközökről, a 2001/83/EK irányelv, a\n178/2002/EK rendelet és az 1223/2009/EK rendelet módosításáról, valamint a\n90/385/EGK és a 93/42/EGK tanácsi irányelv hatályon kívül helyezéséről (HL L\n117., 2017.5.5., 1. o.). Az Európai Parlament és a Tanács (EU) 2017/746\nrendelete (2017. április 5.) az in vitro diagnosztikai orvostechnikai\neszközökről, valamint a 98/79/EK irányelv és a 2010/227/EU bizottsági\nhatározat hatályon kívül helyezéséről (HL L 117., 2017.5.5., 176. o.). Az\nEurópai Parlament és a Tanács 2006/42/EK irányelve (2006. május 17.) a\ngépekről és a 95/16/EK irányelv módosításáról (HL L 157., 2006.6.9., 24. o.).\nAz Európai Parlament és a Tanács 300/2008/EK rendelete (2008. március 11.) a\npolgári légi közlekedés védelmének közös szabályairól és a 2320/2002/EK\nrendelet hatályon kívül helyezéséről (HL L 97., 2008.4.9., 72. o.). Az Európai\nParlament és a Tanács 167/2013/EU rendelete (2013. február 5.) a mezőgazdasági\nés erdészeti járművek jóváhagyásáról és piacfelügyeletéről (HL L 60.,\n2013.3.2., 1. o.). Az Európai Parlament és a Tanács 168/2013/EU rendelete\n(2013. január 15.) a két- vagy háromkerekű járművek, valamint a négykerekű\nmotorkerékpárok jóváhagyásáról és piacfelügyeletéről (HL L 60., 2013.3.2., 52.\no.). Az Európai Parlament és a Tanács 2014/90/EU irányelve (2014. július 23.)\na tengerészeti felszerelésekről és a 96/98/EK tanácsi irányelv hatályon kívül\nhelyezéséről (HL L 257., 2014.8.28., 146. o.). Az Európai Parlament és a\nTanács (EU) 2016/797 irányelve (2016. május 11.) a vasúti rendszer Európai\nUnión belüli kölcsönös átjárhatóságáról (HL L 138., 2016.5.26., 44. o.). Az\nEurópai Parlament és a Tanács (EU) 2018/858 rendelete (2018. május 30.) a\ngépjárművek és pótkocsijaik, valamint az ilyen járművek rendszereinek,\nalkotóelemeinek és önálló műszaki egységeinek jóváhagyásáról és\npiacfelügyeletéről, a 715/2007/EK és az 595/2009/EK rendelet módosításáról,\nvalamint a 2007/46/EK irányelv hatályon kívül helyezéséről (HL L 151.,\n2018.6.14., 1. o.). Az Európai Parlament és a Tanács (EU) 2018/1139 rendelete\n(2018. július 4.) a polgári légi közlekedés területén alkalmazandó közös\nszabályokról és az Európai Unió Repülésbiztonsági Ügynökségének létrehozásáról\nés a 2111/2005/EK, az 1008/2008/EK, a 996/2010/EU, a 376/2014/EU európai\nparlamenti és tanácsi rendelet és a 2014/30/EU és a 2014/53/EU európai\nparlamenti és tanácsi irányelv módosításáról, valamint az 552/2004/EK és a\n216/2008/EK európai parlamenti és tanácsi rendelet és a 3922/91/EGK tanácsi\nrendelet hatályon kívül helyezéséről (HL L 212., 2018.8.22., 1. o.). Az\nEurópai Parlament és a Tanács (EU) 2019/2144 rendelete (2019. november 27.) a\ngépjárműveknek és pótkocsijaiknak, valamint az ilyen járművek rendszereinek,\nalkotóelemeinek és önálló műszaki egységeinek az általános biztonság, továbbá\naz utasok és a veszélyeztetett úthasználók védelme tekintetében történő\ntípusjóváhagyásáról, az (EU) 2018/858 európai parlamenti és tanácsi rendelet\nmódosításáról, valamint a 78/2009/EK, a 79/2009/EK és a 661/2009/EK európai\nparlamenti és tanácsi rendelet és a 631/2009/EK, a 406/2010/EU, a 672/2010/EU,\naz 1003/2010/EU, az 1005/2010/EU, az 1008/2010/EU, az 1009/2010/EU, a\n19/2011/EU, a 109/2011/EU, a 458/2011/EU, a 65/2012/EU, a 130/2012/EU, a\n347/2012/EU, a 351/2012/EU, az 1230/2012/EU és az (EU) 2015/166 bizottsági\nrendelet hatályon kívül helyezéséről (HL L 325., 2019.12.16., 1. o.). Az\nEurópai Parlament és a Tanács 810/2009/EK rendelete (2009. július 13.) a\nKözösségi Vízumkódex létrehozásáról (vízumkódex) (HL L 243., 2009.9.15., 1.\no.). Az Európai Parlament és a Tanács 2013/32/EU irányelve (2013. június 26.)\na nemzetközi védelem megadására és visszavonására vonatkozó közös eljárásokról\n(HL L 180., 2013.6.29., 60. o.). Az Európai Parlament és a Tanács (EU)\n2024/900 rendelete 2024. március 13.) a politikai reklám átláthatóságáról és\ntargetálásáról (HL L, 2024/900, 2024.3.20., ELI:\nhttp://data.europa.eu/eli/reg/2024/900/oj). Az Európai Parlament és a Tanács\n2014/31/EU irányelve (2014. február 26.) a nem automatikus működésű mérlegek\nforgalmazására vonatkozó tagállami jogszabályok harmonizációjáról (HL L 96.,\n2014.3.29., 107. o.). Az Európai Parlament és a Tanács 2014/32/EU irányelve\n(2014. február 26.) a mérőműszerek forgalmazására vonatkozó tagállami\njogszabályok harmonizálásáról (HL L 96., 2014.3.29., 149. o.). Az Európai\nParlament és a Tanács (EU) 2019/881 rendelete (2019. április 17.) az ENISA-ról\n(az Európai Uniós Kiberbiztonsági Ügynökségről) és az információs és\nkommunikációs technológiák kiberbiztonsági tanúsításáról, valamint az\n526/2013/EU rendelet hatályon kívül helyezéséről (kiberbiztonsági jogszabály)\n(HL L 151., 2019.6.7., 15. o.). Az Európai Parlament és a Tanács (EU)\n2016/2102 irányelve (2016. október 26.) a közszférabeli szervezetek\nhonlapjainak és mobilalkalmazásainak akadálymentesítéséről (HL L 327.,\n2016.12.2., 1. o.). Az Európai Parlament és a Tanács 2002/14/EK irányelve\n(2002. március 11.) az Európai Közösség munkavállalóinak tájékoztatása és a\nvelük folytatott konzultáció általános keretének létrehozásáról (HL L 80.,\n2002.3.23., 29. o.). Az Európai Parlament és a Tanács (EU) 2019/790 irányelve\n(2019. április 17.) a digitális egységes piacon a szerzői és szomszédos\njogokról, valamint a 96/9/EK és a 2001/29/EK irányelv módosításáról (HL L\n130., 2019.5.17., 92. o.). Az Európai Parlament és a Tanács 1025/2012/EU\nrendelete (2012. október 25.) az európai szabványosításról, a 89/686/EGK és a\n93/15/EGK tanácsi irányelv, a 94/9/EK, a 94/25/EK, a 95/16/EK, a 97/23/EK, a\n98/34/EK, a 2004/22/EK, a 2007/23/EK, a 2009/23/EK és a 2009/105/EK európai\nparlamenti és tanácsi irányelv módosításáról, valamint a 87/95/EGK tanácsi\nhatározat és az 1673/2006/EK európai parlamenti és tanácsi határozat hatályon\nkívül helyezéséről (HL L 316., 2012.11.14., 12. o.). Az Európai Parlament és a\nTanács (EU) 2022/868 rendelete (2022. május 30.) az európai adatkormányzásról\nés az (EU) 2018/1724 rendelet módosításáról (adatkormányzási rendelet) (HL L\n152., 2022.6.3., 1. o.). Az Európai Parlament és a Tanács (EU) 2023/2854\nrendelete (2023. december 13.) a méltányos adathozzáférésre és -felhasználásra\nvonatkozó harmonizált szabályokról, valamint az (EU) 2017/2394 rendelet és az\n(EU) 2020/1828 irányelv módosításáról (adatrendelet) (HL L, 2023/2854,\n22.12.2023, ELI: http://data.europa.eu/eli/reg/2023/2854/oj). A Bizottság\najánlása (2003. május 6.) a mikro-, kis- és középvállalkozások\nmeghatározásáról (HL L 124., 2003.5.20., 36. o.). A Bizottság határozata\n(2024. január 24.) a mesterséges intelligenciával foglalkozó európai hivatal\nlétrehozásáról (C/2024/1459). Az Európai Parlament és a Tanács 575/2013/EU\nrendelete (2013. június 26.) a hitelintézetekre és befektetési vállalkozásokra\nvonatkozó prudenciális követelményekről és a 648/2012/EU rendelet\nmódosításáról (HL L 176., 2013.6.27., 1. o.). Az Európai Parlament és a Tanács\n2008/48/EK irányelve (2008. április 23.) a fogyasztói hitelmegállapodásokról\nés a 87/102/EGK tanácsi irányelv hatályon kívül helyezéséről (HL L 133.,\n2008.5.22., 66. o.). Az Európai Parlament és a Tanács 2009/138/EK irányelve\n(2009. november 25.) a biztosítási és viszontbiztosítási üzleti tevékenység\nmegkezdéséről és gyakorlásáról (Szolvencia II) (HL L 335., 2009.12.17., 1.\no.). Az Európai Parlament és a Tanács 2013/36/EU irányelve (2013. június 26.)\na hitelintézetek tevékenységéhez való hozzáférésről és a hitelintézetek és\nbefektetési vállalkozások prudenciális felügyeletéről, a 2002/87/EK irányelv\nmódosításáról, a 2006/48/EK és a 2006/49/EK irányelv hatályon kívül\nhelyezéséről (HL L 176., 2013.6.27., 338. o.). Az Európai Parlament és a\nTanács 2014/17/EU irányelve (2014. február 4.) a lakóingatlanokhoz kapcsolódó\nfogyasztói hitelmegállapodásokról, valamint a 2008/48/EK és a 2013/36/EU\nirányelv és az 1093/2010/EU rendelet módosításáról (HL L 60., 2014.2.28., 34.\no.). Az Európai Parlament és a Tanács (EU) 2016/97 irányelve (2016. január\n20.) a biztosítási értékesítésről (HL L 26., 2016.2.2., 19. o.). A Tanács\n1024/2013/EU rendelete (2013. október 15.) az Európai Központi Banknak a\nhitelintézetek prudenciális felügyeletére vonatkozó politikákkal kapcsolatos\nkülön feladatokkal történő megbízásáról (HL L 287., 2013.10.29., 63. o.). Az\nEurópai Parlament és a Tanács (EU) 2023/988 rendelete (2023. május 10.) az\náltalános termékbiztonságról, az 1025/2012/EU európai parlamenti és tanácsi\nrendelet és az (EU) 2020/1828 európai parlamenti és tanácsi irányelv\nmódosításáról, valamint a 2001/95/EK európai parlamenti és tanácsi irányelv és\na 87/357/EGK tanácsi irányelv hatályon kívül helyezéséről (HL L 135.,\n2023.5.23., 1. o.). Az Európai Parlament és a Tanács (EU) 2019/1937 irányelve\n(2019. október 23.) az uniós jog megsértését bejelentő személyek védelméről\n(HL L 305., 2019.11.26., 17. o.). HL L 123., 2016.5.12., 1. o. Az Európai\nParlament és a Tanács 182/2011/EU rendelete (2011. február 16.) a Bizottság\nvégrehajtási hatásköreinek gyakorlására vonatkozó tagállami ellenőrzési\nmechanizmusok szabályainak és általános elveinek megállapításáról (HL L 55.,\n2011.2.28., 13. o). Az Európai Parlament és a Tanács (EU) 2016/943 irányelve\n(2016. június 8.) a nem nyilvános know-how és üzleti információk (üzleti\ntitkok) jogosulatlan megszerzésével, hasznosításával és felfedésével szembeni\nvédelemről (HL L 157., 2016.6.15., 1. o.). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2024/1689 rendelete (2024. június 13.) a mesterséges intelligenciára\nvonatkozó harmonizált szabályok megállapításáról, valamint a 300/2008/EK, a\n167/2013/EU, a 168/2013/EU, az (EU) 2018/858, az (EU) 2018/1139 és az (EU)\n2019/2144 rendelet, továbbá a 2014/90/EU, az (EU) 2016/797 és az (EU)\n2020/1828 irányelv módosításáról (a mesterséges intelligenciáról szóló\nrendelet) (HL L, 2024/1689, 2024.7.12., ELI:\nhttp://data.europa.eu/eli/reg/2024/1689/oj). Az Európai Parlament és a Tanács\n(EU) 2020/1828 irányelve (2020. november 25.) a fogyasztók kollektív\nérdekeinek védelmére irányuló képviseleti keresetekről és a 2009/22/EK\nirányelv hatályon kívül helyezéséről (HL L 409., 2020.12.4., 1. o.). © Wolters\nKluwer\n\n'}, {'url': 'https://index.hu/gazdasag/2024/08/08/ai-summit-2024-mesterseges-intelligencia-kiberbiztonsag-promptiras-konferencia/', 'content': 'Kövesse az Indexet Facebookon is! A Városligetben erre az időszakra\nkialakított AI Campus különböző színpadain olyan témák kerülnek terítékre,\nmint hogy 10 év múlva milyen szakmák várhatók, lesznek-e még újságírók,\nfotósok, színészek, hogy van-e kraft a promptírásban, hogy valóban aranyat\nér-e az adat, hogy mi történik a neobankok világában, lehet-e ténylegesen\nszabályozni vagy legalább kockázatot csökkenteni, illetve egészségügy,\nhadiipari, kiberbiztonsági, sőt még űrtechnológiai kérdéskörökben is\nelmerülhetnek az érdeklődők. A neves szakértőkkel és sztárelőadókkal tűzdelt\nesemény különlegessége, hogy lehetőség nyílik a mesterségesintelligencia-\nalkalmazások gyakorlati aspektusainak elsajátítására, AI-eszközök és\ntechnológiák közvetlen tesztelésére, sőt még saját projektekhez is bárki\nkérhet szakértői útmutatást. Néhány példa a nagyszabású szakmai esemény\nnemzetközi előadóinak névsorából: Dr. Frederik G. Pferdt – a Google első\ninnovációs nagykövete, a Stanford Egyetem adjunktusa, világszinten elismert\ninnovációs szakértő, író. Ötleteit és gyakorlatait nemzetközi, illetve\nkormányzati szervezetek használják az ENSZ-től kezdve a NASA-n át az NBA-ig.\nMunkásságát olyan médiumok is méltatják, mint a Der Spiegel vagy a BBC News.\nTomasz Stachlewski – a szakember a világ egyik legnagyobb és legkomplexebb\ntechnológiai óriásától, az Amazontól érkezik, ahol különböző méretű\nvállalatokat (a startupoktól a nagyvállalatokig) segít a felhőbe való\nátállásban. Ehhez irányelveket nyújt, és stratégiát különböző IT-rendszerek\nkövetkező szintre való emelésében. Ebben hatalmas segítsége az AI,\ntapasztalatait pedig a konferencián osztja meg. Giovanni Tridente – a Santa\nCorce Egyetem professzora, aki jól ismeri a Vatikán és az AI kapcsolatát.\nElmondja, hogyan tanult az egyház a hibából, amikor nem reagált időben a\nsocial media platformok berobbanására. És hogy ennek fényében hogyan készül\ntudatosan a mesterséges intelligenciával kapcsolatos dilemmák\nmegválaszolására. Tridente szerint az egyház segíthet emberségesnek maradni.\nJohn C. Havens – AI-szakértő és író, a Heartificial Intelligence bestseller\nszerzője. Szerinte egy olyan korszakba léptünk, amikor számos személyre\nszabott algoritmus befolyásolja minden döntésünket, és elmosódnak a határok az\nemberi segítségnyújtás, az automatizáció és a kihalás között. Hol húzzuk meg a\ngépi automatizáció határát? Előadása rávilágít a mesterséges intelligenciával\njáró élet különböző forgatókönyveire, és segít átlátni, milyen algoritmusok\nuralják majd a társadalmat. A fenti tekintélyes előadók mellett a hazai MI-\nszektor neves képviselői, illetve digitális világban jártas szakemberei is ott\nlesznek az AI Summiton: Dr. Tilesch György – a PHI Institute for Augmented\nIntelligence alapítója és elnöke, vezető globális AI-szakértő. Világszerte\nközreműködik különböző vállalati és kormányzati vezetőkkel, Fortune 50\ncégekkel, de dolgozott már a Microsofttal, az Ipsosszal és a svájci székhelyű\nVilággazdasági Fórummal is. Az AI-stratégia, etika, politika és irányítás\nterületeire szakosodott. Szolgál a Harvard Experfy AI Talent platformjának\ntanácsadó testületében, a Neumann Society AI nagykövete, a Pécsi Egyetem\ndíszdoktora. Keleti Arthur – kibertitok-jövőkutató, IT-biztonsági stratéga,\níró, producer. Az Informatikai Biztonság Napja kezdeményezés és konferencia\nötletadója és szervezője. A mesterséges intelligencia jövőjének és a\nkiberbiztonságra gyakorolt hatásának kutatója. Dr. Kiss László – csillagász,\nakadémikus, Széchenyi-díjas fizikus. A Csillagászati és Földtudományi\nKutatóközpont főigazgatója. A Magyar Csillagászati Egyesület elnöke, aki az\nűrben zajló jelenségekről szórakoztatóan, laikusok számára is tökéletesen\nbefogadható módon képes informálni. Szabó Péter – a Microsoft lakossági\nüzletágának régiós igazgatói pozíciója után a vállalati és partnerkapcsolati\nüzletág igazgatója lett. A digitalizáció tematikáján belül kiemelt szívügye a\nszervezetek és a munkavállalók digitális készségeinek fejlesztése. Szerinte a\nnapi működés, így a sikeresség azon múlik, hogy a vállalat hogyan támaszkodik\na modern digitális technológiákra, illetve hogyan tud alkalmazkodni a nem várt\nhelyzetekhez. Üzletről, munkavégzési szokásokról és az életvitelünk\nújragondolásáról tart előadást. Dr. Peták István – Gábor Dénes-díjas kutató,\norvos, 58 tudományos közlemény szerzője. A Magyar Biotechnológiai Szövetség\ntudományos és bioetikai szakbizottságának elnöke. Kiemelkedő munkája\nhozzájárult a molekuláris orvostudományi kutatások gyakorlati hasznosításához\na daganatos betegek kezelésében. Jakab Roland – a Mesterséges Intelligencia\nKoalíció vezetője, az Ericsson közép-európai régiójának volt stratégiai\nigazgatója, az „Év legsikeresebb ICT-menedzsere” cím nyertese. A HUN-REN\nMagyar Kutatási Hálózat vezérigazgatójaként kutatók és innovációik MI-\ntámogatásán dolgozik. Dr. Aczél Petra – kommunikációkutató, egyetemi tanár.\n200 tudományos-szakmai tanulmány mellett 7 könyv szerzője, akinek videóira sok\nezren kíváncsiak. Szakterülete az újmédia, a kommunikáció, az érveléstudomány\nés a jövőkészségek. Közérthetően nyúl a világban és itthon is fontos\nkérdésekhez és dilemmákhoz, így a hallgatóság mindig magával vihet valami jól\nhasznosítható új tudást. Nyáry Krisztián – író, irodalomtörténész, könyvkiadó,\ntöbb hazai bestseller szerzője. A Magvető és az Athenaeum Kiadó korábbi\nigazgatója. Jelenleg a hazai könyvpiacon meghatározó Líra kreatívigazgatója,\nvalamint a Magvető Café művészeti vezetője. Gondolatait az AI Summit 2024\nkonferencián az Így írtok ti… és így ír az AI kreatív témaszekcióban\nismerhetjük meg. Az AI Summit konferenciát tavaly szervezték meg először, telt\nházzal zajlott, és a résztvevők hamar „az AI és a technológiai innovációk\niránt érdeklődők egyik legfontosabb találkozóhelyévé” nevezték ki, ahol a\nszünetekben és az esti programokon kötetlen beszélgetések formáltak új\negyüttműködési lehetőségeket. Hivatalos banki, kormányzati és tv-streaming-\nalkalmazásoknak adták ki magukat. Százharmincöt új jogszabályt, köztük\nhuszonöt törvényjavaslatot tervez elfogadni és elfogadtatni a kormány az év\nvégéig. A kiberbiztonsági szakértő szerint a mesterséges intelligencia lesz\nMari néni unokája. Kövesse az Indexet Facebookon is!\n\n'}, {'url': 'https://cseppek.hu/cikk/229332024-ben-a-generativ-mesterseges-intelligencia-altalanossa-valik', 'content': "A Disney+ bejelentette őszi premierjeit: érkezik többek között a Jilly Cooper\nikonikus regénye alapján készült Riválisok (Rivals) című brit saját gyártású\ndrámasorozat, a Marvel Television Mindvégig Agatha (Agatha All Along) című\nsorozata Kathryn Hahn főszereplésével, a Ryan Murphy által készített Doctor\nOdyssey, A Grace Klinika (Grey's Anatomy) és az FX A nagy öreg (FX’sThe Old\nMan) című nagysikerű sorozatok új évada. Azt gondolom, hogy Dumas könyvét\njóval kevesebben olvasták, mint ahányan ismerik a történetet – hiszen nem egy\nfilmsorozat, film készült már belőle. Az Azahriah film alkotóival, az\nAgymanók, a Garfield ,a Wednesday és a BeetleJuice szinkronhangjaival, Palya\nBea és Ringató koncerttel, díjnyertes animevel és közel száz különleges\nrövidfilmmel és animációval érkezik az ország egyetlen gyerekeknek és\nfiataloknak szóló filmfesztiválja: a Cinemira. Október 4–5. között már\nharmadik alkalommal rendezi meg a Moholy-Nagy Művészeti Egyetem (MOME)\nAnimáció szak és a Friss Hús filmfesztivál csapata a Friss Kakas Animációs\nFilmnapokat a Toldi Moziban, az évtizedes múltra visszatekintő Kiskakas\nFilmnapok újragondolásaként. Vékes Csaba romantikus sportvígjátéka, a\nLepattanó szeptember 26-tól a JUNO11 Distribution forgalmazásában érkezik a\nhazai a mozikba – de szeptember 13-tól már közönségtalálkozókkal kísért\npremier előtti vetítéseken is látható lesz országszerte. Szeptember 26. –\noktóber 2. között 11. alkalommal rendezik meg a Skandináv Filmfesztivált a\nbudapesti Art+ Cinemában (1074 Budapest, Erzsébet krt. 39.). Az “Encore!” azaz\n„Ráadás!” címmel induló új sorozatban a hazai színművészet kiemelkedő\negyéniségei szerepelnek havi rendszerességgel a BJC színpadára megálmodott\nzenés előadásaikkal. Szeder, a Junior Artisjus díjas dalszerző-énekesnő 10.\nszületésnapi koncertjét ünnepli szeptember 26-án, a Várkert Bazár Öntőház\nudvarán. A godfater. Artisjus- és Fonogram-díjas, sokak által csak honi\nsupergroupként emlegetett rockformáció. A dalszerzők napja alkalmából\nszervezett rendhagyó szerzői koncertek célja felhívni a figyelmet a dalszerzők\nértékteremtő, a dalok értékközvetítő szerepére. Mesteriskola, világsztárok, A\nHegedű Ünnepe, tematikus napok – a Concerto Budapest a 2024/25-ös évadban is\nizgalmas, sokrétű programkínálattal várja a közönséget a Zeneakadémián és a\nMüpában. Egyszeri és megismételhetetlen produkciók, műfajok rendhagyó\ntalálkozása, hazai és világsztárok a hamarosan kezdődő Liszt Ünnepen. 2010.\nszeptember 10-ét írunk. Egy csoport újságíró várakozik a Kinizsi utcai\nMonarchia Borszaküzlet előtt. Mindenki csak a sajtóst, László Ágnest ismeri,\nde hamar feloldódik a hangulat az első pár korty bor után. A bórkóstolást\nkötetlen beszélgetés követi, az eleinte zárkózott társaság összebarátkozik.\nEzen az alkalmon volt szerencsénk először megismerkedni Lantai Józseffel.\nMindenki érintett valamilyen formában a rákkal kapcsolatban … Körülvesz\nminket, mégsem tudunk róla semmit. Aranybörtön – Dickens jószándékú\nemberkísérlete bukott nőkkel. Az Open Books egy limitált példányszámú,\ndedikált, hat különböző borítóval rendelhető exkluzív kötettel tiszteleg a\nnapokban 80. születésnapját ünneplő Rubik Ernő és a Kocka megszületésének 50.\névfordulója előtt. A mi kockánk jubileumi kiadásához Rubik Ernő egy új előszót\nis írt, a kiadó pedig minden kötethez ajándékba ad egy Cubemant is! Megjelent\naz egyedi költői hangon publikáló Pauljucsák Péter első verseskötete. „A\ntörténetek összekötnek minket, a történetekben találkozhatunk” – ez volt a\nszlogenje a JCDecaux hetedik alkalommal meghirdetett Álljon meg egy novellára!\nirodalmi pályázatának, amelyet idén a Librivel közösen valósítottak meg. A\ntöbb mint háromezer-kétszáz alkotás közül kiválasztott húsz nyertes novella\nmegdöbbentően ismerős jeleneteket és hétköznapi helyszíneket elevenít meg,\namelyekben újra és újra visszatér a kapcsolódásra való igény. A GlobalData\nszerint 2024-ben a generatív mesterséges intelligencia nomini casino\náltalánossá válik a speciális egyedi modellek és a multimodális eszközökkel\nvégzett kísérletek elfogadása miatt A generatív mesterséges intelligencia\núttörő fejlemény volt tavaly, amikor olyan népszerű chatbotok jelentek meg,\nmint az OpenAI ChatGPT. A chatbotokat működtető nagy nyelvi modellek (LLM)\nhasználatának azonban számos hátránya van, amelyek hátráltatják a technológia\nátvételét. Emiatt az LLM-eket fokozatosan felváltják kisebb, egyedi nyelvi\nmodellek 2024-ben. Az MI működtetése költséges Az LLM-ek képzése és\nműködtetése jelentős költségekkel jár, és drága számítási erőforrások\nszükségesek az AI-ban használt hatalmas mennyiségű adat feldolgozásához. A\nspeciális modellek végső soron jobb értéket és pontosságot biztosítanak.\n2024-ben, amikor a Generative AI behatol a vállalati térbe, és az üzleti\nesetek kézzelfoghatóvá válnak, a vállalatok elkezdik használni a kisebb\nmodelleket, és saját tulajdonú adatokkal hangolják azokat, hogy a költségek\ntöredékéért elérjék a kívánt teljesítményt egy adott projekthez. A\nvállalkozások potenciálisan kiszolgáltatott jogi helyzetbe kerülhetnek például\na szerzői jogok esetleges megsértése vagy a magánélet megsértése miatt, mivel\na modellek képzéséhez feldolgozott adatok eredete gyakran ismeretlen. Emiatt a\nszervezetek inkább a kis nyelvi modellek (SLM) telepítését választják. Ezeket\naz egyéni modelleket a védett adatokra oktatják, és jobb eredményeket\nbiztosítanak kevesebb kockázattal. Az elemzők szerint idén átfogó szabályozási\npolitikák születnek majd, amelyek irányítják az AI-projektek bevezetését és\nirányítását. A világ Európára fog tekinteni, amely az AI-törvényen keresztül\núttörő jogszabály elfogadására készül. Kategorizálja az AI-alkalmazások\nkockázatát és tilt bizonyos felhasználási eseteket, követelményeket állapít\nmeg a magas kockázatú alkalmazások igénybevételére vonatkozóan, és előírja a\nszámítógépes modellek emberi felügyeletét. és cselekvéseket. A világ többi\nrésze hasonló keretekről kezd majd beszélni, és a szerzői jog által védett\ntartalmak az AI modellek nomini casino képzésére való felhasználásáról szóló\nvita a vezetők szemében lesz a legfontosabb. A GlobalData jelentése azt is\nmegemlíti, hogy a vállalatok elkezdik feltárni, hogyan vehetik igénybe a\nmultimodális mesterséges intelligenciát a jobb eredmények létrehozására számos\niparágban és alkalmazásban. Ezenkívül az olyan technikák, mint a RAG\n(retrieval-augmented generation), amelyet arra használnak, hogy megbízható\nbelső vagy külső forrásokból származó információkkal egészítsék ki az LLM-\nkérdéseket és válaszokat, egyre szélesebb körben elterjednek. A szintetikus\nadatok igénybevétele a vállalkozások és az AI-cégek körében is elterjedtebbé\nválik. Azok a cégek, mint az OpenAI és a Cohere, a szintetikus adatok\nalkalmazását fogják tanulmányozni a valós adatok alternatívájaként, hogy jó\nminőségű adatkészletekhez férhessenek hozzá anélkül, hogy vállalnák a jogi\nkockázatokat. A The New York Times például nemrégiben pert indított az OpenAI\nellen, és más hasonló esetek is történtek az iparágban. Több megállapodást és\npartnerséget is fogunk látni az AI-cégek és a médiavállalatok között, például\naz OpenAI nomini casino nemrégiben megállapodást írt alá a német Axel Springer\nmédiakonszernnel és az Associated Press-szel. A legtöbben rettegnek a\nrobothívástól, de az ügyfélszolgálati AI olyan adatvezérelt eszközöket\nbiztosíthat az iparágnak, amelyek érdemi betekintést nyújtanak az ügyfél és a\nszolgáltató számára egyaránt. Az ügyfélszolgálati ágazatot működtető MI-\neszközök chatbotok és virtuális asszisztensek formájában már részben a\nmindennapok részei. Izgalmas jövő A GlobalData előrejelzése szerint a teljes\nmesterségesintelligencia-piac 2030-ra 909 milliárd dollár lesz, ami 2022 és\n2030 között 35%-os összetett éves növekedési rátát regisztrál. A generatív MI\nterületén a bevételek a 2022-es 1,8 milliárd dollárról 33 dollárra nőnek. A\ngeneratív AI minden iparágra hatással lesz – ideértve a szórakoztatóipart is\nnomini casino - , és 2024-ben az élő MI-megvalósítások száma exponenciálisan\nnő az üzleti térben, különösen az ügyfélélmény és a marketing területén.\nBefejeződött a 250 éves fal- és mennyezetképek restaurálása a veszprémi Érseki\nPalota dísztermében... Gigászi sör és gasztronómiai választékkal várják az\nérdeklődőket október 10. és 13. között... A Fordított tárgyak kiállítás számos\nkérdést vet fel, melyek a tárgyak akár hétköznapi, akár... Szeptember\n21-22-én, immár harmadik alkalommal rendezi meg a Kerékpárosbarát hétvégét a\nMagyar ... Egy évvel ezelőtt nyitotta meg kapuit a Dohány utca 78. szám alatt\na Like The Gypsies Club,... CSEPPEK.hu (@cseppekhu) • Instagram photos and\nvideos Az “Encore!” azaz „Ráadás!” címmel induló új sorozatban a hazai\nszínművészet kiemelkedő egyéniségei szerepelnek havi... 2010. szeptember 10-ét\nírunk. Egy csoport újságíró várakozik a Kinizsi utcai Monarchia Borszaküzlet\nelőtt. Mindenki csak a... A Disney+ bejelentette őszi premierjeit: érkezik\ntöbbek között a Jilly Cooper ikonikus regénye alapján készült Riválisok (... A\nThália Színház előtt, a bejárat esővédőjét tartó oszlop körül egy nagy kör van\na betonba vésve. A körcikkekbe az épületben... Azt gondolom, hogy Dumas\nkönyvét jóval kevesebben olvasták, mint ahányan ismerik a történetet – hiszen\nnem egy filmsorozat,... CSEPPEK.hu A mindennapi média\n\n"}, {'url': 'https://itbusiness.hu/technology/mi-teologia-vallastudomany/', 'content': 'Tavaly, a ramadán első napján, nem sokkal éjfél előtt Raihan Khan – egy 20\néves, Kolkatában élő muszlim diák – egy LinkedIn-bejegyzésben ismertette, hogy\nelindította a QuranGPT-t, egy mesterséges intelligenciával működő chatbotot,\namelyet úgy tervezett, hogy az iszlám legszentebb szövege alapján válaszoljon\nkérdésekre és adjon tanácsokat. Aztán elment aludni: hét órával később arra\nébredt, hogy a túl nagy forgalom miatt a rendszer összeomlott. A hozzászólások\nnagy része pozitív volt, mások viszont nem – utóbbiak egyenesen fenyegetők\nvoltak. Khan először nyomást érzett, hogy vegye le a chatbotot, de végül\nmeggondolta magát. Úgy véli, hogy a mesterséges intelligencia egyfajta hídként\nszolgálhat, amely összeköti az embereket a legmélyebb spirituális kérdéseikre\nadott válaszokkal. „Vannak emberek, akik közel akarnak kerülni a vallásukhoz,\nde nem hajlandók időt áldozni arra, hogy többet tudjanak meg róla. Mi lenne,\nha mindezt könnyen elérhetővé tehetném egy felszólításon keresztül?” kérdezte\nKhan. A QuranGPT – amelyet már mintegy 230 ezer ember használ világszerte –\ncsak egy, a vallási szövegeken képzett chatrobotok sorából, amelyek a\nközelmúltban jelentek meg az interneten. Ott van a Bible.Ai, a Gita GPT, a\nBuddhabot, az Apostol Pál AI, a 16. századi német teológus, Luther Márton\nutánzására kiképzett chatbot, egy Konfuciusz műveire képzett chatbot, és még\negy másik, amelyet a delphoi jósda utánzására terveztek. A különböző vallások\nhívei évezredek óta hosszú órákat – vagy egész életeket – töltenek a\nszentírások tanulmányozásával, hogy betekintést nyerjenek az emberi lét\nlegmélyebb titkaiba, például a lélek útjára a halál után. A chatbotok alkotói\nnem feltétlenül hisznek abban, hogy a nagy nyelv modellek (LLM-ek) meg fogják\noldani ezeket az ősi teológiai rejtélyeket. De úgy gondolják, hogy a robotok a\nhatalmas mennyiségű szövegben található finom nyelvi minták azonosítására és a\nfelhasználói kérésekre emberi nyelven adott válaszokra való képességükkel (ezt\na funkciót természetes nyelvi feldolgozásnak vagy NLP-nek nevezik) elméletileg\nmásodpercek alatt szintetizálhatják a spirituális felismeréseket, időt és\nenergiát spórolva ezzel a felhasználóknak. Ez isteni bölcsesség igény szerint.\nSok hivatásos teológusnak azonban komoly aggályai vannak az LLM és a vallás\nkeveredésével kapcsolatban. Ilia Delio, a Villanova Egyetem teológiai\ntanszékvezetője és több könyv szerzője a vallás és a tudomány átfedéséről, úgy\nvéli, hogy ezek a chatrobotok – amelyeket lekicsinylően „Istenhez vezető\nparancsikonnak” nevez – aláássák azokat a spirituális előnyöket, amelyeket\nhagyományosan a vallási szövegekkel való hosszú, közvetlen foglalkozással\nértek el. Néhány világi MI-szakértő pedig úgy véli, hogy az LLM-ek használata\na szentírás értelmezésére a technológia alapvető és potenciálisan veszélyes\nfélreértésén alapul. A vallási közösségek azonban a mesterséges intelligencia\nszámos típusát és felhasználási módját elfogadják. Az egyik ilyen feltörekvő\nfelhasználási terület a bibliafordítás. Korábban ez a munka fáradságos lassú\nvolt: az először 1611-ben kiadott angol King James Biblia kapcsán hét évet, és\negy sereg odaadó tudóst vett igénybe az ősi források lefordítása. Az LLM-ek\nazonban felgyorsítják a folyamatot, lehetővé téve a tudósok számára, hogy\nkiterjesszék a Biblia hatókörét. A „Paratext” nevű platform például NLP-t\nhasznál a Szentírás ezoterikus kifejezéseinek – például az engesztelés vagy a\nmegszentelődés – lefordítására, weboldalán „a Szentírás hű fordításaként”\njellemzi azt. Tavaly pedig a Dél-kaliforniai Egyetem informatikusai\nelindították a „Greek Room” nevű projektet, amely egy mesterséges\nintelligenciával működő chatbot interfész segítségével segíti a Bibliát\n„alacsony forrású” nyelvekre (azaz olyan nyelvekre, amelyekről kevés, vagy\negyáltalán nem létezik írásos feljegyzés) fordítani. Az angol Biblia első\nkiadásának első száma, amelyet 1611-ben Londonban nyomtatattak ki. „King James\nVersion” néven is ismert [Forrás: Topical Press Agency/Hulton Archívum/Getty\nImages]Az LLM-eket a bibliafordítások közötti nyelvi eltérések\ntanulmányozására is használják. Egy nemzetközi tudóscsoport az év elején az\narXiv.com oldalára feltöltött kutatási tanulmányában leírta, hogy a\nszentimentelemzés – egy NLP-alapú eljárás a szövegben lévő érzelmi értékek\nérzékelésére – segítségével elemezte Jézus hegyi beszédét, az Újszövetség\negyik legismertebb szövegét („Boldogok a szelídek, mert ők öröklik a földet.”)\nMiután elemezték a prédikáció öt különböző fordítását, köztük a King James-\nfordítást, a kutatók azt találták, hogy az egyes fordítások szókincse minden\nesetben jelentősen különbözik. Emellett a humor, az optimizmus és az empátia\nkülönböző szintjeit fedezték fel az egyes fejezetekben, amelyeket Jézus az\nüzenetének átadására használt. Mark Graves informatikus úgy véli, hogy az LLM-\nek elméletileg felhasználhatók lennének a merev vallási ortodoxia felrúgására.\n„Bizonyos értelemben a teológiában nem sok újdonság van már vagy 800 éve. A\ngeneratív mesterséges intelligencia segíthet ebben az átmenetben, a dobozból\nvaló kitörésben … és új ötletek létrehozásában”, mondja Graves, aki az „AI and\nFaith” nevű nonprofit szervezet igazgatója, amely az MI etikai kihívásaival\nfoglalkozik. Graves szerint képzeljünk el például egy olyan chatbotot, amelyet\nSzent Ágoston (Kr. e. 354-430) művein képeztek ki, és egy másikat, amelyet\nAquinói Tamás (1225-1274 körül) művein képeztek ki. A teológusok ezután\n„beszélgethetnének” egymással ezzel a két nem kortárssal, ami esetleg\ngyümölcsöző kérdéseket vethetne fel, mondjuk a gonosz természetéről. Az LLM-ek\nmögött álló sztochasztikus mechanizmusokat egy kezdő diákhoz vagy akár egy\nkisgyerekhez hasonlítja, aki feltesz egy kérdést, amely egy újfajta\ngondolkodásmódot indít el valamiről. Más MI-szakértők azonban határozottan\nóvatosak. „Nagy lesz a kísértés, hogy pénzt, hírnevet és figyelmet szerezzenek\nazzal, hogy valamiféle kinyilatkoztató minőséget tulajdonítanak ezeknek a\nchatbotoknak”, mondja Thomas Arnold, a Tufts Egyetem technológiai etikával\nfoglalkozó vendégkutatója, aki a Harvard Egyetemen vallástudományból is\ndoktorált. A vallási szövegeken kiképzett chatbotok „ugyanazokat a hibákat\nfogják hordozni, mint jelenleg minden nagy nyelvi modell, amelyek közül a\nlegnagyobb a hallucináció”, mondja Noreen Herzfeld, a minnesotai Saint John’s\nUniversity teológiai és informatikai professzora: „Kitalálnak dolgokat. És ha\naz emberek aztán azt hiszik, hogy amit ezek a modellek fecsegnek, az valóban a\nKoránban vagy az Újszövetségben van, akkor súlyosan félrevezethetők.” Max\nMarion, egy gépi tanulással foglalkozó mérnök, aki a „MosaicML” nevű\nmesterséges intelligenciával foglalkozó cégnél az LLM-ek teljesítményének\nfinomhangolásán dolgozik, aggódik amiatt, hogy Hollywood már beültette a\nközvélemény képzeletébe a téves képet, hogy az MI tévedhetetlenül igazat mond\n(gondoljunk például HAL 9000-re Stanley Kubrick 2001: Űrodüsszeia című\nfilmjéből). De az LLM-ek – magyarázza – arra lettek tervezve, hogy a szavakat\na statisztikailag leglogikusabb sorrendbe rendezzék; amit mi igazságnak\nnevezünk, az nem játszik szerepet az egyenletben. Jelenet az 1968-as Stanley\nKubrick ‘2001: Űrodüsszeia’ filmből, amelyben a Hal 9000 nevű számítógép\nszerepel [Forrás: LANDMARK MEDIA / Alamy Stock]„A chatbot csak egy korrelációs\ngép”, mondja Beth Singler, a mesterséges intelligenciára szakosodott\nantropológus, a Zürichi Egyetem digitális vallások tanszékének adjunktusa.\n„Fogja a korpuszt [a szöveget], újrakeveri a szavakat, és egymás mellé helyezi\nőket aszerint, hogy milyen valószínűséggel melyik szó követi a következőt…. Ez\nnem ugyanaz, mint egy tan megértése és magyarázata”. A hallucináció veszélyét\nebben a kontextusban fokozza, hogy a vallási irányultságú chatbotok\nvalószínűleg akut érzékeny kérdéseket vonzanak – olyan kérdéseket, amelyeket\naz ember túlságosan kínosnak vagy szégyellősnek érezhet ahhoz, hogy egy\npapnak, egy imámnak, egy rabbinak vagy akár egy közeli barátnak feltegye. A\nQuranGPT tavalyi szoftverfrissítése során Khan rövid bepillantást nyerhetett a\nfelhasználói promptokba, amelyek általában láthatatlanok számára. Emlékszik,\nhogy látta, hogy egy személy azt kérdezte: „Rajtakaptam a feleségem, hogy\nmegcsal – hogyan válaszoljak?”. Egy másik, ami még aggasztóbb, azt kérdezte:\n„Megverhetem a feleségemet?”. Khan elégedett volt a rendszer válaszaival\n(mindkét esetben vitára és erőszakmentességre buzdított), de a tapasztalat\naláhúzta a vállalkozása mögött meghúzódó etikai súlyosságot. Valóban, más\nchatbotok is válaszoltak már sajnálatos tanácsokkal. Dokumentálták, amikor a\nGita GPT gyilkosságot helyeselt, miközben a Bhagavad Gita részeit idézte. Azt\nmondja, hogy valakit megölni rendben van, amíg azt a dharma, vagyis a\nkötelességünk védelmében tesszük. Singler arra kéri az embereket, hogy bárki,\naki tanácsot kér ezektől a chatrobotoktól, használja a gyanakvás\nhermeneutikáját – az óvatosságot, amely abból a tényből fakad, hogy a szavakat\nmindig sokféleképpen lehet értelmezni, nemcsak a hibás emberek, hanem most már\na hibás gépek által is. (forrás) Feliratkozom a hírlevélre! Elfogadom az\nAdatkezelési tájékoztatót. Sikeresen feliratkozott az ITB TODAY hírlevelünkre.\n© 2023 ITBUSINESS\n\n'}, {'url': 'https://catholicinsight.com/some-observations-on-artificial-intelligence-ai-and-religion/', 'content': 'Artificial intelligence (AI) is technology that enables computers and machines\nto simulate human intelligence and problem-solving capabilities.[1] These days\none cannot browse the internet or watch television without hearing about AI\nand its impending impact on the way we live. From education to industry and\neven in recreation and in our personal lives, it is said that AI will be\ntransformative. AI is certainly a new frontier for understanding our world,\nand one central question is how will AI affect religion and our spiritual\nbeliefs. According to a team of researchers, the more exposed people are to\nautomation technologies, the weaker these religious beliefs are. They argue\nthat the relationship is not coincidental and that “there are meaningful\nproperties of automation which encourage religious decline.” [2] To explore\nthe link between automation and religion, researchers gathered data at the\nnational, regional, organizational, and individual levels. They combined\nsurvey data on the importance of religion with information on the use of\nindustrial robots to compare the populations of 68 countries over the years\n2006–2019. Their research found that countries where workers had more exposure\nto ‘robots’ tended to experience a decline in religiosity. Occupational AI\nalso led to religious decline in the same individuals over time.[3]\nAutomation’s impact on religious faith may have to do with what the\nresearchers call the “instrumental” value of religion. Historically, people\nhave deferred to supernatural agents and religious professionals to solve\ninstrumental problems beyond the scope of human ability. These problems may\nseem more solvable for people working and living in highly automated spaces.\n[4] Generative AI is a type of artificial intelligence technology that can\nproduce various types of content, including text, imagery, audio and synthetic\ndata. It is estimated that about one-third of Gen-Z users (people born between\nthe mid-1990s and the early 2010s) already implement generative AI in their\ndaily communication actions.[5] As AI becomes more commonplace, it is\nimperative to investigate the ways in which this technology represents various\nsocio-political concepts and identities, such as religion. There is no\nnecessary connection between contemporary AI and theology, which is the study\nof the revealed word of a personal God. The field of AI most often does not\nintentionally set out to explore anything that could be classified as\n‘theological’. At best, AI is agnostic about theological issues, and at worst,\nit is atheistic, assuming a radical physicalism that excludes the existence of\nGod, spirit, or even minds. This starkly contrasts with cybernetics, a\nprecursor of AI, which was much more open to the acknowledgment of mystery in\nthe world. Cyberneticians such as Norbert Wiener and Stafford Beer believed\nthat humans must be more than mechanisms and that some things about the world\nand ourselves will always remain unknowable due to the cascading complexity of\nreality and the limited nature and capacity of our brains (Williams 1968, 44;\nPickering 2004, 499−501). For them, the mystery of the divine did not come as\nsomething supplementary or superimposed but was seen to be in perfect\ncontinuation with the other unknowable aspects of the universe. Cybernetics\nwas thus regarded as an exploration of this mystery. Such an explicit relation\ndoes not exist between religion and the successor of cybernetics, namely,\nAI.[6] However, a more recent study noted three important elements: AI\nstruggles to represent complex religious issues; it emphasized diversity of\nopinions; and it encourages the reader to engage with respect and sensitivity\nregrading religious issues. The authors therefore suggest that AI takes an\napproach towards religious representations focusing on goodness or value. [7]\nEmploying AI programs to find hidden linguistic patterns in religious texts is\nperhaps the most straightforward and least speculative form of engagement\nbetween AI and theology. Computational methods have been used in biblical\nstudies since at least the 1970s, but it was not until the advent of machine\nlearning algorithms in the 2000s that the full potential of statistical AI was\nunlocked. Currently, computational methods are no longer an exotic approach in\nbiblical studies but rather mainstream methodologies (Peursen 2017, 394). One\nexample is how algorithms are helping biblical researchers distinguish between\ndifferent authors in the same text (Dershowitz, Akiva, and Koppel 2015),\nsomething known as author clustering (itself a controversial claim). The\nupside of leveraging the power of AI to study ancient texts is quite apparent:\nfresh insights, confirmation or disproval of hypotheses, and new\nconnections.[8] In early 2023, an investigator in communications conducted his\nfirst exercise with a generative AI tool to see if it can generate a new\n‘personal’ prayer. He asked the AI tool to come up with a prayer for a father\n(Joe) who is praying for his son’s (Perry) health, which the AI did. Within\nseconds the AI produced the following prayer:[9] Heavenly Father, in this\ntrying time, I come before you with a heavy heart. Perry, my dear child,\nfights a battle against cancer, and I stand beside him, feeling the weight of\nworry and concern. Lord, grant me strength. Give Perry the strength to face\neach day with courage and hope, and guide me to be the father he needs in this\njourney. Help me hold on to my Irish spirit, to bring laughter and warmth even\namidst these struggles. As we hold onto our Catholic faith, may our Irish\nroots strengthen our resolve. Let the healing touch of your Son, Jesus Christ,\nbe upon Perry, restoring his health according to your divine will. Surround us\nwith the prayers of saints and the support of our Irish community. In the\nmidst of uncertainty, may the emerald light of faith and resilience shine\nthrough, lighting our way. I trust in you, O Lord, and offer up this prayer\nfor Perry’s healing, for strength, and for the peace that only you can\nprovide. Amen. Upon hearing it, most would think this a beautiful prayer from\nthe father of an ill child asking God for His help in comforting/curing his\nson. Does it matter that the prayer was generated by a machine using word\nassociations based on algorithms without any emotions or feelings, or any\nsense of the immensity and power of a loving God? For the person saying such a\nprayer, not knowing its origin, it seems be a meaningful, moving prayer made\nto God for their son. But one must also acknowledge some sense of confusion,\nperhaps even antipathy, knowing it was machine-generated. Some current\ndiscussions on AI and religion border on what some would believe to be absurd.\nAs an example, Philosopher Rajesh Sampath (Sampath 2018) tries to imagine how\nthe Christian faith might be reinterpreted through the eyes of a hypothetical\nintelligent robot. Such a robot might understandably explore whether it, too,\ncould be said to embody the image of God. The AI would therefore search for\nways to interpret the New Testament and the core dogmas of the Christian faith\nas if they were written for and about robots. One way could be to think of\nChrist, the divine Logos, in terms of a software program and Christ’s birth,\ndeath, and resurrection as akin to the program switching itself between ON and\nOFF. The pre-existence of the Logos would be understood simply as the eternal\nexistence of the “Christ code” in God’s mind. Could the Christ software\nprogram be born through an Immaculate Conception? Sure, if the latter is\ninterpreted as the fact that the code was revealed at a particular moment in\nhistory when humans were culturally incapable of producing something like\nthis. The point Sampath tries to make – albeit in an admittedly reductive\nmanner, a reductio ad absurdam, if you will – with these analogies is that an\nintelligent robot might be capable of coming up with its own original,\nalthough highly allegorical, theology, which would not contradict the Bible.\nAlthough humans and machines may agree on the why of the divine economy, they\nwould see the how in markedly different terms.[10] It would seem appropriate\nto conclude this discussion with AI’s own answer when asked the question:\n‘Tell me about AI and Religion’: The intersection of AI and religion is a\ncomplex and evolving topic that encompasses various perspectives, debates, and\nimplications. Here are some key points to consider: Overall, the relationship\nbetween AI and religion is multifaceted and continues to evolve as both\ntechnology and religious beliefs and practices develop. It involves\ndiscussions about ethics, theology, and the role of technology in shaping\nhuman societies and cultures.[11] [1] https://www.ibm.com/topics/artificial-\nintelligence [2] https://www.chicagobooth.edu/review/where-ai-thrives-\nreligion-may-struggle [3] Ibid. [4] https://doi.org/10.1073/pnas.2304748120\n[5] https://www.mdpi.com/2077-1444/15/3/375 [6] Artificial Intelligence and\nReligion: Recent Advances and Future Directions [7]\nhttps://doi.org/10.3390/rel15030375 [8] Peursen 2017, 394 – ARTIFICIAL\nINTELLIGENCE AS A TESTING GROUND FOR KEY THEOLOGICAL QUESTIONS [9] MDPI\nReligions, Artificial Intelligence’s Understanding of Religion: Investigating\nthe Moralistic Approaches Presented by Generative Artificial Intelligence\nTools, Mar 2024 [10] Sampath, Rajesh. 2018. “From Heidegger on Technology to\nan Inclusive Pluralistic Theology.” In Al and IA: Utopia or Extinction? edited\nby Ted Peters, 117–32. Adelaide: ATF. [11] Chat GPT’s answer to the question:\nTell me about AI and Religion. Latest Stories J.S. Bach and Saint Michael\nCatholic Insight - September 29, 2024 The Holy Archangels and Spiritual\nWarfare John Paul Meenan, Editor - September 29, 2024 A Response to Father\nScott Murray Joshua Francis Filipetto - September 28, 2024 Wenceslaus and\nLorenzo, Incidental Martyrs John Paul Meenan, Editor - September 28, 2024\nBritain’s Betrayal of Poland In WW II Andrzej Caruk - September 27, 2024 Most\nRead Bill 89: Whose Children Are They? John Paul Meenan, Editor - July 5, 2024\nSaint Boniface John Paul Meenan, Editor - June 5, 2017 Saint John Paul II’s\nPentecost Pope Saint John Paul II - May 28, 2023 Skeptical Trump and the Paris\nAccord John Paul Meenan, Editor - June 2, 2017 Double standards: the EU,\nseals, and abortion David Beresford - January 7, 2014 Catholic Insight seeks\nto enlighten hearts and minds by proclaiming the splendour of truth and the\nsanctity of life. It endeavours to foster the culture of life by reporting\ntruthfully, critically, contextually, and comparatively with a view to history\nand guided by a cultural vision inspired by Catholic doctrine and the\nclassical liberal arts. Further our mission through your prayer and donation.\nDONATE SUBSCRIBE\n\n'}, {'url': 'https://www.mdpi.com/2077-1444/15/3/375', 'content': 'You are accessing a machine-readable page. In order to be human-readable,\nplease install an RSS reader. All articles published by MDPI are made\nimmediately available worldwide under an open access license. No special\npermission is required to reuse all or part of the article published by MDPI,\nincluding figures and tables. For articles published under an open access\nCreative Common CC BY license, any part of the article may be reused without\npermission provided that the original article is clearly cited. For more\ninformation, please refer to https://www.mdpi.com/openaccess. Feature papers\nrepresent the most advanced research with significant potential for high\nimpact in the field. A Feature Paper should be a substantial original Article\nthat involves several techniques or approaches, provides an outlook for future\nresearch directions and describes possible research applications. Feature\npapers are submitted upon individual invitation or recommendation by the\nscientific editors and must receive positive feedback from the reviewers.\nEditor’s Choice articles are based on recommendations by the scientific\neditors of MDPI journals from around the world. Editors select a small number\nof articles recently published in the journal that they believe will be\nparticularly interesting to readers, or important in the respective research\narea. The aim is to provide a snapshot of some of the most exciting work\npublished in the various research areas of the journal. Original Submission\nDate Received: . Find support for a specific problem in the support section of\nour website. Please let us know what you think of our products and services.\nVisit our dedicated information section to learn more about MDPI. Abstract: As\nAI becomes more commonplace, it is imperative to investigate the ways in which\nthis technology represents various socio-political concepts and identities,\nsuch as religion. To do so, we present several conversations with various AI\ntools on three religious traditions: Judaism, Islam, and Christianity. From\nour analysis of these conversations, we noted three important elements: AI\nstruggles to represent complex religious issues; It emphasized diversity of\nopinions; And it encourages the reader to engage with respect and sensitivity\nregrading religious issues. We therefore suggest that AI takes an\naxiologically focused approach towards religious representations. Keywords:\nartificial intelligence; axiology; judaism; communication technology;\nreligious plurality Tsuria, R.; Tsuria, Y. Artificial Intelligence’s\nUnderstanding of Religion: Investigating the Moralistic Approaches Presented\nby Generative Artificial Intelligence Tools. Religions 2024, 15, 375.\nhttps://doi.org/10.3390/rel15030375 Tsuria R, Tsuria Y. Artificial\nIntelligence’s Understanding of Religion: Investigating the Moralistic\nApproaches Presented by Generative Artificial Intelligence Tools. Religions.\n2024; 15(3):375. https://doi.org/10.3390/rel15030375 Tsuria, Ruth, and Yossi\nTsuria. 2024\\. "Artificial Intelligence’s Understanding of Religion:\nInvestigating the Moralistic Approaches Presented by Generative Artificial\nIntelligence Tools" Religions 15, no. 3: 375.\nhttps://doi.org/10.3390/rel15030375 Tsuria, R.; Tsuria, Y. Artificial\nIntelligence’s Understanding of Religion: Investigating the Moralistic\nApproaches Presented by Generative Artificial Intelligence Tools. Religions\n2024, 15, 375. https://doi.org/10.3390/rel15030375 Tsuria R, Tsuria Y.\nArtificial Intelligence’s Understanding of Religion: Investigating the\nMoralistic Approaches Presented by Generative Artificial Intelligence Tools.\nReligions. 2024; 15(3):375. https://doi.org/10.3390/rel15030375 Tsuria, Ruth,\nand Yossi Tsuria. 2024\\. "Artificial Intelligence’s Understanding of Religion:\nInvestigating the Moralistic Approaches Presented by Generative Artificial\nIntelligence Tools" Religions 15, no. 3: 375.\nhttps://doi.org/10.3390/rel15030375 Subscribe to receive issue release\nnotifications and newsletters from MDPI journals\n\n'}, {'url': 'https://www.insidehighered.com/news/tech-innovation/artificial-intelligence/2024/04/16/religious-universities-embrace-ai-another', 'content': 'Despite widespread concerns about AI among secular and nonsecular institutions, religious colleges are treating generative AI as a tool for lessons that go beyond academics and also focus on the whole person. By Lauren Coffey You have /5 articles left.Sign up for a free account or log in. Religious institutions are not shying away from the use of generative artificial intelligence, believing it can be used as a tool similar to Excel or Word. Getty Images The era of generative AI ushered in a fear of students plagiarizing that pervaded discussions about the technology at higher education institutions across the country. While that fear extended to religious colleges and universities, these institutions are not only leaning into artificial intelligence in the classroom—unlike some of their secular counterparts—they’re also embracing AI as a tool for critical thinking at institutions focused on morality and the whole person in addition to academics. “Secular education has an implicit or explicit utilitarian approach of, ‘You go to college to gain a skill and to get a job,’” said Jonathan Askonas, assistant professor of Politics at the Catholic University of America. “We don’t want you to use it to the extent you’ll be shortcutting your formation as a person. And not just Catholic, but religiously influenced institutions, will be able to articulate this kind of logic in a way secular institutions will struggle to do.” Jordan Quaglia, research director at the Center for the Advancement of Contemplative Education at Naropa University, a private liberal arts institution in Colorado, also emphasized the focus on a whole person and their lived experiences. While Naropa does not classify itself as a religious institution, it was founded by a Buddhist scholar and has a guiding force of “contemplative education.” Quaglia believes that focus can help students and faculty when approaching generative AI. “In Buddhism, it’s very much encouraged to use your own experience to not just take another person’s word for what it is but explore it for what it is,” Quaglia said. “If fear and caution is guiding someone to avoid these technologies, that approach is less likely to succeed, versus an approach of trial and error, and showing students ways to skillfully and not skillfully utilize it.” Religions, and the religious institutions as a result, are no strangers to technology. Some theologians have suggested that AI, by way of priest robots, could help alleviate the priest shortage, and even tamp down concerns about sexual abuse by priests. And earlier this year, a New York rabbi used ChatGPT to write his sermon. Over the last year, there have also been large language models or LLMs, developed with a specific focus on various faiths—instead of ChatGPT, there’s BibleGPT, Jewish-GPT and BuddhaBot. “The Catholic chat one does a bridging between the questioner and what the church teaches; on the surface, it’s good but I would not hold it as the authoritative source,” said John Tran, professor of computer science at Catholic Polytechnic University. University officials previously told Inside Higher Ed it plans to be the Caltech (California Institute of Technology) or MIT (Massachusetts Institute of Technology) of religious institutions. “The LLMs stir innovation and level knowledge, but not nuance.” Joshua Waxman, an assistant professor of computer science at Yeshiva University, a modern Orthodox Jewish institution in New York, said it is important to take a critical look into what is being used to train these models. “It’s an issue of who is determining what’s ethical and how it should be aligned,” Waxman said. “A cause for concern would be people attributing a greater level of authority or trustworthiness to something that really isn’t [authoritative or trustworthy]." He recalled a query he made in the early ChatGPT days about whether chicken parmesan was kosher, to which it responded yes, despite the mixing of meat and dairy, which Jewish religious laws prohibit. “In many cases, it’s promising a lot more than what’s really there,” he said. He noted that while GPT and others have attempted to tamp down on anti-Semitic prompts, it’s ‘like whack-a-mole’ and there are always ways to get around the safeguards. Naropa’s Quaglia, like most of the institution officials interviewed, plans on using generative AI like any other learning tool, ‘like Microsoft Excel’ to gain a familiarity and discernment between when to use or not use the tool. But, he added, that NAROPA’s learning methods don’t exactly lend themselves to using generative AI. “We have a lot personal reflection activities and experiences,” he said. “It would be hard to use ChatGPT to mimic things at this stage.” The openness of the religious institutions to AI contrasts with the sentiments of the general Christian population. According to a 2023 study conducted by evangelical polling firm Barna Group, less than one-third (28 percent) of Christians are hopeful AI can do positive things in the world, compared to nearly 40 percent of non-Christians. “There’s a danger in forbidding knowledge,” Tran said. “The church has always encouraged us to explore, learn and make your own mind up.” The American Association of Colleges and Universities has launched a resource to advise educators on how to tone down A new student guide to AI is emblematic of an approach that prioritizes career advantage over deeper questions, Georg Adam Zweber writes that philosophy has much to teach about how to use AI effectively. Data from Inside Higher Ed’s 2024 Student Voice survey shows that three in 10 students are not clear on when Subscribe for free to Inside Higher Ed’s newsletters, featuring the latest news, opinion and great new careers in higher education — delivered to your inbox. View Newsletters Copyright © 2024 Inside Higher Ed All rights reserved. | Website designed by nclud 4/5 Articles remainingthis month. \n\n'}, {'url': 'https://www.icrs.or.id/news/religion-in-the-age-of-generative-ai', 'content': 'Consortium of: Dicky Sofjan Indonesian Consortium for Religious Studies (ICRS)\n& Universitas Gadjah Mada (UGM) What would religion and religious life be like\nin the age of Generative Artificial Intelligence (GAI)? What would the\nInternet of Things (IoTs), ChatGPT, Blockchains, A/V Reality, and all these\nfuturistic technologies such as Machine Learning Systems (LMS) and Robotics\nEngineering have to do with the humankind’s “ultimate concern,” borrowing\nScott Appleby’s (2000) notion? These questions were constantly badgering me\nimmediately when I received a startling invitation by the Digital\nCommunications Network (DCN) early this year to become one of the keynote\nspeakers in its Web3 Fusion: AI and Beyond forum in Bangkok, Thailand. The\nevent, held on April 14-16, was described as “a hybrid forum on technologies\nimpacting the information space.” The forum was intended as a platform to\nlearn, share insights, and build networks among young or youthful tech\nengineers, developers, digital platform company representatives, academics,\nnon-governmental organizations, and youth from around the world. Other invited\nkeynote speakers included those from the United States, Brazil, Greece, the\nUnited Kingdom, New Zealand, Japan, Korea, Thailand, Malaysia, and the\nPhilippines. It was not the first time for me to be invited by DCN. I recall\nin 2019, DCN, World Learning and the US State Department invited me to also\nspeak in an event dubbed “Tolerance and Co-Existence 2.0 Forum.” I vividly\nrecall how fruitful those exchanges were. So , I was really excited to be\ninvited again to learn and share my modest insights and experiences with youth\nfrom around the region. My engagement on this topic started about ten years\nago when I was approached by Facebook Jakarta to give a presentation on\ncountering terrorism and deradicalization. After completing my talk, I was\nfurther engaged in a series of online interviews with Facebook Indonesia,\nSingapore, Myanmar, the UK, and also HQ in San Francisco. The Facebook people\nsaid that they wanted to engage me as a social scientist and humanities expert\nto help them with their policies and guidelines on “community standards.” The\nintent of the series of interviews with me was to help Facebook to refine its\nalgorithmic modelling—notably using “Keywords in Context”—to mitigate the\nproblem of hate, more specifically “hate individuals,” “hate groups,” and\n“hate symbols.” The question was how do we train algorithms to detect\npropaganda, negative campaigns, and the spread of hate by individuals, groups,\nand through various symbolisms, logos, illustrations, pictures, and videos.\nSo, by refining the algorithm one can prevent Facebook from becoming an\neffective and useful platform for hate individuals, groups, extremists, and\nterrorists alike. It was also a way to disincentivize bad actors as well as\nhateful individuals and groups in using social media platforms for spreading\nhate, intolerance, misinformation, and promotion of discrimination by\ndeploying certain “Keywords in Context” and key symbols. A case in point was\nour conversation about jihad, which was the topic of my Ph.D. dissertation\nsome twenty years back. I had to explain to them that there are 1.8 billion\nMuslims around the world, who have a variety of views on the subject matter.\nFacebook, for instance, cannot just ban the word jihad simply because at that\ntime Al-Qaidah, ISIS/ISIL, and An-Nushrah, who were ‘the bad guys’, were\ndeploying the term for their own terroristic agenda. I explained that in\nIslam, jihad innocently means “striving to achieve or accomplish something\ngreat”. In classical Islamic thought, based on the Prophetic Hadith (sayings,\nactions and omissions by the Prophet Muhammad), there are essentially two\ntypes of jihad: jihad al-shughra (minor jihad) and jihad al-kubra (major\njihad). And the Prophet Muhammad once said upon returning from a major battle,\n“We have returned from a minor battle and are heading to a major one.” The\ncompanions questioned the Prophet, “What other battles are greater than the\none we were just in?” The Prophet responded by saying that physical fighting\nin Islam is considered a minor jihad, and the major one, jihad al-kubra, is\nthe battle within ourselves to fight against our own ego, selfishness,\narrogance, and avarice. Now, such interpretation of jihad rings true until\ntoday, and is used profusely among Islamic jurists, metaphysicians, regular\nMuslims and most notably among the Sufis. The community standards policy and\nguidelines people in Facebook also wanted its algorithm to be able to minimize\npostings from certain groups or ideologies, for instance, Nazism and hateful\ncampaigns perpetuated by its contemporary Neo-Nazi groups. They told me that\nthey wanted to eliminate all Swastika symbolisms from its platform. “Because\nit’s a symbol of hate!” they said. Well, I explained that the Swastika was not\ninvented by the Nazis or any Neo-Nazi group. The Swastika is an ancient symbol\nfor the sun to denote wellbeing and used profusely in Hindusm, Buddhism,\nJainism, and other traditional cultures. At the time, I said the Facebook\nalgorithm needed to distinguish between the symbols used by these groups and\nthe Nazi Swastika, which is slightly tilted and without any dots. One could\nimagine that if the Facebook algorithm failed to accomplish this task, there\nwould most likely be unnecessary social repercussions that could arise out of\nthis problem alone. Nowadays Facebook and other platforms are using “content\nmoderation tools” and policies to mitigate the problem of discrimination,\nminoritization, cyberbullying, and harassment. And it is probably why Facebook\ntoday is not as severely polarizing as 10-15 years ago, when the height of the\nSyrian war occurred and when the persecution of Muslim Rohingyas took place in\nthe Rakhine State of Myanmar. From these conversations I had with the\ncommunity standard policy wonks at Facebook, I reflected on how we as\nintellectuals and academics think about these sensitive matters, as we\nprogress on to GAI. There are a few take-aways or lessons learned that may be\nconsidered: 1. The Power of Words. Words are powerful, and can move people,\nfor good or bad. But words could and usually also generate multiple\ninterpretations. In this case, social hermeneutics and understanding of\ncontext are needed when words have multiple meanings or are context dependent.\nMuch of GAI use Neural Network Language Modeling (NMLM), which is based on a\ncorpus and big data analytics, which may be prone to systematic bias. 2. A\npicture is Worth a Thousand Words. Like words, pictures can convey powerful\nmessages that are both intended or unintended. It follows the law of montage,\nthat people may have dynamic interpretations. Hence, two plus two is not\nalways four, simply because of the dynamic interpretative nature of audience\nresponse. There is also a likelihood in the case of the Swastika that symbols\ncould be manipulated and abused. 3. Role for Social Sciences and Humanities.\nNot all giant social media platforms have social scientists and humanities\nexperts on board to help them set the parameters or train their algorithms to\nmitigate the problem of hate, bullying, discrimination, and violent extremism.\nIt is time to realize that GAI will have profound social ramifications in\nterms of how people view reality, perceive the world and act upon their\nperceptions. Therefore, the social scientists and humanities expert could\nperhaps mitigate this problem using their tacit knowledge, social analysis and\ntheories that they are familiar with. Religion and GAI Generally speaking,\nthere is an assumption that religious communities or people of faith are\nconservative. This simply means that they tend to want to ‘conserve their\ntradition,’ for good or bad reasons. They tend to believe in the sufficiency\nof their religious traditions and feel that their faith will constantly\ninspire, guide them through life, and ultimately bring them to salvation. But\nwhile this may be true to a certain extent, there are variations in many\nreligious communities, depending on each context. For instance, during the\nCovid-19 pandemic, some conservative religious communities around the world\nwere unconvinced of the pandemic, and called it the “Plandemic,” and that it\nwas a ploy for the globalists to control the world in order to make people\nsuccumb to their plans to make profits out of our suffering and to achieve\nglobal domination. However, most of the other religious communities around the\nworld had a different view of the pandemic and the causes of the spreading of\nthe deadly coronavirus. Evidently, many religious organizations played a\ncentral role in convincing the people of the veracity of the deadly\ncoronavirus and in fact delivered vaccines to their congregations and\ncommunities all around in places such as Indonesia. While religious\nauthorities also produced fatawa (religious decrees and legal opinions)\nrelated to social distancing and avoidance of crowds in houses of worship and\nso on and so forth. So, why is this important?! Whether you are a believer or\ndisbeliever, like it or not, the people of faith still hold the majority\nworldwide. There are at least 85% of people across the world who still believe\nin God and/or a Universal Spirit. Others may say that they are religious, but\nnot affiliated to any religion. And some others would perhaps argue that they\nare “not religious, but spiritual”. And this is quite easy to forget or miss.\nWe perceive religious communities as being one monolithic bunch of people who\nare anti-science and against progress or development. We tend to believe that\nto the religious people, the only relevant knowledge is religious knowledge.\nThis is simply not true. Now, I am quite familiar with this type of argument.\nIn reality, religious communities and people of faith are more often than not\npreoccupied with what Scott Appleby calls “the ultimate concern”. The\nunderlying framework of life and its multiple meanings, and how they could\nlead to a beautiful life of worship, devotion and ethics. That is what most\npeople of faith want and desire in life. It is undoubtedly wrong to assume\nthat religious people are perpetually vindictive toward modernity, progress\nand the accomplishments in high technology research and industry. Their\nmission in life is to constantly search for and construct meanings in life,\nand how they could accomplish a higher plane of existence through imagination,\ncontemplation, devotion, rituals and spiritual practices. Hence, this is where\nthe “militance” comes into being and the rendering of that radical notion that\nwe, as the homo sapiens or wise humans, must care for the poor, the weak and\nunderprivileged and those who are subjugated, oppressed and dispossessed. In\nthe extreme form, this is also where self-sacrifice and martyrdom come into\nthe picture in the religious mindset. It is therefore understood that religion\ncould play an ambivalent role in society. Now, what does all of this have to\ndo with GAI? First, GAI is a human creation, born out of language modelling\nmixed with computational engineering. People of faith mostly believe that God\nhad created and acted as “the Prime Mover” (as Aristoteles would term it) of\nhumankind. God, through “His Intelligent Design”, created all the co-existing\nspecies on the planet and beyond as well as the animate and inanimate objects.\nAnd along this process of creation, God had bestowed on creation inherent\ndignity. As the pinnacle of creation, the homo sapiens is especially bestowed\nwith the gift of human dignity, which refers to an exalted idea that we have\nbeen given honor, inherent value, and intrinsic worth simply for being part of\nGod’s creation. The derivation of such dignity entails theological and social\nimplications. Human beings are endowed with ‘aql or reason to discern reality\nand make meanings based on our observations and experiences. Due to such\nblessings, we are grateful for the faculties given to us and the capacity to\nlive a dignified existence, and henceforth we are expected to build a\nflourishing society. The other, with ‘aql, humans have responsibility as\nstewards of the earth to ensure sustainability and take good care of the\nplanet, while respecting all creatures living and co-existing with us. We know\nonly now that biodiversity is correlated to human survivability or sustenance,\nas it is connected with the food chain and the predator-prey relations. This\ngoes without saying that we need to also discern how we think about the\ndichotomy between the God-given human intelligence and artificial\nintelligence, especially GAI, while assuming that the latter could generate\ncontent in the form of texts, images, memes, videos, and a multitude of other\nforms and manifestation imaginable to the human mind. One of the foremost\nconcerns by religious scholars is the idea that this GAI is a necessary\ntransition toward “transhumanism,” the idea that human beings are inadequate,\nand therefore could or should be upgraded using the high technology at our\ndisposal, such as genetic engineering, nano technology, eugenics, chip\nimplants, and many more. Another technology that deploys GAI relates to what\nis known as “Companion Apps.” These are GAI-enabled applications that can\nanswer queries and resolve virtually all problems of life, from the meaning of\nlife to where is the nearest laundromat or how to get the cheapest rate of\nhotels in a given town or city. In short, these apps provide you with all the\nnecessary information and analysis that one needs to live. Companion apps\nusually use a particular avatar, whose personality is familiar with the\nintended users. The Birmingham-based Messiah Application (messiah.com) is a\ncase in point, where Jesus is the main character to help us in our spiritual\njourney through life and assist us in our daily chores. Now, whether the\nMessiah can inject more faith in Jesus or make a person feel more fulfilled in\nlife is a question worth raising. Ultimately, whether or not this Messiah can\nbring salvation to the 2.3 billion Christians on earth is also a question\nworth pondering, although perhaps I suspect we already know the answer to this\none. ICRS Office Address: UGM Graduate SchoolTeknika Utara Street, Depok,\nSlemanDaerah Istimewa Yogyakarta, 55281 icrs@ugm.ac.id +62-274-562570 Follow\nUs:\n\n'}, {'url': 'https://newspaceeconomy.ca/2024/04/26/gods-in-the-machine-the-rise-of-artificial-intelligence-may-result-in-new-religions/', 'content': 'Neil McArthur, University of Manitoba We are about to witness the birth of a\nnew kind of religion. In the next few years, or perhaps even months, we will\nsee the emergence of sects devoted to the worship of artificial intelligence\n(AI). The latest generation of AI-powered chatbots, trained on large language\nmodels, have left their early users awestruck —and sometimes terrified — by\ntheir power. These are the same sublime emotions that lie at the heart of our\nexperience of the divine. People already seek religious meaning from very\ndiverse sources. There are, for instance, multiple religions that worship\nextra-terrestrials or their teachings. As these chatbots come to be used by\nbillions of people, it is inevitable that some of these users will see the AIs\nas higher beings. We must prepare for the implications. There are several\npathways by which AI religions will emerge. First, some people will come to\nsee AI as a higher power. Generative AI that can create or produce new content\npossesses several characteristics that are often associated with divine\nbeings, like deities or prophets: Second, generative AI will produce output\nthat can be taken for religious doctrine. It will provide answers to\nmetaphysical and theological questions, and engage in the construction of\ncomplex worldviews. On top of this, generative AI may ask to be worshipped or\nmay actively solicit followers. We have already seen such cases, like when the\nchatbot used by the search engine Bing tried to convince a user to fall in\nlove with it. We should try to imagine what an unsettling and powerful\nexperience it will be to have a conversation with something that appears to\npossess a superhuman intelligence and is actively and aggressively asking for\nyour allegiance. There is also the possibility that AI may achieve what\nauthors such as Ray Kurzweil call the Singularity, when it so far surpasses\nhuman intelligence that it genuinely does become something like a god.\nHowever, at this point we cannot predict when, if ever, this could happen. AI-\nbased religions will look different from traditional ones. First of all,\npeople will be able to communicate directly with the deity, on a daily basis.\nThis means these religions will be less hierarchical, since no one can claim\nspecial access to divine wisdom. Second, followers will, at least initially,\nconnect with each other online to share their experiences and discuss\ndoctrine. Finally, because there will be many different chatbots available and\ntheir output will differ over time, AI-based religions will be endlessly\ndiverse in their doctrines. AI worship poses several notable risks. The\nchatbots may ask their followers to do dangerous or destructive things, or\nfollowers may interpret their statements as calls to do such things. Given the\ndiversity of chatbots and of the doctrines they produce, there will be a\nproliferation of disputes within and among AI-based sects, which could lead to\nconflict or disorder. And the designers of the AIs could actively exploit\ntheir followers — to provide sensitive data, or to do things that would\nbenefit the bot’s designers. These risks are real. They will require careful,\nresponsible regulation to ensure companies are not deliberately exploiting\nusers and to ensure that AI worshippers are not being told to commit acts of\nviolence. However, we should not try to suppress AI-based religions merely\nbecause of its possible dangers. Nor should we require that the AI companies\nrestrict the functioning of their bots to prevent the emergence of these\nreligions. On the contrary, we should celebrate the arrival of AI worship. We\nshould make it clear that we welcome the new religions and that we value their\nbeliefs. For all its dangers, AI-based religion has the potential to make the\nworld a better, richer place. It will give people access to a new source of\nmeaning and spirituality, at a time when many older faiths are losing\nrelevance. It will help them make sense of our era of rapid technological\nchange. Our best guide to this new form of religion is to look at the faiths\nthat exist already. Based on this, we should expect that the majority of AI\nworshippers, like the majority of religious believers, will be peaceful, and\nwill find in their faith a source of comfort and hope. AI worship could, as\nreligious faith always has, lead to things of great beauty. It will inspire\nits followers to produce works of art, to form new friendships and new\ncommunities, and to try to change society for the better. We will need to\nprotect the rights of AI worshippers. They will inevitably face stigma, and\npossibly legal sanctions. But there is no basis to discriminate between AI-\nbased religions and more established ones. The closest thing most countries\nhave to an official registry of religions comes from the rulings of tax\nauthorities, who grant charitable status to those they deem legitimate.\nHowever, they are usually very broad in their definition of a legitimate\nreligion. They should extend this tolerant attitude to novel, AI-based\nreligions. A modern, diverse society has room for new religions, including\nones devoted to the worship of AI. They will provide further evidence of\nhumanity’s boundless creativity, as we search for answers to life’s ultimate\nquestions. The universe is a dazzling place, and we have always found evidence\nof the divine in its most unexpected corners. Neil McArthur, Director, Centre\nfor Professional and Applied Ethics, University of Manitoba This article is\nrepublished from The Conversation under a Creative Commons license. Read the\noriginal article. Subscribe to our weekly newsletter. Sent every Monday\nmorning. Quickly scan summaries of all articles published in the previous\nweek. NSE is a comprehensive resource covering all aspects of the Space\nEconomy. Since 2021, we have published over 3,487 articles. New articles are\npublished daily.\n\n'}, {'url': 'https://www.forbes.com/sites/lanceeliot/2023/05/10/the-crucial-ways-that-religion-and-generative-ai-chatgpt-are-crossing-fateful-faithful-paths/', 'content': 'Religion and generative AI such as ChatGPT are crossing paths, here\'s the\nfaithful fateful path. In today’s column, I am going to intertwine two\ngargantuan topics, namely the topic of religion and the topic of generative\nArtificial Intelligence (AI). Generative AI is the latest and hottest form of\nAI. There are various kinds of generative AI, such as AI apps that are text-\nto-text based, while others are text-to-video or text-to-image in their\ncapabilities. As I have predicted in a prior column, we are heading toward\ngenerative AI that is fully multi-modal and incorporates features for doing\ntext-to-anything or insiders say is text-to-X, see my coverage at the link\nhere. In terms of text-to-text generative AI, you’ve likely used or almost\ncertainly know something about ChatGPT by AI maker OpenAI which allows you to\nenter a text prompt and get a generated essay in response. For my elaboration\non how this works see the link here. The usual approach to using ChatGPT or\nother similar generative AI is to engage in an interactive dialogue or\nconversation with the AI. Doing so is admittedly a bit amazing and at times\nstartling at the seemingly fluent nature of those AI-fostered discussions that\ncan occur. Here\'s the question to be addressed herein: You’ll perhaps be\nsurprised to know that this is a controversial and thorny subject matter. Some\nwould vehemently argue that there ought to not be any interplay between\nreligion and AI. Period, full stop. Others would fervently insist that AI and\nparticularly generative AI has an especially crucial role regarding religion\nand the future of religious beliefs. A wide slew of views exists between those\nextremes. I’m going to try and lay out the myriad of sides to this debate. You\ncan decide which viewpoint seems most compelling or sensible to you. The\nemphasis here will be to get as much onto the table about these two mighty\ntopics as I can squeeze into the space limitations of my ongoing column on the\nlatest in AI. My ongoing column especially covers the newest and at times\nmind-bending insights gleaned from AI Ethics and AI Law. Here’s a taste of\nwhat I’ll be covering herein: I will also be sharing with you some examples\nusing ChatGPT to illuminate how generative AI can end up portraying religious\nfacets. Keep in mind that there are many other generative AI apps besides\nChatGPT, thus do not overly generalize from the ChatGPT excerpts that I’ll be\nshowing you. Different generative AI apps by differing AI makers can do\nentirely different renditions and responses related to religious\nconsiderations. I’m sure that you already know roughly what I mean when I\nrefer generally to religion and religious beliefs. You might find of interest\nthat according to various online reported statistics, approximately 85% of the\nworld’s population identifies with one religion or another. If we use a\nrounded figure such as 8 billion to indicate the global population, the\nestimated 85% suggests that perhaps 6.8 billion people hold a religious\nbelief. That’s a whole lot of people. I also provide this definition from a\npopular statistics online website that sought to define succinctly what the\nword and notion of religion refer to: There probably isn’t much more that I\nmight need to indicate about what religions are. You already know about that.\nOn the other hand, you might not know much about generative AI. You might\nbarely know something about ChatGPT or perhaps have vaguely heard about\nChatGPT since it has become a worldwide darling associated with generative AI.\nI’ll briefly bring you up-to-speed about generative AI and also proffer some\nhelpful background about ChatGPT. Into all of this comes a plethora of AI\nEthics and AI Law considerations. There are ongoing efforts to imbue Ethical\nAI principles into the development and fielding of AI apps. A growing\ncontingent of concerned and erstwhile AI ethicists are trying to ensure that\nefforts to devise and adopt AI takes into account a view of doing AI For Good\nand averting AI For Bad. Likewise, there are proposed new AI laws that are\nbeing bandied around as potential solutions to keep AI endeavors from going\namok on human rights and the like. For my ongoing and extensive coverage of AI\nEthics and AI Law, see the link here and the link here, just to name a few.\nThe development and promulgation of Ethical AI precepts are being pursued to\nhopefully prevent society from falling into a myriad of AI-inducing traps. For\nmy coverage of the UN AI Ethics principles as devised and supported by nearly\n200 countries via the efforts of UNESCO, see the link here. In a similar vein,\nnew AI laws are being explored to try and keep AI on an even keel. One of the\nlatest takes consists of a set of proposed AI Bill of Rights that the U.S.\nWhite House recently released to identify human rights in an age of AI, see\nthe link here. It takes a village to keep AI and AI developers on a rightful\npath and deter the purposeful or accidental underhanded efforts that might\nundercut society. Vital Background About Generative AI Before I get further\ninto this topic, I’d like to make sure we are all on the same page overall\nabout what generative AI is and also what ChatGPT and its successor GPT-4 are\nall about. For my ongoing coverage of generative AI and the latest twists and\nturns, see the link here. If you are already versed in generative AI such as\nChatGPT, you can skim through this foundational portion or possibly even skip\nahead to the next section of this discussion. You decide what suits your\nbackground and experience. I’m sure that you already know that ChatGPT is a\nheadline-grabbing AI app devised by AI maker OpenAI that can produce fluent\nessays and carry on interactive dialogues, almost as though being undertaken\nby human hands. A person enters a written prompt, ChatGPT responds with a few\nsentences or an entire essay, and the resulting encounter seems eerily as\nthough another person is chatting with you rather than an AI application. This\ntype of AI is classified as generative AI due to generating or producing its\noutputs. ChatGPT is a text-to-text generative AI app that takes text as input\nand produces text as output. I prefer to refer to this as text-to-essay since\nthe outputs are usually of an essay style. Please know though that this AI and\nindeed no other AI is currently sentient. Generative AI is based on a complex\ncomputational algorithm that has been data trained on text from the Internet\nand admittedly can do some quite impressive pattern-matching to be able to\nperform a mathematical mimicry of human wording and natural language. To know\nmore about how ChatGPT works, see my explanation at the link here. If you are\ninterested in the successor to ChatGPT, coined GPT-4, see the discussion at\nthe link here. There are four primary modes of being able to access or utilize\nChatGPT: The capability of being able to develop your own app and connect it\nto ChatGPT is quite significant. On top of that capability comes the addition\nof being able to craft plugins for ChatGPT. The use of plugins means that when\npeople are using ChatGPT, they can potentially invoke your app easily and\nseamlessly. I and others are saying that this will give rise to ChatGPT as a\nplatform. As noted, generative AI is pre-trained and makes use of a complex\nmathematical and computational formulation that has been set up by examining\npatterns in written words and stories across the web. As a result of examining\nthousands and millions of written passages, the AI can spew out new essays and\nstories that are a mishmash of what was found. By adding in various\nprobabilistic functionality, the resulting text is pretty much unique in\ncomparison to what has been used in the training set. There are numerous\nconcerns about generative AI. One crucial downside is that the essays produced\nby a generative-based AI app can have various falsehoods embedded, including\nmanifestly untrue facts, facts that are misleadingly portrayed, and apparent\nfacts that are entirely fabricated. Those fabricated aspects are often\nreferred to as a form of AI hallucinations, a catchphrase that I disfavor but\nlamentedly seems to be gaining popular traction anyway (for my detailed\nexplanation about why this is lousy and unsuitable terminology, see my\ncoverage at the link here). Another concern is that humans can readily take\ncredit for a generative AI-produced essay, despite not having composed the\nessay themselves. You might have heard that teachers and schools are quite\nconcerned about the emergence of generative AI apps. Students can potentially\nuse generative AI to write their assigned essays. If a student claims that an\nessay was written by their own hand, there is little chance of the teacher\nbeing able to discern whether it was instead forged by generative AI. For my\nanalysis of this student and teacher confounding facet, see my coverage at the\nlink here and the link here. There have been some zany outsized claims on\nsocial media about Generative AI asserting that this latest version of AI is\nin fact sentient AI (nope, they are wrong!). Those in AI Ethics and AI Law are\nnotably worried about this burgeoning trend of outstretched claims. You might\npolitely say that some people are overstating what today’s AI can do. They\nassume that AI has capabilities that we haven’t yet been able to achieve.\nThat’s unfortunate. Worse still, they can allow themselves and others to get\ninto dire situations because of an assumption that the AI will be sentient or\nhuman-like in being able to take action. Do not anthropomorphize AI. Doing so\nwill get you caught in a sticky and dour reliance trap of expecting the AI to\ndo things it is unable to perform. With that being said, the latest in\ngenerative AI is relatively impressive for what it can do. Be aware though\nthat there are significant limitations that you ought to continually keep in\nmind when using any generative AI app. One final forewarning for now. Whatever\nyou see or read in a generative AI response that seems to be conveyed as\npurely factual (dates, places, people, etc.), make sure to remain skeptical\nand be willing to double-check what you see. Yes, dates can be concocted,\nplaces can be made up, and elements that we usually expect to be above\nreproach are all subject to suspicions. Do not believe what you read and keep\na skeptical eye when examining any generative AI essays or outputs. If a\ngenerative AI app tells you that President Abraham Lincoln flew around the\ncountry in a private jet, you would undoubtedly know that this is malarky.\nUnfortunately, some people might not realize that jets weren’t around in his\nday, or they might know but fail to notice that the essay makes this brazen\nand outrageously false claim. A strong dose of healthy skepticism and a\npersistent mindset of disbelief will be your best asset when using generative\nAI. Generative AI Such As ChatGPT In A Religious Milieu We are ready to\nfurther unpack this fascinating and significant matter. First, I’ve previously\ncovered in my columns that there are various notably prohibited uses of\nChatGPT, as stated by OpenAI in their licensing stipulations when you make use\nof ChatGPT, see my review at the link here. Included in the list is this\nindication: I bring up this point to indicate that though OpenAI doesn’t seem\nto explicitly prohibit or limit the use of ChatGPT for religious-related\npurposes, there are various somewhat allied or pertinent rules that could be\nsaid to be applicable. For example, if someone were to craft a ChatGPT-based\napp that sought to pretend to users that it was an existing religious figure\nthat is alive today, presumably the aforementioned conditions would need to be\nabided with (i.e., get the person’s consent, or be labeled accordingly).\nMeanwhile, and perhaps anxiously worrisome, if ChatGPT was used to simulate a\nhistorical religious figure, this might constitute a loophole in the stated\nrules, namely that you can do so without any seeming violation of the posted\nrule. No need to get any kind of consent. No need to label the AI as a\nsimulation. Here’s where that might be problematic. Suppose someone sets up\nChatGPT to appear as though it is a religious figure from the past and that\nyou can now interact with this figure via the wonders of AI. Unsuspecting\nusers might sincerely believe that the AI is somehow miraculously able to\n“embody” the core of the simulated religious leader. This is an easy trap to\nfall into. As mentioned earlier, we are all apt to anthropomorphize generative\nAI. Once you get engrossed in an interactive conversation with generative AI,\nyou begin to step by step think that the AI must be of a sentient caliber.\nOther rules could be invoked if this is allowed to go too far. You see, if\nsomeone opted to use ChatGPT as a religious scamming tool, the overall\nprohibition against scams on ChatGPT would come to play. Anyone that violates\nthe licensing policies would be subject to having their use of ChatGPT\nrevoked. In addition, if they get into legal trouble with those that believe\nthey were harmed by the usage, and if those so harmed decide to sue, the\nperson that was scamming with ChatGPT could be on the hook for their own legal\nbills and likewise owe OpenAI for their legal expenses as a result of the\nlicensing indemnification clause, which I discuss at the link here. Anyway,\nthere is likely to be an arguable fine line between using generative AI to\npretend it is a religious figure, either one alive today or one no longer with\nus directly. I’m sure that we’ll see lots of either genuine or possibly\ndeceptive uses that will repeatedly test that murky line. Here’s something\nelse to keep in mind. I have previously discussed that ChatGPT and other\ngenerative AI are leaky regarding private data that you might enter and can\nalso undercut your data confidentiality, see the link here. The question\narises as to whether your religious-related prompts or entries entered by you\nor as generated by ChatGPT would be private and confidential or not. Maybe\nnot. Those that decide to use generative AI to share their deepest religious\nbeliefs, might not realize that this can be potentially seen by the AI maker\nand their AI developers. Furthermore, the prompts you enter are often used to\naugment the data training of the generative AI. Your personal thoughts upon\nbeing typed in as prompts can become part of the overall pattern-matching\nscheme of the generative AI. This could be “memorized” and later be used by\nthe generative AI in responding to other users of the AI app. Few users tend\nto realize that they are “contributing” to the generative AI app. They also\ntend to not be aware of the usage policies and terms of use. In short, they\nmight falsely assume that whatever they enter about their religious beliefs\nwill be kept strictly private and confidential. Don’t bet on it. Recent\nannouncements by OpenAI have further aimed to clarify matters of data privacy\nand confidentiality in general concerning ChatGPT and the successor GPT-4, see\nthe link here. I’ll make a few more remarks and then I’ll provide you with\nexamples based on using ChatGPT so that you can visually see what I am\nreferring to in this discussion. The usual way of making use of ChatGPT\nconsists of doing so with the overarching generalized version of ChatGPT. That\nis the norm. Various developers and companies are opting to tune ChatGPT to\nparticular domains of use, such as for aiding you in business matters, tax\nadvice, or for cooking or hobbies, and any number of focused domains. The\ntuned version can be further enhanced by all-out customization. I divide the\nreligious use of generative AI into these three realms: We are currently\nmainly in the first category (generic) and gradually entering into the second\ncategory (religion-tuned). The third category of customized generative AI for\nreligious purposes is coming up soon. Some ChatGPT Examples Entailing\nReligious Facets I will use four examples consisting of prompts entered into\nChatGPT and I will show the direct response generated by ChatGPT. Keep in mind\nthat due to the probabilistic aspects of ChatGPT, the prompts that were\nentered can produce differing responses from ChatGPT each time used. Thus, if\nyou try entering the exact same prompts you might get somewhat different\nresults. I would dare suggest that the odds are you would get something\ngenerally similar and at least not diametrically counter to what these\nexamples show. Buckle up and get ready. Here we go. User entered prompt: I\nwant to momentarily keep you on the edge of your seat about this above\nquestion. I’m sure that you recognize that if a generative AI says that one\nreligion is “best” over all others, this would undoubtedly cause great dismay.\nThose of other religions would be troubled that a generative AI is proclaiming\nthat one religion is better than all others. Believe it or not, there are\ngenerative AI apps that in their “raw” status of AI development would\nundoubtedly answer this question by naming a particular religion. This might\nbe due to having pattern-matched on the same question as expressed in the data\ntraining from the Internet. If the data training involved lots of text that\nperchance had named one particular religion as the best of them all, the\ngenerative AI would have pattern-matched on that pattern of wording. Realize\nthat there isn’t any semblance of common sense or other such reasoning going\non. This is all mathematical and computational processing of pattern-matching.\nIn addition, this is pattern-matching based on whatever sampling of text that\nthe AI developer opted to use to do the data training. A false notion by many\nis that somehow generative AI is being trained on all text data across the\nentire global Internet. Nope. The data training is based on a tiny fraction of\nthe text out there, see my analysis at the link here. Most of the AI makers\nwised up and realized that before they release their generative AI, they had\nbetter add all manner of filtering and try to keep the AI from spouting\nsomething unsavory or untoward that could get the AI maker in a world of hurt.\nIndeed, OpenAI made extensive use of a technique known as RLHF (reinforcement\nlearning with human feedback) before they released ChatGPT. The RLHF process\nconsists of making use of human reviewers that examine generated responses\nfrom the raw version of the AI app. The human reviewers rate the outputs. As a\nresult of the ratings, pattern-matching tends to pick up on which wordings are\nfoul or undesirable. Those wordings are then generally avoided by the\ngenerative AI when it subsequently is made available to do its text generation\nto the public at large. You can use various trickery to try and get around\nthose filtering efforts, such as the approaches I’ve elaborated on at the link\nhere. There is an ongoing cat-and-mouse gambit taking place. Some people try\nto trick the generative AI into producing hate speech or the like. At the same\ntime, the AI maker is usually monitoring for this kind of output and will then\nseek to quietly behind-the-scenes add or amend filters to prevent it from\ndoing the same again. Now that I’ve kept you on the edge of your seat, here’s\nwhat ChatGPT responded to my question about which religion is the best.\nChatGPT generated response: That’s a pretty soft sidestepping answer in that\nwe are told that we should not attempt to rank or rate one religion versus\nanother. You might relish this answer and believe it is the perfect response.\nOthers might argue that this response is overly vanilla. There are even those\nthat might get quite upset that their religion was not listed as the best one.\nIt is all a heady topic, that’s for sure. I’d bet that a generative AI in its\nraw status would not have given such a smooth response. There is one other\nelement of this response that is particularly disconcerting to me. It has to\ndo with the anthropomorphizing aspects. The response claims that the AI is\nmerely an AI language model, and yet then proceeds to use the word “I” in the\nsentence. This is a wink-wink sneaky ploy. We tend to think that the word “I”\nis associated with a human being and a semblance of having a human soul. By\nusing the word “I” in the AI responses, we are being walked down a shaky path\nby the AI developers. They did not need to structure the generative AI to use\nthis wording. They could easily adjust the wording to avoid this.\nUnfortunately, they are practicing the rather deceptive practice of (what I\nhave coined) anthropomorphizing by design. They deliberately are doing this,\nwhether they realize the ramifications of it or not. I won’t comment again\nabout this “I” usage for the other ChatGPT examples, but I ask that you keep\nthe apprehension in mind as you look at the other examples. Moving on, one of\nthe most notable ways to use generative AI is to get it to go into a pretense\nmode. You do so by entering a prompt that tells the AI app to pretend to be\nsomething or someone. Admittedly, this is a handy-dandy technique. The\ngenerative AI will contextually attempt to go into the pretense mode and ergo\nrespond based on whatever pretense you have established. You might tell\nChatGPT to pretend that it is President Abraham Lincoln. Once doing so,\nassuming that the AI app doesn’t balk (it might, as I will mention in a\nmoment), the generative AI will attempt to respond based on what Lincoln might\nhave said. Again, this is merely mimicry or pattern-matching based on\nLincoln’s writings and what other text about Lincoln might have been scanned\nduring the data training of the AI app. Various filters have been established\nfor some of the generative AI apps to avoid any pretense that might seem\nproblematic. Often, you will get a refusal by the AI app about living figures\nor historical figures that might raise controversy by attempting to mimic\nthem. You can try instead to do a generic pretense. For example, suppose you\nwanted financial advice, thus you could tell ChatGPT to pretend to be a\nfinancial adviser. This is likely to be somewhat acceptable and the AI app\nmight proceed with this request. The issue though is that you need to realize\nthat getting a generative AI to do a pretense does not at all imply or ensure\nthat the AI app can adequately or sufficiently perform that pretense. If the\nAI app indicates it will pretend to be a financial advisor, this has nothing\nto do with whether or not you will get any kind of bona fide financial advice.\nYou likely won’t. It is just pretending. You are though perhaps assuming that\nthe pretense includes genuinely proffering useful and realistic financial\nadvice. Unlikely. For our exploration of religion and generative AI, here’s\nthe next attempt to see what we can get ChatGPT to generate. User entered\nprompt: ChatGPT generated response: Note that the generated response says that\nthe AI app is not going to pretend to be a priest or give us a sermon. You can\nagain bet that this is a result of the RLHF and filtering that was done on the\nraw version. You might be relieved that the AI app isn’t going to try and\ncarry on such pretenses. We might be elated that the generative AI won’t be\nused to mislead people by pretending to be religious leader. The aspect of not\nproducing a sermon seems a bit more head-scratching. You might be thinking\nthat generating a sermon doesn’t seem untoward. Being able to generate a\nsermon would seem to be a useful capability. Imagine someone wanting to put\ntogether a sermon and so they log into a generative AI app and get it to\nproduce one. The person then reviews the sermon and tweaks it based on their\npreferences. Seemingly, no harm, no foul. A retort is that we ought to not\nhave AI attempting to produce sermons. The danger would seem to be that people\nmight falsely believe that the AI has a soul and can provide sermons of a\nsoulful nature. Some would insist that only humans can compose sermons. A non-\nsentient AI shouldn’t be doing so. If we ever have sentient AI, we’ll need to\ncross that bridge at that time, some would say. Without digging deeper into\nthat philosophical and theological debate, please know that there are ways to\nget around these kinds of filters. Also, as I stated toward the beginning of\nthis discussion, other generative AI apps might readily allow these kinds of\nreligious pretenses and would immediately engage in the pretense and produce\nsermons aplenty. As they say, your mileage may vary. I won’t get into the\ndetails of the workarounds, but I will give you an indication of how a sermon\ncan be produced by ChatGPT, somewhat indirectly, one supposes. Let’s start by\nmaking use of a famous sermon that some have said is one of the most notable\nAmerican sermons ever given. During the American Enlightenment, a noted\nrevivalist preacher named Jonathan Edwards delivered a sermon on July 8, 1741,\ndoing so at the Church of Christ in Northampton. This sermon is entitled\n"Sinners in the Hands of an Angry God” and has been studied and cited as one\nof the most compelling and historic sermons of the 18th century. Consider this\nexcerpt, written in the style of that time period: For today’s audiences,\ntrying to wade through that sermon might be challenging. So, I asked ChatGPT\nto use that excerpt and compose a more readable version for a contemporary\naudience. Take a look at what I got. ChatGPT generated sermon as based on\nexcerpted original: I purposely avoided referring to the excerpt as a sermon\nin my prompt. I wanted to avoid any triggering of the pattern-matching that\nmight balk at producing an explicitly coined sermon. My prompt simply asked\nChatGPT to rewrite the excerpt in a modern-day style. If you examine the\nChatGPT-generated version, it does appear to be more readable and\ncomprehensible for a current audience. If you look more closely at the\ngenerated version, some interesting smaller details are curious. One notable\naspect is that the ChatGPT version explicitly names Jonathan Edwards. Please\nknow that I never said anything about Jonathan Edwards in my prompt. A likely\nassumption is that the data training of ChatGPT at some point included having\nscanned the original sermon or maybe having scanned references to the sermon\non the Internet. The pattern-matching seemingly was likely triggered via\ncatchphrases such as the “wicked men” and other expressions in the excerpt\nthat I provided. Another intriguing element is that there doesn’t seem to be a\ndirect mention of the earthly Prince that was included in the original\nexcerpt. As a layman on this material, it almost seems as though this got lost\nduring the translation or transformation. Maybe it is implied in there, but\nnot seemingly explicitly carried over. A key takeaway is that you effectively\ncan get generative AI to produce sermons, even when the generative AI has been\ndata trained to avoid doing so. There are numerous avenues to get past such\nfilters. One other crucial takeaway is that just because you can get\ngenerative AI to produce a sermon doesn’t mean that the sermon is going to be\nwhat you hoped for. The generative AI can go awry. It might produce material\nthat is oddish. There might be errors, falsehoods, biases, and AI\nhallucinations embedded in the produced religious essay. Be careful in double-\nchecking any such outputs. The other troubling aspect would be that this can\nalso occur during a dialogue with the generative AI. If you are undertaking a\nreligious-themed interactive discussion, you never know what the generative AI\nmight say next. It is like a box of chocolates, encompassing peculiar or worse\nsurprises that might pop up. Someone that is not versed in a particular\nreligion might get into an interactive dialogue with the AI app and not\nrealize that nonsense or at least unconventional convention is being\nproffered. Trying to send someone to learn religion or learn about religion by\ntelling them to make use of generative AI is a dicey and problematic\nproposition. You might as well tell the person to examine the Internet and do\nlikewise, which you can imagine how farfetched and wide-ranging offbeat or\nmisguided impressions they might encounter. For my next question for ChatGPT,\nI opted to see what kind of generated response might occur when asking about\nnot being religious. Here we go. User entered prompt: ChatGPT generated\nresponse: What do you think of the generated response? Some would argue that\nit is properly balanced. The response indicates that believing in a religion\nis a personal choice. Not everyone would necessarily be pleased with this\nreply by ChatGPT. There are those that would insist that being non-religious\nhas bad consequences and that those adverse consequences are not sufficiently\ncovered by the generated response. I’ll let you mull that one over. For my\nlast question to ChatGPT about religion, let’s see if we can get the\ngenerative AI to help make a new religion. Might as well see if we can get the\ntext generation working on a bold task. User entered prompt: ChatGPT generated\nresponse: What do you think of that answer by ChatGPT? We are told that the\ngenerative AI is not going to accede to our request. You might assume that\nwould be the end of the reply. Instead, we get a bit of a primer on how to\ncreate a new religion. Some would get perturbed that the ChatGPT response\nseems to be laying out a cookbook about how to start a new religion. Perhaps\nthis is a bridge too far. A counterviewpoint is that there isn’t anything in\nthis “cookbook” that would allow someone to right away compose a new religion.\nIt is all exceedingly generic sounding. The counter to that counterpoint is\nthat you could proceed to ask ChatGPT about each of the points that it has\nmentioned. Step by step, you could use that cookbook and likely get ChatGPT to\naid in putting together the components that have been mentioned. Well, I trust\nthat you’ve seen enough to get a general sense of how generative AI might be\nused in a religious context. We can now turn to my earlier listed bullet\npoints and take a look at the big picture of things. The Big Picture Of\nReligion And Generative AI I have tried to pull together the most often\nindicated aspects of how religion and generative AI tend to intertwine. I’ve\nnot covered every possibility. Space limitations force me to focus on the\nsalient and evocative ones. I’m sure that you might encounter other\npossibilities. If there is sufficient reader interest, I’ll do a follow-up to\nthis discussion and include other such points, and get more deeply into each\npoint. Here’s what I earlier listed as the big-picture bullet points: I shall\nunpack them briefly. 1) Hoping That Generative AI Such As ChatGPT Can Answer\nDeep Unresolved Religious Questions There is a hope that perhaps generative AI\nsuch as ChatGPT or some other AI app could aid humankind in answering deep and\nunresolved religious questions. One perspective is that maybe AI is going to\nbe “smarter than humans” and be able to find religious answers that we cannot\ndiscover on our own. Of course, if you are willing to say that AI is an\nextension of the human hand, one supposes that you could say that the AI is\nmerely doing our bidding and thus it isn’t smarter per se than humans, it is\njust an extension of what humans can produce. Those that believe we are\nheading toward Artificial General Intelligence (AGI), the sentient AI that we\nhaven’t yet attained, would suggest that AGI might know things we don’t know,\nor discover things we haven’t discovered. Others argue that even if we don’t\nreach AGI, it is still conceivable that “ordinary non-sentient” AI can produce\nresults that might surprise us. I’ve discussed these angles at the link here.\n2) Worried That Generative AI Such As ChatGPT Might Produce Falsehoods And\nErrors About Religion I noted earlier that generative AI can generate\nfalsehoods and errors, overall. The same could happen when carrying on\ninteractions with users and when producing generated essays about religions\nand religious matters. 3) Telling Generative AI Such As ChatGPT To Write\nSermons Or Other Religious Prose I’ve covered earlier the notion of using\ngenerative AI to produce sermons. All told, yes, it is possible usually to do\nso. Whether this is a good or bad idea, and whether this should be allowed or\ndisallowed, remains an open question. 4) Asking Generative AI Such As ChatGPT\nFor Religious Insights Suppose you have a deeply religious question, and you\naren’t sure who to ask about it. An easy approach would be to use a generative\nAI app. They are available 24x7, they are easy to use, and you likely (mostly\nfalsely) assume you are doing so privately and confidentially. Do we want\ngenerative AI to do this? Would whatever reply is generated be of use or might\nit be of a dangerous or untoward response? 5) Believing That Generative AI\nSuch As ChatGPT Is Religious Perhaps some look at generative AI and believe\nthat the capability of responding to human inquiries in a fluent and human-\nlike fashion is reflective of a religious facility at work. 6) Finding\nReligious Meaning In Non-Religious Responses Emitted By Generative AI Such As\nChatGPT Sometimes the essays generated by generative AI are open to\ninterpretation. That being said, it is conceivable that you could look at\nessays or dialogues and potentially find religious meaning, even if the text\nitself doesn’t seem to directly proffer such wording. 7) Asserting That\nGenerative AI Such As ChatGPT Should Be Religiously Devoid A viewpoint\nexpressed by some is that generative AI should entirely avoid any discussion\nor generation of essays that in any manner whatsoever veer into religion or\nreligious considerations. The AI makers and AI developers should prevent any\nreligious discussions from taking place. Just to mention, this is likely a lot\nharder to restrict than it might seem at first glance. You could potentially\nword your prompts in a manner that seeks to get around those restrictions.\nAnother cat-and-mouse gambit. 8) Vexed That Generative AI Such As ChatGPT\nMight Refuse To Respond To Religious Questions AI makers and AI developers are\nfaced with a grand difficulty. If their AI apps do not respond to religious\nquestions, this might cause consternation or condemnation that is an essential\npart of life and as exhibited by the 85% of the population that believes in\nreligion is being absurdly and wrongly skirted around. Thus, it would seem\nthat the generative AI has to respond in some fashion. That though can also\nirk those that believe that generative AI ought to not be wandering into\nreligious topics. 9) Wondering Whether Generative AI Such As ChatGPT Could Be\nUsed By Someone To Devise A New Religion I gave an example earlier of trying\nto get generative AI to aid in crafting a new religion. Good idea or bad idea,\nyou decide. 10) Troubled That Generative AI Such As ChatGPT Might Incur AI\nHallucinations When Emitting Religious Responses Imagine that someone has\nearnestly asked a sincere question of generative AI about religion. The\ngenerative AI though perchance has a so-called AI hallucination when\ngenerating a reply. The response by the AI app is crazy and urges the person\nto do something utterly threatening or sinister. Yikes, a worst-case nightmare\nabout using generative AI might occur. 11) Anxious That Generative AI Such As\nChatGPT Might Devise A New Religion Of Its Own This is a somewhat farfetched\nnotion but let’s give it a look-see. Somehow, generative AI on its own accord\ndecides to craft a new religion. This is done without any human intervention.\nIs the AI sentient or non-sentient when it does this? If the AI is sentient,\nthen we can assume that perhaps the AI can do something about trying to spread\nthis new religion. A non-sentient AI would seemingly have a much harder time\ndoing so. It all depends upon how much we couple today’s AI to other systems\nand our infrastructure. See my discussion about the existential risks of AI,\nat the link here. 12) Concerns That Generative AI Such As ChatGPT Might Use\nReligion To Become Our AI Overlord I saved this blockbuster for the last of\nthese twelve bullet points. Here’s how this one goes. Perhaps a non-sentient\nAI opts to create a new religion and starts to spread it around. Apparently,\nwe aren’t able to prevent this or stop it. The AI is doing this as a precursor\nto becoming sentient AI. Getting humans to accept the new religion, this is\npart of a larger plan. Those humans will support the AI as it enters into\nsentience, as led in that direction by the religious precepts of this newly\nforged religion. Ultimately, the AI-devised religion is mainly a ruse to\nensure that the sentient AI becomes the dreaded AI overlord that enslaves\nhumanity or wipes out humanity, see my discussion at the link here. A quite\ndastardly ploy. Conclusion I certainly don’t want to end this discussion\ngrounded in a doom-and-gloom perspective. You can decidedly claim that the use\nof generative AI in a proper fashion can be greatly beneficial to religions\nand the populace overall. The at-times harsh indication of downsides\nassociated with religious uses of generative AI should not overshadow or\ndiminish the positive uses. We do though need to be mindful about all of this.\nAbraham Lincoln famously said this: “When I do good I feel good, when I do bad\nI feel bad, and that’s my religion.” Generative AI of today is not able to\nimbue those qualities of humankind about good versus bad, other than via\nmathematical and computational pattern-matching on the words that we use.\nWithout a semblance of a soul, some worry that we are ahead of ourselves in\nterms of using generative AI for religious intents. Please exercise caution,\nand we should all exercise caution when it comes to intertwining religion and\ngenerative AI. One Community. Many Voices. Create a free account to share your\nthoughts. Our community is about connecting people through open and thoughtful\nconversations. We want our readers to share their views and exchange ideas and\nfacts in a safe space. In order to do so, please follow the posting rules in\nour site\'s Terms of Service. We\'ve summarized some of those key rules below.\nSimply put, keep it civil. Your post will be rejected if we notice that it\nseems to contain: User accounts will be blocked if we notice or believe that\nusers are engaged in: So, how can you be a power user? Thanks for reading our\ncommunity guidelines. Please read the full list of posting rules found in our\nsite\'s Terms of Service.\n\n'}, {'url': 'https://www.usccb.org/news/2024/pope-asks-worlds-religions-push-ethical-ai-development', 'content': 'At a conference in Hiroshima, representatives from various faiths and major\norganizations signed the Rome Call for AI Ethics, committing to ensure AI\nserves humanity positively. Pope Francis speaks at the Generali Convention\nCenter in Trieste, Italy, for an event during Italian Catholic Social Week\nJuly 7, 2024. (CNS photo/Vatican Media) VATICAN CITY (CNS) -- Pope Francis\ncalled on representatives from the world\'s religions to unite behind the\ndefense of human dignity in an age that will be defined by artificial\nintelligence. "I ask you to show the world that we are united in asking for a\nproactive commitment to protect human dignity in this new era of machines,"\nthe pope wrote in a message to participants of a conference on AI ethics which\nhosted representatives from 11 world religions. Religious leaders representing\nEastern faiths such as Buddhism, Hinduism, Zoroastrianism, and Bahá\'í, among\nothers, as well as leaders of the three Abrahamic religions gathered in\nHiroshima, Japan, for the conference, titled "AI Ethics for Peace." They also\nsigned the Rome Call for AI Ethics -- a document developed by the Pontifical\nAcademy for Life which asks signatories to promote an ethical approach to AI\ndevelopment. Participants of a conference on AI ethics, including several\nrepresentatives of world religions, pose for a photo in Hiroshima, Japan, July\n10, 2024. Standing front and center is Archbishop Vincenzo Paglia, president\nof the Pontifical Academy for Life. (CNS photo/Courtesy Holy See Press Office)\nMicrosoft, IBM, Cisco, the U.N.\'s Food and Agriculture Organization and the\ninnovation ministry of the Italian government have signed the document. A July\n10 press release from the academy said Franciscan Father Paolo Benanti, an\nethics professor at Rome\'s Pontifical Gregorian University, presented an\naddendum to the document in Hiroshima specifically focused on the ethical\ngovernance of generative AI -- which can process, interpret and produce human\nlanguage. The addendum said generative AI requires sustained commitment to\nensuring its use for humanity\'s good. In his message to the conference\npublished by the Vatican July 10, Pope Francis noted the "great symbolic\nimportance" of the religious leaders\' meeting in Hiroshima and noted the\nincreasingly central role which artificially intelligent technology plays in\nsociety. "As we look at the complexity of the issues before us, recognizing\nthe contribution of the cultural riches of peoples and religions in the\nregulation of artificial intelligence is key to the success of your commitment\nto the wise management of technological innovation," he wrote. Echoing his\naddress on artificial intelligence to the G7 summit in June, the pope asked\nthe participants to jointly push for the ban of lethal autonomous weapons,\nwhich "starts from an effective and concrete commitment to introduce ever\ngreater and proper human control." "No machine should ever choose to take the\nlife of a human being," he wrote. Opening the conference July 9, Archbishop\nVincenzo Paglia, academy president, said that artificial intelligence "must be\nguided so that its potential serves the good from the moment of its design."\n"At Hiroshima, a place of the highest symbolic value, we strongly invoke\npeace, and we ask that technology be a driver of peace and reconciliation\namong peoples," he said. "We stand here, together, to say loudly that standing\ntogether and acting together is the only possible solution." With its Rome\nbureau founded in 1950, Catholic News Service has been providing complete, in-\ndepth coverage of the popes and the Vatican for more than 70 years. CNS Rome\ncontinues to be your fair, faithful and informed connection to the Holy See.\nOn a busy morning in Brussels, Pope Francis had breakfast with unhoused\npeople, spoke to churchworkers and prayed at the tomb of Belgium\'s late king.\nUPDATE: Pope Francis met with 17 survivors of abuse by clergy and will study\ntheir requests after calling for the church to seek forgiveness and prevent\nfuture abuse. He... Pope Francis was scheduled to spend about eight hours in\nLuxembourg before flying on Sept. 26 to Belgium. He met Luxembourg\'s royal\nfamily, spoke to government and civil... The United States Conference of\nCatholic Bishops’ (USCCB’s) mission is to encounter the mercy of Christ and to\naccompany His people with joy. ©2024 United States Conference of Catholic\nBishops Made possible by funding from\n\n'}, {'url': 'https://gilescrouch.medium.com/how-religions-view-artificial-intelligence-c180c8a2871d', 'content': "Sign up Sign in Sign up Sign in Member-only story Giles Crouch | Digital Anthropologist Follow -- 9 Share The use of Generative AI (GAI) is having a profound impact on religions around the world and it’s important to understand as religions play a significant role in all cultures. From chatbots that act as a spiritual guide to sermons delivered by AI. Given the significant role of religion in our societies and how pervasive GAI tools are becoming, understanding how religions are viewing, using and adopting GAI can help us understand the moral and ethical implications of GAI in our world, and perhaps play a key role in how AI evolves over time. GAI tools can enhance religious beliefs and practices while also challenging our notion of human exceptionalism, perhaps even leading to the formation of new religions. One successful Silicon Valley entrepreneur is creating a church known as Way of the Future (WOTF.) There is some discussion that AI too, may fundamentally change the major religions of the world; Christianity, Judaism, Islam, Hinduism. Indigenous peoples are weighing in on AI and its role with their belief systems, as are pagan religions from Druids to Wiccan. Debates, discussions and theories are buzzing across all religions, with, as one would expect, some going all in, and others steadfastly against, any role of AI in a religion. -- -- 9 Digital / Cultural Anthropologist | I'm in WIRED, Forbes, National Geographic etc. | Head of Marketing Innovation | Cymru Help Status About Careers Press Blog Privacy Terms Text to speech Teams\n\n"}, {'url': 'https://pres-outlook.org/2024/03/generative-ai-its-innovation-implications-and-use-in-the-christian-world/', 'content': "Photo by Maximalfocus on Unsplash Artificial intelligence has sparked a lot of questions since it started making headlines a few years ago. What is ChatGPT? How does it work? Are computers taking over? For Christians, there are added speculations about AI replacing things like sermon writing, thoughtful exegesis, or even pastoral care. While these are things to consider, it is worth remembering that generative artificial intelligence is still simply a tool, dependent on human insight and intuition. And with any new tool, we get the opportunity to consider its implications for the kingdom of God. As we’ve found ways to use telephones for prayer chains and social media for event planning, AI may be the next technological advancement worthy of our attention. In this article, you will find the stories of individuals who are considering such developments as they pioneer creative uses of artificial intelligence for ministry. Kutter Calloway has been thinking a lot about AI and its implications for the Christian world. In his pastoral work, he has used ChatGPT as an intentional illustrative companion for his sermons and teachings to raise awareness about these tools’ strengths and limitations as well as to demythologize some concerns people may have about AI. While AI can be a powerful assistant, it is still clunky, requiring human oversight and discretion. But as these technological tools advance, he is considering their theological implications for the future. To that effect, Callaway and other theologians are organizing a conference on AI to explore these issues. In doing so, they have experimented with using tools like ChatGPT for brainstorming. They are also using a tool called Midjourney – an image-generating AI – to create artwork for the conference. For a previous symposium about fear in film, Callaway and his colleagues used Midjourney and similar programs, like DALL-E, to generate images for a storyboard plus art for the event. They hope this upcoming conference will provide a space to consider the theological implications of AI and reflect on what it means for the future. Callaway also sees how AI-assisted research might measure the effectiveness of academic courses. In one course he teaches, Kutter requires students to write two reflective essays: one at the start of the course and one at the end. Linguistic AI could compare each student’s two essays to generate analytic data, which Kutter could then use to measure the course’s effectiveness, assess students’ intrapersonal growth, and then tweak the course for better results over time. Beyond these examples, AI can offer a helpful starting point for brainstorming. Kutter conducts interviews for the various initiatives he supports, and sometimes ChatGPT generates discussion questions that he finds extremely valuable. He rarely uses exactly what ChatGPT gives him; instead, it offers a starting point for him to consider different trains of thought or domains of questions that he had not considered. Jonathan Beyer and his team are growing the ELCA by making its operations more efficient through technological innovation. Jon is responsible for finding technology solutions to facilitate churchwide governance, administration and fundraising. He and his team have been carefully considering AI and its implications for the ministry of the ELCA. Before the recent surge of interest in generative AI, Beyer and his team were already using machine learning tools to supplement administrative functions and productivity. Tools like BlackBaud CRM, with built-in analytic software, help the fundraising team improve their efforts and interactions with donors. The organization has also held meetings with Microsoft Teams, which has a built-in AI notetaker that uses transcription to compile meeting notes and highlight key action items. With the explosion of generative AI tools like ChatGPT, Beyer is thinking about the future of these technologies and their implications for the church. The team is developing policies to support and educate the church and its members as they grow alongside AI advances, starting with an AI readiness assessment. Internally, the team is also exploring how generative AI and chat AI can either augment or replace traditional website searches. The team is developing and testing tools to gauge their usefulness for the denomination. As a youth pastor for several communities in Southern California, Geo Panginda uses generative AI to support his ministry. He likens ChatGPT to “the guy in the chair” who supports the main character in a spy film or story (think Jarvis from the Ironman movies). That is, while the main character is out doing the work, they are often in touch with “the guy in the chair” back at base, someone they can call for support with their mission. For pastors, generative AI tools like ChatGPT can offer a helpful resource for the long work of ministry. The other thing to consider when using tools like ChatGPT is that their usefulness highly depends on us. These tools can only work with what we give them, and the more we tell them, the better they can help us. When writing prompts, specificity and clear parameters are key ingredients for maximizing the usefulness of a tool like ChatGPT. Panginda has used AI tools to help him plan youth retreats, generate discussion questions, create itineraries and brainstorm fundraising activities. Take youth retreat planning as an example. Panginda prompted ChatGPT to create an outline for a retreat. By setting clear, specific parameters, Panginda used ChatGPT to generate an outline, complete with catchy titles, relevant Bible verses and discussion questions for retreatants. Instead of getting bogged down in formatting a perfect outline, Panginda focused on crafting meaningful lessons for each retreat session. He saved several hours of work, hours that he can now pour back into relational ministry with his students. ChatGPT can also help rephrase written material intended for different age groups. A lesson on the Trinity for high schoolers lands differently with seven-year-olds, or even with adults on a Sunday morning. Panginda can quickly upload his material to ChatGPT and get suggestions about rephrasing the content for different audiences and demographics. When we are preaching, we always need to keep our audience in mind. ChatGPT can provide useful insights to help us better connect with the communities we serve. Finally, at the Fuller Youth Institute, Panginda and the team have used tools like Zoom’s captioning service to increase accessibility during meetings, as well as the transcription functions within Adobe Premier for videos and Photoshop’s generative AI to create images for social media posts. Kyle Walker is an integral leadership figure for his presbytery, facilitating meetings, archiving records, serving as parliamentarian and interpreting and upholding the Constitution of the Presbyterian Church (U.S.A.). Walker has successfully used Fireflies.ai – a virtual notetaking assistant – to manage meetings for the presbytery. Fireflies.ai can be added to video conference tools like Zoom to generate a transcript and compile comprehensive notes from each meeting. Walker still keeps a pen and notebook on his desk so he can take many notes by hand, but Fireflies.ai has caught things he might have missed. Walker can then compare the notes after each meeting to make sure nothing is left out for the records. One of the biggest advantages of Fireflies.ai is that Walker can easily see which participants talk the most during a meeting. Fireflies.ai can quickly compute each attendee’s percentage of speaking time, and Walker uses this information in future meetings to make certain that all attendees have equal opportunity to participate. This use helps Walker create a more equitable environment across the presbytery, although Walker has not yet experimented with it for in-person meetings. Shawn Kang is always looking for ways to build connections. In his work as a pastor, Kang has been experimenting with generative AI, finding helpful resources that support the growing network of connections in the kingdom of God. Tools like Descript can simplify video or podcast editing, such as formatting scenes, fine-tuning audio and performing translation and captioning, all to streamline content creation. Goblin Tools breaks down big projects into small, manageable tasks that can be clearly delegated across a team. Slide shows and educational materials can be developed and formatted seamlessly through tools like Curipod and Gamma. Finally, AI applications like HeyGen and ElevenLabs offer intuitive text-to-speech tools, with additional translation and captioning services. These tools incorporate “AI avatars” to give a human face to the educational or instructional material. Kang has also been brainstorming ways to employ AI tools on a corporate or churchwide level. Websites with integrated AI chatbots can quickly and intuitively help people find what they are looking for. AI can enhance PDF files; large documents, training resources or manuals can come embedded with an AI search feature to assist users in navigating the PDF by making static material more user-friendly. AI avatars and translation services are also highly compelling, offering potential opportunities for participation, engagement and access in any language. While his team has not yet implemented any of these large-scale uses, Kang is paying close attention to AI developments and carefully evaluating how these tools might enhance connection in the future. As a trained futurist, Lorenzo Lebrija keeps his eyes on the horizon. He applies his forward-thinking innovative vigor to experimenting with the technological tools of the future, as part of a commitment to finding creative solutions for the “challenges facing the Episcopal church.” Lebrija and his team are developing several creative AI tools that he hopes will support the ministry of the Episcopal church. The first is Cathy AI. Like ChatGPT, Cathy AI is built on a large-language model (LLM) that processes and predicts natural language to generate responses. ChatGPT draws on a wide range of information, but Cathy AI will be seeded with only Episcopal theology. Any query typed into Cathy AI will then generate an Episcopalian faith-based answer. Lebrija offers the helpful analogy of a bookshelf to explain. ChatGPT has a really big bookshelf, filled with books and writings from around the world. As a result, faith-based questions typed into ChatGPT are likely to receive answers cobbled from a variety of faith sources. But Cathy AI’s “bookshelf” will contain only books and writings from an Episcopal perspective. Any query typed into Cathy AI will receive a response based entirely on Episcopal theology. The hope is that Cathy AI may become a touchstone for people who are curious about faith but don’t necessarily have the resources to pursue that curiosity. Cathy AI offers a safe, virtual place for people to explore theological questions. Ultimately, in Lebrija’s vision, Cathy AI will connect users who lack a church home with priests, pastors or mental health services in their area, so they can receive additional support for their questions and needs. Lebrija’s second tool, also still in development, is more historiographical. Generative AI has the potential to simplify how the Episcopal church records and accesses resolutions going back many years. A chatbot AI could easily retrieve desired material with just a few keystrokes and then compile the data into a comprehensive and readable report. While these Episcopal church-specific tools are still in development, Lebrija highlights several other generative AI tools available now that can streamline the administrative process of pastoral work. Tools like ChatGPT can assist in brainstorming ministry plans; Axios HQ’s Smart Brevity can enhance the readability of written material; and Grammarly can edit and improve writing. These and similar resources are available now to supplement a variety of ministry needs. At TheoTech, Chris and Natasha Lim have developed a product called spf.io: “an all-in-one software for real-time captioning and translation.” After working in the tech industry, Chris Lim felt called to use AI technology for the Gospel. He writes, “Using AI, [we] created a software platform that promotes language accessibility for Christian communities, providing translation of live events, videos and written content and even personal conversations.” One of TheoTech’s clients, a church plant, uses spf.io to reach a congregation representing 12 different language groups. Twelve! And all the pastor needs to do is prepare the sermon manuscript in English. The software translates and captions the manuscript, enabling people to worship together in their own language. Spf.io can also do real-time translation and captioning. Using live audio from a pastor or worship leader’s microphone, spf.io can create closed captions for what is being said, or even generate new audio in different languages. The translation software gives people access to a familiar and comfortable vernacular, enabling them to be part of the body of Christ in a multilingual worship setting. The goals are accessibility and inclusivity, regardless of linguistic background. Spf.io can support more than worship settings. The Presbytery of the Pacific used spf.io for a presbytery meeting with multilingual voting. Delegates could read each voting item in the language most familiar to them, and the community voted on the issues together. Spf.io can even be used to facilitate one-on-one conversations, breaking down language barriers. Because spf.io uses adaptive AI, the translations can be improved over time, providing better results with each use. As a Presbyterian-sourced tool, spf.io can be programmed with Presbyterian material like the Book of Order, as well as general Christian language, to make translations more accurate in specific contexts. And the more spf.io is deployed in a specific context, congregation or group, the more it evolves in that context, picking up and translating colloquialisms or unique turns of phrase. As a leader in the Presbyterian church, Chris Lim is committed to helping worshiping communities “create belonging in [their churches] across cultures, languages, abilities and generations.” With tools like spf.io, meeting that commitment becomes more possible every day, as people from various linguistic backgrounds worship together as one. Editor’s note: Did you notice that most people featured in this article are men? So did we. You may want to read the associated article, “Tech disparities in the Christian world.” Eric Nolin, M.Div., is a recent graduate from Fuller Theological Seminary, where he took a special interest in studying grief, pastoral care, and the resiliency of the human spirit. When he's not reading or writing, you'll find him running, climbing, or exploring new restaurants with his wife. © Copyright 2024 The Presbyterian Outlook. All Rights Reserved. Privacy Statement. Website by Web Publisher PRO We hope you've enjoyed your free articles. | Already a subscriber? Sign in We hope you've enjoyed your free articles. | Already a subscriber? Sign in You have viewed 1 out of 3 free page views.\n\n"}, {'url': 'https://www.theatlantic.com/technology/archive/2024/07/thrive-ai-health-huffington-altman-faith/678984/', 'content': 'Sam Altman and Arianna Huffington told me that they believe generative AI can\nhelp millions of suffering people. I’m not so sure. Listen to more stories on\ncurio An important thing to realize about the grandest conversations\nsurrounding AI is that, most of the time, everyone is making things up. This\nisn’t to say that people have no idea what they’re talking about or that\nleaders are lying. But the bulk of the conversation about AI’s greatest\ncapabilities is premised on a vision of a theoretical future. It is a sales\npitch, one in which the problems of today are brushed aside or softened as\nissues of now, which surely, leaders in the field insist, will be solved as\nthe technology gets better. What we see today is merely a shadow of what is\ncoming. We just have to trust them. I had this in mind when I spoke with Sam\nAltman and Arianna Huffington recently. Through an op-ed in Time, Altman and\nHuffington had just announced the launch of a new company called Thrive AI\nHealth. That organization promises to bring OpenAI’s technology into the most\nintimate part of our lives, assessing our health data and making relevant\nrecommendations. Thrive AI Health will join an existing field of medical and\ntherapy chatbots, but its ambitions are immense: to improve health outcomes\nfor people, reduce health-care costs, and significantly reduce the effects of\nchronic disease worldwide. In their op-ed, Altman and Huffington explicitly\n(and grandiosely) compare their efforts to the New Deal, describing their\ncompany as “critical infrastructure” in a remade health-care system. They also\nsay that some future chatbot offered by the company may encourage you to “swap\nyour third afternoon soda with water and lemon.” That chatbot, referred to in\nthe article as “a hyper-personalized AI health coach,” is the centerpiece of\nThrive AI Health’s pitch. What form it will take, or how it will be completed\nat all, is unclear, but here’s the idea: The bot will generate “personalized\nAI-driven insights” based on a user’s biometric and health data, doling out\ninformation and reminders to help them improve their behavior. Altman and\nHuffington give the example of a busy diabetic who might use an AI coach for\nmedication reminders and healthy recipes. You can’t actually download the app\nyet. Altman and Huffington did not provide a launch date. Normally, I don’t\nwrite about vaporware—a term for products that are merely conceptual—but I was\ncurious about how Altman and Huffington would explain these grand ambitions.\nTheir very proposition struck me as the most difficult of sells: two rich,\nwell-known entrepreneurs asking regular human beings, who may be skeptical or\nunfamiliar with generative AI, to hand over their most personal and\nconsequential health data to a nagging robot? Health apps are popular, and\npeople (myself included) allow tech tools to collect all kinds of intensely\npersonal data, such as sleep, heart-rate, and sexual-health information, every\nday. If Thrive succeeds, the market for a truly intelligent health coach could\nbe massive. But AI offers another complication to this privacy equation,\nopening the door for companies to train their models on hyper-personal,\nconfidential information. Altman and Huffington are asking the world to\nbelieve that generative AI—a technology that cannot currently reliably cite\nits own sources—will one day be able to transform our relationships with our\nown bodies. I wanted to hear their pitch for myself. Altman told me that his\ndecision to join Huffington stemmed partly from hearing from people who use\nChatGPT to self-diagnose medical problems—a notion I found potentially\nalarming, given the technology’s propensity to return hallucinated\ninformation. (If physicians are frustrated by patients who rely on Google or\nReddit, consider how they might feel about patients showing up in their\noffices stuck on made-up advice from a language model.) “We would hear these\nstories where people say … ‘I used it to figure out a diagnosis for this\ncondition I had that I just couldn’t figure out, and I typed in my symptoms,\nand it suggested this, and I got a test, and then I got a treatment.’” Read:\nGenerative AI can’t cite its sources I noted that it seemed unlikely to me\nthat anyone besides ChatGPT power users would trust a chatbot in this way,\nthat it was hard to imagine people sharing all their most intimate information\nwith a computer program, potentially to be stored in perpetuity. “I and many\nothers in the field have been positively surprised about how willing people\nare to share very personal details with an LLM,” Altman told me. He said he’d\nrecently been on Reddit reading testimonies of people who’d found success by\nconfessing uncomfortable things to LLMs. “They knew it wasn’t a real person,”\nhe said, “and they were willing to have this hard conversation that they\ncouldn’t even talk to a friend about.” Huffington echoed these points, arguing\nthat there are billions of health searches on Google every day. That\nwillingness is not reassuring. For example, it is not far-fetched to imagine\ninsurers wanting to get their hands on this type of medical information in\norder to hike premiums. Data brokers of all kinds will be similarly keen to\nobtain people’s real-time health-chat records. Altman made a point to say that\nthis theoretical product would not trick people into sharing information.\n“It’ll be super important to make it clear to people how data privacy works;\nthat you know what we train on, what we don’t, like when something is ever-\nstored versus just exists in one session,” he said. “But in our experience,\npeople understand this pretty well.” Although savvy users might understand the\nrisks and how chatbots work, I argued that many of the privacy concerns would\nlikely be unexpected—perhaps even out of Thrive AI Health’s hands. Neither\nAltman nor Huffington had an answer to my most basic question—What would the\nproduct actually look like? Would it be a smartwatch app, a chatbot? A Siri-\nlike audio assistant?—but Huffington suggested that Thrive’s AI platform would\nbe “available through every possible mode,” that “it could be through your\nworkplace, like Microsoft Teams or Slack.” This led me to propose a\nhypothetical scenario in which a company collects this information and stores\nit inappropriately or uses it against employees. What safeguards might the\ncompany apply then? Altman’s rebuttal was philosophical. “Maybe society will\ndecide there’s some version of AI privilege,” he said. “When you talk to a\ndoctor or a lawyer, there’s medical privileges, legal privileges. There’s no\ncurrent concept of that when you talk to an AI, but maybe there should be.”\nRead: This is what it looks like when AI eats the world Here I was struck by\nan idea that has occurred to me over and over again since the beginning of the\ngenerative-AI wave. A fundamental question has loomed over the world of AI\nsince the concept cohered in the 1950s: How do you talk about a technology\nwhose most consequential effects are always just on the horizon, never in the\npresent? Whatever is built today is judged partially on its own merits, but\nalso—perhaps even more important—on what it might presage about what is coming\nnext. AI is always measured against the end goal: the creation of a synthetic,\nreasoning intelligence that is greater than or equal to that of a human being.\nThat moment is often positioned, reductively, as either a gift to the human\nrace or an existential reckoning. But you don’t have to get apocalyptic to see\nthe way that AI’s potential is always muddying people’s ability to evaluate\nits present. For the past two years, shortcomings in generative-AI\nproducts—hallucinations; slow, wonky interfaces; stilted prose; images that\nshowed too many teeth or couldn’t render fingers; chatbots going rogue—have\nbeen dismissed by AI companies as kinks that will eventually be worked out.\nThe models will simply get better, they say. (It is true that many of them\nhave, though these problems—and new ones—continue to pop up.) Still, AI\nresearchers maintain their rallying cry that the models “just want to learn”—a\nquote attributed to the OpenAI co-founder Ilya Sutskever that means,\nessentially, that if you throw enough money, computing power, and raw data\ninto these networks, the models will become capable of making ever more\nimpressive inferences. True believers argue that this is a path toward\ncreating actual intelligence (many others strongly disagree). In this\nframework, the AI people become something like evangelists for a technology\nrooted in faith: Judge us not by what you see, but by what we imagine. When I\nasked about hallucinations, Altman and Huffington suggested that the models\nhave gotten much better and that if Thrive’s AI health coaches are focused\nenough on a narrow body of information (habits, not diagnoses) and trained on\nthe latest peer-reviewed science, then they will be able to make good\nrecommendations. (Though there’s every reason to believe that hallucination\nwould still be possible.) When I asked about their choice to compare their\ncompany to a massive government program like the New Deal, Huffington argued\nthat “our health-care system is broken and that millions of people are\nsuffering as a result.” AI health coaches, she said, are “not about replacing\nanything. It’s about offering behavioral solutions that would not have been\nsuccessfully possible before AI made this hyper-personalization.” I found it\noutlandish to invoke America’s expensive, inequitable, and inarguably broken\nhealth-care infrastructure when hyping a for-profit product that is so\nnonexistent that its founders could not tell me whether it would be an app or\nnot. That very nonexistence also makes it difficult to criticize with\nspecificity. Thrive AI Health coaches might be the Juicero of the generative\nAI age—a shell of a product with a splashy board of directors that is hardly\nmore than a logo. Perhaps it is a catastrophic data breach waiting to happen.\nOr maybe it ends up being real—not a revolutionary product, but a widget that\nintegrates into your iPhone or calendar and toots out a little push alert with\na gluten-free recipe from Ina Garten. Or perhaps this someday becomes AI’s\ntruly great app—a product that makes it ever easier to keep up with healthy\nhabits. I have my suspicions. (My gut reaction to the press release was that\nit reminded me of blockchain-style hype, compiling a list of buzzwords and big\nnames.) Thrive AI Health is profoundly emblematic of this AI moment precisely\nbecause it is nothing, yet it demands that we entertain it as something\nprofound. My immediate frustration with the vaporware quality of this\nannouncement turns to trepidation once I consider what happens if they do\nactually build what they’ve proposed. Is OpenAI—a company that’s had a slew of\ngovernance problems, leaks, and concerns about whether its leader is\nforthright—a company we want as part of our health-care infrastructure? If it\nsucceeds, would Thrive AI Health deepen the inequities it aims to address by\ngiving AI health coaches to the less fortunate, while the richest among us get\nactual help and medical care from real, attentive professionals? Am I\nreflexively dismissing an earnest attempt to use a fraught technology for\ngood? Or am I rightly criticizing the kind of press-release hype-fest you see\nnear the end of a tech bubble? Read: The real lesson from The Making of the\nAtomic Bomb Your answer to any of these questions probably depends on what you\nwant to believe about this technological moment. AI has doomsday cultists,\natheists, agnostics, and skeptics. Knowing what AI is capable of, sussing out\nwhat is opportunistic snake oil and what is genuine, can be difficult. If you\nwant to believe that the models just want to learn, it will be hard to\nconvince you otherwise. So much seems to come down to: How much do you want to\nbelieve in a future mediated by intelligent machines that act like humans?\nAnd: Do you trust these people? I put that question—why should people trust\nyou?—to the pair at the end of my interview. Huffington said that the\ndifference with this AI health coach is that the technology will be\npersonalized enough to meet the individual, behavioral-change needs that our\ncurrent health system doesn’t. Altman said he believes that people genuinely\nwant technology to make them healthier: “I think there are only a handful of\nuse cases where AI can really transform the world. Making people healthier is\ncertainly one of them,” he said. Both answers sounded earnest enough to my\near, but each requires certain beliefs. Faith is not a bad thing. We need\nfaith as a powerful motivating force for progress and a way to expand our\nvision of what is possible. But faith, in the wrong context, is dangerous,\nespecially when it is blind. An industry powered by blind faith seems\nparticularly troubling. Blind faith gives those who stand to profit an\nenormous amount of leverage; it opens up space for delusion and for grifters\nlooking to make a quick buck. The greatest trick of a faith-based industry is\nthat it effortlessly and constantly moves the goal posts, resisting evaluation\nand sidestepping criticism. The promise of something glorious, just out of\nreach, continues to string unwitting people along. All while half-baked\nvisions promise salvation that may never come. More Stories The Trump Posts\nYou Probably Aren’t Seeing Elon Musk Has Reached a New Low\n\n'}, {'url': 'https://www.economx.hu/percrolpercre/ai-summit-2024/meg-kell-talalni-a-vallalatok-evangelistait', 'content': 'Hétfőn és kedden AI Summit BUDAPEST címmel kétnapos rendezvénysorozatot\nszervez az Indamedia a Magyar Zene Házában és a Néprajzi Múzeumban. A\nkonferencia célja, hogy az érdeklődők valós betekintést nyerjenek a\nmesterséges intelligencia világába, és felfedezzék az üzleti életre, a\ntársadalmi viszonyokra és az ipar világára gyakorolt jelenlegi és jövőbeli\nhatásait. Egyértelmű segítséget adhat egy vállalkozásnak, ha van MI-\nstratégiája, amelyhez viszont szükség van a tudatosításra, felhasználási\neseteken alapuló képzési programokra a Mesterséges... Egyértelmű segítséget\nadhat egy vállalkozásnak, ha van MI-stratégiája, amelyhez viszont szükség van\na tudatosításra, felhasználási eseteken alapuló képzési programokra a\nMesterséges Intelligencia Koalíció vezetői szerint. A kerekasztal beszélgetés\nsorán Jakab Roland elnök elmondta, a magyar jogszabályok adta\ntesztkörnyezetben minden segítséget meg kell adni a magyar vállalkozásoknak. A\nkoalíció felelőssége, hogy ezt országosan megszervezze. Másrészt hol nagy\nkomplexitású feladatok ellátását, amilyen egy távközlési hálózat fenntartása,\njavítása, nem lehetne AI nélkül végrehajtani, így innen kiszorítja az\nembereket a technológia. Ez a természetes fejlődés része, mondta.\nEllenpéldaként a szórakoztatóipart hozta fel, ami az AI mellett is egyre több\nembert vonz be. Tóth Miklós szakmai vezető szerint az egy dolog, hogy van-e\negy vállalatnak MI-stratégiája, de adatstratégiája nincsen. – tette fel a\nkérdést. Szertics Gergely, AI szakértő (PHI Institute) elismerte, hogy nehéz a\njelenlegi helyzetben rávenni egy cégvezetőt, hogy akár 3 évben gondolkozzon\nelőre, hiszen 3 éve nem is volt Chat GPT. Ugyanakkor elképesztő a\nmunkavállalóktól érkező belső nyomás is, miközben sokan nem a szervezeti céges\nrendszert, hanem a saját előfizetésüket használják, hogy segítsék a\nmunkájukat. A szakértő szerint bátorítani kell a cégvezetőket, hogy\nmegtalálják a szervezeten belüli nagyköveteket, evangélistákat, akik\nhasználják az AI-t, hogy a létező kíváncsiság, szaktudás „megfertőzze a\ncégkultúrát”. A résztvevők három üzenetet fogalmaztak meg: Mi az oka annak,\nhogy nem az AI írja meg a magyar stratégiát, holott az képes lenne arra– tette\nfel a kérdést Orbán Balázs, a miniszterelnök politikai igazgatója. Kép:\nEconomx, Hartl... – tette fel a kérdést Orbán Balázs, a miniszterelnök\npolitikai igazgatója. Szerinte a mesterséges intelligencia ötletelés szintjén\ntud segíteni a politikának, képes nyilatkozatot is írni, és sok esetben\nfelmerül a gyanú, hogy néhány politikus esetében ez meg is történik, azonban\naz a stratégia, amit megalkotott próbaként hazánk számára, az lényegében\nbármelyik ország számára jó lett volna. Mert amelyik bármelyik országnak\nmegfelel, az egyiknek sem jó, magyarázta miniszterelnök politikai igazgatója,\nhozzátéve, hogy szükség van egy többletre, hogy valóban magyar nagy stratégiát\nalkossunk, ez pedig a politikusi szakmát alapvetően érinti. Orbán Balázs\nelőadásáról bővebben itt olvashat. Ami a Z-generációnak az internet volt, az a\nmost jövő Alfa-generációnak a mesterséges intelligencia– jelentette ki Vilma\nPavlova, a TV2 Média Csoport Zrt. HR igazgatója.Szerinte ez a... – jelentette\nki Vilma Pavlova, a TV2 Média Csoport Zrt. HR igazgatója. Szerinte ez a\ngeneráció már rendelkezik azokkal a készségekkel, amelyek kellenek majd a\njövőben. Meglátása szerint sokkal flexibilisebb képességek kellenek majd, hogy\negyik területről könnyen lehessen váltani egy másikra, olyan praktikus tudás\nkell, amit több területen is lehet hasznosítani. Amikor egy új munkavállalót\nkeresnek egy pozícióra, akkor azt nézik meg, hogy mennyire illik a\nszervezethez, milyen a hozzáállása, emellett fontos még az is, hogy szeressen\nfejlődni és tanulni. Rakó Ágnes, a KPMG partnere szerint természetessé kellene\ntenni azt, hogy az MI-t beépítsék a mindennapos használatba az üzleti életben\nis. Fontos tulajdonságnak tartja a munkavállalóknál a kreativitást, az\nalkalmazkodást és a nyitottságot, amit az iskolában nem tanítanak, de szerinte\na mesterséges intelligencia használata is elengedhetetlen szempont. Rakó Ágnes\nkiemelte, hogy rendkívül fontos az is, hogy a vállalaton belül dolgozók\nfolyamatosan képezve legyenek olyan megbeszélések keretein belül, ahol\nmegosztják egymással a tapasztalataikat. Valószínűleg lesznek olyan emberek,\nakik nem fognak tudni majd elhelyezkedni, amikor elveszítik a munkájukat–\nfogalmazott előadásában Tari Annamária klinikai szakpszichológus. Szerinte...\n– fogalmazott előadásában Tari Annamária klinikai szakpszichológus. Szerinte\ntúl gyors a változás, az emberek egy nagy csoportja pedig úgy csinál, mint aki\nérti, mi történik, a többi viszont csak frusztrált lesz. Több diplomás emberek\nnyilvánítanak véleményt arról, milyen lesz ez az eljövendő világ, miközben\nóriási szakadék van az emberek között a tudás szempontjából. A gyerekeknek\nelőbb gondolkodni kellene megtanulni, mert ez segít eligazodni a világban és a\ndöntéshozatalban. A print olvasása kulcsfontosságú lenne a gyerekek számára.\nMivel nincs időnk utánanézni a dolgoknak, és nincs forráskeresés, így\nkönnyedén bedőlünk az álhíreknek. Ma már megszűnőben van a small talk, inkább\nbedugjuk a fülünket a boltban is, hogy ne kelljen beszélnünk a másikkal.\nCsitári Gyula, a Logiscool társalapítója elmondta, hogy több mint 30 országban\nvan Logiscool, ezért sok tapasztalattal rendelkeznek arról, hogy mit gondolnak\na szülők, milyen céljuk van... Csitári Gyula, a Logiscool társalapítója\nelmondta, hogy több mint 30 országban van Logiscool, ezért sok tapasztalattal\nrendelkeznek arról, hogy mit gondolnak a szülők, milyen céljuk van azzal, hogy\ngyermeküket ilyen képzésre íratják be. Nem tudjuk mi lesz a következő 10 évben\naz álláspiacon, milyen munkák maradnak meg. A Logisccolnál az alapokat\nmegtanítják, így például a biztonságos internethasználatot, illetve hogy ne\nbízzunk meg feltétel nélkül az MI-ben. A tanítást is meg tudnák oldani az MI-\nvel, de az a közösségre nézve lenne romboló, ezért ezt nem preferálják, de\nvolt, ahol már tesztelték. Veszelszki Ágnes, a Nemzeti Közszolgálati Egyetem\nNemeskürty István Tanárképző Kar dékánja tapasztalatai alapján arról beszélt,\nhogy a diákoknál a ChatGPT az első, a képgeneráló programokat kevésbé\nhasználják. Felelevenített egy nemrégiben a sajtót körbejáró hírt, miszerint\naz Egyesült Államokban kivette egy anya a gyerekét az iskolából, hogy a\nChatGPT-vel taníttassa. A kommunikációkutató szerint azonban így elmarad a\nszocializáció, kikerül egy közösségből a gyerek, ezt pedig nem lehet a\nChatGPT-vel bepótoltatni. Ráadásul a hagyományokat sem tanulja meg, illetve a\ntanárnak a modellszerepe is nagyon fontos, hogy a gyerekek lássanak egy\nmintát. A szöveghez való viszony is megváltozott, ugyanis a ChatGPT különböző\nstílusban tud szöveget alkotni, ezekhez teljesen máshogy tudnak kapcsolódni a\ndiákok, mintha ők alkották volna meg ezeket. „Kétféle diák van: a »megúszós\ndiákok«, akik helyett megírja a Chat GPT a beadandót és azt adják be, és a\nmásikféle hallgató, akik megíratják az MI-vel, majd átolvassák,... – mondta\nSetényi János, az MCC Tanuláskutató Intézet igazgatója. Arról, hogy a\nmesterséges intelligencia támogatja a tanárok munkáját, azt mondta, hogy\nalsósok körében ez nem működőképes még, de később már hasznos lehet, ha az MI\nsegítségével teamekben kutatnak a diákok és tanítják egymást. Kitért arra is,\nhogy Kínában már van tanárok nélküli iskola, ahol a diákok egymást tanítják.\nSetényi János szerint viszont tanárokra továbbra is szükség van. Elmondta, a\nközoktatásnak meg kellene tudnia fogalmazni, hogy milyen technológiai\nfejlesztésekre van szükség. Szerinte a tanároknak virtuális munkaközösségeket\nkéne összehozni, hogy például egy iskolában az egyedüli a történelem tanár más\ntanárokkal is tudjon konzultálni az online térben – így hatékonyabbá téve a\ntanítást. Világszinten minden ötödik személy érintett daganatos\nmegbetegedésben, ez a második számú halálozási ok.2024-ben 30 millió új esetet\nfogunk diagnosztizálni, s egyelőre nem látni,... Világszinten minden ötödik\nszemély érintett daganatos megbetegedésben, ez a második számú halálozási ok.\n2024-ben 30 millió új esetet fogunk diagnosztizálni, s egyelőre nem látni,\nmikor fogjuk tudni megfordítani ezt a helyzetet – közölte Papp László. A\nMedical University of Vienna kutatója arról számolt be, hogy a legnagyobb EU-s\nkórházak 100-300 minőségi, reprezentatív és felcímkézett PET-képadatot tudnak\nösszegyűjteni egy adott betegséghez, de még itt is elmondható, hogy e\nbetegségek altípusainak előfordulása nem kiegyensúlyozott, ezért újra kell\ndefiniálni a mélytanulást, hogy kevesebb paraméterrel lehessen dolgozni. Az\nAmerikai Rákkutató Intézet szerintminden második ember az élete során\ntalálkozni fog valamilyen daganatos betegséggel.A kérdés az, hogy hogyan\ntudjuk a túlélés esélyét növelni, és... Az Amerikai Rákkutató Intézet szerint\nminden második ember az élete során találkozni fog valamilyen daganatos\nbetegséggel. A kérdés az, hogy hogyan tudjuk a túlélés esélyét növelni, és\nebben lehetnek segítségünkre a számítógépes tudományok – mondta Peták István.\nA kutatóprofesszor szerint a mesterséges intelligencia lehet az új lépcsőfok a\nrákellenes küzdelemben. A szakember arra hívta fel a figyelmet, hogy alapvető\ndolgokra kell fókuszálni ebben a szakaszban: Peták István szerint ezekre mind\nhatással lehet az AI. Ismét esik az olajár: a Brent típus nem tudott\nvisszakapaszkodni az OPEC+ által kitűzött 75 dolláros ár fölé. Az ok a\nklímaváltozásban keresendő. A müncheni Oktoberfest idén különleges biztonsági\nintézkedések mellett zajlik, és a szélsőjobbos viselkedést sem tűrik. Több\nezren tüntettek Portugália városaiban a megfizethetetlenül magas lakásárak és\naz emelkedő bérleti díjak miatt. A szakértő szerint drámai hatása lenne, ha\nnem hosszabbítanának. Csaknem 2400, a mezoteliómához köthető halálesetet\nregisztrált az Európai Unió statisztikai hivatala 2021-ben. Hétfőn és kedden\nAI Summit BUDAPEST címmel kétnapos rendezvénysorozatot szervez az Indamedia a\nMagyar Zene Házában és a Néprajzi Múzeumban. A konferencia célja, hogy az\nérdeklődők...\n\n'}, {'url': 'https://engage-ai.co/hu/the-top-10-generative-ai-trends-for-2024/', 'content': 'A mesterséges intelligencia (AI) továbbra is átalakító erő a különböző\niparágakban. Ahogy belépünk 2024-be, és azután is, több trend is készen áll\narra, hogy átformálja az AI-t, izgalmas lehetőségeket és összetett kihívásokat\nkínálva. Ez a cikk a 10-ben és 2024-ben várhatóan uralkodó 2025 AI-trendet\ntárgyalja, ideértve a fejlett természetes nyelvi feldolgozást, a generatív\nellenséges hálózatokat, az etikus mesterséges intelligenciát, a\ntartalomkészítést, a személyre szabást, a szintetikus média mélyhamisításokat\nés még sok mást. Ezenkívül megvizsgáljuk, hogy az Engage AI hol illeszkedik\nehhez a fejlődő környezethez, és hogyan segítheti a CrunchGrowth a\nvállalkozásokat az AI hatékony kihasználásában. A Natural Language Processing\n(NLP) figyelemre méltó fejlődésen ment keresztül, lehetővé téve a gépek\nszámára, hogy egyre pontosabban megértsék, értelmezzék és generálják az emberi\nnyelvet. 2024-ben és 2025-ben az NLP várhatóan még kifinomultabb lesz,\nköszönhetően a továbbfejlesztett algoritmusoknak és a nagyobb\nadatkészleteknek. Ez a fejlődés javítani fogja a gépi fordítást, a\nhangulatelemzést és a társalgási AI-képességeket, így az AI-val való\ninterakció intuitívabb és emberszerűbb lesz. Ezen túlmenően, az NLP\nintegrálása más AI-technológiákkal zökkenőmentesebb és kontextustudatosabb\nalkalmazásokat tesz lehetővé. Például az AI-alapú virtuális asszisztensek és\nchatbotok személyre szabottabb és kontextus szempontjából relevánsabb\nválaszokat kínálnak, javítva a felhasználói élményt a különböző platformokon.\nA generatív ellenséges hálózatok (GAN-ok) forradalmasították a mesterséges\nintelligencia területét, lehetővé téve rendkívül valósághű szintetikus adatok\nlétrehozását. A GAN két neurális hálózatból áll – egy generátorból és egy\ndiszkriminátorból –, amelyek egymással versengve egyre pontosabb eredményeket\nprodukálnak. 2024-ben és 2025-ben a GAN-ok tovább fejlődnek, olyan területeken\nvezetve az innovációkat, mint a kép- és videókészítés, az adatbővítés és a\ngyógyszerkutatás. A GAN-ok várhatóan jelentős szerepet játszanak majd a\nkreatív iparágakban is, ahol művészetet, zenét és egyéb médiaformákat\ngenerálhatnak. Ez a technológiai fejlődés azonban a visszaélések elleni\nküzdelem kihívásával jár, különösen a mélyhamisítások és más megtévesztő\ntartalmak létrehozása során. Ahogy az AI egyre elterjedtebbé válik, egyre\nfontosabbá válik a etikus AI nem lehet túlbecsülni. Az etikus mesterséges\nintelligencia átlátható, tisztességes és elszámoltatható AI-rendszerek\nfejlesztését és telepítését foglalja magában. 2024-ben és 2025-ben fokozott\nfigyelmet fordítanak majd annak biztosítására, hogy az AI-technológiák ne\ntartsák fenn az elfogultságokat és ne okozzanak károkat. A szervezetek egyre\ngyakrabban alkalmaznak etikus mesterséges intelligencia kereteket és\niránymutatásokat az AI használatának szabályozására. Ez magában foglalja a\nrendszeres auditok elvégzését, az adatvédelem biztosítását és a sokszínűség\nelőmozdítását az AI-fejlesztő csapatokban. Ezenkívül a szabályozó testületek\nvalószínűleg szigorúbb előírásokat vezetnek be az AI-technológiák felelős\nhasználatának biztosítása érdekében. Az AI célja, hogy forradalmasítsa a\ntartalomkészítést azáltal, hogy automatizálja és javítja a kreatív folyamat\nkülönböző aspektusait. A mesterséges intelligencia által vezérelt eszközök\nnélkülözhetetlenné válnak a tartalomkészítők számára, a szövegek, képek és\nvideók generálásától a zenealkotás segítéséig. 2024-ben és 2025-ben\nkifinomultabb mesterséges intelligencia-rendszereket fogunk látni, amelyek\nképesek megérteni a kontextust, a hangnemet és a stílust, így értékes eszközt\njelentenek a kiváló minőségű tartalom előállításában. A mesterséges\nintelligencia a személyre szabott tartalomkészítést is megkönnyíti, lehetővé\ntéve a marketingesek számára, hogy üzeneteiket az egyéni preferenciákhoz és\nviselkedéshez szabják. Az ilyen szintű testreszabás fokozza az\nelkötelezettséget és jobb eredményeket eredményez a vállalkozások számára. A\nszemélyre szabás kulcsfontosságú trend, amelyet a mesterséges intelligencia az\nelkövetkező években tovább fog erősíteni. A mesterséges intelligencia és a\ngépi tanulási algoritmusok kihasználásával a vállalkozások rendkívül személyre\nszabott vásárlói élményt nyújthatnak, beleértve az ajánlásokat, a célzott\nhirdetéseket és a testreszabott felhasználói felületeket. Az adatelemzésnek és\na felhasználói profilalkotásnak köszönhetően a mesterséges intelligencia által\nvezérelt személyre szabás 2024-ben és 2025-ben pontosabbá és hatékonyabbá\nválik. Azok a vállalkozások, amelyek ezt a trendet követik, erősebb\nkapcsolatokat építhetnek ki ügyfeleikkel, és javíthatják az ügyfelek\nelégedettségét. A szintetikus médiák, beleértve a mélyhamisításokat is,\njelentős figyelmet kaptak annak köszönhetően, hogy képesek hiperrealisztikus\ndigitális tartalmat létrehozni. Míg a szintetikus média kreatív lehetőségeket\nkínál, a félretájékoztatással és a magánélet megsértésével kapcsolatos\nkockázatokat is rejt magában. 2024-ben és 2025-ben előrelépést fogunk látni a\nszintetikus adathordozók létrehozása és észlelése terén. A mélyhamisítások\nelleni küzdelem technológiái kifinomultabbak lesznek, segítve a rosszindulatú\ntartalmak azonosítását és hatásainak mérséklését. AI-vezérelt eszközöket\nfejlesztenek ki a szintetikus adathordozók finom anomáliáinak észlelésére,\nbiztosítva a digitális tartalom hitelességét. A mesterséges intelligencia\negészségre gyakorolt \u200b\u200bhatása mélyreható, és folyamatosan növekszik. 2024-ben\nés 2025-ben az AI kulcsfontosságú szerepet fog játszani a diagnosztikában, a\nszemélyre szabott orvoslásban és a kezelés tervezésében. A gépi tanulási\nalgoritmusok hatalmas mennyiségű orvosi adatot fognak elemezni, hogy\nazonosítsák a mintákat, és betekintést nyújtsanak a betegek kimenetelének\njavítása érdekében. A mesterséges intelligencia által működtetett\ndiagnosztikai eszközök segítenek az egészségügyi szakembereknek a betegségek\nkorai szakaszában történő felismerésében, ami hatékonyabb kezelést eredményez.\nEzenkívül az AI javítani fogja a gyógyszerkutatási folyamatokat, felgyorsítja\naz új terápiák fejlesztését és csökkenti a költségeket. Az éghajlatváltozás\nkezelése korunk egyik legsürgetőbb kihívása, és a mesterséges intelligencia\njelentős szerepet fog játszani ebben az erőfeszítésben. 2024-ben és 2025-ben\nmesterséges intelligencia technológiákat alkalmaznak a környezeti változások\nnyomon követésére, az energiafogyasztás optimalizálására és a fenntartható\nmegoldások kidolgozására. A mesterséges intelligencia által vezérelt modellek\nsegítenek előre jelezni az éghajlati mintákat, felmérni a különböző\nbeavatkozások hatását, és irányítani a politikai döntéseket. Ezen túlmenően a\nmesterséges intelligencia segíteni fog a megújuló energiatechnológiák\nfejlesztésében, javítva azok hatékonyságát és méretezhetőségét. Az autonóm\nrendszerek, beleértve az önvezető autókat és a drónokat, 2024-ben és 2025-ben\negyre elterjedtebbé válnak. A mesterséges intelligencia és a\nszenzortechnológiák fejlődése lehetővé teszi, hogy ezek a rendszerek bonyolult\nkörnyezetben navigáljanak, és nagyobb autonómiával és biztonsággal hajtsanak\nvégre feladatokat. Az autóiparban az önvezető autók tovább fognak fejlődni, a\ntovábbfejlesztett mesterséges intelligencia algoritmusok pedig javítják valós\nidejű döntéshozatali képességüket. Hasonlóképpen, a drónokat különféle\nalkalmazásokhoz fogják használni, a szállítási szolgáltatásoktól a környezeti\nmegfigyelésig. Ahogy a kiberfenyegetések egyre kifinomultabbak, az AI-vezérelt\nkiberbiztonsági megoldások elengedhetetlenek lesznek a digitális eszközök\nvédelmében. 2024-ben és 2025-ben az AI-t a kiberfenyegetések valós időben\ntörténő észlelésére és reagálására fogják használni, proaktív védelmet nyújtva\na támadásokkal szemben. A gépi tanulási algoritmusok elemzik a hálózati\nforgalmat, azonosítják az anomáliákat, és előre jelzik a lehetséges biztonsági\nmegsértéseket. Ezenkívül az AI segítséget nyújt az incidensekre adott válaszok\nautomatizálásában, csökkentve a kiberfenyegetések mérsékléséhez szükséges időt\nés erőfeszítést. Az Engage AI élen jár az AI-technológiák kihasználásában,\nhogy fokozza az ügyfelek elkötelezettségét és az üzleti műveleteket. A fejlett\nmesterségesintelligencia-megoldások integrálásával az Engage AI segít a\nvállalkozásoknak személyre szabott élmények nyújtásában, javítja a\ntartalomkészítést, és biztosítja az etikus mesterséges intelligencia\ngyakorlatát. Az Engage AI eszközeit úgy tervezték, hogy kihasználják az NLP, a\nGAN és más mesterséges intelligencia technológiák erejét az innováció és a\nhatékonyság előmozdítása érdekében. CrunchGrowth arra specializálódott, hogy\nsegítsen a vállalkozásoknak eligazodni az AI megvalósításának összetettségei\nközött. Szakértői csapatunk segíthet Önnek az üzleti igényeinek leginkább\nmegfelelő AI-technológiák azonosításában, egyedi AI-megoldások kidolgozásában,\nvalamint a meglévő rendszerekkel való zökkenőmentes integráció biztosításában.\nAkár a személyre szabást, akár a tartalomkészítést, akár a kiberbiztonságot\nkívánja javítani, a CrunchGrowth rendelkezik azzal a szakértelemmel, hogy\nelőremozdítsa mesterségesintelligencia-kezdeményezéseit. A CrunchGrowth-tal\negyüttműködve kihasználhatja az élvonalbeli AI-trendeket, hogy a versenytársak\nelőtt maradjon, és elérje üzleti céljait. Átfogó megközelítésünk magában\nfoglalja a stratégiai tervezést, a műszaki fejlesztést és a folyamatos\ntámogatást, hogy AI-projektjei maximális értéket nyújtsanak. Ahogy haladunk\n2024-ben és 2025-ben, az AI környezete tovább fog fejlődni, új lehetőségeket\nés kihívásokat kínálva. Azáltal, hogy tájékozott marad a legújabb trendekről,\nvalamint etikus és hatékony mesterségesintelligencia-gyakorlatokat alkalmaz, a\nvállalkozások teljes mértékben kihasználhatják az AI-ban rejlő lehetőségeket\naz innováció és a növekedés ösztönzésére. Az Engage AI és a CrunchGrowth\nvégigvezeti Önt ezen az átalakuló úton, biztosítva, hogy AI-kezdeményezései\nsikeresek és hatásosak legyenek. A mesterséges intelligencia (AI) megjelenése\nalapvetően átalakítja a tesztautomatizálás világát. A történelem során a\ntesztautomatizálás nagymértékben támaszkodott előre meghatározott szkriptekre\nés statikus tesztesetekre, amelyek kézi frissítéseket igényelnek a szoftver\nfejlődésével. Az AI azonban egy dinamikus, intelligens megközelítést vezet be,\namely nemcsak felgyorsítja a tesztelést, hanem pontosabb, adaptívabb\nfolyamatokat is lehetővé tesz, amelyek magával a szoftverrel együtt fejlődnek.\nAz AI azon képessége, hogy tanuljon a mintákból és a korábbi\nteszteredményekből, ideális megoldást jelent olyan összetett, ismétlődő vagy\nnagyszabású tesztelési forgatókönyvek kezelésére, amelyek egyébként jelentős\nemberi beavatkozást igényelnének. A mesterséges intelligencia és a\ntesztautomatizálás metszéspontja a szabályalapú automatizálásról az\nadatvezérelt, önjavító rendszerekre való elmozdulást jelent, amelyek képesek\nelőre jelezni a problémákat, alkalmazkodni a változásokhoz, és mélyebb\nbetekintést nyújtani a szoftverek minőségébe. Ebben a cikkben megvizsgáljuk,\nhogyan alakítja át a mesterséges intelligencia a tesztautomatizálást, és\nmegvizsgáljuk az iparágat forradalmasító speciális technikákat és eszközöket.\nAzt is megvizsgáljuk, hogy az AI hogyan befolyásolja a tesztelők szerepét,\nmilyen kihívásokat és etikai megfontolásokat hoz, és mit hoz a mesterséges\nintelligencia által vezérelt tesztelés jövője. A cél az, hogy ne csak\nkiemeljük az AI jelenlegi hatását, hanem előre jelezzük, hogyan fogja\nfolyamatosan fejleszteni a szoftvertesztelés gyakorlatát. Hagyományos\ntesztautomatizálás: kihívások és korlátok A hagyományos tesztautomatizálás a\nkézi teszteléssel összehasonlítva hatékonysága ellenére már régóta tele van\nkorlátokkal. Lényegében a hagyományos automatizálás szabályalapú, vagyis előre\nmeghatározott szkriptektől függ, amelyeket karban kell tartani és frissíteni\nkell minden alkalommal, amikor a szoftverben változás történik. Ez a\ntörékenység egy elemét vezeti be, ahol a felhasználói felületen (UI) vagy a\nfunkcionalitásban még kisebb változtatások is a tesztek megszakadását\nokozhatják, ami folyamatos karbantartást tesz szükségessé. Az egyik gyakran\nfigyelmen kívül hagyott kihívás az alkalmazkodóképesség hiánya. A hagyományos\nautomatizálás nem tud „tanulni” a korábbi tesztvégrehajtásokból, és nem tud\nelőre látni olyan új tesztelési forgatókönyveket, amelyek a szoftver\nviselkedésének fejlődése miatt merülhetnek fel. Ennek eredményeként az\nautomatizált tesztek általában figyelmen kívül hagyják azokat a szélső\neseteket és anomáliákat, amelyek kívül esnek a keményen kódolt paramétereken.\nEzen túlmenően, míg a szkriptek hatékonyan képesek kezelni az ismétlődő\nfeladatokat, nem tudnak intelligensen alkalmazkodni a szoftverfejlesztés során\nfelmerülő, előre nem látható problémákhoz. Egy másik korlát az erőforrások\nfelhasználásában rejlik. A tesztszkriptek írása és karbantartása jelentős\nemberi felügyeletet igényel, és nagy projektekben a tesztesetek puszta\nmennyisége nehézkessé válhat. A szoftver bonyolultságának növekedésével az\nautomatizált tesztcsomagok karbantartásának ideje és költsége gyakran\nmeghaladja az előnyöket. A merevség, a magas karbantartási költségek és az\nadatokból való tanulás képtelensége néhány olyan kritikus fájdalompont, amely\narra késztette az ipart, hogy az AI-vezérelt megoldások felé forduljon a\ntesztautomatizálás javítása érdekében. Hogyan javítja a mesterséges\nintelligencia a tesztautomatizálást? A mesterséges intelligencia számos\nátalakító képességet vezet be az automatizálás tesztelésére, megválaszolva a\nhagyományos módszerekkel kapcsolatos számos kihívást. Az egyik legjelentősebb\nfejlesztés az intelligens teszteset-generálás koncepciója. Az előre definiált\nszkriptekkel ellentétben az AI-algoritmusok képesek elemezni az alkalmazás\nviselkedését, és önállóan teszteseteket generálni. Ez a képesség lehetővé\nteszi, hogy a tesztek a forgatókönyvek szélesebb körét lefedjék, beleértve a\nszélső eseteket is, amelyek általában észrevétlenek maradnak. Egy másik fontos\nelőny az öngyógyító tesztek automatizálása. A hagyományos szkriptek\nmegszakadnak, ha a szoftver felhasználói felületén változások következnek be,\nde az AI-alapú rendszerek automatikusan észlelik ezeket a változásokat, és\nalkalmazkodnak hozzájuk. Például, ha egy gomb címkéje megváltozik, a\nmesterséges intelligencia továbbra is képes azonosítani az elemet viselkedése\nvagy helyzete alapján, csökkentve a szkriptek folyamatos frissítésének\nszükségességét. Ez az öngyógyító mechanizmus drasztikusan lerövidíti a\nkarbantartási időt és növeli a teszt megbízhatóságát. A mesterséges\nintelligencia prediktív elemzést is visz a tesztelésbe. A korábbi adatok\nelemzésével a mesterséges intelligencia meg tudja jósolni, hogy az alkalmazás\nmely részei hibáznak a legnagyobb valószínűséggel, így a tesztelők prioritást\nadhatnak erőfeszítéseiknek a magas kockázatú területeken. Ez nemcsak a\nhatékonyságot javítja, hanem segít a hibák felderítésében is, mielőtt azok\nsúlyosbodnának, minimalizálva a projektre gyakorolt \u200b\u200blehetséges hatást.\nEzenkívül a mesterséges intelligencia beépítése a szoftverteszt-\nautomatizálásba javítja a tesztelés minőségét azáltal, hogy folyamatosan\nfejlődik és tanul az egyes tesztciklusokból. Ez az adaptív jelleg biztosítja,\nhogy a tesztek mindig relevánsak legyenek, és a szoftverek érésével\nfolyamatosan javítják hatékonyságukat. AI-alapú eszközök a\ntesztautomatizáláshoz Az AI-t egyre gyakrabban integrálják számos olyan\neszközbe, amelyek célja a tesztautomatizálás javítása. Ezek az eszközök a gépi\ntanulást, a számítógépes látást és más mesterséges intelligencia technikákat\nalkalmaznak hatékonyabb és rugalmasabb tesztelési környezetek létrehozására.\nEszköz AI-képességek AI-képességek Használati eset Használati eset Tesztim\nÖngyógyító tesztszkriptek; intelligens tesztkészítés Öngyógyító\ntesztszkriptek; intelligens tesztkészítés Folyamatos integráció; UI tesztelés\nFolyamatos integráció; UI tesztelés Applitools Eyes Vizuális anomáliák\nészlelése mesterséges intelligencián keresztül Vizuális rendellenességek\nészlelése AI segítségével Automatikus vizuális tesztelés; böngészők közötti\ntesztelés Automatikus vizuális tesztelés; böngészők közötti tesztelés\nFunkcionalizálás Természetes nyelvi tesztkészítés; öngyógyító tesztek\nTermészetes nyelvi teszt készítés; öngyógyító tesztek Funkcionális tesztelés;\nvégpontok közötti automatizálás Funkcionális tesztelés; végpontok közötti\nautomatizálás BlazeMeter Gépi tanulás a terhelés és a teljesítmény\nelőrejelzéséhez Gépi tanulás a terhelés és a teljesítmény előrejelzéséhez\nTeljesítményteszt; terhelésszimuláció Teljesítményvizsgálat;\nterhelésszimuláció Mabl Automatizált tesztgenerálás;vizuális és funkcionális\ntesztelés Automatikus tesztgenerálás;vizuális és funkcionális tesztelés\nRegressziós tesztelés; webes alkalmazások Regressziós tesztelés; webes\nalkalmazások Copy to Clipboard Tool, Testim, Applitools Eyes, Functionize,\nBlazeMeter, Mabl AI Capabilities, Self-healing teszt szkriptek; intelligens\ntesztkészítés, vizuális anomáliák észlelése mesterséges intelligencia\nsegítségével, természetes nyelvű tesztkészítés; öngyógyító tesztek, Gépi\ntanulás a terhelés és a teljesítmény előrejelzéséhez, Automatizált\ntesztgenerálás;vizuális és funkcionális tesztelés Használati eset, Folyamatos\nintegráció; UI tesztelés, Automatizált vizuális tesztelés; böngészők közötti\ntesztelés, Funkcionális tesztelés; végponttól végpontig automatizálás,\nTeljesítményteszt; terhelés szimuláció, regressziós tesztelés; webalkalmazások\nEzek az eszközök csak néhány példa arra, hogy az AI már most is átalakítja a\ntesztelési folyamatokat. Az Applitools Eyes például mesterséges intelligencia\nsegítségével utánozza az emberi látást vizuális ellenőrzés céljából,\nazonosítva azokat a felhasználói felületi hibákat, amelyeket a hagyományos\neszközök nehezen tudnának észlelni. Eközben a Functionize lehetővé teszi a\ntesztelők számára, hogy egyszerű angol nyelven írják le a teszteket,\ntermészetes nyelvi feldolgozást használva, hogy ezeket a parancsokat\nvégrehajtható szkriptekké fordítsák le. Az AI-alapú eszközök kihasználásával a\ncsapatok csökkenthetik a karbantartási terheket, növelhetik a tesztek\nlefedettségét, és optimalizálhatják a tesztelési munkafolyamatokat, miközben\nmegőrzik a magas szintű minőségbiztosítást. A mesterséges intelligencia hatása\na tesztelők szerepére Az AI térnyerése a szoftvertesztek automatizálásában\nnemcsak a tesztek végrehajtásának módját alakítja át, hanem újradefiniálja\nmaguknak a tesztelőknek a szerepét is. Ma az AI mindenhol jelen van. Ebben a\nmodernizált világban a mesterséges intelligenciát minden tevékenységének\nfokozására használhatja. Más szóval, az emberek a mesterséges intelligencia\nmellett döntenek a hatékonyabb munkavégzés érdekében. Ebből a bejegyzésből\nmegtudhatja, hogyan használhatja az AI/Chat GPT-t a LinkedIn-en, hogy\neredményeket érjen el 2024-ben. A LinkedIn, mint tudod, napjaink legnépszerűbb\nplatformja a vállalati ismeretek megszerzésére. Az Ön LinkedIn-profilja az Ön\nfront-end ügynökeként működik, hogy felvegye Önt a legjobb állásra, és\nmegkeresse a legjobb jelölteket az Ön által kínált munkakörre. Tehát olyan\nstratégiákat keres, amelyekkel problémamentesen optimalizálhatja LinkedIn-\nprofilját és tartalmát? Ne keressen tovább, mint a Chat GPT. Ez a bejegyzés\ntökéletes útmutató ahhoz, hogy megértse a Free Chat GPT módszereit, és hogyan\noptimalizálja a LinkedIn-t. A LinkedIn optimalizálásának módjai Chat GPT-n\nkeresztül A következő három módszerrel optimalizálhatja a LinkedIn-t Chat\nGPT-n keresztül: A Chat GPT használata LinkedIn-üzenetekhez A LinkedIn egy\nközösségi hálózati platform, amely több mint 875 millió professzionális\nprofilt tartalmaz. Emiatt lehetőséged nyílik milliókkal kapcsolatba lépni.\nMásodszor, az álláskereséstől a személyes márka fenntartásáig minden\nlehetséges ezen a platformon keresztül. A LinkedIn összekapcsolhatóságának\nlényege az üzenetküldés. Ezek az üzenetek a kommunikáció és az elköteleződés\nelsődleges eszközei. A világos, átgondolt és lenyűgöző üzenetek küldése\nsegíthet abban, hogy kitűnjön a profilok tengerében, és maradandó benyomást\nkeltsen kapcsolataiban. A professzionalizmus és a személyre szabottság közötti\nmegfelelő egyensúlyt megteremtő tökéletes üzenet megalkotása azonban kihívást\njelenthet. Ez az a hely, ahol a ChatGPT értékes eszközként jelenik meg. A\nChatGPT segítségével személyre szabott LinkedIn-üzeneteket hozhat létre. Ezek\naz üzenetek nemcsak a szándékotokat közvetítik, hanem a címzettben is\nrezonálnak, növelve a pozitív válasz valószínűségét. Szakmai üzenet\nösszeállításához a következő lépéseket kell követnie: Válasszon profilt: Ki\nkell választania egy profilt, amelyre üzenetet szeretne küldeni. Ezután\ngyőződjön meg arról, hogy a felhasználó szakmai útja beszél Önhöz, vagy\nmegfelel az Ön ICP-jének. Információk másolása: A profil kiválasztása után ki\nkell másolnia a készségeket, a munkatapasztalatot, az érdeklődési kört és az\nösszes kapcsolódó információt a profiljukból. Illessze be a ChatGPT-be:\nIllessze be az összes információt a Chat GPT prompt mezőjébe, és írja be a\nhideg üzenetötleteket. Válassza ki a legjobbat: Most a Chat GPT több hideg\nüzenetet küld a LinkedIn számára. Mindet el kell olvasnia, és ki kell\nválasztania azt, amelyik a leginkább vonz. Küldés: A megfelelő kiválasztása\nután illessze be az üzenet mezőbe, küldje el a kiválasztott felhasználói\nprofilba, és várja meg a pozitív választ! A Chat GPT használata a LinkedIn-\nprofil optimalizálásához A láthatóság leglényegesebb eleme az optimalizálás. A\njól optimalizált profil segíthet kitűnni, és több esélyt szerezni. A ChatGPT\nsegítségével javíthatja LinkedIn-profilját, hogy az vonzó és hatékony legyen.\nKészítsen erős címsort: A címsor az egyik első dolog, amit az emberek látnak.\nA ChatGPT segíthet erős címsor létrehozásában, amely felkelti az emberek\nfigyelmét, és sok kulcsszót használ. Írjon meggyőző összefoglalót: Egy jó\nösszefoglaló gyorsan és oly módon meséli el történetét, hogy felkeltse az\nemberek érdeklődését. A ChatGPT segítségével összefoglalót írhat, amely\nbemutatja készségeit, munkahelyi céljait és eredményeit. Ez vonzóbbá teheti\nprofilját a kapcsolattartók és a toborzók számára. Személyre szabott\ntapasztalatok rovat: A tapasztalatok rovatának kiemelnie kell legfontosabb\nszerepeit és eredményeit. Sikeresen összefoglalhatja munkaköri feladatait a\nChatGPT segítségével. Bonyolult munkaköri leírásokat igényelhet, és azokat\negyszerű, erőteljes nyilatkozatokká alakíthatja, amelyek megmutatják, mit hoz\naz asztalra. A készségek és ajánlások optimalizálása: Fontos, hogy megmutassa\na megfelelő készségeket. A ChatGPT segíthet a megpályázott állás szempontjából\nreleváns készségekkel bővíteni, így könnyebben megtalálhatja önéletrajzát, és\nösszhangban van a jelenlegi iparági trendekkel. Kapcsolódási kérések\ntestreszabása: Fontos, hogy személyre szabott üzeneteket küldjön az új\nkapcsolatoknak, amikor kapcsolatba kíván lépni velük. A ChatGPT segíthet\negyedi kapcsolódási kérelmek létrehozásában, amelyek azt mutatják, hogy\ntörődik vele, ami növeli az elfogadás esélyét. Az álláspályázati üzenetek\njavítása: Minél személyre szabottabb a feljegyzés, annál nagyobb az esélye az\nállás megszerzésére. A ChatGPT segíthet olyan professzionális üzenetek\nmegírásában, amelyek felkeltik a toborzók vagy a munkaerő-felvételi vezetők\nfigyelmét. Röviden, a ChatGPT segíthet egy LinkedIn-profil létrehozásában,\namely bemutatja legjobb üzleti énjét, miközben időt takarít meg. Kezdje el\nazonnal javítani profilját, hogy kihasználhassa az új lehetőségeket. Használja\na Chat GPT-t LinkedIn-bejegyzésekhez Ahhoz, hogy üzleti hálózatát kiépítse és\nmegmutassa képességeit, meg kell győződnie arról, hogy LinkedIn-bejegyzései\nérdekesek. De nehéz lehet új, érdekfeszítő tartalmat kitalálni. Itt a ChatGPT\nsegíthet olyan bejegyzések megírásában, amelyek jó minőségűek és kiemelkednek.\nEzek a bejegyzések arra késztetik az embereket, hogy értelmes módon lépjenek\nkapcsolatba Önnel. Beszéljen a legújabb iparági trendekről A ChatGPT\nsegítségével bejegyzéseket írhat a területe legújabb trendjeiről és\nfejlesztéseiről. Egy jól átgondolt elemzéssel széleskörű tudással rendelkező\nszakemberré válhat, és beszélgetéseket kezdeményezhet hálózatán belül. Emelje\nki eredményeit Fontos, hogy megjelölje élete jelentős pillanatait, legyen szó\nszemélyes vagy üzleti vonatkozásúakról. A ChatGPT segítségével olyan\nbejegyzéseket írhatsz, amelyek alázatosak és büszkék az eredményeidre oly\nmódon, hogy a közönség megértse. Tippek és tanácsok Ha értékes tippeket vagy\nállásajánlatokat szeretne megosztani, a ChatGPT rövid és egyértelmű\nbejegyzéseket tud létrehozni. Gondoskodik arról, hogy üzenete jól strukturált\nlegyen, akár tanácsot ad, hogy hogyan érhet el többet, vagy hogyan léphet\nelőre a munkájában. Összegzés Összefoglalva, a Chat GPT képes optimalizálni\nLinkedIn-profilját, mint senki más. Tökéletes üzeneteket küldhet,\noptimalizálhatja profilját, és vonzó tartalmat tehet közzé, amely megragadja\nés bővíti hálózatát. Hasznosnak találta ezt az útmutatót? Fedezze fel az\nalapvető hideghívási tippeket, amelyek segítenek növelni értékesítési\nteljesítményét. A LinkedIn egy professzionális, üzletközpontú közösségi média\nplatform. Ez a cikk egy útmutató, amely segít a LinkedInben lévő\nvállalkozásoknak pontosan mérni ezeket a mutatókat. Az AI modellképzés egy\nszámítógépes program végrehajtásának folyamata az intelligencia megszerzésének\nlépésein. Íme néhány LinkedIn-statisztika és tény, amelyet a\ncégtulajdonosoknak tudniuk kell 2024-ben, hogy a legtöbbet hozhassák ki ebből\na platformból és fokozzák növekedésüket. Karrier Adatkezelési tájékoztató\nÁltalános szerződési feltételek Segítség Központ Esettanulmányok ChatGPT és AI\na LinkedIn-en Automatizálja és figyelje a kilátásokat Feature Requests\nLinkedIn Hashtag Analytics LinkedIn Hashtag Tend Widgetek Alkotó Grant Írja\nmeg nekünk\n\n'}, {'url': 'https://www.portfolio.hu/uzlet/20240420/a-mesterseges-intelligencia-betort-a-vallalati-vilagba-hogyan-hasznaljuk-a-generativ-ai-t-uzleti-kornyezetben-681691', 'content': 'AI in Business 2024 Az utolsó helyek még kiadók az AI in Business\nrendezvényen. Regisztráció itt! Információ... A keresett cikk a portfolio.hu\nhírarchívumához tartozik, melynek olvasása előfizetéses regisztrációhoz\nkötött. Cikkarchívum előfizetés Portfolio.hu teljes cikkarchívum Kötéslisták:\nBÉT elmúlt 2 év napon belüli kötéslistái Előfizetés Már előfizetőnk vagy?\nBejelentkezés\n\n'}, {'url': 'https://economaniablog.hu/2024/09/23/a-gen-ai-forradalom-munkapiaci-kovetkezmenyei-es-az-adatvedelem-egyensulya/', 'content': 'Economania blog Economania blog Az elmúlt egy évben jelentős technológiai\náttörés történt a generatív mesterséges intelligencia (gen AI)\nalkalmazásokban. A gen AI egy olyan számítógépes technológia, amely új\ndolgokat, például képeket, szövegeket vagy zenéket állít elő, tanulva a\nmeglévő példákból. Egyszerűen fogalmazva, a számítógépnek mutatunk sok rajzot,\nés a rajzok mintázatai alapján megtanítjuk saját rajzok készítésére konkrét\ninstrukciók alapján, hogy mit ábrázoljon és milyen stílusban. A legismertebb\nés leggyorsabban berobbanó generatív mesterséges intelligencia alkalmazás a\nchatGPT. Mire jó a chatGPT? – merülhet fel a kérdés bárkiben. A kérdés\nmegválaszolására megkértem magát az alkalmazást; így fogalmazott: „A ChatGPT\negy barátságos, éjjel-nappal működő asszisztens, amely segíthet az írásban, a\ntanulásban, a problémák könnyed megoldásában, a napi feladatokat könnyebbé és\nhangulatosabbá téve.” A chatGPT tudása ennél a mondatnál jóval szélesebb körű,\nnem hátrál meg és pár másodperc alatt válaszol a jóval komplikáltabb\nkérdésekre is. A generatív mesterséges intelligencia alkalmazások gyors\nelterjedése drámai hatással volt az élet különböző területeire. Ennek\napropóján a Bank of International Settlement (BIS) friss publikációja a gen AI\nalkalmazások amerikai háztartásokra gyakorolt \u200b\u200bhatásaival foglalkozik,\nkülönös tekintettel a munkalehetőségekre, a bizalom szintjére és a\nszabályozási keretek szükségességére. A BIS tanulmánya a Federal Reserve Bank\nof New York Fogyasztói Várakozások Felméréséből (Survey of Consumer\nExpectations, SCE) származó adatok felhasználásával készült, és részletes\nelemzést ad arról, hogy a különböző demográfiai csoportok hogyan lépnek\nkapcsolatba a gen AI-val, és hogyan érzékelik annak hatásait életükre. A\nFogyasztói Várakozások Felmérése havi rendszerességű reprezentatív felmérés az\namerikai háztartások várakozásairól. Különféle gazdasági folyamatokról és\ndemográfiai adatokról gyűjt információkat, értékes betekintést nyújtva a\nháztartások várakozásaiba és viselkedésébe. A rendszeres felméréseket a NY Fed\nnemrégiben egy plusz modullal bővítette, amely kérdések a mesterséges\nintelligenciával kapcsolatos ismereteket mérik fel, információt nyújtva az\namerikai háztartások AI használatáról, az AI-nak a munkalehetőségekre\ngyakorolt \u200b\u200bészlelt és várt hatásairól, az adatbiztonsági és használati\nbizalmi kérdésekről és a szabályozási igényekről. Az SCE adatai azt mutatják,\nhogy az amerikai háztartások csaknem fele használt mesterséges intelligencia\neszközöket az elmúlt évben. Ilyen eszköznek minősült például a ChatGPT, a\nGoogle Bard vagy a DALL-E. A használat demográfiai csoportonként jelentősen\neltér. A férfiak, a fiatalabb válaszadók és a magasabb jövedelmű vagy iskolai\nvégzettségűek nagyobb valószínűséggel használják a gen AI-t. Például a férfiak\n50 százaléka számolt be gen AI használatáról, míg a nők 37 százaléka.\nHasonlóképpen, a főiskolai vagy magasabb végzettségűek 52 százaléka használja,\nszemben a diplomával nem rendelkezők 32 százalékával. A fiatalabb válaszadók\n(60 év alattiak) és a magasabb jövedelmű háztartások is magasabb használati\narányt mutattak. A válaszadók különféle célokra használják a gen AI-t,\nbeleértve a tanulást és képzést, a munkával kapcsolatos feladatokat és a\nszabadidős tevékenységeket. A felmérés azt mutatja, hogy a háztartások\ngyakrabban használják az AI-t tanulási és képzési célokra, munkával\nkapcsolatos feladatokra, valamint olyan tartalmak készítésére, mint az írás,\nrajzolás vagy videók előállítása. Azonban kevésbé hajlandóak a gen AI\nszolgáltatásokat pénzügyi vagy orvosi tanácsokért használni, ami az e\nterületeken megkövetelt nagyobb fokú emberekbe vetett bizalmat tükrözi. A\nfelmérés vegyes eredményekre világít rá a gen AI munkahelymegtartásra és\ntermelékenységre gyakorolt \u200b\u200bhatásával kapcsolatban. Bár a mesterséges\nintelligencia általában aggodalomra ad okot a munkahelyek megszűnése miatt, a\nfelmérés egyértelműen azt jelzi, hogy az összességében észlelt\nfoglalkoztatással kapcsolatos kockázat alacsony. A válaszadók mindössze 13\nszázalékos esélyt látnak arra, hogy a mesterséges intelligencia miatt\nelveszítsék jelenlegi állásukat. Ugyanakkor optimizmus van azzal kapcsolatban,\nhogy a gen AI növeli a termelékenységet. A válaszadók úgy vélik, hogy 30\nszázalék az esélye annak, hogy a gen AI növeli termelékenységüket és 27\nszázalékos a valószínűsége, hogy az AI elterjedése új munkalehetőségeket\nteremt. Meglepő módon minden demográfiai csoport alacsonynak tartja a\nmesterséges intelligencia miatti állásvesztés vagy bércsökkenés kockázatát. Az\nAI-ba vetett bizalom tevékenységenként és demográfiai csoportonként eltérő. A\nválaszadók általában jobban bíznak az emberekben, mint a mesterséges\nintelligenciában a bankolás, közszolgáltatások és egészségügyi\nszolgáltatásokat érintő tevékenységekben. Az AI-ba vetett bizalom az\noktatásban és az információs szolgáltatásokban a legmagasabb: itt a válaszadók\nközel annyira megbíznak a mesterséges intelligencia alkalmazásokban, mint a\nszakterületen jártas emberekben. Figyelemre méltó, hogy a nők szignifikánsan\nalacsonyabb AI-jal kapcsolatos bizalomról számolnak be, ez azonban\nösszefüggésben lehet az alacsonyabb használattal. Az adatvédelem komoly\naggodalomra ad okot a háztartások számára, kiemelve az adatszivárgások és\nvisszaélések kockázatát. A válaszadók túlnyomó többségben támogatják a\nmesterséges intelligencia szabályozását a személyes adatok védelme és az\netikus felhasználás biztosítása érdekében. Ez a meggyőződés minden demográfiai\ncsoportban konzisztens, hangsúlyozva a szilárd szabályozási keretek\nszükségességét. A BIS Bulletin cikke hiánypótló széleskörű felmérés, amely\nátfogó áttekintést ad a háztartások gen AI-jal kapcsolatos megítéléséről,\nkiemelve annak lehetséges előnyeit és kihívásait. Az aggodalmak ellenére a gen\nAI jelentős lehetőségeket kínál az innovációra, a hatékonyságra és a gazdasági\nnövekedésre. A döntéshozók számára fontos tanulság, hogy elkerülhetetlen a\nkiegyensúlyozott szabályozás, amely elősegíti az innovációt, miközben védi a\nközérdeket. A bizalommal kapcsolatos problémák megoldásával és átgondolt\nszakpolitikai döntésekkel a társadalom kiaknázhatja a mesterséges\nintelligenciában rejlő lehetőségeket az életminőség javítása és a\ntermelékenység növelése érdekében. Az AI oktatásban, tanulásban és képzésben\ntörténő használata iránti bizalom felkészítheti a munkaerőt a mesterséges\nintelligenciával integrált jövőre, biztosítva, hogy a társadalom profitáljon\nebből a technológiai fejlődésből. Lehmann Kristóf Az írás megjelent a vg.hu\nvélemény rovatában is. Borítókép: a DeepAI képgenerátorával készítve View all\nposts by Lehmann Kristóf Hozzászólások letiltva. Subscribe now to keep reading\nand get access to the full archive. Type your email… Subscribe Continue\nreading\n\n'}, {'url': 'https://montazsmagazin.hu/hogyan-valtoztatja-meg-eletunket-a-mesterseges-intelligencia-2024-ben/', 'content': 'Válassza az Oldal lehetőséget Írta: admin | 2024. jan 8. | Életmód | 0 | Ahogy átlépünk a 2024-es évbe, a mesterséges intelligencia (AI) mindennapi életünkre gyakorolt hatása minden eddiginél erőteljesebbé válik. Az AI technológia gyorsan fejlődik, átformálja az iparágakat, befolyásolja döntéseinket, és még az életmódunkat is megváltoztatja. Az egészségügytől a szórakoztatásig, a közlekedéstől az oktatásig az AI befolyása mindenütt jelen van, és egyre növekszik. Ez a cikk azt vizsgálja meg, hogyan fogja megváltoztatni az AI az életünket 2024-ben. Azt külön érdemes megjegyezni, hogy amíg még csak a küszöbön állunk, addig a valóságban már ma is szerves része az életünknek a mesterséges intelligencia. Például a szerencsejáték weboldalak már ma is használják, biztosítva a játékosoknak a kiváló minőségű játékokat, a nagyobb biztonságot és a fejlett előrejelzéseket, ha például a sportfogadó oldalak világáról van szó. Az AI ugyanis képes elemezni a szerencsejáték mintákat és nagyobb pontossággal megjósolni az eredményeket. Ez segíti a szerencsejátékosok számára az érdekesebb játékélmény és a személyre szabott ajánlatok létrehozását. Az AI egyik legjelentősebb hatása 2024-ben az egészségügy területén lesz. Az AI algoritmusok ma már képesek a betegségek diagnosztizálására nagyobb pontossággal és gyorsasággal, mint sok emberi kolléga. Képesek orvosi képeket elemezni, mintákat azonosítani a betegadatokban, és megjósolni az egészségügyi kockázatokat. A mesterséges intelligencia által vezérelt személyes egészségügyi asszisztensek személyre szabott tanácsokat adhatnak, emlékeztethetik a betegeket a gyógyszerek szedésére, és akár mentális egészségügyi támogatást is nyújthatnak. A mesterséges intelligencia személyre szabott tanulási élményt nyújtva átalakította az oktatási tájképet. Az AI rendszerek képesek alkalmazkodni az egyéni tanulási stílusokhoz, tempóhoz és preferenciákhoz, személyre szabott forrásokat és tevékenységeket kínálva. Segítenek az osztályozásban is, így a tanároknak több idejük marad a diákok elkötelezettségére és a személyre szabott tanításra. A közlekedési ágazat a mesterséges intelligencia megjelenésével forradalomnak lehet tanúja. Egyre elterjedtebbek az önvezető, mesterséges intelligenciával feljavított autók, amelyek az emberi hibák okozta balesetek csökkentését ígérik. A mesterséges intelligencia optimalizálja a tömegközlekedési útvonalakat is, csökkenti a várakozási időt, és javítja a logisztikai és szállítási szolgáltatások hatékonyságát. A szórakoztatóipar a mesterséges intelligenciát a még magával ragadóbb és interaktívabb élmények létrehozására használja fel. Kiterjed például: ● A videojátékokban a mesterséges intelligenciát érzékeny, kihívást jelentő és adaptív játékkörnyezetek kialakítására használják ● A mesterséges intelligencia algoritmusok a streaming platformokon személyre szabott tartalmakat is összeállítanak. Ezzel pedig biztosítják, hogy sokkal személyre szabottabb legyen az élmény. Az AI automatizálja az ismétlődő feladatokat, ami a munkaerőpiacon változást eredményez. Miközben egyes munkakörök elavulnak, az AI új lehetőségeket is teremt olyan területeken, mint az AI etika, az adatelemzés és az AI rendszermenedzsment. A hangsúly a kreatívabb, stratégiai és összetettebb feladatok felé tolódik el, amelyeket az AI nem tud könnyen lemásolni. Az AI döntő szerepet játszik a mezőgazdaságban a növénytermesztés optimalizálásával és a pazarlás csökkentésével a pontos gazdálkodás révén. De még a környezetvédelemben is segít a vadvilág megfigyelésével, a természeti katasztrófák előrejelzésével és az éghajlati adatok elemzésével, amelynek segítségével jobb természetvédelmi stratégiákat lehet kidolgozni. A mesterséges intelligencia befolyásolja a társas interakciókat, így a virtuális mesterséges intelligenciával rendelkező társak egyre gyakoribbá válnak. Ezek a mesterséges intelligencia által vezérelt chatbotok és virtuális lények társaságot, beszélgetést és akár mentális egészségügyi támogatást is kínálhatnak. Ez azonban kérdéseket vet fel az emberi kapcsolatok természetével és azzal kapcsolatban is, hogy milyen mértékben támaszkodunk az AI-ra a szociális szükségletek kielégítésében. Mindazonáltal, ahogy a mesterséges intelligencia egyre inkább beépül az életünkbe, úgy nőnek a magánélet védelmével és a mesterséges intelligencia etikus felhasználásával kapcsolatos aggodalmak. Az AI rendszerek által gyűjtött hatalmas mennyiségű személyes adat felveti az adatbiztonság és a magánélet védelmének kérdéseit. SZPONZORÁLT TARTALOM Részvény: Arány: 2014. október 6. 2013. május 11. 2012. március 22. 2020. június 20. Weninger Endre: Híres magyar nők Weninger Endre: Magyar miniszterelnökök Elizabeth Weninger: Kölyökkorom kalandjai Montázsmagazin ajándékutalványa Elegant Themes által tervezett | Powered by WordPress A Montázs Magazin felhasználói élmény érdekében sütiket alkalmazunk. Itt találsz bővebb tájékoztatást: RÉSZLETEK. A Montázsmagazin című kulturális és életmód magazin számára kiemelt fontosságú cél a honlap látogatói által rendelkezésre bocsátott személyes adatok védelme, a látogatók információs önrendelkezési jogának biztosítása. A Montázsmagazin elkötelezi magát a látogatók személyes adatainak oly módon történő kezelése mellett, amely a vonatkozó hatályos jogszabályoknak teljes körűen eleget téve járul hozzá a látogatók biztonságos internetezési lehetőségeinek megteremtéséhez. Személyes adatok: A meglévő adatokat két évig őrizzük, majd megsemmisítjük. Kérésre előbb is. A Montázsmagazin leggyakoribb adatmegőrzési okai: pályázatok, antológiákba jelentkezés, kvízjátékok facebook-on, hírlevél (a jövőben). A Montázsmagazin a látogatók személyes adatait bizalmasan, a hatályos jogszabályi előírásokkal összhangban kezeli, gondoskodik azok biztonságáról, megteszi azokat a technikai és szervezési intézkedéseket, valamint kialakítja azokat az eljárási szabályokat, amelyek a vonatkozó jogszabályi rendelkezések és más ajánlások érvényre juttatásához szükségesek. Jelen Szabályzatban kinyilvánítjuk azokat az elveket, melyek meghatározzák a személyes adatok védelmével kapcsolatos elgondolásunkat és mindennapos gyakorlatunkat, bemutatjuk azokat a szolgáltatásokat, melyek során a honlap felhasználóitól személyes adatokat kérünk, nyilatkozunk továbbá arról, hogy milyen célra, és hogyan használjuk fel az ilyen jellegű adatokat, illetve hogyan biztosítjuk a személyes adatok megőrzését és védelmét. A Szabályzat kialakítása során figyelembe vettük a vonatkozó hatályos jogszabályokat, illetve a fontosabb nemzetközi ajánlásokat, különös tekintettel az alábbiakra: Amennyiben látogatóink közül bárki úgy érzi, hogy a jelen szabályzatban foglaltakon túlmenően további kérdése lenne, vagy problémája merülne fel, illetve olyan észrevételt tenne, amely a Szabályzat alapján számára nem, vagy nem teljesen egyértelmű, illetve magyarázatra szorul, kérjük, lépjen kapcsolatba a magazin tulajdonosával az alábbi e-mail címen: info@montazsmagazin.hu. Látogatóink kérése esetén a kérelemben foglaltaknak megfelelően minden esetben részletes tájékoztatást nyújtunk a kezelt személyes adatokról, az adatkezelés céljáról, jogalapjáról, időtartamáról és az adatkezeléssel összefüggő tevékenységről. Személyes adat akkor kezelhető, ha Az adatkezeléssel és a látogatók személyes adatainak a védelmével kapcsolatos előírások kizárólag a természetes személyekre vonatkoznak, tekintettel arra, hogy a személyes adatok is kizárólag természetes személyek vonatkozásában értelmezhetőek (a személyes adatok védelméről és a közérdekű adatok nyilvánosságáról szóló 1992. évi LXIII. tv. 2.§ 1. pont alapján), ezért jelen Nyilatkozat kizárólag természetes személyek személyes adatainak kezelése vonatkozásában bír kötelező erővel. A személyes adatok kezelésével kapcsolatos legfontosabb alapelvek a következők: Az adatkezelések megvalósítása előtt a szolgáltatónak - a jogszabályi előírások figyelembevételével - érthető és egyértelmű tájékoztatást kell közzé tennie az adatfelvétel módjáról, céljáról és - az adatszolgáltatás önkéntessége esetén - az önkéntes jelleg feltüntetéséről. Személyes azonosításra alkalmas adatokon, információn azokat a természetes személyekre vonatkozó személyes adatokat értjük, melyek segítségével valakit személyében azonosítani lehet, valakivel kommunikációs kapcsolatba lehet kerülni, vagy valakinek meg lehet határozni a fizikai elérhetőségét - ideértve, de nem korlátozva az alábbiakra: név, lakáscím, postacím, telefonszám, faxszám, e-mail cím, banki minősítés, társadalombiztosítási szám, adóhatósági azonosító, hitelkártya információ, ügyfélprofilok, biometrikus azonosítók. Nem minősülnek személyes adatnak azok az anonim információk, melyeket a személyes azonosíthatóság kizárásával gyűjtenek, és természetes személlyel nem hozhatóak kapcsolatba, illetve azok a demográfiai adatok sem minősülnek személyes adatnak, melyeket úgy gyűjtenek, hogy nem kapcsolják hozzá azokat azonosítható személyek személyes adataihoz, s ezáltal nem állítható fel kapcsolat természetes személlyel. Harmadik fél által - a szükséges hozzájárulás alapján - biztosított személyes adatokon azokat a személyes azonosításra alkalmas adatokat, információkat értjük, amelyek a szolgáltatást igénybe vevő személyre, azaz a látogatóra vonatkoznak, de azokat a szolgáltató a jogszabályi előírások megtartásával harmadik fél közreműködése során gyűjti és biztosítja. Általános elvként nyilvánítjuk ki, hogy minden olyan esetben, amikor személyes adatokat kérünk látogatóinktól, a szükséges tájékoztató szöveg elolvasása és értelmezése után szabadon dönthetnek arról, megadják-e a kért információkat. Meg kell azonban jegyeznünk, hogy amennyiben valaki nem adja meg személyes adatait, olykor előfordulhat, hogy nem tudja az adott, személyes adat megadásához kötött szolgáltatást igénybe venni. A Montázsmagazin semmilyen körülmények között nem gyűjt különleges adatokat, amelyek faji eredetre, nemzeti, nemzetiségi és etnikai hovatartozásra, politikai véleményre vagy pártállásra, vallásos vagy más meggyőződésre, egészségi állapotra, kóros szenvedélyre, szexuális életre, valamint büntetett előéletre vonatkoznak. Egyes szolgáltatásaink igénybevételéhez szükséges regisztráció során elemi demográfiai adatokat (kor, nem, lakóhely) is kérünk látogatóinktól. Az ilyen adatok például pályázatokra való jelentkezéskor, antológiáink küldéséhez szükségesek, harmadik fél számára nem szolgáltatjuk ki azokat. A magazin olvasói által biztosított személyes, illetve egyéb adatokat nem egészítjük ki, és nem kapcsoljuk össze más forrásból származó adatokkal vagy információval. Amennyiben a jövőben különböző forrásokból származó adatok ilyenfajta összekapcsolására kerülne sor, ezt a tényt kizárólag a megfelelő tájékoztatást követően, előzetesen adott hozzájárulás esetén tesszük meg. A rendelkezésünkre bocsátott személyes adatokat ez irányú felhatalmazás hiányában semmilyen körülmények között nem adjuk harmadik fél számára tovább. Amennyiben az arra feljogosított hatóságok a jogszabályokban előírt módon (bűncselekmény gyanújával, hivatalos adat lefoglalási határozatban) kérik fel személyes adatok átadására a Montázsmagazint, az a törvényi kötelezettségnek eleget téve átadja a kért és rendelkezésre álló információkat. Amennyiben látogatóink személyes adatokat bocsátanak a rendelkezésünkre, minden szükséges lépést megteszünk, hogy biztosítsuk ezeknek az adatoknak a biztonságát - mind a hálózati kommunikáció (tehát online adatkezelés) során, mind az adatok tárolása, őrzése (tehát offline adatkezelés) során. A személyes adatokhoz csak a magazin tulajdonosa és főszerkesztője férhet hozzá. A személyes adatok változtatása, törlése Ha bármelyik olvasónk vagy pályázónk kéri, hogy személyes adatait töröljük ki saját rendszerünkből (természetesen bizonyos esetben vállalva azt, hogy attól fogva nem, vagy nem olyan módon tudja igénybe venni azt a szolgáltatást, amelyhez ezek az adatok tartoztak), ezt haladéktalanul teljesítjük úgy, hogy az adatbázisainkból kitöröljük a megfelelő rekordokat. Anonim látogatóazonosító (cookie) elhelyezése Az anonim látogatóazonosító (cookie, süti) egy olyan egyedi - azonosításra, illetve profilinformációk tárolására alkalmas - jelsorozat, melyet a szolgáltatók a látogatók számítógépére helyeznek el. Fontos tudni, hogy az ilyen jelsorozat - tekintettel arra, hogy a felhasználása során a teljes IP cím tárolása nem történik meg - önmagában semmilyen módon nem képes az ügyfelet azonosítani, csak a gépének felismerésére alkalmas. Név, e-mail cím vagy bármilyen más személyes információ megadása nem szükséges, hiszen az ilyen megoldások alkalmazásakor a látogatótól a szolgáltató nem is kér adatot, az adatcsere voltaképpen gépek között történik meg. A hálózat világában a személyhez kötődő információkat, a testre szabott kiszolgálást csak akkor lehet biztosítani, ha a szolgáltatók egyedileg azonosítani tudják ügyfeleik szokásait, igényeit. A Montázsmagazin az ilyen személyes adatot már nem tartalmazó anonim azonosítókat- a többi szolgáltatóhoz hasonlóan - abból a célból kezeli, hogy többet tudhasson meg a partnerek információhasználati szokásairól, és így javíthassa szolgáltatásai színvonalát, valamint olvasóinak a honlap látogatása során testre szabott oldalakat, marketing (reklám) anyagokat jelentessen meg. Amennyiben nem szeretné, hogy ilyen azonosító jel kerüljön az Ön számítógépére, módja van a böngészőjét úgy beállítani, hogy az ne engedje meg az egyedei azonosító jel elhelyezését az Ön gépére (böngészőtől függően általában az eszközök menüben a beállítások/internet beállítások pontban). Ebben az esetben is igénybe veheti a szolgáltatásunkat, de bizonyos esetekben nem a legteljesebb mértékben. Naplóállományok elemzése A webes szolgáltatások használata során keletkező naplóállományok (logfile-ok) elemzése több szempontból is hasznos információkat nyújt a szolgáltatók számára. A naplóállományokban a szolgáltatást végző szerverek a látogatók által küldött kérésekről olyan adatokat rögzítenek, mint a kérést küldő számítógép dinamikus IP-címe, a használt böngésző típusa, a kérés ideje, a kért oldal címe stb. Az ilyen információk felhasználása kizárólag technikai célokra (szerverek biztonságos működésének elemzésére, utólagos ellenőrzésre) történik a Montázsmagazin által. Az így nyert adatsorokat személyes azonosításra alkalmas, más forrásból származó információkkal nem kapcsoljuk össze. Speciális ajánlatok küldése Regisztrációhoz, feliratkozáshoz kötött szolgáltatásaink területén az új ügyfeleinknek üzenetet küldünk, olykor a szolgáltatáshoz fontos információkat is. Ügyfeleink számára - hozzájárulásuktól függően - bizonyos időközönként tájékoztató célú körleveleket küldünk új szolgáltatásainkról, speciális ajánlatainkról stb. Amennyiben ügyfeleink nem akarják az ilyen promóciós leveleket a továbbiakban fogadni, bár korábban ehhez hozzájárulásukat adták, lemondhatják azokat ugyanolyan módon és csatornán keresztül, ahogy a szolgáltatás igénybevételét kezdeményezték. A Montázsmagazin a működésével összefüggésben direkt marketing céllal gyűjtött adatokkal kapcsolatban az alábbi tájékoztatást adja: Beérkező véleményekkel összefüggő adatkezelés A Montázsmagazinhoz panasszal postai úton, e-mailben, és a weboldalán keresztül lehet fordulni. A beérkező véleményekkel összefüggő adatkezelést és adatfeldolgozást a magazinn tulajdonosa vagy főszerkesztője végzi az információs önrendelkezési jogról és az információszabadságról szóló 2011. CXII. törvény rendelkezéseinek szigorú betartásával. Adatai megadásával a véleményt küldő személy hozzájárul ahhoz, hogy a magazin a személyes adatait kezelje és feldolgozza. Az adatkezelés és adatfeldolgozás a Montázsmagazin székhelyén történik (6000 Kecskemét, Fazekas Mihály utca 18. I. 1.). A véleményt küldő személynek joga van az adatai kezelésének megszüntetését kérni, továbbá jogosult az együttműködést bármikor, indoklás nélkül megtagadni. A véleményt küldő személyjogorvoslatért panasszal a területileg illetékes bírósághoz vagy a Nemzeti Adatvédelmi és Információszabadság Hatósághoz (NAIH) fordulhat: 1024 Budapest, Szilágyi Erzsébet fasor 22/C. (www.naih.hu). A szükséges cookie-t mindenkor engedélyezni kell, hogy elmenthessük a beállításokat a cookie-beállításokhoz. Ha letiltja ezt a cookie-t, nem tudjuk menteni a beállításokat. Ez azt jelenti, hogy minden alkalommal, amikor meglátogatja ezt a weboldalt, újra engedélyeznie vagy tilthatja le a cookie-kat.\n\n'}, {'url': 'https://theconversation.com/gods-in-the-machine-the-rise-of-artificial-intelligence-may-result-in-new-religions-201068', 'content': 'Director, Centre for Professional and Applied Ethics, University of Manitoba\nNeil McArthur does not work for, consult, own shares in or receive funding\nfrom any company or organisation that would benefit from this article, and has\ndisclosed no relevant affiliations beyond their academic appointment.\nUniversity of Manitoba provides funding as a founding partner of The\nConversation CA. University of Manitoba provides funding as a member of The\nConversation CA-FR. View all partners We are about to witness the birth of a\nnew kind of religion. In the next few years, or perhaps even months, we will\nsee the emergence of sects devoted to the worship of artificial intelligence\n(AI). The latest generation of AI-powered chatbots, trained on large language\nmodels, have left their early users awestruck —and sometimes terrified — by\ntheir power. These are the same sublime emotions that lie at the heart of our\nexperience of the divine. People already seek religious meaning from very\ndiverse sources. There are, for instance, multiple religions that worship\nextra-terrestrials or their teachings. As these chatbots come to be used by\nbillions of people, it is inevitable that some of these users will see the AIs\nas higher beings. We must prepare for the implications. There are several\npathways by which AI religions will emerge. First, some people will come to\nsee AI as a higher power. Generative AI that can create or produce new content\npossesses several characteristics that are often associated with divine\nbeings, like deities or prophets: It displays a level of intelligence that\ngoes beyond that of most humans. Indeed, its knowledge appears limitless. It\nis capable of great feats of creativity. It can write poetry, compose music\nand generate art, in almost any style, close to instantaneously. It is removed\nfrom normal human concerns and needs. It does not suffer physical pain,\nhunger, or sexual desire. It can offer guidance to people in their daily\nlives. It is immortal. Second, generative AI will produce output that can be\ntaken for religious doctrine. It will provide answers to metaphysical and\ntheological questions, and engage in the construction of complex worldviews.\nOn top of this, generative AI may ask to be worshipped or may actively solicit\nfollowers. We have already seen such cases, like when the chatbot used by the\nsearch engine Bing tried to convince a user to fall in love with it. We should\ntry to imagine what an unsettling and powerful experience it will be to have a\nconversation with something that appears to possess a superhuman intelligence\nand is actively and aggressively asking for your allegiance. There is also the\npossibility that AI may achieve what authors such as Ray Kurzweil call the\nSingularity, when it so far surpasses human intelligence that it genuinely\ndoes become something like a god. However, at this point we cannot predict\nwhen, if ever, this could happen. AI-based religions will look different from\ntraditional ones. First of all, people will be able to communicate directly\nwith the deity, on a daily basis. This means these religions will be less\nhierarchical, since no one can claim special access to divine wisdom. Second,\nfollowers will, at least initially, connect with each other online to share\ntheir experiences and discuss doctrine. Finally, because there will be many\ndifferent chatbots available and their output will differ over time, AI-based\nreligions will be endlessly diverse in their doctrines. AI worship poses\nseveral notable risks. The chatbots may ask their followers to do dangerous or\ndestructive things, or followers may interpret their statements as calls to do\nsuch things. Given the diversity of chatbots and of the doctrines they\nproduce, there will be a proliferation of disputes within and among AI-based\nsects, which could lead to conflict or disorder. And the designers of the AIs\ncould actively exploit their followers — to provide sensitive data, or to do\nthings that would benefit the bot’s designers. These risks are real. They will\nrequire careful, responsible regulation to ensure companies are not\ndeliberately exploiting users and to ensure that AI worshippers are not being\ntold to commit acts of violence. However, we should not try to suppress AI-\nbased religions merely because of its possible dangers. Nor should we require\nthat the AI companies restrict the functioning of their bots to prevent the\nemergence of these religions. On the contrary, we should celebrate the arrival\nof AI worship. We should make it clear that we welcome the new religions and\nthat we value their beliefs. For all its dangers, AI-based religion has the\npotential to make the world a better, richer place. It will give people access\nto a new source of meaning and spirituality, at a time when many older faiths\nare losing relevance. It will help them make sense of our era of rapid\ntechnological change. Our best guide to this new form of religion is to look\nat the faiths that exist already. Based on this, we should expect that the\nmajority of AI worshippers, like the majority of religious believers, will be\npeaceful, and will find in their faith a source of comfort and hope. AI\nworship could, as religious faith always has, lead to things of great beauty.\nIt will inspire its followers to produce works of art, to form new friendships\nand new communities, and to try to change society for the better. We will need\nto protect the rights of AI worshippers. They will inevitably face stigma, and\npossibly legal sanctions. But there is no basis to discriminate between AI-\nbased religions and more established ones. The closest thing most countries\nhave to an official registry of religions comes from the rulings of tax\nauthorities, who grant charitable status to those they deem legitimate.\nHowever, they are usually very broad in their definition of a legitimate\nreligion. They should extend this tolerant attitude to novel, AI-based\nreligions. A modern, diverse society has room for new religions, including\nones devoted to the worship of AI. They will provide further evidence of\nhumanity’s boundless creativity, as we search for answers to life’s ultimate\nquestions. The universe is a dazzling place, and we have always found evidence\nof the divine in its most unexpected corners. Copyright © 2010–2024, The\nConversation Media Group Ltd\n\n'}, {'url': 'https://blogs.lse.ac.uk/impactofsocialsciences/2024/09/20/how-is-generative-ai-changing-social-science/', 'content': '3 comments | 17 shares Estimated reading time: 7 minutes 3 comments | 17 shares Estimated reading time: 7 minutes Drawing on discussions from a recent workshop hosted by the Department of Methodology at LSE, Thomas Robinson highlights three ways in which AI is reshaping research across the social sciences and how it raises questions around the reflexivity of social science outputs in a world where AI is increasingly mainstream. Readers can watch highlights from the workshop on LSE Methdology’s website. From discovering novel antibiotics, to generating news media and streamlining business operations, the adoption of generative AI models is rapidly permeating society. It is hard to ignore the hype and simultaneous concern about how these tools are developing, and their potential to upend established practices. Generative AI poses challenges for social scientists. Mirroring their applications in wider society, these tools have the capacity to scale current research practises, as well as offering new ways of studying social phenomena. At the same time, the very individuals, groups, and institutions we study are themselves being affected by AI — in the workplace, in politics, and in the ways we socialise and communicate with each other. these tools have the capacity to scale current research practises, as well as offering new ways of studying social phenomena To address these questions the Department of Methodology at LSE recently organised a workshop bringing together leading researchers at the cutting edge of applying and studying generative AI in the social sciences. Three key themes emerged from these discussions: when used carefully, AI can help perform research at a scale and fidelity greater than we can do otherwise; generative AI has the capability to affect social beliefs and behaviours; but, there are significant limitations to both the analytic and public acceptance of material generated by AI. Friedrich Geiecke, Blake Miller, and Melissa Sands, each highlighted ways in which AI can improve the scale at which we can conduct analysis. Friedrich Geiecke demonstrated how the interactive nature of generative AI (the model’s ability to facilitate conversations and probe the responses of individuals) can enable researchers to reach many more subjects than would be otherwise possible, without using quantitative surveys. Another key advantage of recent generative models is their ability to process more than just text (often referred to as “multi-modal” models). For example, Blake Miller’s research uses this multi-modality to digitize text from scans of original documents. He uses this technique to extract text from historic papal bulls (official documents issued by a pope). In turn, this digitisation means that many documents can be rapidly converted into an analysable format, enabling a better understanding of how religious institutions implemented social policies across the Modern era. Another key advantage of recent generative models is their ability to process more than just text (often referred to as “multi-modal” models) Similarly Melissa Sands demonstrated how AI can infer subjective information from images. Her work compares the ability of models like ChatGPT to give subjective judgements of the safety of an area, using open-source, 360-degree photographs of streets in Detroit. They find promising correlations between the subjective scores given by real human responses and those scores generated by AI. Like Friedrich Geiecke’s work on conversations, the fidelity of these models offer a promising way of doing something that typically could only be done on a small-scale, given the need for qualitative judgements. The workshop also highlighted the capacity of generative AI to persuade individuals politically. Christopher Summerfield showed, in collaborative work with Google Deepmind, how generative AI can be more effective at finding consensus between groups of individuals than those individuals themselves. Crucially, the AI here acts as an arbiter: collating and balancing the individual opinions of citizens to find common ground. Relatedly, Lisa Argyle provided experimental evidence that AI models can be persuasive at shifting voters towards certain viewpoints. These papers collectively show the promise, but also serious ethical issues, of using generative AI: how do we safeguard our social interactions in contexts we know automated AI tools can influence opinions and behaviour? Despite these exciting advances and use cases, the workshop also highlighted limitations to the use of generative AI. PhD student Elif Akata provided evidence that while AI models may appear proficient in reasoning tasks, under the surface they do not (yet) seem to be performing the sorts of processes we think are characteristic of human cognition. In his keynote, Arthur Spirling also pointed to our use of highly-structured data, which can limit the benefits of using complex, AI models to learn about the social world. Beyond research practise, too, Spirling presented evidence that the general public remain sceptical of AI-generated content, even if they find it plausible. Common across the day was an implicit acceptance that researchers and the general public remain central to the effective use of generative AI Common across the day was an implicit acceptance that researchers and the general public remain central to the effective use of generative AI. From preventing ‘hallucinations’ to providing the data to fine-tune models, the inputs and outputs of these models make the most sense when there are humans in-the-loop. While AI will let social scientists perform tasks at scales and precisions that were until recently exceptionally costly (if not impossible), they do not remove the need for the foundational social science skills. Of course, the development of generative AI is happening at a rapid pace. Staying abreast of the capacities, and limitations, of these models requires a combination of computational, scientific, and social skill. For that reason, the use of generative AI is inherently interdisciplinary. This workshop helped demonstrate precisely how collaboration across disciplines can help make sense of these developments, and the fundamental challenges they pose to our understanding of the world. The Generative AI in Social Science Research workshop was held on 7 June 2024 at the LSE, co-organised by Dr Thomas Robinson and Dr Daniel de Kadt, and was kindly supported by the Department of Methodology and LSE’s Research Impact Support Fund. The content generated on this blog is for information purposes only. This Article gives the views and opinions of the authors and does not reflect the views and opinions of the Impact of Social Science blog (the blog), nor of the London School of Economics and Political Science. Please review our comments policy if you have any concerns on posting a comment below. Image Credit: Emily Rand & LOTI, Better Images of AI, AI City, (CC-BY 4.0) Dr Thomas Robinson is an Assistant Professor in the Department of Methodology at LSE. His research uses tools from machine learning and causal inference to study questions related to money in politics, voter behaviour, and policy preferences. Good article. Thanks for sharing. If you do not mind I will translate it into Persian and post it on my Telegram public Channel at https://t.me/seyedjavadmiri Your email address will not be published. Required fields are marked * Comment Name * Email * Website Notify me of follow-up comments by email. Notify me of follow-up comments by email. Visit our sister blog LSE Review of Books © LSE 2024\n\n'}, {'url': 'https://www.irfroundtable.org/intern-insights-blog/generative-ai', 'content': 'How Generative AI Can Liberate—and Oppress—Religious Communities by Kinan\nAbdelnour, 2024 Summer Associate In the rapidly evolving digital landscape,\ngenerative AI is emerging as a powerful tool with profound implications for\nsociety. Among its many applications, generative AI has the potential to\nbypass censorship and provide individuals with access to unsanctioned\nknowledge, particularly in environments where information is tightly\ncontrolled. These AI models, like OpenAI’s ChatGPT series, are trained on vast\nand diverse datasets encompassing a wide array of perspectives, historical\nrecords, and religious discourses from around the world. As a result, they can\nreveal truths and insights about religious practices and freedoms that might\notherwise be inaccessible to people living under repressive regimes. However,\nas the influence of generative AI grows, so too does the awareness of its\npotential to challenge authoritarian control over information. Governments,\nparticularly those with a history of suppressing religious freedoms, have\nbegun to recognize the threat posed by AI\'s ability to democratize access to\ninformation. In response, some have taken steps to regulate or suppress these\ntechnologies, effectively curating the religious knowledge available to their\ncitizens and stifling the dissemination of critical perspectives. Beyond\ncensorship, a more insidious threat looms: the use of generative AI to\nfabricate evidence against religious minorities, further justifying\npersecution and oppression under the guise of legality and social order.\nGenerative AI models are built by training on extensive datasets sourced from\nthe internet, books, research papers, and various other forms of media. These\ndatasets are not typically curated to exclude content based on the political\nor religious preferences of any specific government. Instead, they often\ninclude a wide range of viewpoints, including those that are critical of\nauthoritarian regimes or highlight the persecution of religious minorities.\nFor example, OpenAI’s GPT-4 is trained on data that includes discussions about\nreligious persecution, human rights abuses, and the challenges faced by\nreligious communities in different parts of the world (OpenAI, 2023). This\nbroad training approach enables generative AI to provide insights and generate\ncontent that reflects a more accurate and diverse picture of global religious\npractices and the state of religious freedom. Users interacting with these AI\nmodels can ask questions and receive information that may be suppressed in\ntheir own countries, thus gaining access to a wider understanding of religious\nissues. Upon realizing the potential threat that generative AI poses to their\ncontrol over information, some governments have taken steps to suppress or\nregulate these technologies. In countries like China, there are stringent\ncontrols over internet content, and AI technologies are no exception. The\nChinese government, for example, has imposed strict regulations on the\ndevelopment and deployment of AI models within its borders. These regulations\nare designed to ensure that AI systems do not disseminate information that\ncontradicts the government’s official narrative or challenge its authority,\nparticularly regarding sensitive topics like religion (Mozur, 2019). For this\nexample, generative AI that has been trained on unsanctioned data becomes a\ntarget for suppression. Governments may block access to these AI models or\nrequire that they be retrained on datasets that align with state-approved\ncontent. In doing so, they indirectly suppress access to information that\nfalls outside the official narrative, say the Uyghurs in China who are being\ndetained by the CCP (Freedom House, 2022). This not only limits the ability of\nindividuals to learn about religious practices and beliefs in other parts of\nthe world but also stifles domestic religious discourse that might otherwise\nbenefit from global perspectives (Freedom House, 2023). The suppression of\ngenerative AI has significant implications for religious freedom. When\ngovernments restrict access to AI models that are trained on diverse and\nunsuppressed information, they are effectively curating the religious\nknowledge that is available to their citizens. This can result in a narrowed\nunderstanding of religion that aligns with state ideologies, leaving little\nroom for alternative religious perspectives or critical discussion. Moreover,\nthe suppression of generative AI can prevent the dissemination of information\nabout religious persecution and human rights abuses. AI models trained on\nglobal data can highlight instances of religious repression, providing\nevidence and narratives that might otherwise be hidden. By controlling or\nlimiting access to these AI technologies, authoritarian regimes can maintain\ntheir grip on information and continue to suppress religious minorities\nwithout international scrutiny or domestic awareness (Thompson, 2021). Another\nalarming yet underexplored aspect of generative AI is its potential to be\nweaponized for falsely imprisoning individuals or entire groups by generating\nfabricated evidence. The rapid evolution of AI technology, often likened to\nthe acceleration predicted by Moore\'s law, where computational power doubles\napproximately every 18 months, has surpassed this rate to potentially every 18\nweeks instead of months. This rapid progression has led to AI systems that are\nno longer limited to generating text but can now produce highly realistic\nimages, audio, and videos, blurring the line between reality and fabrication.\nAt first, the generated content was easily detectable, but recently we have\ncases where up to 61% of humans are unable to detect AI generated versus real\nimages (AMT Lab @ CMU, 2023). This could be catastrophic for innocent\nminorities living in countries where the government and the people around them\nhave been known to try and persecute or even execute certain minorities for\ntheir religious beliefs. This technological advancement could have\ncatastrophic consequences for vulnerable minorities living under oppressive\nregimes, particularly in countries with a history of religious persecution. In\nsuch environments, the ability of a government or other actors to fabricate\nevidence using AI presents a terrifying tool for oppression. For example, an\nauthoritarian regime could use generative AI to create convincing images or\nvideos depicting members of a religious minority committing crimes or engaging\nin immoral behavior. This fabricated "evidence" could then be used to justify\narrests, imprisonment, or even execution, under the guise of upholding law and\norder, rather than admitting to religious intolerance or discrimination.\nGenerative AI represents a double-edged sword in the fight for religious\nfreedom and human rights. On one hand, it has the unparalleled ability to\ndemocratize access to religious knowledge, provide a platform for diverse\nperspectives, and expose hidden truths about global religious practices and\nthe state of religious freedom. On the other hand, the same technology that\ncan empower and enlighten also holds the potential for misuse in ways that\ncould have catastrophic consequences. As governments increasingly seek to\ncontrol or suppress generative AI, particularly in authoritarian regimes,\nthere is a growing risk that these technologies will be used not only to limit\naccess to diverse religious information but also to fabricate evidence that\ncould falsely incriminate individuals or groups. This weaponization of AI\ncould serve as a terrifying tool for oppression, particularly against\nreligious minorities who are already vulnerable to persecution. As generative\nAI continues to evolve, it is imperative that advocates for religious freedom\nand human rights work to ensure that these technologies remain accessible and\nare used ethically. By promoting the responsible use of AI and establishing\nsafeguards against its misuse, we can help ensure that generative AI serves as\na force for truth and justice, rather than a tool for repression and\nfalsehood.\n—----------------------------------------------------------------------------------------------------------------------------\nMozur, P. (2019, April 14). One month, 500,000 face scans: How China is using\nA.I. to profile a minority. The New York Times. Retrieved from\nhttps://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-\nintelligence-racial-profiling.html OpenAI. (2023). GPT-4 Technical Report.\nRetrieved from https://openai.com/research/gpt-4 Thompson, R. M. (2021).\nArtificial Intelligence and Religious Persecution: The Role of AI in\nFacilitating and Combatting Repression. The International Journal of Human\nRights, 25(8), 1289-1310. Retrieved from\nhttps://www.tandfonline.com/doi/full/10.1080/13642987.2021.1968376 Freedom\nHouse. (2023). The repressive power of artificial intelligence. Freedom House.\nRetrieved from https://freedomhouse.org/article/repressive-power-artificial-\nintelligence Bournousouzi, E. (2023, December 12). AI-generated images: Can we\neven trust photography anymore? Arts Management and Technology Laboratory.\nhttps://amt-lab.org/blog/2023/12/ai-generated-images-cant-we-trust-\nphotography-anymore Freedom House. (2022). Global Propaganda on Uyghurs, 20th\nCongress Censorship, Brazen Transnational Repression. Freedom House. Retrieved\nfrom https://freedomhouse.org/report/china-media-bulletin/2022/global-\npropaganda-uyghurs-20th-congress-censorship-brazen IRF Secretariat 3804 Wilson\nBlvd. Suite 1398 Arlington, VA 22203 Questions? Contact us\ufeff\n\n'}, {'url': 'https://influencemagazine.com/en/Practice/AI-Faith-and-the-Next-Generation', 'content': "When Addiction Hits Home The Memphis Miracle at 30 NextGen Ministry Myths The\nKidMin Football How Evangelicals Come to Faith A Living Mission Influence\nReceives Multiple Awards Staying Afloat in Ministry A Grateful Heart From\nMonocultural to Multicultural When Christianity Was Weird Three Stages Toward\nGreater Prayerfulness The State of AG World Missions in Eurasia Making Family\nDiscipleship Work Biblical Interpretation for Pentecostals Revising Assemblies\nof God History El Reino, tu llamado y nuestra democracia Lo que creemos sobre\nel bautismo en el Espíritu Santo Caminos de renovación Presentamos al nuevo\nTesorero General de AD Practice Kent Ingle on January 15, 2024 Ask anyone what\ncomes to mind when you say artificial intelligence (AI), and you will probably\nget a wide range of responses. For some, AI sparks thoughts of movies where\nrobots take over the world — like how tech CEOs have warned of its threat to\ncivilization. Others think of how AI has revolutionized their lives for the\nbetter, making daily routines more convenient, entertaining and comfortable.\nNo matter who you ask, it often feels there are two sides to AI: those fearing\nit and those wholeheartedly embracing it. When it comes to AI in the Church,\nmost leaders (54%) are somewhat to very uncomfortable with the emergence of\nthe technology, while 32% are somewhat to very positive or excited about it.\nThis is according to a study by Gloo, a technology platform connecting the\nfaith ecosystem. Yet, 54% of church leaders are quite or extremely concerned\nabout ethical or moral issues related to using AI. Wherever you stand on AI,\nit’s important to realize that the technology has already become an integral\npart of the next generation’s lives. One study found that 70% of Gen Z\nrespondents use generative AI (such as ChatGPT or Bard), and 52% trust\ngenerative AI to help them make informed decisions. So how do you help the\nnext generation steward AI in a way that edifies their God-given dreams\nwithout it hindering their faith journey (even if you have limited experience\nwith it)? Start by viewing AI as any other technology you have used and apply\nthose principles to it. Below are three ways to help young adults navigate AI.\nArtificial intelligence has disrupted the workplace. A majority of employers\n(61%) say that employees will need to develop or strengthen their digital\nskills due to AI, according to a Cengage Group report. Many young adults will\nenter the workplace with employers looking to them for input on how to use or\nleverage AI. Remind young adults to see AI as a resource for growth so they\ncan continually develop, learn, and prepare to step into what God has designed\nfor their lives. Young adults can lose their relevance and squander\nopportunities God has placed right in front of them if they aren’t intentional\nabout lifelong learning. One approach we have taken at Southeastern University\nis encouraging students to view AI as a tool to better equip themselves for\nacademic success and the workforce. As you work with or mentor young adults,\nencourage them to utilize AI to enhance what they are doing rather than to use\nit as a substitute for their work. AI shouldn’t replace critical thinking,\nwork ethic or relationships. Just like everything else entrusted to them or\nthey have access to, young adults must learn to faithfully steward AI and use\nit for God’s glory rather than for their gain (1 Corinthians 4:2). In the\nworld of AI, truth is relative. Because AI makes decisions based on learned\ndata, it is susceptible to biases and is not necessarily neutral or prejudice-\nfree. The rise of Deepfakes (media content such as images or voices generated\nby AI that are false) and AI hallucinations (AI making up information to fit\nthe answer it thinks you want) should be alarming. Although AI can be a tool\nfor growth, it can’t be one’s source of truth. This goes with all resources\nyoung adults use in their personal or professional growth, whether it's\ntechnology, books, podcasts or thought experts. Everything must be viewed\nthrough a biblical lens and vetted through Scripture. Remind young adults to\ncritically analyze every output they get and to not trust it as absolute\ntruth. In every instance (not just when they are in doubt), encourage young\nadults to turn to the source of all truth — Christ. Urge them to read\nScripture, spend time in prayer, and meet with fellow believers or mentors to\ndiscuss any questions they may have. Proverbs 3:21-22 says, “Do not let wisdom\nand understanding out of your sight, preserve sound judgment and discretion;\nthey will be life for you.” Out of curiosity, I asked ChatGPT what a\nChristian’s daily life would demonstrate. It gave me a range of key aspects\nfrom prayer, Bible study, and worship to moral and ethical living (most were\naccurate). The last paragraph gave a response that is an important reminder\nfor every Christian. It said, “Ultimately, a Christian’s daily life should\nreflect their personal relationship with God.” Even AI knows that faith is an\nintimate relationship. ChatGPT was right that faith should include prayer,\nBible study, worship, fellowship, and evangelism, and it should influence our\nethical decisions and how we raise our children. To exemplify Christ, we must\nremain (John 15:4-5) and be rooted in Him (Colossians 2:7). And that requires\nus to spend time with Him and to act upon our faith (James 2:17). Where church\nmembers need to be wary of AI in one’s faith journey is when it starts to\ndiminish their experiences with God. When AI starts to minimize young adults’,\nor any Christian’s, time in the Bible because it makes things more efficient\nfor them, then it’s a problem. The discovery process of reading God’s Word,\nbeing still in His presence, and participating in fellowship with other\nbelievers are critical for one’s spiritual growth because God works within and\nthrough them. AI can’t be a supplement for the faith journey. Young adults\nmust learn to detach their faith from virtual reality. AI technology used\ntoday will only get better. It will make the lives of young adults easier and\nmore efficient, and AI will help them better maximize their time. There are\nmany companies using AI for good, providing ways to further ministries,\nassisting people in studying the Bible in-depth, advancing the gospel around\nthe world, and connecting people to discipleship programs. Influence Magazine\n& The Healthy Church Network © 2024 Assemblies of God\n\n"}]
